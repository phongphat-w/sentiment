{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### @author: Phongphat Wiwatthanasetthakarn   @create: 2020-04-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main sentiment analysis process\n",
    "### Reduce features and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\os\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\os\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\os\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\os\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nlp_process as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_sentiment as sta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_name_list = [\"ramathibodi-hospital\", \"siriraj-hospital\", \"king-chulalongkorn-memorial-hospital\", \"bangkok-hospital\"]\n",
    "hosp_name_abb = [\"rama\", \"siri\", \"chula\", \"bdms\"]\n",
    "\n",
    "#hosp_name_list = [\"ramathibodi-hospital\"]\n",
    "#hosp_name_abb = [\"rama\"]\n",
    "\n",
    "sta_hosp = {}\n",
    "\n",
    "#Constant configuration\n",
    "mode_nlp = \"nlp\"\n",
    "mode_model = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:00<00:00, 35102.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====================================================\n",
      "\n",
      "Hospital name: ramathibodi-hospital\n",
      "\n",
      "====================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      ">>>>> Step: Read data for NLP process <<<<<\n",
      "\n",
      " load_dataset() is activated...\n",
      "\n",
      "\n",
      ">> Positive and negative dataset:\n",
      "     score                                                 en  polarity\n",
      "0        5  Had tried the part-time clinic service at the ...         1\n",
      "1        4  I've been to Lasik here. Very good. Now, after...         1\n",
      "2        5  Healed many years since age 14 This is a bache...         1\n",
      "4        4  Its a public hospital so service is bad (nurse...         1\n",
      "5        5  My friend has a lung disease, lung leak. The d...         1\n",
      "..     ...                                                ...       ...\n",
      "219      5  The service is very clean, the doctor asks all...         1\n",
      "220      5                                  Very good service         1\n",
      "221      4  Quite a lot of patients, causing the service t...         1\n",
      "222      1  Waiting from 9 o'clock in the morning to noon ...         0\n",
      "223      5  Dr. Keng gave detailed and clear advice. Moder...         1\n",
      "\n",
      "[210 rows x 3 columns]\n",
      "\n",
      ">> Positive dataset:\n",
      "     score                                                 en  polarity\n",
      "0        5  Had tried the part-time clinic service at the ...         1\n",
      "1        4  I've been to Lasik here. Very good. Now, after...         1\n",
      "2        5  Healed many years since age 14 This is a bache...         1\n",
      "4        4  Its a public hospital so service is bad (nurse...         1\n",
      "5        5  My friend has a lung disease, lung leak. The d...         1\n",
      "..     ...                                                ...       ...\n",
      "218      5  The doctors and nurses were very attentive and...         1\n",
      "219      5  The service is very clean, the doctor asks all...         1\n",
      "220      5                                  Very good service         1\n",
      "221      4  Quite a lot of patients, causing the service t...         1\n",
      "223      5  Dr. Keng gave detailed and clear advice. Moder...         1\n",
      "\n",
      "[164 rows x 3 columns]\n",
      "\n",
      ">> Negative dataset:\n",
      "     score                                                 en  polarity\n",
      "38       2  Went to have an appointment and had palpitatio...         0\n",
      "50       1  Division # Benefits, Service recipients on the...         0\n",
      "55       2  Come to disburse directly to Grandma to submit...         0\n",
      "60       1  Emergency department on June 24, 2016. Father ...         0\n",
      "64       1  Treatment is OK. But parking issues should be ...         0\n",
      "67       1  Uncle aches. I asked to pay first. There shoul...         0\n",
      "68       1                                 My father is sick.         0\n",
      "69       1  Many nurses are good and bad. Especially the r...         0\n",
      "71       2  Go to the Ear, Nose and Throat Special Clinic....         0\n",
      "72       2  Both being a leading hospital in terms of trea...         0\n",
      "75       1  The shoulders fell off and there was no xray. ...         0\n",
      "76       1  The nurse here talked a lot. I told him. I was...         0\n",
      "81       1  The nurse here spoke very badly. I said it. I ...         0\n",
      "89       1  The word emergency room, doctors and nurses mu...         0\n",
      "90       1                Poor service, especially for nurses         0\n",
      "93       1  No one said anything. How to contact? Poor man...         0\n",
      "94       1  Excellent dentistry. The doctor and the nurse ...         0\n",
      "95       2               Improve the nursing services as well         0\n",
      "96       1  Really don't want to give a star Nurse, dog-ma...         0\n",
      "102      1  Meaning understand that many patients But this...         0\n",
      "104      1  Nurses, Screening Unit, Accident and Emergency...         0\n",
      "105      1  End of the line 022004249 I didn't know how to...         0\n",
      "107      1  Learn to receive employees who have a toe at t...         0\n",
      "109      1  Blood Drawing Room, 1st Floor, Phra Thep Nang ...         0\n",
      "117      1  Terrible, rhythmic, delayed work, patients go ...         0\n",
      "121      1  The system sucks after the appointment and hel...         0\n",
      "123      1  Very bad about parking. The hospital invested ...         0\n",
      "125      1  The aunt nurse is a little old. Ear, nose and ...         0\n",
      "126      1  Waiting for medication for a long time. Poor m...         0\n",
      "127      1  Waiting to give birth at Rama Hospital With Dr...         0\n",
      "135      1         Very bad service, a lot of responsibility.         0\n",
      "137      1  Complain. Dr. Pan, Achan Pimchai Niphaklak, fo...         0\n",
      "143      1  It's my first time here. Come to receive medic...         0\n",
      "144      1  Staff at the new building, card room, date 8-0...         0\n",
      "147      1  If waiting for this medicine for too long Can ...         0\n",
      "155      1       Is a hospital that sucks Poor working system         0\n",
      "156      2  I am a relative of the patients from the provi...         0\n",
      "159      1  I want to contact the direct disbursement depa...         0\n",
      "165      1  Requesting a mass mouth shut to monitor tuberc...         0\n",
      "173      2  Today, come to see a doctor, see 2 doctors. Bu...         0\n",
      "179      1  Improve your speech. Terrible, female nurses. ...         0\n",
      "187      1  Afternoon appointment at 2 pm has not entered ...         0\n",
      "199      1  Take her to the ER at Ramathibodi hospital. Th...         0\n",
      "202      1  Many years ago I took Ama to do eye treatment ...         0\n",
      "211      2  With a long sound beam And with close people a...         0\n",
      "222      1  Waiting from 9 o'clock in the morning to noon ...         0\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 210\n",
      "Positive = 164\n",
      "Nagative = 46\n",
      "\n",
      "Dataframe size\n",
      "(210, 3)\n",
      "\n",
      " up_sample() is activated...\n",
      "\n",
      "\n",
      "Dataset after up sample\n",
      "\n",
      "     score                                                 en  polarity\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0\n",
      "1        5  It is a public hospital that offers a modern a...         1\n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0\n",
      "3        4  Good service, first time coming to Ramathibodi...         1\n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0\n",
      "..     ...                                                ...       ...\n",
      "323      4  Doctors and nurses are very professional. Able...         1\n",
      "324      1  The word emergency room, doctors and nurses mu...         0\n",
      "325      1  Learn to receive employees who have a toe at t...         0\n",
      "326      2  Went to have an appointment and had palpitatio...         0\n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0\n",
      "\n",
      "[328 rows x 3 columns]\n",
      "\n",
      "Dataset after up sample group by class\n",
      "\n",
      "1    164\n",
      "0    164\n",
      "Name: polarity, dtype: int64\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 328\n",
      "Positive = 164\n",
      "Nagative = 164\n",
      "\n",
      "Dataframe size\n",
      "(328, 3)\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert sentense to token <<<<<\n",
      "\n",
      " gen_token() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:00<00:00, 2003.69it/s]\n",
      "100%|██████████| 328/328 [00:00<00:00, 29907.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0   \n",
      "1        5  It is a public hospital that offers a modern a...         1   \n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0   \n",
      "3        4  Good service, first time coming to Ramathibodi...         1   \n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0   \n",
      "..     ...                                                ...       ...   \n",
      "323      4  Doctors and nurses are very professional. Able...         1   \n",
      "324      1  The word emergency room, doctors and nurses mu...         0   \n",
      "325      1  Learn to receive employees who have a toe at t...         0   \n",
      "326      2  Went to have an appointment and had palpitatio...         0   \n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0   \n",
      "\n",
      "                                                 token  \n",
      "0    [Nurses, ,, Screening, Unit, ,, Accident, and,...  \n",
      "1    [It, is, a, public, hospital, that, offers, a,...  \n",
      "2    [Afternoon, appointment, at, 2, pm, has, not, ...  \n",
      "3    [Good, service, ,, first, time, coming, to, Ra...  \n",
      "4    [Requesting, a, mass, mouth, shut, to, monitor...  \n",
      "..                                                 ...  \n",
      "323  [Doctors, and, nurses, are, very, professional...  \n",
      "324  [The, word, emergency, room, ,, doctors, and, ...  \n",
      "325  [Learn, to, receive, employees, who, have, a, ...  \n",
      "326  [Went, to, have, an, appointment, and, had, pa...  \n",
      "327  [Take, her, to, the, ER, at, Ramathibodi, hosp...  \n",
      "\n",
      "[328 rows x 4 columns]\n",
      "(328, 4)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert text to lowercase <<<<<\n",
      "\n",
      " lowercase_text() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0   \n",
      "1        5  It is a public hospital that offers a modern a...         1   \n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0   \n",
      "3        4  Good service, first time coming to Ramathibodi...         1   \n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0   \n",
      "..     ...                                                ...       ...   \n",
      "323      4  Doctors and nurses are very professional. Able...         1   \n",
      "324      1  The word emergency room, doctors and nurses mu...         0   \n",
      "325      1  Learn to receive employees who have a toe at t...         0   \n",
      "326      2  Went to have an appointment and had palpitatio...         0   \n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Nurses, ,, Screening, Unit, ,, Accident, and,...   \n",
      "1    [It, is, a, public, hospital, that, offers, a,...   \n",
      "2    [Afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [Good, service, ,, first, time, coming, to, Ra...   \n",
      "4    [Requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [Doctors, and, nurses, are, very, professional...   \n",
      "324  [The, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [Learn, to, receive, employees, who, have, a, ...   \n",
      "326  [Went, to, have, an, appointment, and, had, pa...   \n",
      "327  [Take, her, to, the, ER, at, Ramathibodi, hosp...   \n",
      "\n",
      "                                             lowercase  \n",
      "0    [nurses, ,, screening, unit, ,, accident, and,...  \n",
      "1    [it, is, a, public, hospital, that, offers, a,...  \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...  \n",
      "3    [good, service, ,, first, time, coming, to, ra...  \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...  \n",
      "..                                                 ...  \n",
      "323  [doctors, and, nurses, are, very, professional...  \n",
      "324  [the, word, emergency, room, ,, doctors, and, ...  \n",
      "325  [learn, to, receive, employees, who, have, a, ...  \n",
      "326  [went, to, have, an, appointment, and, had, pa...  \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...  \n",
      "\n",
      "[328 rows x 5 columns]\n",
      "(328, 5)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove special character <<<<<\n",
      "\n",
      " remove_spec_char() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0   \n",
      "1        5  It is a public hospital that offers a modern a...         1   \n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0   \n",
      "3        4  Good service, first time coming to Ramathibodi...         1   \n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0   \n",
      "..     ...                                                ...       ...   \n",
      "323      4  Doctors and nurses are very professional. Able...         1   \n",
      "324      1  The word emergency room, doctors and nurses mu...         0   \n",
      "325      1  Learn to receive employees who have a toe at t...         0   \n",
      "326      2  Went to have an appointment and had palpitatio...         0   \n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Nurses, ,, Screening, Unit, ,, Accident, and,...   \n",
      "1    [It, is, a, public, hospital, that, offers, a,...   \n",
      "2    [Afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [Good, service, ,, first, time, coming, to, Ra...   \n",
      "4    [Requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [Doctors, and, nurses, are, very, professional...   \n",
      "324  [The, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [Learn, to, receive, employees, who, have, a, ...   \n",
      "326  [Went, to, have, an, appointment, and, had, pa...   \n",
      "327  [Take, her, to, the, ER, at, Ramathibodi, hosp...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [nurses, ,, screening, unit, ,, accident, and,...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, ,, first, time, coming, to, ra...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                         rem_spec_char  \n",
      "0    [nurses, , screening, unit, , accident, and, e...  \n",
      "1    [it, is, a, public, hospital, that, offers, a,...  \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...  \n",
      "3    [good, service, , first, time, coming, to, ram...  \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...  \n",
      "..                                                 ...  \n",
      "323  [doctors, and, nurses, are, very, professional...  \n",
      "324  [the, word, emergency, room, , doctors, and, n...  \n",
      "325  [learn, to, receive, employees, who, have, a, ...  \n",
      "326  [went, to, have, an, appointment, and, had, pa...  \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...  \n",
      "\n",
      "[328 rows x 6 columns]\n",
      "(328, 6)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word <<<<<\n",
      "\n",
      " remove_stop_word() is activated...\n",
      "\n",
      "\n",
      "stop_words:\n",
      "\n",
      "{'before', 'how', 'on', 'yourself', 'should', 'ours', 'more', 'aren', \"mustn't\", \"shouldn't\", 'no', 'being', \"needn't\", 'myself', 'are', 'too', \"mightn't\", 'o', 'ourselves', 'whom', 'who', 'down', \"should've\", 'from', 'during', 'shan', 'at', 'theirs', 'couldn', 'through', \"you've\", 'again', 'all', 'nor', \"you're\", 'into', 'this', 'weren', \"it's\", 'the', 'yourselves', 'while', 'haven', 'isn', 'themselves', 'why', 'until', 'under', 's', 'hasn', 'because', 'wasn', 'can', 'now', 'doing', 'with', \"don't\", 'my', \"aren't\", 'their', 'both', 'wouldn', 'we', 'in', 'or', 'hadn', 'up', 'by', 'yours', 'few', 'those', 'below', 'll', 'itself', 'and', 'than', 'own', \"that'll\", 'did', 'about', 'mustn', 'once', \"wasn't\", \"won't\", 'ma', 'don', 'some', \"shan't\", 'our', 'won', 'here', \"she's\", 'was', 'has', 'each', 'y', 'they', 'ain', 'is', 've', 'hers', 'such', 'against', 'only', 'above', 'shouldn', \"couldn't\", 'them', 'mightn', 'you', 'had', 't', 'there', 'its', 'any', 'will', 'that', 'a', 'needn', 'me', 'she', 'having', \"haven't\", 'so', 'which', 'for', 'be', 'after', 'further', 'i', 'am', 'most', 'these', 'himself', \"you'd\", 'over', 'just', 'very', \"wouldn't\", \"you'll\", 'were', 'been', 'd', 're', 'does', 'didn', 'as', \"isn't\", 'his', \"hasn't\", 'her', 'not', 'him', 'then', 'doesn', 'he', 'it', \"hadn't\", 'have', 'm', 'where', \"didn't\", 'out', 'other', 'when', 'but', 'your', 'herself', 'an', \"doesn't\", 'if', 'of', 'what', 'do', 'same', 'between', \"weren't\", 'to', 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [01:45<00:00,  3.11it/s]\n",
      "100%|██████████| 328/328 [00:00<00:00, 32813.33it/s]\n",
      "100%|██████████| 328/328 [00:00<00:00, 25221.96it/s]\n",
      "  0%|          | 0/328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0   \n",
      "1        5  It is a public hospital that offers a modern a...         1   \n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0   \n",
      "3        4  Good service, first time coming to Ramathibodi...         1   \n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0   \n",
      "..     ...                                                ...       ...   \n",
      "323      4  Doctors and nurses are very professional. Able...         1   \n",
      "324      1  The word emergency room, doctors and nurses mu...         0   \n",
      "325      1  Learn to receive employees who have a toe at t...         0   \n",
      "326      2  Went to have an appointment and had palpitatio...         0   \n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Nurses, ,, Screening, Unit, ,, Accident, and,...   \n",
      "1    [It, is, a, public, hospital, that, offers, a,...   \n",
      "2    [Afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [Good, service, ,, first, time, coming, to, Ra...   \n",
      "4    [Requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [Doctors, and, nurses, are, very, professional...   \n",
      "324  [The, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [Learn, to, receive, employees, who, have, a, ...   \n",
      "326  [Went, to, have, an, appointment, and, had, pa...   \n",
      "327  [Take, her, to, the, ER, at, Ramathibodi, hosp...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [nurses, ,, screening, unit, ,, accident, and,...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, ,, first, time, coming, to, ra...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [nurses, , screening, unit, , accident, and, e...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, , first, time, coming, to, ram...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, , doctors, and, n...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                             stop_word  \n",
      "0    [nurses, , screening, unit, , accident, emerge...  \n",
      "1    [public, hospital, offers, modern, good, servi...  \n",
      "2    [afternoon, appointment, 2, pm, entered, yet, ...  \n",
      "3    [good, service, , first, time, coming, ramathi...  \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...  \n",
      "..                                                 ...  \n",
      "323  [doctors, nurses, professional, , able, deal, ...  \n",
      "324  [word, emergency, room, , doctors, nurses, mus...  \n",
      "325  [learn, receive, employees, toe, tip, feet, , ...  \n",
      "326  [went, appointment, palpitations, doctor, went...  \n",
      "327  [ramathibodi, hospital, , doctor, inject, colo...  \n",
      "\n",
      "[328 rows x 7 columns]\n",
      "(328, 7)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word (Special) <<<<<\n",
      "\n",
      ">>>>> 've, ``, 's, n't, '', ' ' <<<<<\n",
      "\n",
      " remove_stop_word_spec() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0   \n",
      "1        5  It is a public hospital that offers a modern a...         1   \n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0   \n",
      "3        4  Good service, first time coming to Ramathibodi...         1   \n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0   \n",
      "..     ...                                                ...       ...   \n",
      "323      4  Doctors and nurses are very professional. Able...         1   \n",
      "324      1  The word emergency room, doctors and nurses mu...         0   \n",
      "325      1  Learn to receive employees who have a toe at t...         0   \n",
      "326      2  Went to have an appointment and had palpitatio...         0   \n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Nurses, ,, Screening, Unit, ,, Accident, and,...   \n",
      "1    [It, is, a, public, hospital, that, offers, a,...   \n",
      "2    [Afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [Good, service, ,, first, time, coming, to, Ra...   \n",
      "4    [Requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [Doctors, and, nurses, are, very, professional...   \n",
      "324  [The, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [Learn, to, receive, employees, who, have, a, ...   \n",
      "326  [Went, to, have, an, appointment, and, had, pa...   \n",
      "327  [Take, her, to, the, ER, at, Ramathibodi, hosp...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [nurses, ,, screening, unit, ,, accident, and,...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, ,, first, time, coming, to, ra...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [nurses, , screening, unit, , accident, and, e...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, , first, time, coming, to, ram...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, , doctors, and, n...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [nurses, , screening, unit, , accident, emerge...   \n",
      "1    [public, hospital, offers, modern, good, servi...   \n",
      "2    [afternoon, appointment, 2, pm, entered, yet, ...   \n",
      "3    [good, service, , first, time, coming, ramathi...   \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...   \n",
      "..                                                 ...   \n",
      "323  [doctors, nurses, professional, , able, deal, ...   \n",
      "324  [word, emergency, room, , doctors, nurses, mus...   \n",
      "325  [learn, receive, employees, toe, tip, feet, , ...   \n",
      "326  [went, appointment, palpitations, doctor, went...   \n",
      "327  [ramathibodi, hospital, , doctor, inject, colo...   \n",
      "\n",
      "                                          stop_word_02  \n",
      "0    [nurses, , screening, unit, , accident, emerge...  \n",
      "1    [public, hospital, offers, modern, good, servi...  \n",
      "2    [afternoon, appointment, 2, pm, entered, yet, ...  \n",
      "3    [good, service, , first, time, coming, ramathi...  \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...  \n",
      "..                                                 ...  \n",
      "323  [doctors, nurses, professional, , able, deal, ...  \n",
      "324  [word, emergency, room, , doctors, nurses, mus...  \n",
      "325  [learn, receive, employees, toe, tip, feet, , ...  \n",
      "326  [went, appointment, palpitations, doctor, went...  \n",
      "327  [ramathibodi, hospital, , doctor, inject, colo...  \n",
      "\n",
      "[328 rows x 8 columns]\n",
      "(328, 8)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove single and space token <<<<<\n",
      "\n",
      " remove_single_token() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0   \n",
      "1        5  It is a public hospital that offers a modern a...         1   \n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0   \n",
      "3        4  Good service, first time coming to Ramathibodi...         1   \n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0   \n",
      "..     ...                                                ...       ...   \n",
      "323      4  Doctors and nurses are very professional. Able...         1   \n",
      "324      1  The word emergency room, doctors and nurses mu...         0   \n",
      "325      1  Learn to receive employees who have a toe at t...         0   \n",
      "326      2  Went to have an appointment and had palpitatio...         0   \n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Nurses, ,, Screening, Unit, ,, Accident, and,...   \n",
      "1    [It, is, a, public, hospital, that, offers, a,...   \n",
      "2    [Afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [Good, service, ,, first, time, coming, to, Ra...   \n",
      "4    [Requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [Doctors, and, nurses, are, very, professional...   \n",
      "324  [The, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [Learn, to, receive, employees, who, have, a, ...   \n",
      "326  [Went, to, have, an, appointment, and, had, pa...   \n",
      "327  [Take, her, to, the, ER, at, Ramathibodi, hosp...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [nurses, ,, screening, unit, ,, accident, and,...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, ,, first, time, coming, to, ra...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [nurses, , screening, unit, , accident, and, e...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, , first, time, coming, to, ram...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, , doctors, and, n...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [nurses, , screening, unit, , accident, emerge...   \n",
      "1    [public, hospital, offers, modern, good, servi...   \n",
      "2    [afternoon, appointment, 2, pm, entered, yet, ...   \n",
      "3    [good, service, , first, time, coming, ramathi...   \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...   \n",
      "..                                                 ...   \n",
      "323  [doctors, nurses, professional, , able, deal, ...   \n",
      "324  [word, emergency, room, , doctors, nurses, mus...   \n",
      "325  [learn, receive, employees, toe, tip, feet, , ...   \n",
      "326  [went, appointment, palpitations, doctor, went...   \n",
      "327  [ramathibodi, hospital, , doctor, inject, colo...   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0    [nurses, , screening, unit, , accident, emerge...   \n",
      "1    [public, hospital, offers, modern, good, servi...   \n",
      "2    [afternoon, appointment, 2, pm, entered, yet, ...   \n",
      "3    [good, service, , first, time, coming, ramathi...   \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...   \n",
      "..                                                 ...   \n",
      "323  [doctors, nurses, professional, , able, deal, ...   \n",
      "324  [word, emergency, room, , doctors, nurses, mus...   \n",
      "325  [learn, receive, employees, toe, tip, feet, , ...   \n",
      "326  [went, appointment, palpitations, doctor, went...   \n",
      "327  [ramathibodi, hospital, , doctor, inject, colo...   \n",
      "\n",
      "                                       rem_single_char  \n",
      "0    [nurses, screening, unit, accident, emergency,...  \n",
      "1    [public, hospital, offers, modern, good, servi...  \n",
      "2    [afternoon, appointment, pm, entered, yet, dep...  \n",
      "3    [good, service, first, time, coming, ramathibo...  \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...  \n",
      "..                                                 ...  \n",
      "323  [doctors, nurses, professional, able, deal, im...  \n",
      "324  [word, emergency, room, doctors, nurses, must,...  \n",
      "325  [learn, receive, employees, toe, tip, feet, ta...  \n",
      "326  [went, appointment, palpitations, doctor, went...  \n",
      "327  [ramathibodi, hospital, doctor, inject, color,...  \n",
      "\n",
      "[328 rows x 9 columns]\n",
      "(328, 9)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Normalization (Lemmatization: root word) <<<<<\n",
      "\n",
      " lemmatize_token() is activated...\n",
      "\n",
      "\n",
      "Test POS:\n",
      "\n",
      "This is a book\n",
      "\n",
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('book', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:05<00:00, 61.73it/s]\n",
      "100%|██████████| 328/328 [00:00<00:00, 7144.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1  Nurses, Screening Unit, Accident and Emergency...         0   \n",
      "1        5  It is a public hospital that offers a modern a...         1   \n",
      "2        1  Afternoon appointment at 2 pm has not entered ...         0   \n",
      "3        4  Good service, first time coming to Ramathibodi...         1   \n",
      "4        1  Requesting a mass mouth shut to monitor tuberc...         0   \n",
      "..     ...                                                ...       ...   \n",
      "323      4  Doctors and nurses are very professional. Able...         1   \n",
      "324      1  The word emergency room, doctors and nurses mu...         0   \n",
      "325      1  Learn to receive employees who have a toe at t...         0   \n",
      "326      2  Went to have an appointment and had palpitatio...         0   \n",
      "327      1  Take her to the ER at Ramathibodi hospital. Th...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Nurses, ,, Screening, Unit, ,, Accident, and,...   \n",
      "1    [It, is, a, public, hospital, that, offers, a,...   \n",
      "2    [Afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [Good, service, ,, first, time, coming, to, Ra...   \n",
      "4    [Requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [Doctors, and, nurses, are, very, professional...   \n",
      "324  [The, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [Learn, to, receive, employees, who, have, a, ...   \n",
      "326  [Went, to, have, an, appointment, and, had, pa...   \n",
      "327  [Take, her, to, the, ER, at, Ramathibodi, hosp...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [nurses, ,, screening, unit, ,, accident, and,...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, ,, first, time, coming, to, ra...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, ,, doctors, and, ...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [nurses, , screening, unit, , accident, and, e...   \n",
      "1    [it, is, a, public, hospital, that, offers, a,...   \n",
      "2    [afternoon, appointment, at, 2, pm, has, not, ...   \n",
      "3    [good, service, , first, time, coming, to, ram...   \n",
      "4    [requesting, a, mass, mouth, shut, to, monitor...   \n",
      "..                                                 ...   \n",
      "323  [doctors, and, nurses, are, very, professional...   \n",
      "324  [the, word, emergency, room, , doctors, and, n...   \n",
      "325  [learn, to, receive, employees, who, have, a, ...   \n",
      "326  [went, to, have, an, appointment, and, had, pa...   \n",
      "327  [take, her, to, the, er, at, ramathibodi, hosp...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [nurses, , screening, unit, , accident, emerge...   \n",
      "1    [public, hospital, offers, modern, good, servi...   \n",
      "2    [afternoon, appointment, 2, pm, entered, yet, ...   \n",
      "3    [good, service, , first, time, coming, ramathi...   \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...   \n",
      "..                                                 ...   \n",
      "323  [doctors, nurses, professional, , able, deal, ...   \n",
      "324  [word, emergency, room, , doctors, nurses, mus...   \n",
      "325  [learn, receive, employees, toe, tip, feet, , ...   \n",
      "326  [went, appointment, palpitations, doctor, went...   \n",
      "327  [ramathibodi, hospital, , doctor, inject, colo...   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0    [nurses, , screening, unit, , accident, emerge...   \n",
      "1    [public, hospital, offers, modern, good, servi...   \n",
      "2    [afternoon, appointment, 2, pm, entered, yet, ...   \n",
      "3    [good, service, , first, time, coming, ramathi...   \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...   \n",
      "..                                                 ...   \n",
      "323  [doctors, nurses, professional, , able, deal, ...   \n",
      "324  [word, emergency, room, , doctors, nurses, mus...   \n",
      "325  [learn, receive, employees, toe, tip, feet, , ...   \n",
      "326  [went, appointment, palpitations, doctor, went...   \n",
      "327  [ramathibodi, hospital, , doctor, inject, colo...   \n",
      "\n",
      "                                       rem_single_char  \\\n",
      "0    [nurses, screening, unit, accident, emergency,...   \n",
      "1    [public, hospital, offers, modern, good, servi...   \n",
      "2    [afternoon, appointment, pm, entered, yet, dep...   \n",
      "3    [good, service, first, time, coming, ramathibo...   \n",
      "4    [requesting, mass, mouth, shut, monitor, tuber...   \n",
      "..                                                 ...   \n",
      "323  [doctors, nurses, professional, able, deal, im...   \n",
      "324  [word, emergency, room, doctors, nurses, must,...   \n",
      "325  [learn, receive, employees, toe, tip, feet, ta...   \n",
      "326  [went, appointment, palpitations, doctor, went...   \n",
      "327  [ramathibodi, hospital, doctor, inject, color,...   \n",
      "\n",
      "                                            norm_lemma  \n",
      "0    [nurse, screen, unit, accident, emergency, med...  \n",
      "1    [public, hospital, offer, modern, good, servic...  \n",
      "2    [afternoon, appointment, pm, enter, yet, depar...  \n",
      "3    [good, service, first, time, come, ramathibodi...  \n",
      "4    [request, mass, mouth, shut, monitor, tubercul...  \n",
      "..                                                 ...  \n",
      "323  [doctor, nurse, professional, able, deal, imme...  \n",
      "324  [word, emergency, room, doctor, nurse, must, r...  \n",
      "325  [learn, receive, employee, toe, tip, foot, tal...  \n",
      "326  [go, appointment, palpitation, doctor, go, che...  \n",
      "327  [ramathibodi, hospital, doctor, inject, color,...  \n",
      "\n",
      "[328 rows x 10 columns]\n",
      "(328, 10)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF) <<<<<\n",
      "\n",
      " vec_tf_idf() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 1338\n",
      "\n",
      "\n",
      "\n",
      "['00', '01', '02', '022004249', '0369', '080', '081', '0847355004', '0852108156', '0887436', '0909876767', '10', '100', '11', '12', '13', '14', '15', '16', '1600', '1730', '18', '1800', '1st', '20', '2005', '2015', '2016', '21', '2100', '22', '24', '24hrs', '25', '28', '29', '2nd', '30', '3rd', '4th', '50', '52', '5th', '60', '600', '611', '619', '620', '621', '645', '6th', '730', '75', '78', '7th', '80', '82', '830', '9hrs', '9th', 'abandon', 'abdomen', 'ability', 'able', 'accept', 'acceptable', 'accepted', 'access', 'accident', 'accord', 'accurate', 'ache', 'acne', 'acquire', 'act', 'actually', 'add', 'additionally', 'adithep', 'adjacent', 'admiral', 'admire', 'admit', 'adult', 'advance', 'advice', 'advise', 'aekchol', 'affordable', 'afraid', 'afternoon', 'age', 'agile', 'ago', 'agree', 'air', 'alive', 'allow', 'almost', 'alone', 'along', 'already', 'although', 'always', 'ambiance', 'ambulance', 'amount', 'anandamahidol', 'anesthetic', 'anne', 'announce', 'annoyance', 'annual', 'another', 'answer', 'antenatal', 'anvil', 'anxiety', 'anyone', 'anything', 'anywhere', 'appear', 'appication', 'appointment', 'appreciate', 'appropriate', 'approximately', 'april', 'ard', 'area', 'arm', 'around', 'arrange', 'arrangement', 'arrhythmia', 'arrive', 'arrogant', 'aside', 'ask', 'asks', 'assist', 'assistance', 'assistant', 'athit', 'attach', 'attack', 'attend', 'attention', 'attentive', 'aunt', 'auspicious', 'authentic', 'available', 'aware', 'away', 'baby', 'bachelor', 'back', 'bad', 'badly', 'ball', 'bangkok', 'bank', 'barcode', 'basket', 'beam', 'bearing', 'beautiful', 'beautifully', 'beauty', 'bed', 'bedtime', 'beg', 'begin', 'behind', 'benefit', 'best', 'big', 'bill', 'birth', 'bit', 'bldg', 'bleeding', 'blood', 'blown', 'body', 'bone', 'book', 'bore', 'boring', 'bother', 'box', 'boy', 'brahma', 'brain', 'breastfeeding', 'breathless', 'bring', 'brings', 'broken', 'brother', 'buffalo', 'building', 'business', 'busy', 'butter', 'buy', 'cafeteria', 'call', 'calmly', 'can', 'cancer', 'cant', 'car', 'card', 'care', 'cart', 'case', 'catch', 'cause', 'ccu', 'center', 'cervicalage', 'chai', 'chair', 'chakri', 'change', 'channel', 'character', 'charge', 'chattharat', 'cheap', 'check', 'checked', 'cheerful', 'chest', 'chewy', 'child', 'childhood', 'chlamydia', 'choose', 'chose', 'chronic', 'chula', 'circumstance', 'citizen', 'city', 'clarify', 'class', 'clean', 'clear', 'clearly', 'clinic', 'clock', 'close', 'code', 'collapse', 'collect', 'collection', 'color', 'combine', 'come', 'comfortable', 'comment', 'common', 'communicate', 'communication', 'company', 'compare', 'compassion', 'complain', 'complete', 'completely', 'complex', 'complicate', 'comprehensive', 'computer', 'con', 'concern', 'concerned', 'conclude', 'condition', 'conditioner', 'confidence', 'confident', 'confirm', 'confuse', 'congenital', 'consciousness', 'consider', 'consideration', 'consistent', 'consult', 'consultation', 'contact', 'continue', 'control', 'convenience', 'convenient', 'conveniently', 'conversation', 'cool', 'corps', 'correctly', 'cosmetic', 'cost', 'cotton', 'could', 'couldnt', 'counter', 'country', 'court', 'courteous', 'courtesy', 'crack', 'crazy', 'create', 'crescent', 'cry', 'ct', 'currently', 'customer', 'cut', 'cute', 'cycle', 'cyst', 'damn', 'data', 'date', 'daughter', 'day', 'dead', 'deal', 'death', 'debris', 'dec', 'december', 'decent', 'decide', 'decision', 'deeply', 'definitely', 'degree', 'delayed', 'delicious', 'deliver', 'delivery', 'demonstrate', 'dental', 'dentistry', 'depart', 'department', 'deprave', 'dept', 'deserve', 'despite', 'detail', 'detailed', 'determination', 'determine', 'diabetes', 'diagnose', 'diagnosis', 'different', 'differently', 'difficult', 'digestive', 'digit', 'direct', 'directly', 'disappear', 'disappointed', 'disburse', 'disbursement', 'discard', 'disease', 'disinfectant', 'disorder', 'dispense', 'distinguish', 'distress', 'divert', 'division', 'do', 'doctor', 'document', 'documentation', 'dog', 'donate', 'donation', 'donor', 'dont', 'dr', 'draw', 'dress', 'drip', 'driver', 'drop', 'drug', 'due', 'duty', 'ear', 'early', 'easily', 'easy', 'eat', 'ecg', 'ectopic', 'edit', 'educate', 'education', 'effect', 'elder', 'electronically', 'eloquently', 'else', 'elsewhere', 'emergency', 'emotion', 'emotionally', 'emphasize', 'employee', 'encourage', 'encouragement', 'endoscopy', 'english', 'enough', 'enrage', 'ensure', 'enter', 'entitle', 'entrance', 'environment', 'epilepsy', 'equally', 'equip', 'equipment', 'especially', 'etc', 'ethic', 'eun', 'even', 'event', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'exact', 'examination', 'examine', 'example', 'excellent', 'exceptional', 'exemplary', 'exercise', 'expect', 'expense', 'expensive', 'experience', 'experienced', 'explain', 'extra', 'eye', 'facial', 'facility', 'fact', 'factory', 'faculty', 'fah', 'family', 'famous', 'far', 'fast', 'fasten', 'faster', 'fat', 'father', 'fatty', 'fb', 'feb', 'fee', 'feel', 'feeling', 'fell', 'female', 'fever', 'fibroid', 'fierce', 'fight', 'file', 'fill', 'film', 'finally', 'financial', 'find', 'fine', 'finish', 'firm', 'first', 'fiscal', 'fit', 'fix', 'flavor', 'flaw', 'flick', 'floor', 'follow', 'food', 'foot', 'foreign', 'foreigner', 'forever', 'forget', 'forgive', 'forgot', 'forgotten', 'form', 'forward', 'found', 'foundation', 'free', 'fresh', 'friend', 'friendliness', 'friendly', 'front', 'full', 'fully', 'fund', 'fungus', 'gallbladder', 'gangrene', 'garden', 'gas', 'gauge', 'general', 'generally', 'generous', 'gentle', 'get', 'girl', 'give', 'glass', 'go', 'god', 'good', 'google', 'government', 'governor', 'grandchild', 'grandma', 'great', 'greatly', 'greet', 'grill', 'group', 'grow', 'grown', 'guard', 'guess', 'guest', 'gut', 'guy', 'gynecological', 'gynecology', 'habit', 'half', 'hand', 'handle', 'hang', 'happen', 'happiness', 'happy', 'harassment', 'hard', 'harder', 'hardly', 'head', 'heal', 'health', 'healthy', 'heart', 'heck', 'heel', 'hehe', 'held', 'hell', 'hello', 'help', 'helpgood', 'high', 'hire', 'history', 'hold', 'hom', 'home', 'horrify', 'hospitable', 'hospital', 'hot', 'hotline', 'hour', 'house', 'housekeeper', 'housewife', 'however', 'hr', 'huge', 'hundred', 'hurry', 'hurt', 'ib523', 'icu', 'id', 'illness', 'image', 'imagine', 'immediate', 'immune', 'impressed', 'impression', 'impressive', 'impressively', 'imprint', 'improve', 'improvement', 'inability', 'inbox', 'include', 'increase', 'inexpensive', 'infect', 'infection', 'infirmary', 'inflammation', 'influenza', 'inform', 'information', 'infrequently', 'inject', 'injection', 'inpatient', 'inquire', 'inquiry', 'insert', 'inside', 'inspect', 'inspection', 'instead', 'institute', 'insurance', 'intention', 'interested', 'interior', 'internationally', 'intersection', 'interview', 'invest', 'iq', 'iron', 'issue', 'jammed', 'jaw', 'job', 'join', 'joint', 'june', 'keep', 'keeper', 'keng', 'kg', 'khun', 'kidney', 'kind', 'kindness', 'knew', 'knife', 'know', 'knowledgeable', 'lampang', 'language', 'laotian', 'laparoscopic', 'large', 'laser', 'lasik', 'last', 'late', 'lately', 'later', 'layer', 'lead', 'leak', 'learn', 'leave', 'left', 'leg', 'less', 'let', 'level', 'life', 'like', 'line', 'listen', 'little', 'locate', 'location', 'logical', 'long', 'longer', 'look', 'lopburi', 'lose', 'lot', 'loud', 'love', 'lovely', 'low', 'luck', 'lung', 'machine', 'mah', 'maha', 'maharaj', 'maintain', 'major', 'make', 'male', 'mall', 'man', 'manage', 'management', 'manager', 'manner', 'many', 'marama', 'mark', 'mass', 'match', 'maternity', 'matter', 'may', 'maybe', 'mean', 'meaning', 'medical', 'medication', 'medicine', 'meet', 'member', 'mentally', 'mention', 'merit', 'message', 'middle', 'might', 'milk', 'million', 'mind', 'minute', 'miss', 'misunderstand', 'mm', 'mobile', 'moderate', 'modern', 'moment', 'money', 'monitor', 'month', 'mop', 'morning', 'mother', 'motorcycle', 'mouth', 'move', 'mr', 'mri', 'much', 'mukdahan', 'multiple', 'mum', 'must', 'nail', 'nalay', 'nang', 'nasty', 'natha', 'naughty', 'near', 'nearly', 'neck', 'need', 'neurological', 'neuroscience', 'never', 'new', 'newborn', 'newcomer', 'next', 'ngam', 'nguansaeng', 'nice', 'night', 'nihon', 'nisarak', 'nittasak', 'nobody', 'nook', 'noon', 'normal', 'normally', 'nose', 'nothing', 'notify', 'nov', 'number', 'nurse', 'nursery', 'nursing', 'nutrition', 'observe', 'obstacle', 'obstetrician', 'obstetrics', 'obvious', 'occasional', 'offer', 'offering', 'officer', 'official', 'often', 'oh', 'ok', 'okay', 'old', 'omg', 'online', 'open', 'operate', 'operates', 'operating', 'operation', 'opportunity', 'order', 'organize', 'original', 'orthopedic', 'others', 'otherwise', 'ouk', 'outpatient', 'outside', 'outstanding', 'ovarian', 'overall', 'overtake', 'packed', 'pain', 'painless', 'palpitation', 'parawi', 'parent', 'park', 'parking', 'part', 'pass', 'passing', 'past', 'pat', 'pathway', 'patient', 'pay', 'payment', 'peace', 'pending', 'penicillone', 'people', 'percentage', 'perfect', 'perform', 'period', 'permanent', 'permission', 'person', 'personal', 'personnel', 'phaya', 'phd', 'philanthropist', 'phone', 'phra', 'phsob', 'phu', 'physical', 'physically', 'physiotherapy', 'pick', 'picture', 'pimjai', 'pinpmm27', 'place', 'plan', 'pleasant', 'please', 'plow', 'plus', 'pm', 'point', 'polite', 'politely', 'politeness', 'poor', 'pop', 'position', 'possible', 'post', 'postoperative', 'posture', 'practice', 'prama', 'prathep', 'premium', 'prepare', 'prescription', 'press', 'pressure', 'pretend', 'price', 'princess', 'principle', 'printing', 'private', 'privilege', 'pro', 'probably', 'problem', 'procedure', 'process', 'profession', 'professional', 'professionalism', 'professor', 'proper', 'properly', 'prosper', 'prosperity', 'prosperous', 'prostrate', 'protect', 'protection', 'provide', 'province', 'provincial', 'psychiatric', 'psychological', 'psychology', 'public', 'pull', 'puncture', 'push', 'put', 'quality', 'queue', 'quick', 'quickly', 'quiet', 'quit', 'quite', 'radiologist', 'raja', 'rake', 'ram', 'rama', 'ramathibodi', 'ramathibun', 'ran', 'rational', 'rattanakarn', 'ray', 're', 'read', 'ready', 'realize', 'really', 'reason', 'receipt', 'receive', 'reception', 'recipient', 'recommend', 'reconcile', 'recover', 'recovery', 'recruit', 'recuperate', 'reduce', 'refer', 'referral', 'refuse', 'regardless', 'register', 'registration', 'regular', 'regularly', 'related', 'relation', 'relative', 'remove', 'renew', 'renovation', 'reply', 'repression', 'reputation', 'repute', 'request', 'reservation', 'reserve', 'resign', 'respect', 'respectively', 'respirator', 'responsibility', 'rest', 'restaurant', 'result', 'return', 'revenue', 'review', 'rhythmic', 'rice', 'rich', 'right', 'risk', 'robot', 'room', 'round', 'rub', 'rule', 'sa', 'sacred', 'sacrifice', 'safe', 'sali', 'salty', 'sat', 'sathu', 'save', 'saw', 'say', 'scan', 'scanner', 'scar', 'scary', 'schedule', 'scold', 'screen', 'screw', 'seat', 'second', 'secretly', 'security', 'see', 'seem', 'seizure', 'self', 'sell', 'send', 'sent', 'separate', 'serious', 'seriously', 'serve', 'service', 'seven', 'several', 'severe', 'share', 'sheet', 'shock', 'shoulder', 'show', 'shut', 'sick', 'side', 'sign', 'since', 'sirindhorn', 'siriraj', 'sit', 'size', 'skilled', 'skin', 'slander', 'sleep', 'sloppy', 'slow', 'small', 'smart', 'smile', 'snack', 'snore', 'somdet', 'someone', 'something', 'sometimes', 'somewhat', 'sorry', 'sort', 'sound', 'space', 'spacious', 'speak', 'speaks', 'special', 'specialized', 'specialty', 'specify', 'speech', 'speed', 'spend', 'spicy', 'spill', 'spoke', 'spot', 'spread', 'srisawat', 'stable', 'staff', 'staffed', 'stage', 'stand', 'standard', 'star', 'starbucks', 'start', 'state', 'station', 'stay', 'step', 'stick', 'still', 'stitch', 'stomach', 'stop', 'story', 'stress', 'stressful', 'strictly', 'strong', 'stubborn', 'stuck', 'student', 'study', 'submit', 'suck', 'suffer', 'suggest', 'suggestion', 'sunday', 'supervisor', 'supplement', 'support', 'sure', 'surgery', 'surgical', 'surprise', 'surprisingly', 'survival', 'survive', 'swear', 'swing', 'sympathetic', 'symptom', 'system', 'systematic', 'systematically', 'table', 'take', 'talented', 'talk', 'tasteless', 'tax', 'taxi', 'teach', 'teacher', 'team', 'tear', 'telephone', 'tell', 'ten', 'term', 'terrible', 'test', 'thai', 'thailand', 'thamhongsa', 'thank', 'thankful', 'tharin', 'thatchaphong', 'thats', 'thep', 'thepparat', 'therapy', 'therefore', 'thigh', 'thing', 'think', 'thorough', 'thoroughly', 'thought', 'thousand', 'thread', 'threaten', 'three', 'threw', 'throat', 'throughout', 'thyroid', 'tidy', 'time', 'timely', 'tip', 'tire', 'today', 'toe', 'together', 'told', 'tomorrow', 'tone', 'tongue', 'tonkoon', 'tool', 'top', 'torture', 'training', 'transportation', 'trash', 'travel', 'treat', 'treatment', 'true', 'truly', 'truth', 'try', 'tuberculosis', 'tuna', 'turn', 'twice', 'two', 'ugly', 'ultimate', 'ultrasound', 'uncle', 'undeniably', 'undergo', 'understand', 'underwent', 'unfold', 'unfriendly', 'union', 'unit', 'unruly', 'up', 'update', 'upon', 'upper', 'upset', 'ur', 'urgent', 'use', 'user', 'usual', 'usually', 'uterine', 'vaccine', 'vaginal', 'various', 'verb', 'villager', 'visit', 'vulgar', 'wait', 'waiver', 'waksy', 'walk', 'walkway', 'want', 'ward', 'waste', 'watch', 'water', 'way', 'wear', 'website', 'week', 'weight', 'welcome', 'welfare', 'well', 'whatever', 'wheelchair', 'whenever', 'whether', 'white', 'wife', 'wildcat', 'willing', 'willingly', 'wish', 'within', 'without', 'woman', 'word', 'work', 'worried', 'worry', 'worth', 'would', 'wound', 'wow', 'wrap', 'write', 'writes', 'wrong', 'wv', 'xray', 'yama', 'yeah', 'year', 'yellow', 'yes', 'yesterday', 'yet', 'young', 'zone']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.31037994 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (0, 628)\t0.13634514071302506\n",
      "  (0, 546)\t0.05681670981111562\n",
      "  (0, 940)\t0.13155229699381246\n",
      "  (0, 240)\t0.13634514071302506\n",
      "  (0, 664)\t0.1275000053689807\n",
      "  (0, 1074)\t0.05369210304665279\n",
      "  (0, 958)\t0.11812378406570832\n",
      "  (0, 783)\t0.109278648721664\n",
      "  (0, 735)\t0.07977991528120082\n",
      "  (0, 1258)\t0.20834940485263073\n",
      "  (0, 1292)\t0.13155229699381246\n",
      "  (0, 443)\t0.1275000053689807\n",
      "  (0, 592)\t0.13634514071302506\n",
      "  (0, 733)\t0.13634514071302506\n",
      "  (0, 599)\t0.049510632484365186\n",
      "  (0, 678)\t0.16206390961339914\n",
      "  (0, 318)\t0.1239897506974422\n",
      "  (0, 773)\t0.109278648721664\n",
      "  (0, 1181)\t0.0837305129267028\n",
      "  (0, 878)\t0.07237065140672427\n",
      "  (0, 208)\t0.09622838492184385\n",
      "  (0, 1000)\t0.1239897506974422\n",
      "  (0, 425)\t0.13634514071302506\n",
      "  (0, 265)\t0.13634514071302506\n",
      "  (0, 237)\t0.10417470242631537\n",
      "  :\t:\n",
      "  (326, 449)\t0.12722034374492236\n",
      "  (326, 506)\t0.44026114002563266\n",
      "  (326, 123)\t0.11006528500640816\n",
      "  (326, 1074)\t0.06141261364017539\n",
      "  (326, 1258)\t0.11915422172286064\n",
      "  (326, 384)\t0.06039326677955321\n",
      "  (326, 544)\t0.3153120069341725\n",
      "  (326, 1050)\t0.08225406093474667\n",
      "  (326, 232)\t0.22560122205885494\n",
      "  (326, 818)\t0.05707533765563267\n",
      "  (327, 793)\t0.24742473230613515\n",
      "  (327, 1153)\t0.24252978657207058\n",
      "  (327, 376)\t0.3043337451101337\n",
      "  (327, 55)\t0.3043337451101337\n",
      "  (327, 259)\t0.3043337451101337\n",
      "  (327, 640)\t0.3043337451101337\n",
      "  (327, 579)\t0.229976536498581\n",
      "  (327, 1241)\t0.3980658333374168\n",
      "  (327, 1142)\t0.19690978215626584\n",
      "  (327, 746)\t0.19288975899369984\n",
      "  (327, 975)\t0.20353583024190988\n",
      "  (327, 599)\t0.10595344124710253\n",
      "  (327, 384)\t0.11299466750809875\n",
      "  (327, 1050)\t0.15389580266353914\n",
      "  (327, 872)\t0.3647656446356281\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "ramathibodi-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF), bigrams <<<<<\n",
      "\n",
      " vec_tf_idf_bigram() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 4047\n",
      "\n",
      "\n",
      "\n",
      "['00 easy', '01 60', '02 16', '022004249 know', '0369 imprint', '080 611', '081 0887436', '0852108156 mum', '0887436 fb', '0909876767 anne', '10 clock', '11 food', '12 00', '13 25', '13 digit', '14 bachelor', '14 dec', '15 less', '15 minute', '15 nurse', '15 year', '16 day', '16 go', '1600 hr', '1730 get', '18 01', '1800 hr', '1st building', '1st floor', '20 long', '2005 seriously', '2015 auspicious', '2015 clock', '2015 male', '2015 service', '2016 father', '2016 pro', '21 22', '21 nov', '2100 great', '22 go', '22 year', '24 2016', '24hrs fully', '25 2015', '25 injection', '28 2015', '29 june', '2nd floor', '30 even', '30 less', '30 year', '3rd floor', '4th floor', '50 50', '50 aunt', '52 age', '5th floor', '60 hot', '600 hr', '611 0369', '619 hr', '620 today', '621 hr', '645 saw', '6th floor', '730 need', '75 pro', '78 year', '7th floor', '80 patient', '82 year', '830 12', '9hrs additionally', '9th floor', 'abandon patient', 'abdomen add', 'ability doctor', 'ability system', 'able deal', 'able donate', 'able health', 'accept donation', 'accept quickly', 'accept treatment', 'accepted internationally', 'access premium', 'accident building', 'accident doctor', 'accident emergency', 'accord personal', 'accord rational', 'accurate call', 'accurate diagnosis', 'ache ask', 'ache think', 'acne increase', 'acquire fiscal', 'act even', 'act really', 'actually use', 'add flavor', 'add water', 'add weight', 'additionally call', 'adithep inform', 'adjacent symptom', 'admiral come', 'admire along', 'admire feel', 'admire male', 'admit accident', 'admit cancer', 'admit come', 'admit donor', 'admit rama', 'admit really', 'admit treatment', 'adult although', 'adult department', 'adult read', 'advance doctor', 'advance nurse', 'advice call', 'advice doctor', 'advice explain', 'advice high', 'advice include', 'advice medical', 'advice modern', 'advice nurse', 'advice patient', 'advice well', 'advise elder', 'advise medication', 'aekchol hospital', 'affordable price', 'afraid provincial', 'afraid surgery', 'afternoon appointment', 'afternoon close', 'afternoon go', 'afternoon hurry', 'afternoon minute', 'afternoon reception', 'afternoon right', 'afternoon specify', 'afternoon talk', 'afternoon would', 'age 14', 'age 21', 'age 30', 'age move', 'ago doctor', 'ago service', 'ago take', 'ago underwent', 'agree pay', 'air conditioner', 'alive even', 'alive nothing', 'alive two', 'allow patient', 'almost collapse', 'almost never', 'alone eat', 'along many', 'already ask', 'already dead', 'already found', 'already offer', 'already still', 'already submit', 'already suffer', 'already worried', 'although disease', 'although many', 'although patient', 'although public', 'although today', 'always feel', 'always hand', 'always look', 'always see', 'always tell', 'always think', 'always wait', 'ambiance friendliness', 'ambulance pick', 'amount patient', 'anandamahidol hospital', 'anesthetic drop', 'anne 0852108156', 'announce assistant', 'annoyance yes', 'annual health', 'another month', 'another person', 'answer beam', 'answer call', 'answer doctor', 'answer way', 'answer whatever', 'antenatal clinic', 'antenatal unit', 'anvil doctor', 'anxiety come', 'anyone call', 'anyone know', 'anything contact', 'anything else', 'anything wait', 'anything yet', 'anywhere hang', 'appication check', 'appointment although', 'appointment another', 'appointment help', 'appointment hospital', 'appointment palpitation', 'appointment pm', 'appointment schedule', 'appointment sheet', 'appointment slow', 'appointment system', 'appointment time', 'appointment wait', 'appreciate staff', 'appropriate job', 'appropriate stay', 'approximately minute', 'april 28', 'ard nurse', 'area make', 'arm finally', 'arm thigh', 'around 1800', 'around 2005', 'around front', 'around grill', 'arrange medical', 'arrange often', 'arrange system', 'arrangement good', 'arrhythmia arrhythmia', 'arrhythmia arrive', 'arrive appointment', 'arrive good', 'arrive mr', 'arrogant look', 'aside physical', 'ask 621', 'ask answer', 'ask assistance', 'ask contact', 'ask damn', 'ask enough', 'ask example', 'ask history', 'ask illness', 'ask nurse', 'ask parking', 'ask patient', 'ask pay', 'ask prescription', 'ask sacred', 'ask spoke', 'ask staff', 'ask symptom', 'ask tell', 'ask time', 'ask treat', 'ask wait', 'ask wrong', 'asks donation', 'asks time', 'assist please', 'assistance urgent', 'assistant doctor', 'assistant philanthropist', 'athit admit', 'attach back', 'attach full', 'attack already', 'attend next', 'attention advice', 'attention medical', 'attention patient', 'attention symptom', 'attention throughout', 'attentive attentive', 'attentive clean', 'attentive nurse', 'attentive patient', 'attentive place', 'attentive service', 'aunt aunt', 'aunt condition', 'aunt eun', 'aunt hand', 'aunt lot', 'aunt nurse', 'aunt recover', 'aunt seriously', 'aunt suffer', 'auspicious shock', 'auspicious time', 'authentic good', 'available much', 'aware time', 'away annoyance', 'away stay', 'baby health', 'bachelor degree', 'back ask', 'back definitely', 'back every', 'back give', 'back recuperate', 'back surgery', 'back thank', 'bad 1st', 'bad bad', 'bad day', 'bad debris', 'bad especially', 'bad eye', 'bad first', 'bad friend', 'bad guy', 'bad habit', 'bad high', 'bad housewife', 'bad kg', 'bad nurse', 'bad parking', 'bad people', 'bad receive', 'bad say', 'bad service', 'bad sick', 'bad work', 'badly afternoon', 'badly finally', 'badly like', 'badly lose', 'badly manner', 'badly nurse', 'badly say', 'badly upper', 'badly upset', 'ball spot', 'ball stop', 'bangkok 24hrs', 'bangkok therefore', 'bank 11', 'barcode printing', 'basket like', 'basket nothing', 'beam close', 'beam dr', 'beam pay', 'bearing grandchild', 'beautiful location', 'beautiful nice', 'beautiful surgical', 'beautifully friendly', 'beauty compassion', 'bed beg', 'bed prepare', 'bed push', 'bed relative', 'bed side', 'bedtime infirmary', 'beg beg', 'beg really', 'begin last', 'behind emergency', 'behind schedule', 'benefit service', 'best ability', 'best concerned', 'best government', 'best hospital', 'best probably', 'best psychological', 'big buffalo', 'big hospital', 'big size', 'big toe', 'bill issue', 'birth 620', 'birth newborn', 'birth rama', 'birth surgery', 'birth without', 'bit blood', 'bit love', 'bit scary', 'bldg zone', 'bleeding refuse', 'blood collection', 'blood draw', 'blood drip', 'blood flick', 'blood line', 'blood puncture', 'blown annual', 'body 50', 'body everything', 'body round', 'bone place', 'book surgery', 'bore probably', 'boring doctor', 'boring say', 'bother find', 'box get', 'box say', 'boy currently', 'brahma impressed', 'brain bearing', 'brain big', 'brain see', 'brain well', 'breastfeeding problem', 'bring child', 'bring grandma', 'bring mother', 'bring physical', 'bring recover', 'bring snack', 'brings death', 'broken people', 'brother doctor', 'buffalo act', 'buffalo bad', 'building 20', 'building 5th', 'building 9th', 'building agree', 'building building', 'building card', 'building driver', 'building good', 'building heart', 'building intersection', 'building like', 'building locate', 'building lot', 'building obstetrics', 'building old', 'building sit', 'building take', 'building treatment', 'business hour', 'business well', 'busy time', 'butter doctor', 'buy rice', 'cafeteria buy', 'call 080', 'call ambulance', 'call anything', 'call clarify', 'call consult', 'call medical', 'call number', 'call pat', 'call pending', 'call people', 'call queue', 'call reserve', 'call talk', 'call woman', 'calmly calmly', 'calmly child', 'can tuna', 'cancer month', 'cancer please', 'cancer spread', 'cancer survive', 'cant go', 'cant google', 'cant tell', 'car gas', 'car hospital', 'car like', 'car meaning', 'card change', 'card examination', 'card place', 'card press', 'card recommend', 'card room', 'care everything', 'care patient', 'care well', 'cart swing', 'case need', 'case pay', 'case still', 'case student', 'case surgery', 'catch queue', 'cause day', 'cause fact', 'cause great', 'cause service', 'cause stress', 'ccu every', 'ccu yama', 'center city', 'center currently', 'center good', 'center ramathibodi', 'chai building', 'chair middle', 'chakri sirindhorn', 'change company', 'change morning', 'change position', 'change system', 'channel beg', 'charge normal', 'charge would', 'chattharat srisawat', 'cheap expensive', 'cheap home', 'check appointment', 'check ask', 'check cervicalage', 'check due', 'check ecg', 'check facial', 'check family', 'check film', 'check go', 'check interior', 'check interview', 'check less', 'check nearly', 'check noon', 'check pay', 'check rama', 'check see', 'check take', 'check thoroughly', 'check wait', 'check yellow', 'checked know', 'checked lampang', 'cheerful smile', 'chest increase', 'chewy lot', 'child cause', 'child communicate', 'child day', 'child department', 'child help', 'child hospital', 'child maintain', 'child naughty', 'child open', 'child rama', 'child receive', 'child see', 'child sorry', 'child therefore', 'child well', 'childhood adult', 'chlamydia surgery', 'choose profession', 'chose get', 'chronic illness', 'chula siriraj', 'circumstance happy', 'citizen price', 'city good', 'clarify 0847355004', 'class chattharat', 'clean convenient', 'clean doctor', 'clean good', 'clean location', 'clean many', 'clean modern', 'clean new', 'clean place', 'clean safe', 'clean spacious', 'clean stable', 'clean surgical', 'clear advice', 'clearly service', 'clinic afraid', 'clinic doctor', 'clinic operates', 'clinic premium', 'clinic rama', 'clinic service', 'clinic somdet', 'clinic wait', 'clock afternoon', 'clock cry', 'clock due', 'clock morning', 'close afternoon', 'close box', 'close open', 'close people', 'close pm', 'code ethic', 'collapse medical', 'collect rule', 'collection 1st', 'collection room', 'collection unit', 'collection young', 'color patient', 'combine staff', 'come 14', 'come back', 'come ccu', 'come check', 'come clinic', 'come hospital', 'come look', 'come lose', 'come mark', 'come people', 'come province', 'come rama', 'come ramathibodi', 'come sunday', 'come talk', 'come treat', 'come treatment', 'comfortable feel', 'comfortable tonkoon', 'comment area', 'common room', 'communicate english', 'communication online', 'company say', 'compare many', 'compassion patient', 'complain know', 'complete skilled', 'completely unfriendly', 'complex plus', 'complicate private', 'comprehensive modern', 'computer system', 'con con', 'con foreigner', 'concern doctor', 'concerned understand', 'conclude everything', 'condition keep', 'condition serious', 'conditioner comfortable', 'confidence user', 'confident continue', 'confirm psychiatric', 'confuse ask', 'congenital disease', 'consciousness service', 'consider improvement', 'consider moderate', 'consider much', 'consistent demonstrate', 'consult staff', 'consultation hotline', 'contact 081', 'contact 0909876767', 'contact clock', 'contact direct', 'contact morning', 'contact number', 'contact poor', 'contact staff', 'contact stand', 'contact think', 'contact willing', 'continue maintain', 'continue treatment', 'control never', 'convenience fast', 'convenient clean', 'convenient communication', 'convenient fast', 'convenient result', 'convenient tidy', 'convenient transportation', 'convenient travel', 'conveniently do', 'conveniently quickly', 'conversation group', 'corps accept', 'correctly accord', 'correctly mop', 'cosmetic make', 'cost cheap', 'cost even', 'cost high', 'cost treatment', 'cotton ball', 'could bed', 'could officer', 'couldnt less', 'counter channel', 'counter fat', 'counter service', 'counter take', 'counter talk', 'court inexpensive', 'courteous spoke', 'crack taxi', 'crazy nail', 'create peace', 'cry jaw', 'cry know', 'ct scanner', 'currently heal', 'currently offering', 'customer wait', 'cut heel', 'cut knife', 'cut truth', 'cute character', 'cute forward', 'cute good', 'cute greet', 'cute polite', 'cute say', 'cycle long', 'cyst surgery', 'damn answer', 'damn patient', 'data management', 'date 02', 'date 13', 'date 18', 'daughter admit', 'daughter come', 'daughter say', 'daughter sick', 'daughter well', 'day admiral', 'day advance', 'day aunt', 'day contact', 'day doctor', 'day experience', 'day get', 'day go', 'day healthy', 'day hour', 'day left', 'day many', 'day match', 'day next', 'day rama', 'day take', 'day today', 'deal immediate', 'death people', 'debris fill', 'dec 2015', 'december 25', 'december last', 'decent collection', 'decide go', 'decision never', 'deeply doctor', 'definitely know', 'definitely private', 'definitely second', 'degree bedtime', 'delayed somewhat', 'delayed work', 'delicious food', 'deliver medicine', 'delivery room', 'delivery service', 'delivery zone', 'demonstrate inability', 'dental building', 'dentistry doctor', 'depart brahma', 'department accident', 'department adult', 'department december', 'department dental', 'department doctor', 'department front', 'department impressed', 'department june', 'department manner', 'department number', 'department nurse', 'department nursery', 'department patient', 'department place', 'department private', 'department queue', 'department ramathibodi', 'department second', 'department sit', 'department still', 'department talk', 'department work', 'deprave reason', 'dept show', 'deserve government', 'despite government', 'despite staff', 'detail like', 'detail patient', 'detailed advice', 'detailed clear', 'detailed easy', 'detailed history', 'determination excellent', 'determine sick', 'diabetes heart', 'diabetes neurological', 'diagnose early', 'diagnose team', 'diagnosis wildcat', 'diagnosis would', 'different department', 'differently person', 'difficult explain', 'digestive problem', 'digit digit', 'digit phd', 'direct disbursement', 'directly grandma', 'directly line', 'disappear disease', 'disappear heal', 'disappear mother', 'disappear strictly', 'disappear well', 'disappointed thank', 'disburse directly', 'disbursement department', 'discard nurse', 'disease arrhythmia', 'disease cancer', 'disease cause', 'disease disappear', 'disease doctor', 'disease eat', 'disease hospital', 'disease know', 'disease lung', 'disease many', 'disease pressure', 'disease probably', 'disease stick', 'disease year', 'disinfectant medical', 'disorder vaginal', 'dispense medicine', 'distinguish work', 'distress posture', 'divert elsewhere', 'division benefit', 'do eat', 'do service', 'do telephone', 'do well', 'doctor 15', 'doctor although', 'doctor appointment', 'doctor arrange', 'doctor asks', 'doctor attach', 'doctor attentive', 'doctor available', 'doctor cant', 'doctor care', 'doctor child', 'doctor could', 'doctor definitely', 'doctor diagnose', 'doctor different', 'doctor doctor', 'doctor every', 'doctor examine', 'doctor fever', 'doctor found', 'doctor general', 'doctor generally', 'doctor give', 'doctor go', 'doctor god', 'doctor good', 'doctor heart', 'doctor inject', 'doctor join', 'doctor joint', 'doctor keep', 'doctor kind', 'doctor know', 'doctor like', 'doctor love', 'doctor match', 'doctor medical', 'doctor medicine', 'doctor might', 'doctor modern', 'doctor nihon', 'doctor nurse', 'doctor pay', 'doctor poor', 'doctor provide', 'doctor ramathibodi', 'doctor recommend', 'doctor regular', 'doctor room', 'doctor say', 'doctor see', 'doctor service', 'doctor skilled', 'doctor spoke', 'doctor staff', 'doctor start', 'doctor still', 'doctor symptom', 'doctor take', 'doctor talented', 'doctor teacher', 'doctor terrible', 'doctor three', 'doctor time', 'doctor treat', 'doctor understand', 'doctor visit', 'doctor wait', 'doctor want', 'doctor writes', 'doctor zone', 'document actually', 'document afternoon', 'document car', 'document edit', 'document hand', 'document held', 'document know', 'document patient', 'document still', 'documentation ask', 'dog man', 'donate foundation', 'donation make', 'donation old', 'donation open', 'donation poor', 'donor ramathibodi', 'dont get', 'dont know', 'dr adithep', 'dr keng', 'dr parawi', 'dr pimjai', 'dr rattanakarn', 'dr tharin', 'dr thatchaphong', 'draw room', 'dress harder', 'drip okay', 'driver good', 'drop surgery', 'drop wrap', 'drug every', 'due amount', 'due snore', 'due stomach', 'duty already', 'duty fully', 'duty willingly', 'ear nose', 'early arrive', 'early morning', 'easily found', 'easy like', 'easy understand', 'eat first', 'eat food', 'eat know', 'eat much', 'eat patient', 'eat right', 'eat salty', 'eat self', 'eat shoulder', 'eat spicy', 'eat thread', 'ecg examination', 'ectopic stomach', 'edit multiple', 'educate medical', 'education garden', 'education hurt', 'education much', 'education unfold', 'effect medication', 'elder make', 'electronically dont', 'electronically file', 'eloquently doctor', 'elsewhere accurate', 'elsewhere hang', 'emergency building', 'emergency department', 'emergency fill', 'emergency kindness', 'emergency medicine', 'emergency room', 'emotion know', 'emotionally patient', 'emphasize trash', 'employee toe', 'encourage part', 'encourage physical', 'encouragement hold', 'endoscopy hurt', 'english refuse', 'enough handle', 'enough know', 'enough nurse', 'enough register', 'enrage think', 'ensure re', 'enter medical', 'enter yet', 'entitle thai', 'entrance chai', 'environment look', 'epilepsy diabetes', 'epilepsy hospital', 'equally emergency', 'equip handle', 'equip mean', 'equip tool', 'equipment cheap', 'equipment complete', 'equipment doctor', 'equipment include', 'equipment nursing', 'equipment sleep', 'especially gynecology', 'especially nurse', 'especially premium', 'especially princess', 'especially receive', 'especially room', 'especially welfare', 'especially wheelchair', 'etc help', 'ethic do', 'ethic doctor', 'eun threw', 'even cancer', 'even get', 'even old', 'even percentage', 'even special', 'even well', 'event people', 'ever since', 'ever watch', 'every common', 'every day', 'every month', 'every morning', 'every patient', 'every position', 'every room', 'every staff', 'every step', 'every time', 'everyone good', 'everyone impressive', 'everyone sacrifice', 'everyone sick', 'everyone speak', 'everyone take', 'everyone throughout', 'everyone treat', 'everything 16', 'everything convenient', 'everything good', 'everything ok', 'everything overall', 'everything perfect', 'everything systematic', 'everything thank', 'everywhere doctor', 'exact time', 'examination advise', 'examination doctor', 'examination hour', 'examination meet', 'examination payment', 'examination room', 'examination take', 'examine explain', 'examine history', 'example ask', 'excellent dentistry', 'excellent level', 'excellent service', 'exceptional job', 'exercise eat', 'expect meet', 'expect spend', 'expect staff', 'expect top', 'expensive compare', 'expensive convenience', 'expensive miss', 'expensive overall', 'expensive well', 'experience happiness', 'experience sleep', 'experienced doctor', 'explain clearly', 'explain easily', 'explain side', 'extra charge', 'eye department', 'eye disease', 'eye hospital', 'eye surgery', 'eye treatment', 'facial seizure', 'facility great', 'facility various', 'fact eat', 'fact kidney', 'factory checked', 'faculty nurse', 'faculty work', 'fah starbucks', 'family come', 'family experience', 'family medicine', 'family relative', 'famous good', 'far away', 'fast convenient', 'fast every', 'fast expect', 'fast hour', 'fast queue', 'fast waste', 'fasten line', 'faster convenient', 'faster use', 'fat skin', 'fat well', 'father admit', 'father lung', 'father sick', 'father stitch', 'father well', 'fatty service', 'fb waksy', 'feb 2016', 'fee expensive', 'fee little', 'fee stay', 'feel bad', 'feel comfortable', 'feel forever', 'feel good', 'feel hurt', 'feel little', 'feel lot', 'feel really', 'feel terrible', 'feel tire', 'feeling dr', 'feeling patient', 'fell xray', 'female nurse', 'fever first', 'fever go', 'fever time', 'fibroid rama', 'fight know', 'file ask', 'file basket', 'file electronically', 'fill form', 'fill heel', 'film less', 'finally get', 'finally move', 'financial mind', 'financial service', 'financial staff', 'find bangkok', 'find enough', 'find everywhere', 'find near', 'find reason', 'find screw', 'find seat', 'find special', 'find thank', 'find thing', 'fine khun', 'finish check', 'finish found', 'finish write', 'firm upper', 'first contact', 'first day', 'first doctor', 'first every', 'first go', 'first icu', 'first staff', 'first step', 'first surgery', 'first time', 'first wait', 'first word', 'fiscal call', 'fit medication', 'fix bad', 'flavor eat', 'flavor infrequently', 'flaw baby', 'flaw bring', 'flick nurse', 'floor building', 'floor card', 'floor entrance', 'floor instead', 'floor morning', 'floor nurse', 'floor phra', 'floor prathep', 'floor pressure', 'floor recovery', 'floor return', 'floor second', 'floor thank', 'floor understand', 'follow advice', 'follow leave', 'food add', 'food court', 'food delicious', 'food eat', 'food quite', 'food tasteless', 'food worry', 'foot talk', 'foreign language', 'foreigner bring', 'foreigner pay', 'forever thank', 'forget government', 'forget impressed', 'forgive prama', 'forgot patient', 'forgotten rama', 'form provide', 'form swing', 'forward ask', 'forward hospital', 'forward price', 'forward sleep', 'found auspicious', 'found dress', 'found elsewhere', 'found hospital', 'found nobody', 'foundation accord', 'foundation long', 'free blood', 'fresh encourage', 'friend congenital', 'friend crazy', 'friend hospital', 'friend lung', 'friend take', 'friendliness patient', 'friendliness politeness', 'friendly big', 'friendly busy', 'friendly cause', 'friendly citizen', 'friendly distress', 'friendly friendly', 'friendly give', 'friendly impressed', 'friendly manner', 'friendly patient', 'friendly provide', 'friendly service', 'friendly smile', 'friendly staff', 'friendly treat', 'friendly use', 'front blood', 'front counter', 'front ray', 'front room', 'front well', 'full bed', 'full blown', 'full especially', 'full parking', 'full time', 'fully equip', 'fully know', 'fully staffed', 'fund keep', 'fungus doctor', 'gallbladder mind', 'gallbladder surgery', 'gangrene left', 'garden nurse', 'gas station', 'gauge upset', 'general doctor', 'generally friendly', 'generous help', 'generous hour', 'gentle maybe', 'get ask', 'get back', 'get checked', 'get consider', 'get file', 'get hundred', 'get inside', 'get kidney', 'get mother', 'get private', 'get see', 'get surgery', 'get treatment', 'get well', 'get work', 'girl check', 'give birth', 'give detail', 'give detailed', 'give doctor', 'give dont', 'give good', 'give order', 'give star', 'glass second', 'go 3rd', 'go anything', 'go anywhere', 'go appointment', 'go back', 'go bed', 'go car', 'go check', 'go cry', 'go delivery', 'go ear', 'go emergency', 'go every', 'go family', 'go forward', 'go full', 'go give', 'go government', 'go home', 'go hospital', 'go love', 'go night', 'go patient', 'go pay', 'go plow', 'go private', 'go ram', 'go receive', 'go see', 'go since', 'go surgery', 'go treat', 'go treatment', 'go use', 'go wheelchair', 'go work', 'god complex', 'good advice', 'good athit', 'good aunt', 'good bad', 'good beautiful', 'good check', 'good clean', 'good cost', 'good doctor', 'good emergency', 'good especially', 'good feel', 'good first', 'good forget', 'good found', 'good friendly', 'good generous', 'good good', 'good heart', 'good hospital', 'good improve', 'good institute', 'good insurance', 'good keep', 'good know', 'good lately', 'good leave', 'good like', 'good look', 'good luck', 'good management', 'good may', 'good medical', 'good mm', 'good money', 'good mother', 'good much', 'good notify', 'good nurse', 'good patient', 'good poor', 'good quality', 'good quite', 'good reputation', 'good service', 'good smile', 'good speak', 'good specialized', 'good standard', 'good suggestion', 'good surgery', 'good teach', 'good tear', 'good thank', 'good thing', 'good tone', 'good treatment', 'good wait', 'good word', 'good would', 'good year', 'google medical', 'government attentive', 'government good', 'government hospital', 'government use', 'governor need', 'grandchild little', 'grandma submit', 'grandma treat', 'great ability', 'great attention', 'great concern', 'great emergency', 'great impressed', 'great level', 'great modern', 'greatly improve', 'greet cheerful', 'grill see', 'group time', 'grown up', 'guard head', 'guard point', 'guard well', 'guess queue', 'guest plus', 'gut crack', 'guy equally', 'guy schedule', 'gynecological disease', 'gynecology 4th', 'gynecology department', 'habit nurse', 'half hour', 'half screw', 'hand body', 'hand card', 'hand document', 'hand helpgood', 'hand look', 'handle foreign', 'handle waiver', 'hang around', 'hang bad', 'hang divert', 'happen public', 'happiness prosperity', 'happy every', 'happy help', 'happy nurse', 'happy prosperous', 'happy ramathibodi', 'happy treatment', 'harassment staff', 'hard find', 'hard forget', 'hard hurt', 'harder think', 'hardly feel', 'head another', 'heal childhood', 'heal faster', 'heal icu', 'heal many', 'heal much', 'heal need', 'heal quickly', 'heal today', 'heal year', 'health check', 'health consultation', 'health principle', 'health problem', 'health strong', 'healthy body', 'heart 100', 'heart attack', 'heart beauty', 'heart disease', 'heart dr', 'heart supplement', 'heart thank', 'heart whenever', 'heck system', 'heel remove', 'hehe stop', 'held document', 'hell yeah', 'hello id', 'help good', 'help include', 'help life', 'help patient', 'help see', 'help sick', 'help take', 'help time', 'help wait', 'help way', 'help well', 'helpgood service', 'high almost', 'high iq', 'high normal', 'high price', 'high private', 'hire nurse', 'history go', 'history good', 'history quite', 'history talk', 'history treat', 'hold cute', 'hold hand', 'hom nurse', 'home delivery', 'home eat', 'home morning', 'home nurse', 'home problem', 'home stay', 'home think', 'horrify bed', 'hospitable relative', 'hospital 4th', 'hospital advise', 'hospital afraid', 'hospital ambiance', 'hospital anyone', 'hospital asks', 'hospital building', 'hospital business', 'hospital center', 'hospital clean', 'hospital come', 'hospital convenient', 'hospital cost', 'hospital country', 'hospital crescent', 'hospital deliver', 'hospital doctor', 'hospital donation', 'hospital dr', 'hospital duty', 'hospital everyone', 'hospital exemplary', 'hospital facility', 'hospital family', 'hospital famous', 'hospital fast', 'hospital first', 'hospital forever', 'hospital friend', 'hospital get', 'hospital go', 'hospital good', 'hospital happy', 'hospital help', 'hospital hospital', 'hospital huge', 'hospital impressed', 'hospital improve', 'hospital inpatient', 'hospital intention', 'hospital invest', 'hospital khun', 'hospital large', 'hospital like', 'hospital long', 'hospital look', 'hospital lopburi', 'hospital lot', 'hospital love', 'hospital manager', 'hospital many', 'hospital modern', 'hospital much', 'hospital never', 'hospital nurse', 'hospital offer', 'hospital often', 'hospital organize', 'hospital premium', 'hospital provide', 'hospital public', 'hospital regardless', 'hospital save', 'hospital see', 'hospital service', 'hospital slow', 'hospital something', 'hospital staff', 'hospital stay', 'hospital still', 'hospital study', 'hospital suck', 'hospital ten', 'hospital term', 'hospital terrible', 'hospital thailand', 'hospital thank', 'hospital thankful', 'hospital therefore', 'hospital time', 'hospital told', 'hospital try', 'hospital undergo', 'hospital use', 'hospital wait', 'hospital welcome', 'hospital well', 'hospital whether', 'hospital would', 'hot fever', 'hot hot', 'hot service', 'hotline give', 'hour appointment', 'hour behind', 'hour doctor', 'hour jammed', 'hour mother', 'hour pass', 'hour point', 'hour see', 'hour still', 'hour tell', 'hour union', 'hour wait', 'house home', 'house upon', 'housekeeper really', 'housewife speak', 'however doctor', 'however stressful', 'hr 21', 'hr doctor', 'hr friend', 'hr original', 'hr therefore', 'huge place', 'hundred thousand', 'hurry already', 'hurry discard', 'hurry imagine', 'hurt anesthetic', 'hurt free', 'hurt hehe', 'hurt hospital', 'hurt less', 'hurt must', 'hurt queue', 'hurt work', 'ib523 request', 'icu room', 'id ib523', 'id pinpmm27', 'illness call', 'illness emergency', 'illness must', 'illness obvious', 'illness reconcile', 'image hospital', 'imagine patient', 'immediate problem', 'immune related', 'impressed doctor', 'impressed every', 'impressed government', 'impressed know', 'impressed patient', 'impressed share', 'impressed since', 'impressed speed', 'impression patient', 'impressive service', 'impressively happy', 'imprint since', 'improve lot', 'improve nursing', 'improve patient', 'improve personnel', 'improve quality', 'improve renew', 'improve speech', 'improve time', 'improvement area', 'inability manage', 'include exercise', 'include good', 'include medical', 'include nurse', 'increase big', 'increase chest', 'increase cycle', 'inexpensive almost', 'infect eye', 'infection ccu', 'infection wait', 'infirmary normal', 'inflammation gangrene', 'influenza vaccine', 'inform queue', 'inform since', 'inform time', 'information maybe', 'infrequently let', 'inject color', 'injection influenza', 'inpatient lot', 'inquire day', 'inquire rama', 'inquiry faster', 'insert line', 'inside doctor', 'inspect interior', 'inspection room', 'instead go', 'institute adjacent', 'institute chula', 'institute neuroscience', 'institute thailand', 'insurance change', 'intention doctor', 'intention throughout', 'interested ask', 'interior disorder', 'interior regularly', 'internationally come', 'intersection improve', 'interview room', 'invest permanent', 'iq iq', 'iq low', 'issue greatly', 'jammed packed', 'jaw wait', 'job choose', 'job life', 'job scan', 'join sathu', 'joint examination', 'june 24', 'june doctor', 'keep alive', 'keep ball', 'keep educate', 'keep get', 'keep good', 'keep new', 'keep rule', 'keep well', 'keeper best', 'keng give', 'kg lead', 'khun hom', 'khun ramathibun', 'khun thank', 'khun work', 'kidney disease', 'kind although', 'kind ask', 'kind doctor', 'kind everyone', 'kind friendly', 'kind kind', 'kind officer', 'kind spoke', 'kindness brings', 'knew doctor', 'knife 619', 'knife operation', 'know ask', 'know back', 'know contact', 'know couldnt', 'know duty', 'know eat', 'know find', 'know fully', 'know get', 'know hard', 'know heck', 'know hospital', 'know hurry', 'know long', 'know may', 'know maybe', 'know misunderstand', 'know nurse', 'know people', 'know person', 'know philanthropist', 'know please', 'know repression', 'know say', 'know someone', 'know something', 'know student', 'know time', 'know use', 'know willing', 'knowledgeable treatment', 'lampang hospital', 'language cant', 'laotian hospital', 'laparoscopic chlamydia', 'large doctor', 'large rich', 'laser phsob', 'lasik good', 'last add', 'last long', 'last step', 'last year', 'late minute', 'late old', 'lately slow', 'later come', 'layer support', 'lead hospital', 'leak doctor', 'learn receive', 'leave doctor', 'leave find', 'leave hospital', 'leave life', 'leave opportunity', 'leave wrong', 'left admire', 'left day', 'left depart', 'leg surgery', 'less hour', 'less life', 'less look', 'less minute', 'less parking', 'less surprisingly', 'less together', 'let person', 'let tell', 'level good', 'level staff', 'level well', 'life around', 'life cause', 'life decent', 'life especially', 'life family', 'life please', 'life rama', 'life threaten', 'life treat', 'life truly', 'life woman', 'like accident', 'like admire', 'like aekchol', 'like can', 'like child', 'like come', 'like correctly', 'like day', 'like education', 'like everyone', 'like get', 'like girl', 'like give', 'like go', 'like hospital', 'like hot', 'like improve', 'like inquire', 'like know', 'like mall', 'like many', 'like meaning', 'like move', 'like new', 'like nurse', 'like old', 'like past', 'like people', 'like private', 'like quit', 'like rake', 'like service', 'like thank', 'like use', 'like would', 'line 022004249', 'line blood', 'line hard', 'line leg', 'line long', 'line others', 'line people', 'listen result', 'little bit', 'little complicate', 'little doctor', 'little expensive', 'little long', 'little longer', 'little old', 'little tongue', 'little well', 'locate directly', 'location bank', 'location delicious', 'location medical', 'logical without', 'long call', 'long chair', 'long fast', 'long hospital', 'long last', 'long queue', 'long seat', 'long send', 'long sound', 'long time', 'long worth', 'longer examination', 'longer understand', 'look back', 'look bad', 'look clean', 'look daughter', 'look doctor', 'look father', 'look forward', 'look friendly', 'look give', 'look good', 'look happy', 'look like', 'look neck', 'look patient', 'look people', 'look really', 'look turn', 'look well', 'look woman', 'lopburi province', 'lose feeling', 'lose image', 'lose weight', 'lot anxiety', 'lot chronic', 'lot emotion', 'lot good', 'lot mean', 'lot patient', 'lot people', 'lot procedure', 'lot queue', 'lot renovation', 'lot responsibility', 'lot stomach', 'lot strong', 'lot time', 'lot told', 'loud sometimes', 'love cafeteria', 'love clean', 'love education', 'love medical', 'love place', 'love ramathibodi', 'lovely building', 'lovely nurse', 'low quality', 'luck enrage', 'lung disease', 'lung infection', 'lung leak', 'lung surgery', 'machine like', 'mah hour', 'maha chakri', 'maha maharaj', 'maharaj hospital', 'maharaj maha', 'maintain 30', 'maintain appreciate', 'maintain point', 'major medical', 'make breathless', 'make car', 'make corps', 'make decision', 'make doctor', 'make feel', 'make hospital', 'make look', 'make merit', 'make money', 'make much', 'make occasional', 'make patient', 'make realize', 'make recover', 'make room', 'make sure', 'make survive', 'male doctor', 'male eye', 'male staff', 'mall hospital', 'mall many', 'man male', 'manage schedule', 'management especially', 'management system', 'manager hire', 'manner deprave', 'manner harassment', 'manner keep', 'manner professionalism', 'manner service', 'many doctor', 'many fasten', 'many know', 'many layer', 'many medical', 'many nurse', 'many patient', 'many place', 'many private', 'many quality', 'many thing', 'many time', 'many year', 'marama see', 'mark go', 'mass mouth', 'match immune', 'match probably', 'match separate', 'maternity department', 'matter grown', 'matter time', 'matter work', 'may 2015', 'may disappear', 'may family', 'may make', 'may personal', 'may prosper', 'may seem', 'may slow', 'may strong', 'may stubborn', 'may survive', 'may system', 'maybe child', 'maybe lot', 'maybe parent', 'maybe wait', 'mean ct', 'mean parking', 'mean wait', 'meaning nurse', 'meaning old', 'meaning speak', 'meaning understand', 'medical bill', 'medical center', 'medical department', 'medical equipment', 'medical expense', 'medical facility', 'medical faculty', 'medical fee', 'medical institute', 'medical staff', 'medical student', 'medical teacher', 'medical team', 'medical term', 'medical treatment', 'medication examination', 'medication keep', 'medication long', 'medication make', 'medication without', 'medicine cost', 'medicine department', 'medicine long', 'medicine new', 'medicine outpatient', 'medicine process', 'medicine relative', 'medicine sloppy', 'medicine thank', 'medicine time', 'medicine today', 'medicine year', 'meet clock', 'meet queue', 'member look', 'member queue', 'member speak', 'member tire', 'mentally friendly', 'mentally sacrifice', 'mention hospital', 'merit forward', 'message please', 'middle pathway', 'might go', 'might look', 'might okay', 'milk butter', 'million patient', 'mind always', 'mind confidence', 'mind resign', 'mind sick', 'mind sometimes', 'minute 600', 'minute already', 'minute late', 'minute number', 'minute payment', 'minute person', 'minute see', 'minute treatment', 'minute wait', 'minute without', 'miss system', 'misunderstand maybe', 'mm mm', 'mm wv', 'mobile phone', 'moderate good', 'modern create', 'modern endoscopy', 'modern equipment', 'modern good', 'modern hospital', 'modern medical', 'modern nurse', 'modern surgery', 'modern tool', 'modern treatment', 'modern would', 'moment think', 'money appropriate', 'money go', 'money grow', 'money talk', 'money thank', 'monitor tuberculosis', 'month check', 'month old', 'month phra', 'month ready', 'mop floor', 'morning afternoon', 'morning check', 'morning daughter', 'morning ensure', 'morning even', 'morning noon', 'morning yet', 'mother birth', 'mother breastfeeding', 'mother doctor', 'mother eat', 'mother go', 'mother heart', 'mother look', 'mother medical', 'mother mukdahan', 'mother please', 'mother safe', 'motorcycle park', 'mouth shut', 'move department', 'move hospital', 'move month', 'mr natha', 'mri machine', 'much doctor', 'much everything', 'much go', 'much hospital', 'much housekeeper', 'much nurse', 'much often', 'much oh', 'much please', 'much salty', 'much service', 'much time', 'multiple document', 'mum mum', 'mum walk', 'must code', 'must hurry', 'must ready', 'must understand', 'must wear', 'nail badly', 'nalay speaks', 'nang building', 'nang nang', 'nasty say', 'natha nurse', 'naughty spill', 'near hospital', 'near noon', 'nearly noon', 'neck pretend', 'need find', 'need many', 'need medical', 'need prepare', 'need sleep', 'need special', 'need treat', 'neurological disease', 'neurological institute', 'neuroscience hospital', 'neuroscience surgery', 'never able', 'never child', 'never forgotten', 'never go', 'never hospital', 'never hurt', 'never phone', 'never table', 'never thought', 'new brain', 'new building', 'new modern', 'new patient', 'newborn mother', 'newcomer equipment', 'next day', 'next week', 'ngam ouk', 'nguansaeng boy', 'nice food', 'night make', 'night newcomer', 'nihon fine', 'nisarak great', 'nittasak sa', 'nobody know', 'nook money', 'noon clock', 'noon receive', 'noon staff', 'noon well', 'normal clinic', 'normal enough', 'normal life', 'normal time', 'normally never', 'nose throat', 'nothing manner', 'nothing quality', 'notify supervisor', 'nov 15', 'number acquire', 'number hang', 'number hospital', 'number website', 'nurse 7th', 'nurse antenatal', 'nurse ask', 'nurse assist', 'nurse attentive', 'nurse bad', 'nurse beautiful', 'nurse bother', 'nurse cart', 'nurse collect', 'nurse completely', 'nurse consciousness', 'nurse consider', 'nurse cute', 'nurse determine', 'nurse doctor', 'nurse dog', 'nurse ever', 'nurse friendly', 'nurse front', 'nurse give', 'nurse good', 'nurse help', 'nurse however', 'nurse inbox', 'nurse inform', 'nurse keep', 'nurse kind', 'nurse leave', 'nurse little', 'nurse look', 'nurse lovely', 'nurse make', 'nurse mentally', 'nurse must', 'nurse nurse', 'nurse outside', 'nurse pay', 'nurse people', 'nurse perform', 'nurse person', 'nurse personnel', 'nurse professional', 'nurse provide', 'nurse rama', 'nurse ran', 'nurse relative', 'nurse sat', 'nurse say', 'nurse screen', 'nurse service', 'nurse sit', 'nurse sleep', 'nurse smile', 'nurse speak', 'nurse spoke', 'nurse staff', 'nurse step', 'nurse take', 'nurse talk', 'nurse thank', 'nurse wait', 'nurse well', 'nurse work', 'nursery room', 'nursing assistant', 'nursing equipment', 'nursing must', 'nursing service', 'nutrition department', 'observe symptom', 'obstetrician outside', 'obstetrics gynecology', 'obvious benefit', 'occasional check', 'offer modern', 'offer story', 'offering good', 'officer damn', 'officer interested', 'officer nasty', 'officer take', 'official say', 'often arrange', 'often often', 'often think', 'often use', 'oh wear', 'ok outpatient', 'ok parking', 'okay go', 'okay remove', 'okay tomorrow', 'old 22', 'old aunt', 'old building', 'old child', 'old cosmetic', 'old ear', 'old guard', 'old mah', 'old make', 'old nurse', 'old patient', 'old people', 'old walk', 'old year', 'omg pleasant', 'online inquiry', 'online queue', 'online registration', 'open accept', 'open anyone', 'open heart', 'open please', 'open push', 'operate thats', 'operates speed', 'operating room', 'operation 730', 'operation make', 'operation time', 'opportunity help', 'order form', 'order knowledgeable', 'order overall', 'organize system', 'original authentic', 'original delivery', 'original tax', 'orthopedic nurse', 'others passing', 'ouk phra', 'outpatient department', 'outpatient lot', 'outside house', 'outside time', 'outstanding result', 'ovarian cyst', 'overall acceptable', 'overall environment', 'overall good', 'overall hell', 'overall picture', 'overtake queue', 'packed fully', 'pain 10', 'pain gallbladder', 'pain torture', 'painless postoperative', 'palpitation doctor', 'parawi speak', 'parent re', 'park area', 'park guard', 'park officer', 'park sign', 'parking beautiful', 'parking hospital', 'parking issue', 'parking lot', 'parking space', 'parking stop', 'part medical', 'part time', 'pass call', 'passing queue', 'past doctor', 'past year', 'pat old', 'pathway person', 'patient 78', 'patient 80', 'patient accept', 'patient agile', 'patient appointment', 'patient around', 'patient bad', 'patient best', 'patient broken', 'patient building', 'patient catch', 'patient cause', 'patient change', 'patient come', 'patient correctly', 'patient day', 'patient deeply', 'patient despite', 'patient disappear', 'patient doctor', 'patient emergency', 'patient file', 'patient first', 'patient go', 'patient good', 'patient guess', 'patient heal', 'patient hold', 'patient hospital', 'patient hurt', 'patient include', 'patient large', 'patient level', 'patient like', 'patient look', 'patient may', 'patient must', 'patient nurse', 'patient official', 'patient phra', 'patient province', 'patient receive', 'patient reduce', 'patient relative', 'patient say', 'patient scar', 'patient screen', 'patient see', 'patient service', 'patient speak', 'patient staff', 'patient still', 'patient survival', 'patient take', 'patient thank', 'patient thoroughly', 'patient treat', 'patient undeniably', 'patient underwent', 'patient use', 'patient wait', 'patient walk', 'patient well', 'patient work', 'pay attention', 'pay expensive', 'pay financial', 'pay first', 'pay great', 'pay otherwise', 'pay receive', 'pay respect', 'pay tax', 'pay true', 'payment dispense', 'payment fast', 'payment process', 'peace mind', 'pending result', 'penicillone match', 'people admit', 'people already', 'people bring', 'people contact', 'people digestive', 'people doctor', 'people duty', 'people every', 'people find', 'people first', 'people good', 'people hospital', 'people insert', 'people keep', 'people like', 'people little', 'people make', 'people may', 'people money', 'people overtake', 'people province', 'people scar', 'people scold', 'people sick', 'people talk', 'people think', 'people use', 'people wait', 'percentage patient', 'perfect less', 'perfect would', 'perform surgery', 'perform treatment', 'period treatment', 'permanent sign', 'permission announce', 'person bed', 'person many', 'person polite', 'person respect', 'person sit', 'person stay', 'person told', 'person wait', 'personal circumstance', 'personal matter', 'personal physiotherapy', 'personal training', 'personnel confident', 'personnel hospital', 'personnel know', 'personnel prosperous', 'personnel tool', 'personnel work', 'phaya nalay', 'phd history', 'philanthropist personal', 'philanthropist please', 'phone boring', 'phone call', 'phone official', 'phone work', 'phra thep', 'phra thepparat', 'phsob sali', 'phu fah', 'physical illness', 'physical original', 'physical therapy', 'physically mentally', 'physiotherapy nurse', 'pick house', 'pick ramathibodi', 'picture best', 'pimjai nisarak', 'place anyone', 'place ard', 'place behind', 'place clean', 'place convenient', 'place customer', 'place good', 'place help', 'place nurse', 'place relative', 'place service', 'place thank', 'plan treatment', 'pleasant surprise', 'please although', 'please ask', 'please change', 'please consideration', 'please contact', 'please encourage', 'please fight', 'please fix', 'please forgive', 'please inquire', 'please recommend', 'please reply', 'please share', 'plow go', 'plus horrify', 'plus speak', 'pm enter', 'pm time', 'point like', 'point loud', 'point tell', 'point would', 'polite polite', 'polite say', 'polite thank', 'polite word', 'politely doctor', 'politeness usually', 'poor habit', 'poor management', 'poor service', 'poor work', 'pop service', 'position bad', 'position impressed', 'possible always', 'postoperative fit', 'posture impression', 'practice secretly', 'prama hospital', 'prathep bldg', 'premium building', 'premium clinic', 'premium ear', 'premium hospital', 'premium like', 'premium wait', 'prepare 15', 'prepare surgery', 'prescription examination', 'prescription find', 'press press', 'press queue', 'press submit', 'pressure diabetes', 'pressure gauge', 'pretend finish', 'price 30', 'price good', 'price usual', 'price would', 'princess maha', 'princess mother', 'principle without', 'printing counter', 'private car', 'private hospital', 'private place', 'private thank', 'privilege counter', 'pro con', 'pro omg', 'probably cut', 'probably find', 'probably forgot', 'probably heart', 'problem full', 'problem hospital', 'problem like', 'problem patient', 'problem rama', 'problem someone', 'problem wound', 'procedure doctor', 'procedure event', 'process little', 'process slow', 'profession call', 'profession good', 'professional able', 'professionalism expect', 'professor doctor', 'proper combine', 'properly might', 'prosper would', 'prosperity forever', 'prosperous may', 'prostrate send', 'protect place', 'protection child', 'provide assistance', 'provide detail', 'provide detailed', 'provide friendliness', 'provide good', 'provide information', 'provide patient', 'provide service', 'provide thorough', 'province case', 'province contact', 'province expect', 'province feel', 'provincial governor', 'psychiatric ward', 'psychological drug', 'psychology sick', 'public hospital', 'public relation', 'public service', 'pull arm', 'puncture wrong', 'push away', 'push patient', 'put queue', 'quality good', 'quality life', 'quality personnel', 'quality service', 'quality treatment', 'queue auspicious', 'queue card', 'queue check', 'queue early', 'queue family', 'queue hand', 'queue hospital', 'queue long', 'queue management', 'queue money', 'queue next', 'queue people', 'queue press', 'queue queue', 'queue reservation', 'queue see', 'queue small', 'queue specify', 'queue sympathetic', 'queue wait', 'queue worth', 'quick check', 'quickly emergency', 'quickly impressively', 'quickly painless', 'quiet make', 'quiet nittasak', 'quit act', 'quite gentle', 'quite good', 'quite lot', 'quite understand', 'radiologist check', 'raja want', 'rake rub', 'ram doctor', 'ram ram', 'rama come', 'rama feb', 'rama give', 'rama hospital', 'rama impressed', 'rama premium', 'rama stuck', 'rama treatment', 'ramathibodi every', 'ramathibodi foundation', 'ramathibodi hospital', 'ramathibodi institute', 'ramathibun khun', 'ran pull', 'rational health', 'rattanakarn cute', 'ray counter', 'ray ultrasound', 're 75', 're queue', 'read please', 'ready go', 'ready work', 'realize even', 'really arrogant', 'really cute', 'really give', 'really go', 'really good', 'really modern', 'really serious', 'really slander', 'really ugly', 'reason long', 'reason time', 'receipt revenue', 'receive answer', 'receive difficult', 'receive employee', 'receive good', 'receive great', 'receive guest', 'receive help', 'receive medication', 'receive medicine', 'receive privilege', 'receive proper', 'receive referral', 'receive treatment', 'reception afternoon', 'recipient 1st', 'recommend make', 'recommend put', 'recommend ramathibodi', 'recommend thank', 'recommend well', 'reconcile whether', 'recover brain', 'recover go', 'recover lot', 'recovery room', 'recruit personnel', 'recuperate home', 'reduce eat', 'reduce use', 'refer case', 'referral treat', 'refuse call', 'refuse see', 'regardless good', 'register website', 'registration online', 'regular disease', 'regular doctor', 'regularly well', 'related disease', 'relation smile', 'relative good', 'relative little', 'relative million', 'relative nurse', 'relative patient', 'relative prostrate', 'relative province', 'relative quite', 'relative regular', 'relative sick', 'relative sleep', 'relative stay', 'relative thank', 'relative use', 'relative visit', 'remove blood', 'remove wound', 'renew queue', 'renovation staff', 'repression stress', 'reputation doctor', 'repute keeper', 'request mass', 'request permission', 'request small', 'reservation especially', 'reserve advance', 'resign hospital', 'respect old', 'respect patient', 'respectively every', 'respirator doctor', 'rest cool', 'rest eye', 'rest nurse', 'rest protection', 'restaurant within', 'result case', 'result come', 'result plan', 'result price', 'result quick', 'result time', 'return 2nd', 'return normal', 'revenue dept', 'review best', 'review see', 'rhythmic delayed', 'rice fierce', 'rich go', 'rich recommend', 'right close', 'right food', 'right rama', 'right still', 'right time', 'risk take', 'robot start', 'room 1st', 'room 2nd', 'room 6th', 'room anandamahidol', 'room bad', 'room clean', 'room cute', 'room date', 'room doctor', 'room enter', 'room especially', 'room everywhere', 'room find', 'room good', 'room later', 'room nurse', 'room observe', 'room officer', 'room queue', 'room receive', 'room relative', 'room respectively', 'room something', 'room staff', 'room talk', 'room true', 'room wait', 'round aware', 'rub trash', 'rule ask', 'sa nguansaeng', 'sacred thing', 'sacrifice friendly', 'sacrifice treat', 'safe return', 'sali doctor', 'salty get', 'salty reduce', 'sat phone', 'save life', 'saw aunt', 'say already', 'say anything', 'say ask', 'say condition', 'say doctor', 'say extra', 'say go', 'say hello', 'say kind', 'say like', 'say look', 'say lot', 'say lung', 'say nurse', 'say okay', 'say patient', 'say queue', 'say really', 'say seven', 'say speak', 'say thank', 'say thorough', 'say time', 'say well', 'scan ray', 'scanner room', 'scar encouragement', 'scar scar', 'scar surgery', 'scary time', 'schedule always', 'schedule consistent', 'schedule get', 'schedule see', 'screen data', 'screen unit', 'screw blood', 'screw equip', 'screw know', 'seat rest', 'seat wow', 'second floor', 'second person', 'second time', 'secretly conversation', 'see blood', 'see bone', 'see could', 'see doctor', 'see every', 'see feel', 'see good', 'see intention', 'see look', 'see message', 'see mobile', 'see obstetrician', 'see ovarian', 'see say', 'see stay', 'see ultimate', 'seem bit', 'seizure make', 'self care', 'sell state', 'send nutrition', 'send post', 'send refer', 'sent ramathibodi', 'serious body', 'serious still', 'seriously admit', 'seriously brain', 'seriously father', 'serve abandon', 'service 1st', 'service 29', 'service advice', 'service always', 'service appication', 'service bad', 'service begin', 'service check', 'service clean', 'service come', 'service confuse', 'service convenient', 'service delayed', 'service doctor', 'service especially', 'service examination', 'service fast', 'service fee', 'service financial', 'service first', 'service go', 'service good', 'service great', 'service job', 'service lot', 'service many', 'service mind', 'service original', 'service personal', 'service place', 'service private', 'service procedure', 'service profession', 'service public', 'service really', 'service recipient', 'service service', 'service since', 'service smile', 'service staff', 'service standard', 'service suck', 'service systematically', 'service team', 'service terrible', 'service wait', 'service well', 'service whether', 'service work', 'seven sell', 'several day', 'severe illness', 'share case', 'share room', 'shock minute', 'shoulder fat', 'shoulder fell', 'show dont', 'show park', 'shut monitor', 'sick already', 'sick child', 'sick fresh', 'sick people', 'sick possible', 'sick right', 'sick suffer', 'sick year', 'side effect', 'side manner', 'sign attach', 'sign show', 'since 1730', 'since 30', 'since age', 'since first', 'since may', 'since never', 'since nurse', 'sirindhorn medical', 'sit barcode', 'sit front', 'sit left', 'sit wait', 'size long', 'skilled doctor', 'skilled friend', 'skin acne', 'skin feel', 'slander anyone', 'sleep child', 'sleep hospital', 'sleep inspection', 'sleep place', 'sleep problem', 'sleep rest', 'sleep share', 'sleep walkway', 'sloppy pain', 'sloppy treatment', 'slow normally', 'slow service', 'slow thank', 'slow use', 'slow wait', 'small doctor', 'small long', 'small space', 'small thing', 'small wound', 'smart attentive', 'smile calmly', 'smile doctor', 'smile friendly', 'smile mention', 'smile politely', 'smile small', 'smile staff', 'smile suggest', 'smile well', 'snack milk', 'snore problem', 'somdet phra', 'someone health', 'someone want', 'something do', 'something find', 'something hard', 'sometimes card', 'sometimes fierce', 'sometimes may', 'sometimes never', 'somewhat may', 'sorry please', 'sorry would', 'sort half', 'sound beam', 'space hospital', 'space inquire', 'space told', 'spacious good', 'speak badly', 'speak care', 'speak complain', 'speak differently', 'speak emotionally', 'speak hardly', 'speak patient', 'speak terrible', 'speak well', 'speaks everyone', 'special clinic', 'special fee', 'special radiologist', 'special room', 'specialized surgery', 'specialty doctor', 'specify appointment', 'specify exact', 'speech terrible', 'speed manner', 'speed operate', 'spend much', 'spicy food', 'spill water', 'spoke badly', 'spoke beautifully', 'spoke eloquently', 'spoke patient', 'spoke unruly', 'spoke well', 'spot need', 'spread many', 'srisawat thank', 'stable personnel', 'staff accident', 'staff always', 'staff bad', 'staff beam', 'staff care', 'staff close', 'staff come', 'staff everything', 'staff eye', 'staff first', 'staff front', 'staff full', 'staff good', 'staff hospital', 'staff inform', 'staff may', 'staff member', 'staff might', 'staff new', 'staff nurse', 'staff old', 'staff patient', 'staff provide', 'staff rama', 'staff receive', 'staff room', 'staff see', 'staff sick', 'staff smile', 'staff spoke', 'staff take', 'staff terrible', 'staff thank', 'staff willing', 'staff work', 'staffed specialty', 'stage impressed', 'stand watch', 'standard although', 'standard treatment', 'star clinic', 'star doctor', 'star like', 'star nurse', 'star update', 'star well', 'starbucks etc', 'start cut', 'start water', 'start young', 'state hospital', 'station taxi', 'stay alone', 'stay drop', 'stay far', 'stay help', 'stay home', 'stay hospital', 'stay icu', 'stay life', 'stay night', 'stay several', 'step hospital', 'step last', 'step make', 'step payment', 'step service', 'step wheelchair', 'stick think', 'still bad', 'still call', 'still come', 'still confident', 'still low', 'still open', 'still quiet', 'still receive', 'still smile', 'still stay', 'still swear', 'still take', 'still treat', 'still wait', 'stitch bad', 'stitch stitch', 'stomach ache', 'stomach nook', 'stomach pain', 'stop bleeding', 'stop park', 'stop work', 'story quiet', 'stress need', 'stress patient', 'stressful minute', 'strictly follow', 'strong always', 'strong flavor', 'stubborn bad', 'stuck problem', 'student cute', 'student every', 'student nurse', 'student order', 'student practice', 'student say', 'student share', 'study bangkok', 'submit document', 'submit documentation', 'suck appointment', 'suck poor', 'suck speak', 'suffer pain', 'suffer people', 'suffer physically', 'suffer severe', 'suggest way', 'suggestion operation', 'sunday doctor', 'supplement result', 'support doctor', 'support symptom', 'sure accurate', 'surgery 2100', 'surgery 82', 'surgery cancer', 'surgery clean', 'surgery come', 'surgery continue', 'surgery day', 'surgery do', 'surgery doctor', 'surgery ectopic', 'surgery hospital', 'surgery may', 'surgery never', 'surgery rama', 'surgery ramathibodi', 'surgery room', 'surgery stage', 'surgery stay', 'surgery thank', 'surgery think', 'surgery time', 'surgery twice', 'surgery year', 'surgical wound', 'surprise clinic', 'surprisingly logical', 'survival small', 'survive although', 'survive make', 'survive say', 'swear screw', 'swing document', 'swing file', 'sympathetic person', 'symptom appear', 'symptom ask', 'symptom disappear', 'symptom doctor', 'symptom fatty', 'symptom like', 'symptom open', 'symptom patient', 'symptom thoroughly', 'system appointment', 'system arrangement', 'system ask', 'system conveniently', 'system doctor', 'system especially', 'system excellent', 'system hurt', 'system provide', 'system still', 'system suck', 'system talk', 'system teach', 'system treat', 'system waste', 'systematic order', 'systematically service', 'table matter', 'take 15', 'take appointment', 'take approximately', 'take child', 'take cotton', 'take eye', 'take file', 'take good', 'take hospital', 'take life', 'take lot', 'take may', 'take patient', 'take penicillone', 'take relative', 'take smile', 'take time', 'take two', 'talented great', 'talk badly', 'talk doctor', 'talk education', 'talk friendly', 'talk iron', 'talk leave', 'talk lot', 'talk mother', 'talk operating', 'talk patient', 'talk phone', 'talk poor', 'talk talk', 'talk think', 'talk treatment', 'tasteless sometimes', 'tax fund', 'tax receipt', 'tax thailand', 'taxi generous', 'taxi private', 'teach many', 'teach medical', 'teacher give', 'teacher smart', 'team cute', 'team doctor', 'team good', 'team improve', 'team online', 'team staff', 'tear conclude', 'telephone health', 'tell cant', 'tell everyone', 'tell meaning', 'tell people', 'tell relative', 'tell surgery', 'ten thousand', 'term properly', 'term treatment', 'terrible big', 'terrible courtesy', 'terrible daughter', 'terrible ever', 'terrible female', 'terrible let', 'terrible nurse', 'terrible rhythmic', 'terrible speak', 'terrible thank', 'terrible tone', 'terrible understand', 'test experienced', 'thai citizen', 'thailand confirm', 'thailand ramathibodi', 'thailand ur', 'thamhongsa gallbladder', 'thank 15', 'thank comment', 'thank doctor', 'thank dr', 'thank everyone', 'thank everything', 'thank faculty', 'thank friendly', 'thank heart', 'thank help', 'thank khun', 'thank look', 'thank make', 'thank many', 'thank medical', 'thank mother', 'thank much', 'thank nurse', 'thank rama', 'thank really', 'thank true', 'thank work', 'thankful dr', 'tharin thamhongsa', 'thatchaphong ngam', 'thats 830', 'thep building', 'thep hospital', 'thep nang', 'thep premium', 'thepparat medical', 'therapy mind', 'therefore ask', 'therefore chose', 'therefore know', 'therefore quite', 'thigh abdomen', 'thing hurt', 'thing know', 'thing leave', 'thing mother', 'thing protect', 'thing sleep', 'thing time', 'thing tomorrow', 'thing villager', 'think admit', 'think appropriate', 'think brain', 'think definitely', 'think everything', 'think government', 'think happy', 'think heart', 'think look', 'think people', 'think staff', 'think various', 'think work', 'think would', 'thorough examination', 'thorough wait', 'thoroughly detailed', 'thoroughly modern', 'thoroughly willing', 'thought step', 'thousand relative', 'thousand sloppy', 'thousand thing', 'thread sleep', 'threaten case', 'three major', 'three minute', 'threw patient', 'throat department', 'throat special', 'throughout life', 'throughout period', 'throughout treatment', 'thyroid factory', 'time 1600', 'time actually', 'time age', 'time allow', 'time always', 'time around', 'time attend', 'time birth', 'time book', 'time call', 'time check', 'time clinic', 'time close', 'time come', 'time confuse', 'time convenient', 'time cut', 'time delivery', 'time deserve', 'time diagnose', 'time disappointed', 'time doctor', 'time due', 'time examine', 'time father', 'time go', 'time hospital', 'time illness', 'time inspect', 'time know', 'time like', 'time make', 'time mean', 'time medicine', 'time near', 'time nurse', 'time operation', 'time parking', 'time patient', 'time people', 'time perform', 'time phu', 'time poor', 'time professor', 'time receive', 'time recommend', 'time recruit', 'time see', 'time speak', 'time staff', 'time think', 'time time', 'time visit', 'time wait', 'time well', 'timely treatment', 'tip foot', 'today 645', 'today go', 'today lot', 'today maharaj', 'today marama', 'today may', 'today new', 'today nurse', 'today overall', 'today see', 'today thank', 'toe staff', 'toe tip', 'together 9hrs', 'together daughter', 'told doctor', 'told knife', 'told park', 'told patient', 'told well', 'tomorrow bring', 'tomorrow give', 'tomorrow lot', 'tone friendly', 'tone terrible', 'tone time', 'tonkoon sent', 'tool comprehensive', 'tool keep', 'tool small', 'top high', 'torture repute', 'training word', 'transportation building', 'trash emphasize', 'trash like', 'travel first', 'treat best', 'treat brother', 'treat child', 'treat disinfectant', 'treat epilepsy', 'treat gynecological', 'treat hospital', 'treat however', 'treat infect', 'treat kidney', 'treat medical', 'treat patient', 'treat person', 'treat personnel', 'treat rama', 'treat well', 'treatment ask', 'treatment best', 'treatment determination', 'treatment doctor', 'treatment emergency', 'treatment enough', 'treatment everyone', 'treatment expensive', 'treatment eye', 'treatment fact', 'treatment go', 'treatment good', 'treatment high', 'treatment institute', 'treatment kind', 'treatment lose', 'treatment medical', 'treatment neurological', 'treatment ok', 'treatment patient', 'treatment rama', 'treatment ramathibodi', 'treatment result', 'treatment review', 'treatment service', 'treatment timely', 'treatment upper', 'treatment uterine', 'treatment year', 'true air', 'true heart', 'true thank', 'truly happy', 'truth feel', 'try get', 'try part', 'tuberculosis patient', 'tuna expect', 'turn away', 'twice start', 'two day', 'two hour', 'two star', 'two year', 'ultimate security', 'ultrasound result', 'uncle ache', 'undeniably aside', 'undergo laparoscopic', 'undergo lot', 'undergo surgery', 'understand feeling', 'understand finish', 'understand information', 'understand many', 'understand people', 'understand problem', 'understand public', 'understand symptom', 'understand today', 'underwent eye', 'underwent lung', 'unfold point', 'unfriendly doctor', 'union mall', 'unit accident', 'unit cute', 'unit today', 'unruly relative', 'up distinguish', 'update decide', 'update review', 'upon arrive', 'upper adult', 'upper arm', 'upper laser', 'upset lot', 'ur entitle', 'ur sort', 'ur tax', 'urgent mother', 'use 13', 'use able', 'use computer', 'use emotion', 'use friendly', 'use go', 'use patient', 'use polite', 'use psychology', 'use service', 'use undergo', 'use ur', 'use vulgar', 'use word', 'user well', 'usual premium', 'usually happen', 'usually people', 'uterine fibroid', 'vaccine risk', 'vaginal fungus', 'various restaurant', 'various thing', 'verb bad', 'visit impressed', 'visit overall', 'visit patient', 'vulgar word', 'wait 15', 'wait afternoon', 'wait bad', 'wait boring', 'wait business', 'wait clock', 'wait doctor', 'wait everything', 'wait fast', 'wait finish', 'wait follow', 'wait foreigner', 'wait give', 'wait go', 'wait hour', 'wait know', 'wait line', 'wait little', 'wait long', 'wait longer', 'wait medication', 'wait medicine', 'wait moment', 'wait money', 'wait queue', 'wait receive', 'wait see', 'wait sometimes', 'wait stressful', 'wait treatment', 'wait two', 'wait wait', 'wait week', 'waiver come', 'waksy id', 'walk ask', 'walk contact', 'walk many', 'walk minute', 'walkway ask', 'want heal', 'want lose', 'want treat', 'waste lot', 'waste time', 'watch hospital', 'watch nurse', 'water increase', 'water look', 'water see', 'way place', 'way ramathibodi', 'way relative', 'wear glass', 'wear lot', 'wear respirator', 'website long', 'website normal', 'week feel', 'week listen', 'weight firm', 'weight send', 'weight white', 'welcome advice', 'welcome spoke', 'welfare student', 'well accepted', 'well appointment', 'well arrange', 'well bore', 'well control', 'well courteous', 'well day', 'well despite', 'well doctor', 'well especially', 'well everything', 'well father', 'well friendly', 'well go', 'well happy', 'well heal', 'well knew', 'well know', 'well like', 'well look', 'well management', 'well mri', 'well patient', 'well pop', 'well private', 'well provide', 'well really', 'well rest', 'well rich', 'well robot', 'well say', 'well staff', 'well thank', 'well together', 'well treat', 'well update', 'well use', 'well verb', 'well walk', 'well wear', 'well well', 'well wish', 'whatever doctor', 'wheelchair nursing', 'wheelchair right', 'wheelchair staff', 'whenever doctor', 'whether check', 'whether location', 'whether place', 'white skin', 'wife disappear', 'wildcat please', 'willing answer', 'willing patient', 'willing provide', 'willing serve', 'willingly take', 'wish wife', 'within hospital', 'without check', 'without diagnosis', 'without education', 'without flaw', 'without obstacle', 'without pick', 'woman answer', 'woman history', 'woman leave', 'word emergency', 'word fever', 'word guard', 'word hospitable', 'word like', 'word tone', 'word wait', 'word without', 'work buffalo', 'work consider', 'work day', 'work go', 'work help', 'work like', 'work nursing', 'work patient', 'work people', 'work personal', 'work sacred', 'work service', 'work speak', 'work system', 'work team', 'work understand', 'work wait', 'work well', 'work year', 'worried past', 'worry health', 'worth affordable', 'worth treatment', 'would charge', 'would eat', 'would get', 'would good', 'would gut', 'would like', 'would make', 'would pay', 'would think', 'wound call', 'wound doctor', 'wound flaw', 'wound heal', 'wound inflammation', 'wow bad', 'wrap thousand', 'write document', 'writes prescription', 'wrong document', 'wrong say', 'wv wv', 'xray medicine', 'yama raja', 'yeah health', 'year 52', 'year ago', 'year aunt', 'year chewy', 'year doctor', 'year every', 'year lot', 'year old', 'year outstanding', 'year since', 'year still', 'year support', 'year treatment', 'yellow star', 'yes great', 'yesterday rama', 'yet department', 'yet first', 'yet half', 'yet minute', 'young age', 'young doctor', 'zone exceptional', 'zone today', 'zone yet']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (0, 2359)\t0.11959277295907975\n",
      "  (0, 1851)\t0.11538881330387961\n",
      "  (0, 1425)\t0.11959277295907975\n",
      "  (0, 2763)\t0.11959277295907975\n",
      "  (0, 572)\t0.11959277295907975\n",
      "  (0, 1799)\t0.11959277295907975\n",
      "  (0, 3117)\t0.11959277295907975\n",
      "  (0, 2794)\t0.11538881330387961\n",
      "  (0, 3780)\t0.11959277295907975\n",
      "  (0, 2266)\t0.11959277295907975\n",
      "  (0, 2542)\t0.11959277295907975\n",
      "  (0, 2090)\t0.09585186943590514\n",
      "  (0, 3777)\t0.10361022633414678\n",
      "  (0, 3990)\t0.11959277295907975\n",
      "  (0, 2398)\t0.11959277295907975\n",
      "  (0, 3878)\t0.11959277295907975\n",
      "  (0, 1075)\t0.11959277295907975\n",
      "  (0, 2352)\t0.11959277295907975\n",
      "  (0, 1568)\t0.11959277295907975\n",
      "  (0, 2078)\t0.11959277295907975\n",
      "  (0, 1635)\t0.11959277295907975\n",
      "  (0, 1845)\t0.11538881330387961\n",
      "  (0, 722)\t0.11959277295907975\n",
      "  (0, 1372)\t0.11959277295907975\n",
      "  (0, 2234)\t0.11538881330387961\n",
      "  :\t:\n",
      "  (326, 1367)\t0.1639800881170984\n",
      "  (326, 1540)\t0.14927784456691892\n",
      "  (326, 898)\t0.15570021393415406\n",
      "  (326, 1387)\t0.15570021393415406\n",
      "  (326, 28)\t0.12177694929817885\n",
      "  (326, 1109)\t0.13959372431036562\n",
      "  (326, 2383)\t0.12658498891972944\n",
      "  (326, 1371)\t0.1357505125280614\n",
      "  (327, 2285)\t0.25384617826335654\n",
      "  (327, 1527)\t0.25384617826335654\n",
      "  (327, 2532)\t0.24337545456892573\n",
      "  (327, 3034)\t0.20637810861564915\n",
      "  (327, 3374)\t0.25384617826335654\n",
      "  (327, 2140)\t0.2213211397199068\n",
      "  (327, 864)\t0.25384617826335654\n",
      "  (327, 3710)\t0.25384617826335654\n",
      "  (327, 3350)\t0.25384617826335654\n",
      "  (327, 2557)\t0.24337545456892573\n",
      "  (327, 70)\t0.25384617826335654\n",
      "  (327, 2507)\t0.25384617826335654\n",
      "  (327, 619)\t0.25384617826335654\n",
      "  (327, 1769)\t0.25384617826335654\n",
      "  (327, 902)\t0.25384617826335654\n",
      "  (327, 1602)\t0.2157943224984998\n",
      "  (327, 2852)\t0.18595136889367006\n",
      "\n",
      " reduce_feature() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      "Before reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.31037994 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "explained_variance_ratio_:\n",
      "[0.07341527 0.01894656 0.01864682 0.01738959 0.01694111 0.01625822\n",
      " 0.01541902 0.01479054 0.01441349 0.01389687]\n",
      "\n",
      "singular_values_:\n",
      "[179.49740939  91.18642629  90.4622546   87.35940645  86.22553417\n",
      "  84.46979902  82.26087652  80.56696813  79.53340319  78.09503855]\n",
      "\n",
      "Afte reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca, shape:  (328, 10)\n",
      "[[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]]\n",
      "\n",
      " kfold_train_test() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\\X_array_pca:\n",
      "\n",
      "[[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]]\n",
      "\n",
      "y_array:\n",
      "[0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0]\n",
      "\n",
      "KFold:  0\n",
      "\n",
      "X_train:\n",
      " [[-0.62469215 -0.39311882  0.06007659 ... -0.43855976 -0.28117816\n",
      "  -0.32267926]\n",
      " [-0.56863712 -1.08630146 -0.73403206 ... -1.33054458  0.66461899\n",
      "  -1.46806854]\n",
      " [-0.76339149 -0.97514607 -0.66499488 ... -1.01962529 -0.21338664\n",
      "  -1.67371254]\n",
      " ...\n",
      " [-0.55441375 -1.50645695 -0.84490713 ... -1.71697516 -0.14010636\n",
      "  -1.59359283]\n",
      " [-0.58181046  0.64737263 -0.21573358 ...  1.35808328 -0.97291873\n",
      "  -1.19212764]\n",
      " [-0.64789854 -0.98732784  0.51445568 ... -0.9208421  -0.19354811\n",
      "  -0.72908217]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00  1.32459048e+01\n",
      "  -2.06416506e+01  2.42037503e-01  8.21267759e+00 -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01  3.98362742e-02\n",
      "  -7.84527246e-01  1.14473479e+00 -4.01175181e-02 -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 -3.15025734e-01\n",
      "  -3.54722328e-01 -4.58269257e-01 -5.71840389e-01 -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " [-6.74020983e-01 -5.51055782e-01 -2.91279265e-01  1.77385547e-01\n",
      "  -8.54108301e-01 -3.83398348e-01 -7.53071196e-01 -2.76856273e-01\n",
      "  -2.47694919e-01 -5.13938694e-01]\n",
      " [-7.17720651e-01 -9.81011413e-01 -7.03213388e-01 -3.16040812e-02\n",
      "  -5.92323461e-01  8.72749427e-01 -1.35282912e+00 -1.33090424e+00\n",
      "  -5.17278984e-01 -1.46270671e+00]\n",
      " [ 8.21972617e-02 -1.67289818e+00  3.02622424e+00 -8.64285466e-02\n",
      "  -3.06775746e-01 -8.09584435e-01 -1.66228521e+00 -7.47849825e-01\n",
      "   3.18831508e-01  2.27556673e+00]\n",
      " [-6.46872912e-01 -1.20102973e+00 -6.01350554e-01  3.00326331e+00\n",
      "   1.07179860e+00  2.77847762e-01  2.75581687e-02  1.21512274e-02\n",
      "  -3.65995474e-01 -3.39262324e-01]\n",
      " [-6.74579785e-01 -6.68817738e-01 -4.79229340e-01 -8.09935034e-02\n",
      "  -3.14617599e-01 -5.69994317e-01 -3.76146909e-01 -6.61764436e-01\n",
      "  -5.69789287e-01 -5.77001252e-01]\n",
      " [-5.79608782e-01 -2.14018728e+00 -4.53461024e-01 -4.12979470e-01\n",
      "  -2.01911381e-01 -5.43075725e-01 -7.11739914e-01  1.15514746e+00\n",
      "  -2.11684000e+00 -2.02322492e+00]\n",
      " [-6.74998166e-01 -8.54406858e-01 -4.38161928e-01 -1.48981664e-01\n",
      "  -3.07437382e-01 -4.99084632e-01 -7.30826072e-01 -3.38632514e-01\n",
      "  -5.10319022e-01 -3.91201883e-01]\n",
      " [-3.55049918e-01 -9.35446357e-01 -1.71927656e-01 -1.84103889e-01\n",
      "  -2.12167086e-01 -5.02201739e-01 -9.96159925e-01 -5.30633589e-01\n",
      "  -6.35076348e-01 -5.44746450e-01]\n",
      " [-3.30959484e-01 -1.04487103e+00 -7.72116867e-01  8.51675881e-04\n",
      "  -8.28160836e-01  3.45796305e-01 -1.12231774e+00 -1.17113376e+00\n",
      "   2.06590272e+00  3.27727500e-01]\n",
      " [-6.79368669e-01 -1.05418544e+00 -2.98997891e-01 -8.09141099e-02\n",
      "  -6.68431311e-02 -2.06384885e-01 -1.20168753e+00 -1.11005606e+00\n",
      "  -8.78906794e-01 -7.90065497e-01]\n",
      " [-8.06730431e-01 -3.43730805e+00 -1.60376566e-01 -1.42206357e+00\n",
      "   2.10253186e-01 -2.60046186e+00  1.00001983e+01  2.72348494e+01\n",
      "  -2.01032507e+00  1.24703445e+00]\n",
      " [-1.42498363e-01 -4.61629526e-01 -3.35114568e-01  2.10993675e-01\n",
      "  -7.69041291e-01 -4.32469732e-01 -8.00595210e-01 -7.52633099e-01\n",
      "  -3.51710399e-01  5.28671883e-01]\n",
      " [-6.63390351e-01 -9.95611528e-01 -5.19936058e-01  3.93359188e-01\n",
      "  -8.29641190e-02 -4.96947484e-01 -9.41872360e-01 -2.77473916e-01\n",
      "  -2.03709032e-01 -6.88611433e-01]\n",
      " [-6.95000129e-01 -1.12565525e+00 -8.64450382e-02 -2.54310463e-01\n",
      "  -1.99281251e-01 -7.35056416e-01 -1.32665229e-01  1.79311904e+00\n",
      "  -6.93058502e-01 -5.19728904e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 -3.15025734e-01\n",
      "  -3.54722328e-01 -4.58269257e-01 -5.71840389e-01 -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01  1.85590281e-01\n",
      "  -6.22942972e-01 -2.78748665e-01 -8.29479628e-01 -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]\n",
      " [-3.64832453e-01 -1.12732034e+00 -4.03619314e-02  4.13246972e-02\n",
      "   4.69661527e-03 -7.08660330e-01 -8.79908461e-01 -7.13019684e-01\n",
      "  -6.17696022e-01 -5.82707848e-01]\n",
      " [-5.62618615e-01  4.23937008e+00 -2.24466701e+00 -1.26974363e+01\n",
      "   1.66319177e+01 -2.10677648e+01  4.48519820e+01 -1.81199703e+01\n",
      "   7.29248049e+00 -2.00863249e+00]\n",
      " [-6.90357250e-01 -9.09252379e-01 -5.75537996e-01  1.99423674e-01\n",
      "  -9.09097473e-01 -3.34646419e-01 -7.10952783e-01 -8.31696565e-01\n",
      "   1.97229061e-01 -1.22895647e+00]\n",
      " [-5.98131972e-01 -8.97908197e-01 -4.13689241e-01 -1.92075780e-01\n",
      "  -1.86584804e-01 -4.97204970e-01 -5.54147299e-01  1.01487939e-01\n",
      "  -4.55540127e-01 -4.09253742e-01]\n",
      " [-3.85193561e-01 -8.25876704e-01 -4.76764321e-01  1.90441236e-03\n",
      "  -2.68665914e-01 -1.72897888e-01 -3.06333533e-01 -5.33548259e-01\n",
      "  -2.60365054e-01 -7.02454950e-01]\n",
      " [-6.42726546e-01 -1.01483128e+00 -4.25477535e-01  2.61898062e-01\n",
      "  -1.93988306e-01 -1.43929800e-01 -7.79377064e-01 -8.19483807e-01\n",
      "  -4.95196309e-01 -6.65158803e-01]\n",
      " [-6.48842272e-01 -7.93651535e-01 -3.83721055e-01 -3.10908024e-02\n",
      "  -3.06713737e-01 -4.64415460e-01 -8.71337341e-01 -5.02948954e-01\n",
      "  -4.59911843e-01 -3.29753565e-01]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-6.71553445e-01 -9.79187829e-01 -3.93804556e-01  8.78320646e-02\n",
      "  -2.13313638e-01 -7.68244147e-02 -5.06915682e-01 -2.57129769e-01\n",
      "  -3.83976783e-01 -1.57037963e-01]\n",
      " [-6.79961863e-01  3.63552873e-01 -4.31727566e-01  2.93608453e-01\n",
      "  -1.02669002e+00 -5.48888691e-01 -4.53630592e-01 -5.06053195e-01\n",
      "  -7.27695546e-01 -4.67367829e-01]\n",
      " [-7.63391489e-01 -9.75146073e-01 -6.64994880e-01  7.02653951e-01\n",
      "  -9.25213975e-01 -3.67635953e-01 -7.97287979e-01 -1.01962529e+00\n",
      "  -2.13386643e-01 -1.67371254e+00]\n",
      " [-6.29937036e-01 -1.09877564e+00 -5.32774357e-01 -8.99811461e-02\n",
      "  -2.41692199e-01 -2.28910618e-01 -1.01059846e+00 -6.35581754e-01\n",
      "   1.73400983e-02 -5.61458625e-01]\n",
      " [-7.11203079e-01  2.87726326e+00 -7.60097673e-02 -1.92759709e+00\n",
      "   4.44243660e-01 -1.30838172e-01 -9.21229498e-01  6.36821068e+00\n",
      "   6.76395145e+00 -2.26668106e-01]\n",
      " [-5.21538256e-01 -8.00595548e-01 -9.63396531e-01 -5.45285670e-02\n",
      "  -1.38363010e-01 -2.07655740e+00  2.56249476e+00 -1.86747585e+00\n",
      "  -1.54409092e-01  8.45294495e-01]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  0\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.8739163432661297\n",
      "\n",
      " Coefficients \n",
      "[ 1.89477388 -0.24858595  2.29423863  0.66838175  0.39445994 -0.09656167\n",
      " -0.07369249 -0.44107692 -0.10134248  0.54881149]\n",
      "\n",
      " pop_polarity\n",
      "[2.74277714e-02 4.19535349e-01 2.72335565e-01 4.51366268e-01\n",
      " 2.21296883e-01 9.99982560e-01 8.59837847e-01 4.01317281e-01\n",
      " 1.99603489e-01 4.18162118e-01 7.21894800e-01 4.86355524e-01\n",
      " 5.83189125e-01 8.75343355e-06 8.24337527e-01 4.46277233e-01\n",
      " 3.69308197e-01 2.72335565e-01 8.87357132e-01 8.30661320e-01\n",
      " 8.00335556e-02 2.69577912e-01 4.20276781e-01 5.16574702e-01\n",
      " 5.37100013e-01 5.04053433e-01 1.78966165e-01 5.06720568e-01\n",
      " 3.59582981e-01 2.48982435e-01 4.11614006e-01 6.59621234e-03\n",
      " 5.24576493e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.81\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[13  3]\n",
      " [ 8  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6666666666666666\n",
      "recall:  0.5294117647058824\n",
      "specificity:  0.8125\n",
      "precision:  0.75\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70        16\n",
      "           1       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.67        33\n",
      "   macro avg       0.68      0.67      0.66        33\n",
      "weighted avg       0.69      0.67      0.66        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  0\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[0.00000000e+000 1.91179852e-001 3.53240175e-001 3.69977584e-001\n",
      " 4.01144772e-001 1.00000000e+000 3.42635117e-001 3.88724882e-001\n",
      " 4.29784562e-002 3.72639516e-001 5.98579653e-001 4.71817900e-001\n",
      " 3.29609580e-001 3.16117913e-165 9.70511556e-001 3.65465356e-001\n",
      " 3.52183732e-002 3.53240175e-001 6.19107131e-001 5.89983000e-001\n",
      " 0.00000000e+000 4.80772840e-001 2.97372504e-001 5.71793297e-001\n",
      " 3.77045016e-001 3.70160392e-001 1.84299165e-001 3.72633316e-001\n",
      " 2.14607907e-001 6.70615779e-001 3.52274643e-001 3.81050771e-018\n",
      " 6.66539488e-003]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.56\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[13  3]\n",
      " [13  4]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5151515151515151\n",
      "recall:  0.23529411764705882\n",
      "specificity:  0.8125\n",
      "precision:  0.5714285714285714\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.81      0.62        16\n",
      "           1       0.57      0.24      0.33        17\n",
      "\n",
      "    accuracy                           0.52        33\n",
      "   macro avg       0.54      0.52      0.48        33\n",
      "weighted avg       0.54      0.52      0.47        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  0\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.07498934 0.77350321 0.0526849  0.73418374 0.01078584 0.89669527\n",
      " 0.36053837 0.1634881  0.09407897 0.75039923 0.88918722 0.12663961\n",
      " 0.86067991 0.0346803  0.91219385 0.5179523  0.57456919 0.0526849\n",
      " 0.44079952 0.9584188  0.29969068 0.01068691 0.80427775 0.45554178\n",
      " 0.90048824 0.92888095 0.00724279 0.86278725 0.74436018 0.02755051\n",
      " 0.54459921 0.23829761 0.56527615]\n",
      "\n",
      " yhat\n",
      "[0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[16  0]\n",
      " [ 0 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  0\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   15.5s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[3.31267212e-01 4.67243155e-01 3.15155726e-01 4.57124328e-01\n",
      " 3.00105018e-01 9.99999605e-01 7.40310963e-01 4.25516776e-01\n",
      " 2.37746328e-01 4.30868737e-01 6.79350476e-01 5.28507230e-01\n",
      " 5.59394962e-01 2.51063591e-05 7.81766945e-01 4.42942474e-01\n",
      " 3.54035506e-01 3.15155726e-01 8.10284633e-01 7.65039613e-01\n",
      " 3.31453258e-01 3.31227204e-01 4.29988763e-01 5.28646077e-01\n",
      " 5.21285299e-01 5.00000000e-01 2.58154674e-01 4.88715372e-01\n",
      " 4.05490870e-01 3.03637556e-01 4.33580990e-01 2.25125532e-02\n",
      " 5.30163812e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.8\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12  4]\n",
      " [ 8  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6363636363636364\n",
      "recall:  0.5294117647058824\n",
      "specificity:  0.75\n",
      "precision:  0.6923076923076923\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67        16\n",
      "           1       0.69      0.53      0.60        17\n",
      "\n",
      "    accuracy                           0.64        33\n",
      "   macro avg       0.65      0.64      0.63        33\n",
      "weighted avg       0.65      0.64      0.63        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  0\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:47:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:47:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.47661388 0.6008242  0.41745138 0.4967645  0.39194956 0.61537874\n",
      " 0.47661388 0.46979204 0.43899685 0.4675718  0.61093795 0.5125012\n",
      " 0.53318083 0.44436255 0.621825   0.5022556  0.4675718  0.41745138\n",
      " 0.55040425 0.6774365  0.4696681  0.38970366 0.5585973  0.6304909\n",
      " 0.6553598  0.6575748  0.37949443 0.5476699  0.51958126 0.38970366\n",
      " 0.5608176  0.4600801  0.58449984]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1]\n",
      "\n",
      " auc\n",
      "0.88\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[13  3]\n",
      " [ 3 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8181818181818182\n",
      "recall:  0.8235294117647058\n",
      "specificity:  0.8125\n",
      "precision:  0.8235294117647058\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        16\n",
      "           1       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.82        33\n",
      "   macro avg       0.82      0.82      0.82        33\n",
      "weighted avg       0.82      0.82      0.82        33\n",
      "\n",
      "\n",
      "KFold:  1\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-6.24692150e-01 -3.93118815e-01  6.00765881e-02 -4.97413687e-02\n",
      "  -4.36825994e-01 -5.39999576e-01 -6.56404521e-01 -4.38559758e-01\n",
      "  -2.81178155e-01 -3.22679257e-01]\n",
      " [-5.68637119e-01 -1.08630146e+00 -7.34032057e-01  1.08031910e-01\n",
      "  -6.62286960e-01 -4.25570143e-02  8.01226691e-02 -1.33054458e+00\n",
      "   6.64618990e-01 -1.46806854e+00]\n",
      " [-7.63391489e-01 -9.75146073e-01 -6.64994880e-01  7.02653951e-01\n",
      "  -9.25213975e-01 -3.67635953e-01 -7.97287979e-01 -1.01962529e+00\n",
      "  -2.13386643e-01 -1.67371254e+00]\n",
      " [-6.95507568e-01 -8.22583317e-01 -5.31373116e-01 -1.57157281e-01\n",
      "  -3.49773871e-01 -6.30578190e-01 -5.40251594e-01 -2.57062060e-01\n",
      "  -5.22155601e-01 -7.01261539e-01]\n",
      " [-5.15564081e-01 -7.71526008e-02 -3.99377164e-01  2.20586643e-01\n",
      "  -8.60603533e-01 -3.38689368e-01 -6.37510480e-01 -5.09861597e-01\n",
      "  -2.18498545e-01  1.96819529e-02]\n",
      " [-2.64535167e-01 -1.71279817e+00 -5.59965410e-01 -5.35963797e-01\n",
      "  -3.36510719e-01  1.12674316e+00 -4.81246662e-01  1.58083139e-02\n",
      "  -7.80345703e-01  8.70039095e-01]\n",
      " [-6.62245116e-01 -8.39362692e-01 -3.18589857e-01 -1.65919104e-01\n",
      "  -1.92982305e-01 -4.31856612e-01 -7.56545328e-01 -3.64372916e-01\n",
      "  -4.84745418e-01 -4.79376897e-01]\n",
      " [-6.35073900e-01 -1.11642992e+00 -4.91458111e-01  1.00465516e+00\n",
      "   4.00251046e-01 -4.50154314e-01 -1.78668744e-01  4.32071152e-01\n",
      "  -5.51311606e-01 -6.31139772e-01]\n",
      " [-7.61165779e-01 -1.16858070e+00  6.09521727e-01 -3.66853437e-01\n",
      "  -5.40797890e-01 -1.36726797e+00  1.95460436e-01 -2.63386221e+00\n",
      "   6.93534484e-01  4.99112139e-01]\n",
      " [-6.65747272e-01 -1.03081583e+00 -4.35383173e-01 -1.95207771e-01\n",
      "  -2.95768383e-01 -3.88129947e-01 -8.24815909e-01 -5.76820279e-01\n",
      "  -5.57628429e-01  2.25423311e-01]\n",
      " [-6.57498507e-01 -9.40141565e-01 -4.68343203e-01 -9.75774248e-02\n",
      "  -1.73390175e-01 -5.02730174e-01 -6.53869701e-01 -2.50627934e-01\n",
      "  -4.14595743e-01 -4.77860038e-01]\n",
      " [-6.62245116e-01 -8.39362692e-01 -3.18589857e-01 -1.65919104e-01\n",
      "  -1.92982305e-01 -4.31856612e-01 -7.56545328e-01 -3.64372916e-01\n",
      "  -4.84745418e-01 -4.79376897e-01]\n",
      " [-5.35205957e-01  1.22183575e-01  3.54395920e-02  6.09804789e-01\n",
      "  -8.59757909e-01 -5.70730520e-01  8.29404870e-02 -4.52168443e-01\n",
      "  -6.05084569e-01 -9.31817589e-02]\n",
      " [-6.82748432e-01 -7.50546933e-01 -4.78398149e-01 -9.12310125e-02\n",
      "  -3.70732979e-01 -4.76423429e-01 -8.25805592e-01 -4.52928261e-01\n",
      "  -5.08160624e-01 -5.70654345e-01]\n",
      " [-5.35205957e-01  1.22183575e-01  3.54395920e-02  6.09804789e-01\n",
      "  -8.59757909e-01 -5.70730520e-01  8.29404870e-02 -4.52168443e-01\n",
      "  -6.05084569e-01 -9.31817589e-02]\n",
      " [-6.38058410e-01 -9.01546300e-01 -4.54645376e-01 -7.73830045e-02\n",
      "  -3.64035940e-01 -5.26424575e-01 -9.86489778e-01 -5.87823962e-01\n",
      "  -6.39024432e-01 -6.52553258e-01]\n",
      " [-6.38268560e-01 -2.75658147e-01 -2.63196907e-01 -5.38157461e-01\n",
      "   9.18492228e-01 -1.03681767e-01 -3.78469369e-01 -7.98334310e-01\n",
      "   3.51627983e-01  2.93520067e-01]\n",
      " [-8.06730431e-01 -3.43730805e+00 -1.60376566e-01 -1.42206357e+00\n",
      "   2.10253186e-01 -2.60046186e+00  1.00001983e+01  2.72348494e+01\n",
      "  -2.01032507e+00  1.24703445e+00]\n",
      " [-6.82748432e-01 -7.50546933e-01 -4.78398149e-01 -9.12310125e-02\n",
      "  -3.70732979e-01 -4.76423429e-01 -8.25805592e-01 -4.52928261e-01\n",
      "  -5.08160624e-01 -5.70654345e-01]\n",
      " [-6.32090890e-01 -9.88304881e-01  2.20524515e-01  1.14846498e-01\n",
      "  -3.96515641e-01 -5.30947662e-01 -8.72046162e-01 -2.67813508e-01\n",
      "   1.53273563e-02 -5.80019383e-01]\n",
      " [-3.71186133e-01 -1.16218407e+00 -5.71166812e-01 -6.87369595e-02\n",
      "  -5.12841783e-03 -4.62462773e-01 -1.61860699e-01  1.44830997e-01\n",
      "  -6.41265818e-01 -6.59496922e-01]\n",
      " [-4.96017985e-01 -6.81237388e-01 -2.20619294e-02  1.48895488e-01\n",
      "  -3.11706951e-01 -7.24313154e-01 -7.32239853e-01 -4.75992201e-01\n",
      "  -5.89469459e-01  9.81410897e-01]\n",
      " [-5.32276316e-01  1.63337115e+00 -8.61650032e-01 -4.09531524e+00\n",
      "   3.75690226e+00 -5.10320041e+00  3.01980102e+00 -3.90264264e+00\n",
      "  -5.99884475e-01 -1.13839000e+00]\n",
      " [-5.98440847e-01 -5.58703048e-01 -5.14005288e-02 -6.56593697e-02\n",
      "  -3.59763379e-01 -3.68031432e-01 -4.66724436e-01 -4.24223861e-01\n",
      "   2.27854172e-01 -4.30229800e-01]\n",
      " [-6.61165525e-01 -8.90411313e-01 -3.90233945e-01 -4.00257210e-02\n",
      "  -3.54619817e-01 -5.19692685e-01 -9.45367486e-01 -6.41192404e-01\n",
      "  -5.10868950e-01  3.87575615e-01]\n",
      " [-6.64442978e-01  3.07781177e+01  2.19542683e+00 -1.92997167e+01\n",
      "   2.98307133e+01  2.55772978e-01 -1.45753539e+01  5.54276342e+00\n",
      "  -3.99200004e+00  1.18366385e+00]\n",
      " [-5.68637119e-01 -1.08630146e+00 -7.34032057e-01  1.08031910e-01\n",
      "  -6.62286960e-01 -4.25570143e-02  8.01226691e-02 -1.33054458e+00\n",
      "   6.64618990e-01 -1.46806854e+00]\n",
      " [-6.62245116e-01 -8.39362692e-01 -3.18589857e-01 -1.65919104e-01\n",
      "  -1.92982305e-01 -4.31856612e-01 -7.56545328e-01 -3.64372916e-01\n",
      "  -4.84745418e-01 -4.79376897e-01]\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 -5.29046618e-01\n",
      "  -3.59634159e-01 -8.51907233e-01 -8.85718383e-01 -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-7.17720651e-01 -9.81011413e-01 -7.03213388e-01 -3.16040812e-02\n",
      "  -5.92323461e-01  8.72749427e-01 -1.35282912e+00 -1.33090424e+00\n",
      "  -5.17278984e-01 -1.46270671e+00]\n",
      " [-6.95507568e-01 -8.22583317e-01 -5.31373116e-01 -1.57157281e-01\n",
      "  -3.49773871e-01 -6.30578190e-01 -5.40251594e-01 -2.57062060e-01\n",
      "  -5.22155601e-01 -7.01261539e-01]\n",
      " [-6.62245116e-01 -8.39362692e-01 -3.18589857e-01 -1.65919104e-01\n",
      "  -1.92982305e-01 -4.31856612e-01 -7.56545328e-01 -3.64372916e-01\n",
      "  -4.84745418e-01 -4.79376897e-01]\n",
      " [-5.71880101e-01 -2.00562434e-01  2.40703174e-02 -7.23394387e-01\n",
      "   5.43015069e-01  1.25872743e+00 -1.93084907e-01 -1.57631914e-01\n",
      "  -6.70716827e-01  1.25062518e-01]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  1\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.9308578757103427\n",
      "\n",
      " Coefficients \n",
      "[ 1.7044707  -0.29258769  2.76436244  0.50947053  0.24815528 -0.11289953\n",
      " -0.07032705 -0.43453853 -0.11548708  0.59033478]\n",
      "\n",
      " pop_polarity\n",
      "[7.60081179e-01 2.27051661e-01 2.28346579e-01 3.13781982e-01\n",
      " 5.52541085e-01 6.41089915e-01 5.16952105e-01 4.98591610e-01\n",
      " 9.78936042e-01 5.67402327e-01 4.19522759e-01 5.16952105e-01\n",
      " 8.09708230e-01 3.90854294e-01 8.09708230e-01 4.48517428e-01\n",
      " 6.60983382e-01 1.97944317e-05 3.90854294e-01 8.32832772e-01\n",
      " 4.27615355e-01 9.01125692e-01 1.77484426e-01 6.87381520e-01\n",
      " 6.38505193e-01 7.99752610e-03 2.27051661e-01 5.16952105e-01\n",
      " 2.16230040e-01 2.07299435e-01 3.13781982e-01 5.16952105e-01\n",
      " 7.18854065e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.77\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[13  7]\n",
      " [ 3 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.696969696969697\n",
      "recall:  0.7692307692307693\n",
      "specificity:  0.65\n",
      "precision:  0.5882352941176471\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72        20\n",
      "           1       0.59      0.77      0.67        13\n",
      "\n",
      "    accuracy                           0.70        33\n",
      "   macro avg       0.70      0.71      0.69        33\n",
      "weighted avg       0.72      0.70      0.70        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  1\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[5.71649994e-001 5.39145947e-001 7.87738997e-001 5.54057764e-001\n",
      " 5.08973725e-001 7.64820090e-001 5.38376473e-001 3.69432891e-001\n",
      " 4.48144686e-001 5.91485343e-001 5.24143054e-001 5.38376473e-001\n",
      " 4.11500009e-001 5.58163691e-001 4.11500009e-001 5.20866732e-001\n",
      " 5.54308101e-001 4.26643525e-174 5.58163691e-001 6.14664722e-001\n",
      " 5.97338194e-001 7.85454068e-001 8.84840170e-010 5.46840538e-001\n",
      " 6.18477152e-001 0.00000000e+000 5.39145947e-001 5.38376473e-001\n",
      " 5.18434788e-001 5.46588137e-001 5.54057764e-001 5.38376473e-001\n",
      " 3.53820445e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.68\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 5 15]\n",
      " [ 3 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.45454545454545453\n",
      "recall:  0.7692307692307693\n",
      "specificity:  0.25\n",
      "precision:  0.4\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.25      0.36        20\n",
      "           1       0.40      0.77      0.53        13\n",
      "\n",
      "    accuracy                           0.45        33\n",
      "   macro avg       0.51      0.51      0.44        33\n",
      "weighted avg       0.54      0.45      0.42        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  1\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.97119441 0.09061021 0.015323   0.05445406 0.93670353 0.51257603\n",
      " 0.31728822 0.6695891  0.39570125 0.91614879 0.05952027 0.31728822\n",
      " 0.36102964 0.1307407  0.36102964 0.2417926  0.85575666 0.02322545\n",
      " 0.1307407  0.94991532 0.4881114  0.97775172 0.33331056 0.94922918\n",
      " 0.93456346 0.06363996 0.09061021 0.31728822 0.03233642 0.01177448\n",
      " 0.05445406 0.31728822 0.68296511]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[20  0]\n",
      " [ 2 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9393939393939394\n",
      "recall:  0.8461538461538461\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.95      0.92      0.93        33\n",
      "weighted avg       0.94      0.94      0.94        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  1\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.5s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[7.26066710e-01 2.39989860e-01 2.36093913e-01 3.30816682e-01\n",
      " 5.15485512e-01 5.46642407e-01 5.00000000e-01 3.96801697e-01\n",
      " 9.68235918e-01 5.29308822e-01 4.04257466e-01 5.00000000e-01\n",
      " 7.55154104e-01 3.90138892e-01 7.55154104e-01 4.28085957e-01\n",
      " 6.26156452e-01 1.44214062e-04 3.90138892e-01 7.87310643e-01\n",
      " 3.68985577e-01 8.40197330e-01 3.05238098e-01 6.55569127e-01\n",
      " 5.86486255e-01 2.88903970e-01 2.39989860e-01 5.00000000e-01\n",
      " 2.29118460e-01 2.30946055e-01 3.30816682e-01 5.00000000e-01\n",
      " 6.96713301e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.77\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[13  7]\n",
      " [ 3 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.696969696969697\n",
      "recall:  0.7692307692307693\n",
      "specificity:  0.65\n",
      "precision:  0.5882352941176471\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72        20\n",
      "           1       0.59      0.77      0.67        13\n",
      "\n",
      "    accuracy                           0.70        33\n",
      "   macro avg       0.70      0.71      0.69        33\n",
      "weighted avg       0.72      0.70      0.70        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  1\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:47:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:47:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.6449898  0.43061075 0.4104606  0.44941342 0.60576224 0.50466716\n",
      " 0.55342656 0.5607754  0.47678384 0.57909656 0.46178564 0.55342656\n",
      " 0.58570147 0.49144104 0.58570147 0.5861569  0.5370662  0.43471256\n",
      " 0.49144104 0.6584881  0.5430032  0.65241635 0.46729666 0.6449898\n",
      " 0.58944225 0.44649237 0.43061075 0.55342656 0.43468708 0.3982889\n",
      " 0.44941342 0.55342656 0.5120937 ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.83\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[13  7]\n",
      " [ 1 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7575757575757576\n",
      "recall:  0.9230769230769231\n",
      "specificity:  0.65\n",
      "precision:  0.631578947368421\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.65      0.76        20\n",
      "           1       0.63      0.92      0.75        13\n",
      "\n",
      "    accuracy                           0.76        33\n",
      "   macro avg       0.78      0.79      0.76        33\n",
      "weighted avg       0.81      0.76      0.76        33\n",
      "\n",
      "\n",
      "KFold:  2\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00  1.32459048e+01\n",
      "  -2.06416506e+01  2.42037503e-01  8.21267759e+00 -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-6.81528177e-01 -1.00252081e+00 -5.03580876e-01 -1.75174865e-01\n",
      "  -3.73109662e-01 -3.93051786e-01 -7.99855647e-01 -7.89973583e-01\n",
      "  -5.94958317e-01 -9.33429299e-01]\n",
      " [-6.62245116e-01 -8.39362692e-01 -3.18589857e-01 -1.65919104e-01\n",
      "  -1.92982305e-01 -4.31856612e-01 -7.56545328e-01 -3.64372916e-01\n",
      "  -4.84745418e-01 -4.79376897e-01]\n",
      " [-5.90597553e-01 -8.75848659e-01 -1.11218205e-01  1.75285986e-01\n",
      "  -2.59482814e-01 -6.10798592e-01  3.99822033e-01  5.37527568e-01\n",
      "  -8.36018316e-01 -8.07698187e-01]\n",
      " [-5.21859132e-01 -8.30271283e-01 -3.44059985e-01 -1.67752658e-01\n",
      "  -5.03404162e-01  1.54200944e-02 -8.17786746e-01 -3.64269668e-01\n",
      "  -4.27505762e-01 -4.28148807e-01]\n",
      " [-2.94376677e-01 -1.19197442e+00 -6.51195973e-01 -2.61029139e-01\n",
      "  -3.00821786e-03  2.32335113e+00 -1.01207079e-01 -1.11932161e+00\n",
      "  -3.14016222e-01  1.41200665e-01]\n",
      " [-6.64442978e-01  3.07781177e+01  2.19542683e+00 -1.92997167e+01\n",
      "   2.98307133e+01  2.55772978e-01 -1.45753539e+01  5.54276342e+00\n",
      "  -3.99200004e+00  1.18366385e+00]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-6.90357250e-01 -9.09252379e-01 -5.75537996e-01  1.99423674e-01\n",
      "  -9.09097473e-01 -3.34646419e-01 -7.10952783e-01 -8.31696565e-01\n",
      "   1.97229061e-01 -1.22895647e+00]\n",
      " [-5.21859132e-01 -8.30271283e-01 -3.44059985e-01 -1.67752658e-01\n",
      "  -5.03404162e-01  1.54200944e-02 -8.17786746e-01 -3.64269668e-01\n",
      "  -4.27505762e-01 -4.28148807e-01]\n",
      " [-6.96168074e-02 -1.24624340e+00  4.53508918e-01  1.63196546e-01\n",
      "  -9.60188167e-01 -5.52450847e-01 -8.77889704e-01  1.82237120e-02\n",
      "   7.42961648e-02 -4.97328405e-01]\n",
      " [-5.79608782e-01 -2.14018728e+00 -4.53461024e-01 -4.12979470e-01\n",
      "  -2.01911381e-01 -5.43075725e-01 -7.11739914e-01  1.15514746e+00\n",
      "  -2.11684000e+00 -2.02322492e+00]\n",
      " [-5.38753239e-01 -9.20855807e-01  2.93033335e-01 -2.86022115e-01\n",
      "  -2.72717858e-01  5.49588027e-01 -1.23244713e+00 -5.07153949e+00\n",
      "  -2.29031383e+00  3.88820886e+00]\n",
      " [-1.15702662e-01 -8.23761766e-01  4.10882631e-01 -5.79660991e+00\n",
      "   4.74777357e+00  4.38616305e+01  1.59263520e+01 -2.66924270e+00\n",
      "  -3.81322603e+00  7.50995644e-01]\n",
      " [-6.74089234e-01 -1.03800634e+00 -5.49381558e-02 -6.90010961e-02\n",
      "  -4.00621634e-01 -5.78388261e-01 -7.28533599e-01 -5.15192530e-01\n",
      "  -6.21200657e-01 -4.84262025e-01]\n",
      " [-6.02035847e-01 -1.24248295e+00 -5.22878564e-01  9.72500774e-03\n",
      "  -1.34498849e-01 -4.61529300e-01 -8.29536573e-01 -8.72062744e-01\n",
      "  -4.39327387e-01  1.47738323e-01]\n",
      " [-6.12998391e-01 -1.10664516e+00 -3.54445083e-01 -1.25126010e-02\n",
      "  -9.24314782e-01  6.63000208e-01 -1.51059680e+00 -1.37556680e+00\n",
      "   1.77082141e+00  5.74952118e-01]\n",
      " [-6.40326015e-01 -1.56441218e-01  9.80055117e-04  8.30266269e-02\n",
      "  -9.03336319e-01 -4.62987581e-01 -4.69489967e-01 -5.11009787e-01\n",
      "  -4.97442472e-01 -6.62112722e-01]\n",
      " [-5.94239061e-01 -1.41761934e+00 -8.55183080e-01 -1.51644268e-01\n",
      "  -2.10272671e-01 -1.98354123e-01  9.10177625e-01  1.32723256e+00\n",
      "  -7.53521881e-01  1.55332085e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01  1.85590281e-01\n",
      "  -6.22942972e-01 -2.78748665e-01 -8.29479628e-01 -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]\n",
      " [-6.52288564e-01 -8.86250109e-01 -4.34734987e-01 -2.00724961e-01\n",
      "  -3.70828857e-01 -6.35345904e-01 -6.32819883e-01  5.96497121e-02\n",
      "  -3.69273706e-01  8.40876815e-01]\n",
      " [-6.52886168e-01 -7.21596752e-01 -3.52196038e-01 -3.96052435e-01\n",
      "  -9.23054443e-03 -5.74949631e-01 -9.69961612e-01 -1.24478130e-01\n",
      "  -4.25296505e-01 -2.07360145e-01]\n",
      " [-7.61165779e-01 -1.16858070e+00  6.09521727e-01 -3.66853437e-01\n",
      "  -5.40797890e-01 -1.36726797e+00  1.95460436e-01 -2.63386221e+00\n",
      "   6.93534484e-01  4.99112139e-01]\n",
      " [-6.90357250e-01 -9.09252379e-01 -5.75537996e-01  1.99423674e-01\n",
      "  -9.09097473e-01 -3.34646419e-01 -7.10952783e-01 -8.31696565e-01\n",
      "   1.97229061e-01 -1.22895647e+00]\n",
      " [-6.65726416e-01 -5.52121705e-01 -4.40254868e-01 -2.43024797e-01\n",
      "  -2.28064693e-01 -4.07187440e-01 -7.19079213e-01 -1.34828838e-01\n",
      "  -5.34717838e-01 -1.72673222e-01]\n",
      " [-6.52886168e-01 -7.21596752e-01 -3.52196038e-01 -3.96052435e-01\n",
      "  -9.23054443e-03 -5.74949631e-01 -9.69961612e-01 -1.24478130e-01\n",
      "  -4.25296505e-01 -2.07360145e-01]\n",
      " [-6.41280675e-01 -1.14313828e+00 -5.57495755e-01  1.69501628e-02\n",
      "  -7.67995448e-02 -6.39965813e-01 -5.14684727e-01  6.03457891e-01\n",
      "  -5.37334980e-01 -2.79336248e-01]\n",
      " [-3.30959484e-01 -1.04487103e+00 -7.72116867e-01  8.51675881e-04\n",
      "  -8.28160836e-01  3.45796305e-01 -1.12231774e+00 -1.17113376e+00\n",
      "   2.06590272e+00  3.27727500e-01]\n",
      " [ 1.44132188e-02 -6.01164935e-01 -5.07590945e-01 -6.01692488e-01\n",
      "  -1.31663340e-01  4.66188343e-01 -2.37664163e+00 -7.03471370e-01\n",
      "   3.92972521e+00  1.54862578e+00]\n",
      " [-7.21292304e-01 -3.13194213e-01 -2.67576219e-01  2.57257940e-01\n",
      "  -5.00382328e-01 -2.61547663e-01 -8.69546623e-01 -7.38855199e-01\n",
      "   8.80491390e-02 -5.52582119e-01]\n",
      " [-6.20164048e-01 -9.68081887e-01 -5.00070508e-01  1.81666588e-01\n",
      "  -2.07933766e-01 -4.82349272e-01 -7.66740155e-01  1.09968885e-01\n",
      "  -1.74719734e-01 -5.61434593e-01]\n",
      " [-7.63391489e-01 -9.75146073e-01 -6.64994880e-01  7.02653951e-01\n",
      "  -9.25213975e-01 -3.67635953e-01 -7.97287979e-01 -1.01962529e+00\n",
      "  -2.13386643e-01 -1.67371254e+00]\n",
      " [-5.53054805e-01  1.01101289e+00 -3.83442333e-01 -1.50161581e+00\n",
      "   1.23715027e+00 -3.69293127e+00  6.43438285e+00 -1.11861499e+00\n",
      "  -4.92765014e-01  2.90920419e-02]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  2\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "2.323781706520559\n",
      "\n",
      " Coefficients \n",
      "[ 2.25386863 -0.31040925  3.01314311  0.4293873   0.23879979 -0.1292028\n",
      " -0.06238474 -0.41470723 -0.15558809  0.58989917]\n",
      "\n",
      " pop_polarity\n",
      "[0.01671595 0.35147774 0.5152873  0.60524792 0.54745636 0.56410033\n",
      " 0.0329586  0.16849893 0.24255185 0.54745636 0.9727386  0.24254867\n",
      " 0.99894107 0.08982143 0.72724021 0.59330295 0.65345553 0.6769659\n",
      " 0.30668705 0.93823769 0.57306432 0.49326004 0.98136909 0.24255185\n",
      " 0.41194292 0.49326004 0.3375441  0.44058066 0.80305719 0.50870143\n",
      " 0.37956974 0.18983232 0.47307311]\n",
      "\n",
      " yhat\n",
      "[0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.77\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[13  6]\n",
      " [ 4 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.696969696969697\n",
      "recall:  0.7142857142857143\n",
      "specificity:  0.6842105263157895\n",
      "precision:  0.625\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.72        19\n",
      "           1       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.70        33\n",
      "   macro avg       0.69      0.70      0.69        33\n",
      "weighted avg       0.71      0.70      0.70        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  2\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[0.00000000e+000 4.88236239e-001 4.55489629e-001 1.80851632e-001\n",
      " 4.65782248e-001 4.17825552e-001 0.00000000e+000 1.42515063e-001\n",
      " 5.49585039e-001 4.65782248e-001 9.95166054e-001 4.85691876e-002\n",
      " 3.23276208e-001 1.10012467e-306 4.86573765e-001 4.64023224e-001\n",
      " 1.71937015e-001 4.52359987e-001 1.48312824e-001 7.27598520e-001\n",
      " 5.93443849e-001 4.13247010e-001 3.52401618e-001 5.49585039e-001\n",
      " 4.39969270e-001 4.13247010e-001 2.59857054e-001 5.14075836e-001\n",
      " 9.08880393e-001 4.87189498e-001 3.79149651e-001 7.22181312e-001\n",
      " 4.20612067e-017]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.61\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[14  5]\n",
      " [11  3]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5151515151515151\n",
      "recall:  0.21428571428571427\n",
      "specificity:  0.7368421052631579\n",
      "precision:  0.375\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.74      0.64        19\n",
      "           1       0.38      0.21      0.27        14\n",
      "\n",
      "    accuracy                           0.52        33\n",
      "   macro avg       0.47      0.48      0.45        33\n",
      "weighted avg       0.48      0.52      0.48        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  2\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.0601018  0.25957038 0.12938523 0.37069316 0.8057834  0.58269208\n",
      " 0.07706332 0.00619902 0.01319163 0.8057834  0.77711945 0.08228885\n",
      " 0.89077049 0.08817623 0.92073707 0.63686827 0.8357926  0.96784377\n",
      " 0.07329565 0.39822891 0.74538314 0.17547205 0.39026128 0.01319163\n",
      " 0.14713102 0.17547205 0.53188717 0.07760929 0.65158788 0.82939734\n",
      " 0.5058045  0.00213537 0.59271935]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.92\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[17  2]\n",
      " [ 1 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.9285714285714286\n",
      "specificity:  0.8947368421052632\n",
      "precision:  0.8666666666666667\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92        19\n",
      "           1       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.91      0.91      0.91        33\n",
      "weighted avg       0.91      0.91      0.91        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  2\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.6s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.31706383 0.39236468 0.49024493 0.5        0.51578521 0.55659075\n",
      " 0.31714627 0.25439737 0.31719412 0.51578521 0.89313075 0.23480234\n",
      " 0.99395108 0.31699672 0.63596841 0.5574319  0.64557839 0.60995791\n",
      " 0.31707538 0.84529885 0.53196813 0.47612847 0.94067395 0.31719412\n",
      " 0.42700839 0.47612847 0.34436148 0.5        0.75451142 0.50664964\n",
      " 0.38528638 0.26988567 0.47706442]\n",
      "\n",
      " yhat\n",
      "[0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.79\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12  7]\n",
      " [ 4 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6666666666666666\n",
      "recall:  0.7142857142857143\n",
      "specificity:  0.631578947368421\n",
      "precision:  0.5882352941176471\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69        19\n",
      "           1       0.59      0.71      0.65        14\n",
      "\n",
      "    accuracy                           0.67        33\n",
      "   macro avg       0.67      0.67      0.67        33\n",
      "weighted avg       0.68      0.67      0.67        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  2\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:48:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:48:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.48183596 0.48762822 0.5122712  0.58247876 0.59354955 0.6026421\n",
      " 0.4505674  0.38511163 0.3932997  0.59354955 0.57012856 0.41156262\n",
      " 0.6014575  0.48149842 0.53980684 0.614033   0.58230156 0.6041154\n",
      " 0.48922178 0.53728086 0.5093049  0.44633573 0.496652   0.3932997\n",
      " 0.46452874 0.44633573 0.57802033 0.5108042  0.5210121  0.58221865\n",
      " 0.584187   0.3932997  0.5035618 ]\n",
      "\n",
      " yhat\n",
      "[0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.85\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[13  6]\n",
      " [ 1 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7878787878787878\n",
      "recall:  0.9285714285714286\n",
      "specificity:  0.6842105263157895\n",
      "precision:  0.6842105263157895\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.68      0.79        19\n",
      "           1       0.68      0.93      0.79        14\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.81      0.81      0.79        33\n",
      "weighted avg       0.82      0.79      0.79        33\n",
      "\n",
      "\n",
      "KFold:  3\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-6.52886168e-01 -7.21596752e-01 -3.52196038e-01 -3.96052435e-01\n",
      "  -9.23054443e-03 -5.74949631e-01 -9.69961612e-01 -1.24478130e-01\n",
      "  -4.25296505e-01 -2.07360145e-01]\n",
      " [-6.65920799e-01 -8.04437349e-01 -4.05351558e-01 -1.42600305e-01\n",
      "  -2.50994572e-01 -4.39396729e-01 -7.43023930e-01 -3.97942119e-01\n",
      "  -4.78988404e-01 -3.92899180e-01]\n",
      " [-8.06730431e-01 -3.43730805e+00 -1.60376566e-01 -1.42206357e+00\n",
      "   2.10253186e-01 -2.60046186e+00  1.00001983e+01  2.72348494e+01\n",
      "  -2.01032507e+00  1.24703445e+00]\n",
      " [-6.96386922e-01 -1.50255686e-01 -6.92051857e-01  4.11919290e-02\n",
      "  -1.68654673e+00 -4.60998106e-01  1.23520035e-01  4.46059928e-02\n",
      "   2.58045746e+00  6.68711269e-01]\n",
      " [-5.25959665e-01 -1.89706201e-01 -5.34904234e-02  3.06966304e-01\n",
      "  -9.57164583e-01 -3.38718577e-01 -7.39805403e-01 -7.92530853e-01\n",
      "  -6.97734986e-01 -7.30596713e-01]\n",
      " [-6.62245116e-01 -8.39362692e-01 -3.18589857e-01 -1.65919104e-01\n",
      "  -1.92982305e-01 -4.31856612e-01 -7.56545328e-01 -3.64372916e-01\n",
      "  -4.84745418e-01 -4.79376897e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 -3.15025734e-01\n",
      "  -3.54722328e-01 -4.58269257e-01 -5.71840389e-01 -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " [-6.70197753e-01 -8.29152762e-01  7.48397367e-02 -3.21331661e-02\n",
      "  -5.28740152e-01 -6.22655554e-01 -7.28783620e-01 -3.63718925e-01\n",
      "  -5.89030889e-01  2.67598097e-01]\n",
      " [-7.94066851e-02 -1.37672406e+00 -2.18898703e-01 -4.35668466e-01\n",
      "  -4.30473996e-01 -4.81127900e-01 -1.20834858e+00 -7.42099181e-01\n",
      "  -1.56672025e-02  2.23188178e+00]\n",
      " [-4.93202766e-01  2.12390404e+00 -2.74219717e-01  3.97958027e-01\n",
      "   2.42630825e-01  3.83506318e-02 -9.54530303e-01 -3.23913090e-01\n",
      "  -8.43674078e-01 -3.53703922e-01]\n",
      " [-6.77190369e-01  1.35307736e+00 -3.89631128e-01  8.68312687e-01\n",
      "  -1.91890932e+00 -4.03225734e-01 -3.59489065e-01 -7.15762590e-01\n",
      "  -8.14594106e-01 -6.62996752e-01]\n",
      " [-6.52886168e-01 -7.21596752e-01 -3.52196038e-01 -3.96052435e-01\n",
      "  -9.23054443e-03 -5.74949631e-01 -9.69961612e-01 -1.24478130e-01\n",
      "  -4.25296505e-01 -2.07360145e-01]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-7.09515866e-01 -9.44590683e-01 -2.94754834e-01 -1.57224207e-01\n",
      "  -1.19929587e-01 -6.06569851e-01 -8.21016822e-01 -2.53669999e-01\n",
      "  -5.40667291e-01 -5.30721741e-01]\n",
      " [-1.41365258e-01 -1.38379979e+00 -6.09577900e-01 -1.84524789e+00\n",
      "   7.42520873e-01 -1.72105812e-01 -1.58014594e+00 -2.12553397e+00\n",
      "   2.46004938e+00 -2.42567935e-01]\n",
      " [-5.81800874e-01 -2.45852420e-01  2.53545846e-01  1.67852910e+00\n",
      "  -3.03838915e+00 -1.20821668e-01 -1.63710819e+00 -3.27358000e+00\n",
      "  -4.54244529e+00 -5.19684926e+00]\n",
      " [-4.69137122e-01 -9.61362594e-01 -2.47152868e-02  1.65022741e-01\n",
      "  -2.33960039e-01 -5.41408767e-01 -9.65979165e-01 -6.01239076e-01\n",
      "  -5.79066885e-01 -5.39796418e-01]\n",
      " [ 1.52703206e-01  9.37144088e-01 -1.69742239e-01 -1.77897963e+00\n",
      "   1.84242165e+00 -2.98271754e-01 -1.66031360e+00 -3.54783557e-01\n",
      "  -2.58691619e-01 -1.67913039e-01]\n",
      " [-6.54108660e-01  8.11936295e-01  1.27361458e-01 -6.14206259e-01\n",
      "   3.96654768e-01 -3.71855288e-01 -1.31417850e+00 -3.47591621e-01\n",
      "  -1.21053148e+00 -3.70796153e-01]\n",
      " [-8.06730431e-01 -3.43730805e+00 -1.60376566e-01 -1.42206357e+00\n",
      "   2.10253186e-01 -2.60046186e+00  1.00001983e+01  2.72348494e+01\n",
      "  -2.01032507e+00  1.24703445e+00]\n",
      " [-3.69992500e-01 -8.07051229e-01  2.34222208e-01  2.70579644e-01\n",
      "   5.27700414e-02 -5.12579052e-01 -1.00866300e+00 -7.90934380e-01\n",
      "  -5.71220885e-01 -3.88835847e-01]\n",
      " [-7.12649543e-01 -1.17587761e+00 -4.92105252e-01  8.24983932e-01\n",
      "   5.19229828e-01  1.05685552e-01 -2.78648742e-01  2.20331651e-01\n",
      "  -6.24611152e-01  6.60894008e-01]\n",
      " [-6.46415451e-01 -9.50201353e-01 -3.27913045e-01 -3.55046760e-02\n",
      "  -2.57969818e-01 -4.41252230e-01 -9.06852354e-01 -5.89355404e-01\n",
      "  -2.76160254e-01 -6.29615970e-01]\n",
      " [-6.80104291e-01 -1.06766516e+00 -5.13045150e-01 -6.88473610e-02\n",
      "  -3.17141659e-01 -5.68964751e-01 -7.32124307e-01 -1.87837348e-01\n",
      "  -3.95847403e-01 -2.63949097e-01]\n",
      " [-6.57498507e-01 -9.40141565e-01 -4.68343203e-01 -9.75774248e-02\n",
      "  -1.73390175e-01 -5.02730174e-01 -6.53869701e-01 -2.50627934e-01\n",
      "  -4.14595743e-01 -4.77860038e-01]\n",
      " [-6.65726416e-01 -5.52121705e-01 -4.40254868e-01 -2.43024797e-01\n",
      "  -2.28064693e-01 -4.07187440e-01 -7.19079213e-01 -1.34828838e-01\n",
      "  -5.34717838e-01 -1.72673222e-01]\n",
      " [-6.54971390e-01 -9.58615255e-01 -1.13173051e-01 -1.12152481e-01\n",
      "  -5.87267103e-01  5.94753398e-02 -6.97426053e-01 -1.91378099e-01\n",
      "  -8.02516731e-01 -1.10654946e-01]\n",
      " [-5.10844553e-01 -3.27247718e-01 -5.33892437e-01 -1.02501514e+00\n",
      "   8.18080079e-01 -6.00122361e-01 -2.18608959e-01 -9.79057743e-01\n",
      "  -4.01676567e-01 -4.62381306e-01]\n",
      " [-6.48114165e-01 -1.22128902e+00 -3.95997092e-02 -2.14097980e-01\n",
      "  -3.68200141e-01 -6.13777381e-01 -1.17340968e+00 -1.03269446e+00\n",
      "  -4.34531280e-01 -2.81551728e-02]\n",
      " [-6.95507568e-01 -8.22583317e-01 -5.31373116e-01 -1.57157281e-01\n",
      "  -3.49773871e-01 -6.30578190e-01 -5.40251594e-01 -2.57062060e-01\n",
      "  -5.22155601e-01 -7.01261539e-01]\n",
      " [-6.92582049e-01 -3.66979814e-01 -8.16860757e-01 -1.91791942e-01\n",
      "  -4.72512251e-01  2.20023351e+00 -9.77961242e-02 -2.58114508e+00\n",
      "  -8.77536858e-01 -2.68672529e+00]\n",
      " [-6.74579785e-01 -6.68817738e-01 -4.79229340e-01 -8.09935034e-02\n",
      "  -3.14617599e-01 -5.69994317e-01 -3.76146909e-01 -6.61764436e-01\n",
      "  -5.69789287e-01 -5.77001252e-01]\n",
      " [-6.64442978e-01  3.07781177e+01  2.19542683e+00 -1.92997167e+01\n",
      "   2.98307133e+01  2.55772978e-01 -1.45753539e+01  5.54276342e+00\n",
      "  -3.99200004e+00  1.18366385e+00]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  3\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.9387688280422692\n",
      "\n",
      " Coefficients \n",
      "[ 2.03038297 -0.26953485  2.26045935  0.37428178  0.22954624 -0.11404605\n",
      " -0.0767174  -0.35819101 -0.1164365   0.59141426]\n",
      "\n",
      " pop_polarity\n",
      "[4.93158270e-01 4.62398469e-01 1.40025108e-04 2.22943448e-01\n",
      " 6.73638189e-01 5.01143848e-01 3.03613475e-01 7.89401229e-01\n",
      " 9.57997103e-01 5.05904752e-01 3.17685076e-01 4.93158270e-01\n",
      " 2.06615282e-01 4.93056853e-01 6.45405015e-01 5.23740801e-01\n",
      " 7.85320648e-01 8.30460528e-01 6.74867045e-01 1.40025108e-04\n",
      " 9.09174739e-01 6.26757219e-01 5.14860354e-01 4.17196987e-01\n",
      " 4.21927393e-01 4.27380596e-01 6.40600779e-01 4.49244738e-01\n",
      " 7.79323597e-01 3.22912336e-01 9.96674606e-02 4.06023015e-01\n",
      " 5.46340070e-02]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.87\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[14  3]\n",
      " [ 4 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7878787878787878\n",
      "recall:  0.75\n",
      "specificity:  0.8235294117647058\n",
      "precision:  0.8\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        17\n",
      "           1       0.80      0.75      0.77        16\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.79      0.79      0.79        33\n",
      "weighted avg       0.79      0.79      0.79        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  3\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[4.08934521e-001 4.52044207e-001 5.12241729e-164 1.49157621e-001\n",
      " 4.22882668e-001 4.44546982e-001 4.32084185e-001 5.71242940e-001\n",
      " 9.99284116e-001 1.10817820e-003 2.31103841e-002 4.08934521e-001\n",
      " 2.23405632e-001 4.54911420e-001 5.86561396e-001 9.26810576e-001\n",
      " 5.17940507e-001 9.98311161e-001 8.77320490e-002 5.12241729e-164\n",
      " 7.34366031e-001 5.31787429e-001 4.42243645e-001 4.36401443e-001\n",
      " 4.34183408e-001 4.28742069e-001 4.36036838e-001 4.23356999e-001\n",
      " 4.26208406e-001 4.64832700e-001 2.97495323e-001 4.61437617e-001\n",
      " 0.00000000e+000]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.74\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[16  1]\n",
      " [ 9  7]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.696969696969697\n",
      "recall:  0.4375\n",
      "specificity:  0.9411764705882353\n",
      "precision:  0.875\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.94      0.76        17\n",
      "           1       0.88      0.44      0.58        16\n",
      "\n",
      "    accuracy                           0.70        33\n",
      "   macro avg       0.76      0.69      0.67        33\n",
      "weighted avg       0.75      0.70      0.68        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  3\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.11502959 0.76150313 0.03068533 0.09020787 0.8432566  0.12984751\n",
      " 0.05466196 0.8246451  0.88580824 0.63935459 0.78834785 0.11502959\n",
      " 0.00206004 0.6434141  0.16562339 0.94527333 0.97483017 0.48312994\n",
      " 0.07987359 0.03068533 0.95288001 0.65583669 0.89366383 0.079007\n",
      " 0.09106242 0.19351103 0.75529799 0.61064244 0.82608401 0.03536818\n",
      " 0.17782482 0.13508012 0.04179468]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[17  0]\n",
      " [ 1 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9696969696969697\n",
      "recall:  0.9375\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        17\n",
      "           1       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.97        33\n",
      "   macro avg       0.97      0.97      0.97        33\n",
      "weighted avg       0.97      0.97      0.97        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  3\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    1.3s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.9s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.46929088 0.45809556 0.00256075 0.34536485 0.5688194  0.47570063\n",
      " 0.38123374 0.62341847 0.77268709 0.48131033 0.41416804 0.46929088\n",
      " 0.35041436 0.46977229 0.57237573 0.56787897 0.61495348 0.65005362\n",
      " 0.5762054  0.00256075 0.71206722 0.48665239 0.48333746 0.42995565\n",
      " 0.43409894 0.44035631 0.5410026  0.46366753 0.62675419 0.393744\n",
      " 0.29953403 0.43709973 0.37665611]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.88\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[14  3]\n",
      " [ 4 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7878787878787878\n",
      "recall:  0.75\n",
      "specificity:  0.8235294117647058\n",
      "precision:  0.8\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        17\n",
      "           1       0.80      0.75      0.77        16\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.79      0.79      0.79        33\n",
      "weighted avg       0.79      0.79      0.79        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  3\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:48:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:48:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.4391255  0.47744337 0.46307018 0.4702383  0.5917085  0.47744337\n",
      " 0.41432688 0.5328753  0.56543595 0.603017   0.5509265  0.4391255\n",
      " 0.39011738 0.4914649  0.48709065 0.5352729  0.67169714 0.51239014\n",
      " 0.44477677 0.46307018 0.65767556 0.50303155 0.599937   0.44125777\n",
      " 0.44125777 0.42723623 0.47552323 0.51768804 0.55311316 0.42723623\n",
      " 0.441476   0.48934484 0.4741005 ]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[17  0]\n",
      " [ 3 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.8125\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       1.00      0.81      0.90        16\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.93      0.91      0.91        33\n",
      "weighted avg       0.92      0.91      0.91        33\n",
      "\n",
      "\n",
      "KFold:  4\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-7.17720651e-01 -9.81011413e-01 -7.03213388e-01 -3.16040812e-02\n",
      "  -5.92323461e-01  8.72749427e-01 -1.35282912e+00 -1.33090424e+00\n",
      "  -5.17278984e-01 -1.46270671e+00]\n",
      " [-6.95507568e-01 -8.22583317e-01 -5.31373116e-01 -1.57157281e-01\n",
      "  -3.49773871e-01 -6.30578190e-01 -5.40251594e-01 -2.57062060e-01\n",
      "  -5.22155601e-01 -7.01261539e-01]\n",
      " [-6.66377253e-01 -9.68466880e-01 -4.59067460e-01 -1.85842233e-01\n",
      "  -2.65091264e-01 -4.75564003e-01 -5.81013101e-01 -1.40137364e-02\n",
      "  -5.44620808e-01 -4.43717596e-01]\n",
      " [-6.96386922e-01 -1.50255686e-01 -6.92051857e-01  4.11919290e-02\n",
      "  -1.68654673e+00 -4.60998106e-01  1.23520035e-01  4.46059928e-02\n",
      "   2.58045746e+00  6.68711269e-01]\n",
      " [-6.54108660e-01  8.11936295e-01  1.27361458e-01 -6.14206259e-01\n",
      "   3.96654768e-01 -3.71855288e-01 -1.31417850e+00 -3.47591621e-01\n",
      "  -1.21053148e+00 -3.70796153e-01]\n",
      " [-6.90357250e-01 -9.09252379e-01 -5.75537996e-01  1.99423674e-01\n",
      "  -9.09097473e-01 -3.34646419e-01 -7.10952783e-01 -8.31696565e-01\n",
      "   1.97229061e-01 -1.22895647e+00]\n",
      " [-7.32121623e-01 -1.13582618e+00 -4.10986611e-01 -3.48146277e-01\n",
      "  -2.52114706e-01 -8.86580672e-01 -1.46172368e+00 -1.07103845e+00\n",
      "  -8.64576211e-01 -1.06369306e+00]\n",
      " [-4.80656568e-01 -1.11688550e+00 -3.39186936e-01 -2.23743618e-01\n",
      "  -2.79135024e-01 -6.40300247e-01 -1.03317915e+00 -6.55734985e-01\n",
      "  -5.76068711e-01  1.43811118e+00]\n",
      " [-6.57498507e-01 -9.40141565e-01 -4.68343203e-01 -9.75774248e-02\n",
      "  -1.73390175e-01 -5.02730174e-01 -6.53869701e-01 -2.50627934e-01\n",
      "  -4.14595743e-01 -4.77860038e-01]\n",
      " [-6.74998166e-01 -8.54406858e-01 -4.38161928e-01 -1.48981664e-01\n",
      "  -3.07437382e-01 -4.99084632e-01 -7.30826072e-01 -3.38632514e-01\n",
      "  -5.10319022e-01 -3.91201883e-01]\n",
      " [-6.38058410e-01 -9.01546300e-01 -4.54645376e-01 -7.73830045e-02\n",
      "  -3.64035940e-01 -5.26424575e-01 -9.86489778e-01 -5.87823962e-01\n",
      "  -6.39024432e-01 -6.52553258e-01]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-1.71650922e-02  8.64783922e+00  1.80672873e+00 -5.39300373e-01\n",
      "  -4.65324487e+00  6.58610632e+00 -3.22294288e+00  5.35035438e+00\n",
      "   5.20147583e+01  1.37084741e+00]\n",
      " [-4.01210687e-01 -6.90816642e-01 -2.61735634e-01  4.81026074e-01\n",
      "   3.50515701e-01  4.98791360e-01 -3.86893367e-01 -1.14212168e+00\n",
      "  -1.98405127e-01  8.22994930e-01]\n",
      " [-1.15702662e-01 -8.23761766e-01  4.10882631e-01 -5.79660991e+00\n",
      "   4.74777357e+00  4.38616305e+01  1.59263520e+01 -2.66924270e+00\n",
      "  -3.81322603e+00  7.50995644e-01]\n",
      " [ 1.21517799e-01  1.69728381e-01 -5.89916425e-01  6.95140868e-02\n",
      "  -3.03067584e-01 -2.15439649e+00  1.96662617e+00 -1.21588450e+00\n",
      "  -3.51429988e-01  2.52708030e+00]\n",
      " [-6.65726416e-01 -5.52121705e-01 -4.40254868e-01 -2.43024797e-01\n",
      "  -2.28064693e-01 -4.07187440e-01 -7.19079213e-01 -1.34828838e-01\n",
      "  -5.34717838e-01 -1.72673222e-01]\n",
      " [-8.06730431e-01 -3.43730805e+00 -1.60376566e-01 -1.42206357e+00\n",
      "   2.10253186e-01 -2.60046186e+00  1.00001983e+01  2.72348494e+01\n",
      "  -2.01032507e+00  1.24703445e+00]\n",
      " [-5.94239061e-01 -1.41761934e+00 -8.55183080e-01 -1.51644268e-01\n",
      "  -2.10272671e-01 -1.98354123e-01  9.10177625e-01  1.32723256e+00\n",
      "  -7.53521881e-01  1.55332085e+00]\n",
      " [-1.74675166e-01 -6.11520076e-01 -4.65723254e-01 -4.83048766e-02\n",
      "  -5.98892211e-01 -7.52010383e-01 -4.39375869e-01  4.50920510e-01\n",
      "  -5.75175770e-01  9.60529831e-01]\n",
      " [-1.53559556e-01  3.47770655e+01  1.09985556e+00  1.32459048e+01\n",
      "  -2.06416506e+01  2.42037503e-01  8.21267759e+00 -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-6.61539900e-01 -1.46529854e+00 -4.64964921e-01 -1.09148046e-02\n",
      "  -9.05695583e-01 -3.20012220e-01 -8.03282442e-01 -6.64092574e-01\n",
      "  -1.23610033e+00 -1.46592261e+00]\n",
      " [-5.79608782e-01 -2.14018728e+00 -4.53461024e-01 -4.12979470e-01\n",
      "  -2.01911381e-01 -5.43075725e-01 -7.11739914e-01  1.15514746e+00\n",
      "  -2.11684000e+00 -2.02322492e+00]\n",
      " [-7.01040154e-01 -8.07565834e-01 -2.61882189e-01  1.67775529e+00\n",
      "   1.17409546e+00 -3.86957512e-01 -1.13211670e+00 -5.34564145e-01\n",
      "  -2.25647985e-01 -5.75743084e-01]\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 -5.29046618e-01\n",
      "  -3.59634159e-01 -8.51907233e-01 -8.85718383e-01 -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.79938715e-01  1.77341766e+00 -1.27545334e-01 -3.99596718e-01\n",
      "  -6.44320622e-01  1.57979067e+00 -5.29588149e-01 -3.75161052e-03\n",
      "   2.30959948e+00  2.85527905e-01]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-3.01322587e-01 -1.78297595e+00 -1.91468579e-01 -1.11412722e-01\n",
      "  -5.68083597e-01 -7.52537396e-01 -1.18569355e+00 -5.95699933e-01\n",
      "  -1.31408035e+00  3.90768569e+00]\n",
      " [-6.38058410e-01 -9.01546300e-01 -4.54645376e-01 -7.73830045e-02\n",
      "  -3.64035940e-01 -5.26424575e-01 -9.86489778e-01 -5.87823962e-01\n",
      "  -6.39024432e-01 -6.52553258e-01]\n",
      " [-3.07615855e-01 -1.81617565e+00 -1.04797605e+00  8.22323850e-01\n",
      "   7.24227465e-01  6.06453475e+00 -2.70917871e-01 -4.65213547e+00\n",
      "   1.77632481e+00  2.36414898e+01]\n",
      " [-6.82029589e-01 -8.84882570e-01 -7.30968418e-01 -1.32285211e-01\n",
      "  -7.60390019e-01 -8.90881355e-01  4.40735442e-01  2.60409130e-02\n",
      "   9.30108512e-02 -1.06075863e+00]\n",
      " [-6.87944592e-01 -1.03978258e+00 -4.84036716e-01 -3.01648309e-01\n",
      "  -1.39841363e-01 -2.82938217e-01 -7.71398998e-01 -4.68933780e-01\n",
      "  -5.77854859e-01 -1.40557438e-01]\n",
      " [-6.40326015e-01 -1.56441218e-01  9.80055117e-04  8.30266269e-02\n",
      "  -9.03336319e-01 -4.62987581e-01 -4.69489967e-01 -5.11009787e-01\n",
      "  -4.97442472e-01 -6.62112722e-01]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  4\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.6790140659132429\n",
      "\n",
      " Coefficients \n",
      "[ 1.78570303 -0.24694515  2.04116164  0.39186229  0.21626894 -0.1017121\n",
      " -0.06717967 -0.34840727 -0.1680354   0.52011311]\n",
      "\n",
      " pop_polarity\n",
      "[2.41538111e-01 3.38794345e-01 4.04693005e-01 2.05646519e-01\n",
      " 6.62241596e-01 2.84301834e-01 4.44203195e-01 8.12130201e-01\n",
      " 4.27731400e-01 4.41655674e-01 4.54575850e-01 2.32898575e-01\n",
      " 2.33560464e-04 8.45246259e-01 9.11217968e-02 9.23841963e-01\n",
      " 4.30483665e-01 1.73076641e-04 3.89032895e-01 7.23957264e-01\n",
      " 2.80448445e-02 3.71328964e-01 2.77964000e-01 7.39532355e-01\n",
      " 2.67053703e-01 3.28675413e-01 2.32898575e-01 9.74441548e-01\n",
      " 4.54575850e-01 9.99997595e-01 1.75941022e-01 4.59799035e-01\n",
      " 6.00913259e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.93\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[20  1]\n",
      " [ 4  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8484848484848485\n",
      "recall:  0.6666666666666666\n",
      "specificity:  0.9523809523809523\n",
      "precision:  0.8888888888888888\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89        21\n",
      "           1       0.89      0.67      0.76        12\n",
      "\n",
      "    accuracy                           0.85        33\n",
      "   macro avg       0.86      0.81      0.83        33\n",
      "weighted avg       0.85      0.85      0.84        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  4\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[4.38423859e-001 4.66804266e-001 4.01642496e-001 1.48230583e-001\n",
      " 1.04349021e-001 5.51448379e-001 3.89969556e-001 8.27096284e-001\n",
      " 4.34232644e-001 4.52336909e-001 4.29510226e-001 2.26240159e-001\n",
      " 1.32988157e-291 7.60661565e-001 5.22676296e-317 9.99871818e-001\n",
      " 4.31862496e-001 1.26205901e-178 2.14325219e-001 9.70017593e-001\n",
      " 0.00000000e+000 4.23568251e-001 4.93028484e-002 4.95394452e-001\n",
      " 4.26480212e-001 7.23696018e-004 2.26240159e-001 9.99896562e-001\n",
      " 4.29510226e-001 1.00000000e+000 3.40098623e-001 4.71843148e-001\n",
      " 4.31237085e-001]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[20  1]\n",
      " [ 6  6]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7878787878787878\n",
      "recall:  0.5\n",
      "specificity:  0.9523809523809523\n",
      "precision:  0.8571428571428571\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85        21\n",
      "           1       0.86      0.50      0.63        12\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.81      0.73      0.74        33\n",
      "weighted avg       0.80      0.79      0.77        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  4\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.00594511 0.04379705 0.15066892 0.0688273  0.08456037 0.00487767\n",
      " 0.6551525  0.97448639 0.08873761 0.88142305 0.43773299 0.01270681\n",
      " 0.26199207 0.86995425 0.10413878 0.60001963 0.1377759  0.04839356\n",
      " 0.04324206 0.69438227 0.06845007 0.07825487 0.06140207 0.77212959\n",
      " 0.03560825 0.78491753 0.01270681 0.82937692 0.43773299 0.55681215\n",
      " 0.0076917  0.4995611  0.9288943 ]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[21  0]\n",
      " [ 1 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9696969696969697\n",
      "recall:  0.9166666666666666\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        21\n",
      "           1       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        33\n",
      "   macro avg       0.98      0.96      0.97        33\n",
      "weighted avg       0.97      0.97      0.97        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  4\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   16.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[2.97089618e-01 3.53608651e-01 3.99248038e-01 2.00068739e-01\n",
      " 6.55710819e-01 3.19477662e-01 4.51651061e-01 7.45495995e-01\n",
      " 4.28075663e-01 4.36318046e-01 4.58873831e-01 2.69034625e-01\n",
      " 4.70823470e-04 8.26371035e-01 3.15219176e-01 8.95927813e-01\n",
      " 4.24366089e-01 4.43204528e-05 3.31183391e-01 6.67960175e-01\n",
      " 3.16164656e-01 3.88228916e-01 2.82521917e-01 7.60626103e-01\n",
      " 3.15828772e-01 3.63319633e-01 2.69034625e-01 9.36881156e-01\n",
      " 4.58873831e-01 9.99999988e-01 2.00492235e-01 4.46405803e-01\n",
      " 5.87422626e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.93\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[20  1]\n",
      " [ 4  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8484848484848485\n",
      "recall:  0.6666666666666666\n",
      "specificity:  0.9523809523809523\n",
      "precision:  0.8888888888888888\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89        21\n",
      "           1       0.89      0.67      0.76        12\n",
      "\n",
      "    accuracy                           0.85        33\n",
      "   macro avg       0.86      0.81      0.83        33\n",
      "weighted avg       0.85      0.85      0.84        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  4\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:49:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:49:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.39635846 0.4295096  0.44582966 0.47034234 0.4528001  0.3848491\n",
      " 0.450894   0.6699008  0.44582966 0.5021264  0.6208749  0.38941708\n",
      " 0.5        0.6226037  0.4813291  0.57141304 0.4295096  0.44651496\n",
      " 0.49193898 0.5621785  0.4825238  0.3848491  0.44816202 0.5647673\n",
      " 0.45543286 0.53269285 0.38941708 0.5801408  0.6208749  0.5401431\n",
      " 0.3811064  0.5454017  0.6063082 ]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.89\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[19  2]\n",
      " [ 1 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.9166666666666666\n",
      "specificity:  0.9047619047619048\n",
      "precision:  0.8461538461538461\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        21\n",
      "           1       0.85      0.92      0.88        12\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.90      0.91      0.90        33\n",
      "weighted avg       0.91      0.91      0.91        33\n",
      "\n",
      "\n",
      "KFold:  5\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-6.66377253e-01 -9.68466880e-01 -4.59067460e-01 -1.85842233e-01\n",
      "  -2.65091264e-01 -4.75564003e-01 -5.81013101e-01 -1.40137364e-02\n",
      "  -5.44620808e-01 -4.43717596e-01]\n",
      " [-6.06149762e-01  5.32650767e-01  3.29382907e-01 -3.71549582e-01\n",
      "  -7.90165259e-01 -5.61311674e-01 -4.92570789e-01 -1.19963258e+00\n",
      "   3.12898307e+00  7.48977161e-01]\n",
      " [-6.85150964e-01 -6.91778304e-01 -4.32795597e-01 -5.34553002e-02\n",
      "  -5.11281758e-01 -5.74875684e-01 -7.86736019e-01 -6.82861574e-01\n",
      "  -6.72052043e-01  1.82799951e-01]\n",
      " [-6.82748432e-01 -7.50546933e-01 -4.78398149e-01 -9.12310125e-02\n",
      "  -3.70732979e-01 -4.76423429e-01 -8.25805592e-01 -4.52928261e-01\n",
      "  -5.08160624e-01 -5.70654345e-01]\n",
      " [-3.78984114e-01  6.72300612e-01 -5.59629772e-01 -1.49168443e+00\n",
      "   2.39871336e+00 -7.78441846e-01 -1.62345739e+00 -2.54354230e-01\n",
      "  -2.79209100e-02  4.69671402e-01]\n",
      " [-6.33216384e-01 -5.23503781e-01 -5.61408350e-01  1.06686343e+00\n",
      "   2.50791510e-01 -5.87985993e-01 -5.44085732e-01  3.69189040e-01\n",
      "  -4.59755341e-01 -7.20669710e-01]\n",
      " [-6.62245116e-01 -8.39362692e-01 -3.18589857e-01 -1.65919104e-01\n",
      "  -1.92982305e-01 -4.31856612e-01 -7.56545328e-01 -3.64372916e-01\n",
      "  -4.84745418e-01 -4.79376897e-01]\n",
      " [-5.94239061e-01 -1.41761934e+00 -8.55183080e-01 -1.51644268e-01\n",
      "  -2.10272671e-01 -1.98354123e-01  9.10177625e-01  1.32723256e+00\n",
      "  -7.53521881e-01  1.55332085e+00]\n",
      " [-6.90357250e-01 -9.09252379e-01 -5.75537996e-01  1.99423674e-01\n",
      "  -9.09097473e-01 -3.34646419e-01 -7.10952783e-01 -8.31696565e-01\n",
      "   1.97229061e-01 -1.22895647e+00]\n",
      " [-6.25189347e-01 -8.13523314e-01  2.52201233e-01 -5.90572394e-02\n",
      "  -1.57966583e-01  1.50318534e-01 -7.84711226e-01 -8.04162817e-01\n",
      "  -4.08955225e-01 -2.29894133e-01]\n",
      " [-6.75906117e-01 -1.44897673e+00 -2.23032215e-01  1.04846181e-01\n",
      "  -1.01759983e-01  1.15474517e-01  8.61005053e-02  1.47277636e+00\n",
      "  -5.65004406e-01  5.69774756e-01]\n",
      " [-5.63262762e-01 -7.72507229e-01  2.29613324e-01  6.51248757e-01\n",
      "  -1.23171234e+00 -6.39361853e-02 -1.40006388e+00 -1.07432083e+00\n",
      "   7.94123590e-01  5.36134324e-01]\n",
      " [-6.05045952e-01 -9.15092373e-01 -8.73108139e-02 -5.15835445e-02\n",
      "  -4.59029752e-01 -4.22794239e-01 -8.74853360e-01 -7.12959718e-01\n",
      "  -4.74518853e-01 -6.09809875e-01]\n",
      " [-6.82029589e-01 -8.84882570e-01 -7.30968418e-01 -1.32285211e-01\n",
      "  -7.60390019e-01 -8.90881355e-01  4.40735442e-01  2.60409130e-02\n",
      "   9.30108512e-02 -1.06075863e+00]\n",
      " [-6.61539900e-01 -1.46529854e+00 -4.64964921e-01 -1.09148046e-02\n",
      "  -9.05695583e-01 -3.20012220e-01 -8.03282442e-01 -6.64092574e-01\n",
      "  -1.23610033e+00 -1.46592261e+00]\n",
      " [-6.61539900e-01 -1.46529854e+00 -4.64964921e-01 -1.09148046e-02\n",
      "  -9.05695583e-01 -3.20012220e-01 -8.03282442e-01 -6.64092574e-01\n",
      "  -1.23610033e+00 -1.46592261e+00]\n",
      " [-2.25534936e-01 -1.03195046e+00  2.08771412e+00 -2.28781079e-01\n",
      "  -4.11132296e-01 -1.03197473e+00  6.43179024e-01 -2.25517523e+00\n",
      "   6.90963607e-01  9.79195327e-01]\n",
      " [-5.43421267e-01 -1.07301119e+00 -3.68245990e-01  9.97491034e-01\n",
      "   3.19224317e-01  1.10601349e+00  1.47146268e-01  2.00204808e-01\n",
      "  -1.01884806e-01  1.94832566e-01]\n",
      " [-6.16688743e-01 -1.04488866e+00 -2.35110018e-01 -3.45551580e-01\n",
      "  -3.99967643e-01  3.37457096e-01 -5.78411791e-01 -1.24581383e-01\n",
      "   1.25053143e+00  1.16907042e+00]\n",
      " [-6.90357250e-01 -9.09252379e-01 -5.75537996e-01  1.99423674e-01\n",
      "  -9.09097473e-01 -3.34646419e-01 -7.10952783e-01 -8.31696565e-01\n",
      "   1.97229061e-01 -1.22895647e+00]\n",
      " [-6.52886168e-01 -7.21596752e-01 -3.52196038e-01 -3.96052435e-01\n",
      "  -9.23054443e-03 -5.74949631e-01 -9.69961612e-01 -1.24478130e-01\n",
      "  -4.25296505e-01 -2.07360145e-01]\n",
      " [ 3.66406840e-01 -4.57192052e-01  1.51001706e+00 -6.99169507e-02\n",
      "  -1.47509798e+00 -7.84835589e-01 -1.12241593e+00 -2.35705608e+00\n",
      "  -8.94002332e-01  2.83978094e+00]\n",
      " [-6.56768378e-01 -6.67676017e-01 -2.85456972e-01 -7.75337444e-02\n",
      "  -3.72893125e-01 -3.22990145e-01 -8.23508138e-01 -6.48170156e-01\n",
      "  -4.95269276e-01 -6.17054502e-01]\n",
      " [-1.30907449e-01 -3.88626495e-01 -1.92731366e-01  4.27873460e-01\n",
      "  -5.36344661e-01 -5.04937529e-01 -3.18854896e-01 -8.14871894e-01\n",
      "  -4.48101628e-02  2.56514693e-01]\n",
      " [-6.71162393e-01 -8.41483604e-01 -4.54418969e-01  2.96427351e-01\n",
      "  -2.25857269e-01 -3.74130961e-01 -8.83682844e-01 -6.29401476e-01\n",
      "  -3.34355889e-01 -5.29115620e-01]\n",
      " [-6.65581720e-01 -7.07048906e-01 -4.32035625e-01 -1.31851498e-01\n",
      "  -2.63574656e-01 -4.54430004e-01 -7.72768042e-01 -4.49143663e-01\n",
      "  -4.22617854e-01 -4.87022510e-01]\n",
      " [-5.46251736e-01 -2.46100239e-01 -3.73068604e-01 -6.43637068e-01\n",
      "   6.12839981e-01 -5.80441652e-01 -6.30511595e-01 -4.77023386e-01\n",
      "  -3.15929938e-01 -3.68371154e-01]\n",
      " [ 1.79165828e+02 -2.90221781e-01 -1.25146625e+00 -1.31478342e-01\n",
      "   2.38186995e-01 -3.80269399e-01 -1.12039371e-01  3.61201253e-01\n",
      "  -3.99946329e-01 -4.98663662e-01]\n",
      " [-5.21846301e-01 -6.08955532e-01 -2.32769961e-01 -1.04758791e-03\n",
      "  -3.76344948e-01 -4.73099267e-01 -6.54006087e-01 -2.85077006e-01\n",
      "  -4.50337008e-01 -3.66139483e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 -3.15025734e-01\n",
      "  -3.54722328e-01 -4.58269257e-01 -5.71840389e-01 -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " [-6.37142408e-01 -8.68509424e-01  1.36167886e-01  2.65840222e-01\n",
      "  -4.32233162e-01 -5.06855706e-01 -6.62414857e-01  1.81768419e-03\n",
      "  -7.93250118e-01  5.60834968e-02]\n",
      " [-6.42172769e-01 -2.92677605e-03 -3.02893493e-01  1.09487608e-01\n",
      "  -9.34270600e-01 -4.59826283e-01 -8.85921296e-01 -6.87361523e-01\n",
      "   7.68885502e-02 -5.83251538e-01]\n",
      " [-4.69568159e-01 -6.65718862e-01  6.91940124e-01  6.21148580e-02\n",
      "  -6.66088355e-01 -6.36351943e-01 -7.43066614e-01 -7.10242282e-01\n",
      "  -6.65804352e-01 -1.68065396e-03]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
      " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  5\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.9879753731132905\n",
      "\n",
      " Coefficients \n",
      "[ 2.15617222 -0.26248664  2.1597469   0.44980491  0.24777818 -0.11510004\n",
      " -0.0577576  -0.34818268 -0.17151505  0.51814343]\n",
      "\n",
      " pop_polarity\n",
      "[0.40643825 0.77761639 0.54144196 0.40094172 0.5570374  0.44166374\n",
      " 0.5062215  0.39024899 0.28051738 0.83083058 0.57743881 0.88733267\n",
      " 0.67060744 0.17157503 0.37275433 0.37275433 0.99934643 0.67771461\n",
      " 0.64553047 0.28051738 0.48990264 0.99976669 0.51973626 0.8756532\n",
      " 0.48852495 0.43886106 0.51599422 1.         0.62367948 0.30923541\n",
      " 0.80373511 0.44910637 0.95186169]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1]\n",
      "\n",
      " auc\n",
      "0.97\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[11  1]\n",
      " [ 3 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8787878787878788\n",
      "recall:  0.8571428571428571\n",
      "specificity:  0.9166666666666666\n",
      "precision:  0.9473684210526315\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        12\n",
      "           1       0.95      0.86      0.90        21\n",
      "\n",
      "    accuracy                           0.88        33\n",
      "   macro avg       0.87      0.89      0.87        33\n",
      "weighted avg       0.89      0.88      0.88        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  5\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[0.96868406 0.78328858 0.97908595 0.97490941 0.94351774 0.96312412\n",
      " 0.97362878 0.94068827 0.98177233 0.98390279 0.83104632 0.98379133\n",
      " 0.97689077 0.96048941 0.9730034  0.9730034  0.99999244 0.95072689\n",
      " 0.98446923 0.98177233 0.96975955 1.         0.97529808 0.99884126\n",
      " 0.97594191 0.97464992 0.97244454 1.         0.97735414 0.97032787\n",
      " 0.97799234 0.96285739 0.99528883]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " auc\n",
      "0.69\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 0 12]\n",
      " [ 0 21]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6363636363636364\n",
      "recall:  1.0\n",
      "specificity:  0.0\n",
      "precision:  0.6363636363636364\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.64      1.00      0.78        21\n",
      "\n",
      "    accuracy                           0.64        33\n",
      "   macro avg       0.32      0.50      0.39        33\n",
      "weighted avg       0.40      0.64      0.49        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  5\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.15112977 0.70373399 0.90536268 0.10574549 0.56875404 0.31383071\n",
      " 0.13990763 0.0596197  0.01764503 0.91655238 0.57004181 0.86675583\n",
      " 0.93318414 0.03436463 0.06142521 0.06142521 0.6881585  0.63278211\n",
      " 0.84388804 0.01764503 0.08269567 0.82738949 0.74731913 0.94756627\n",
      " 0.60061007 0.80974503 0.79405759 0.59071474 0.9050042  0.08331126\n",
      " 0.87153789 0.9533029  0.85695076]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 0 21]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  5\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.3s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.40273588 0.73631306 0.51035153 0.41482028 0.51948748 0.38912006\n",
      " 0.47685048 0.34455579 0.3485371  0.72272885 0.45939923 0.7881128\n",
      " 0.59178964 0.24100733 0.38808306 0.38808306 0.99086501 0.54480555\n",
      " 0.58288042 0.3485371  0.46523881 0.99487781 0.5        0.74261622\n",
      " 0.46538166 0.4389442  0.48982195 1.         0.54514604 0.34674199\n",
      " 0.67042922 0.46921088 0.85783989]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 4 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8787878787878788\n",
      "recall:  0.8095238095238095\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        12\n",
      "           1       1.00      0.81      0.89        21\n",
      "\n",
      "    accuracy                           0.88        33\n",
      "   macro avg       0.88      0.90      0.88        33\n",
      "weighted avg       0.91      0.88      0.88        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  5\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.43680412 0.52831846 0.572821   0.4526274  0.50050664 0.51879203\n",
      " 0.48352602 0.47858572 0.3966798  0.64355487 0.50890267 0.59362304\n",
      " 0.65759397 0.41540143 0.38519353 0.38519353 0.58102643 0.5804672\n",
      " 0.55440706 0.3966798  0.41770792 0.57340264 0.53180546 0.63136476\n",
      " 0.52179074 0.5025736  0.55217046 0.53004056 0.5952754  0.40348095\n",
      " 0.59027493 0.575927   0.61721563]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[11  1]\n",
      " [ 0 21]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9696969696969697\n",
      "recall:  1.0\n",
      "specificity:  0.9166666666666666\n",
      "precision:  0.9545454545454546\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.97        33\n",
      "   macro avg       0.98      0.96      0.97        33\n",
      "weighted avg       0.97      0.97      0.97        33\n",
      "\n",
      "\n",
      "KFold:  6\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-6.46913242e-01 -9.65448460e-01 -3.64974866e-01 -1.15367708e-01\n",
      "  -4.06583081e-01 -5.14759655e-01 -6.48933116e-01 -4.49575473e-01\n",
      "  -3.99556752e-01 -3.97321233e-01]\n",
      " [-6.59685915e-01 -8.31150128e-01 -4.04850509e-01 -1.68541817e-01\n",
      "  -1.99007330e-01 -4.27520589e-01 -7.16230725e-01 -3.51740605e-01\n",
      "  -4.53386756e-01 -4.25800609e-01]\n",
      " [-5.96646996e-01 -1.12237932e+00 -4.61488698e-01 -2.97585857e-01\n",
      "  -8.34804239e-02  7.20496708e-02 -7.33420279e-01 -5.89943710e-01\n",
      "  -8.10308096e-01  1.36970296e+00]\n",
      " [-6.78367209e-01 -1.08061063e+00 -4.08160056e-01 -1.16548446e-01\n",
      "  -3.46926797e-01 -6.36825858e-01 -1.01996517e+00 -7.30158313e-01\n",
      "  -5.92576555e-01  1.21697155e+00]\n",
      " [-6.74579785e-01 -6.68817738e-01 -4.79229340e-01 -8.09935034e-02\n",
      "  -3.14617599e-01 -5.69994317e-01 -3.76146909e-01 -6.61764436e-01\n",
      "  -5.69789287e-01 -5.77001252e-01]\n",
      " [-6.87160206e-01 -6.98979879e-01 -4.66522312e-01 -1.25589674e-01\n",
      "  -4.42679360e-01  3.64828620e-01 -5.62106090e-01 -6.35481885e-01\n",
      "  -5.21783487e-01 -5.78149137e-01]\n",
      " [-6.33216384e-01 -5.23503781e-01 -5.61408350e-01  1.06686343e+00\n",
      "   2.50791510e-01 -5.87985993e-01 -5.44085732e-01  3.69189040e-01\n",
      "  -4.59755341e-01 -7.20669710e-01]\n",
      " [-6.00671797e-01 -6.46684921e-01 -3.34913254e-02  7.87411941e-02\n",
      "  -5.93853692e-01  2.92915115e-01 -4.49587708e-01 -8.56067776e-01\n",
      "  -4.22076567e-01  2.56080314e-01]\n",
      " [ 7.61075913e-01 -1.42265682e+00 -5.09491153e-01  7.19210602e-01\n",
      "  -2.07326653e+00  8.11954301e-01 -3.58587385e+00 -2.76263428e+00\n",
      "   1.10283547e+01 -1.15316757e+00]\n",
      " [-6.98258830e-01 -1.77168755e+00 -3.31851007e-01  5.64204079e-02\n",
      "  -4.05471632e-01 -7.43334614e-01 -1.93309124e+00 -1.69779010e+00\n",
      "   1.12982948e-01  1.43471590e+00]\n",
      " [-6.95507568e-01 -8.22583317e-01 -5.31373116e-01 -1.57157281e-01\n",
      "  -3.49773871e-01 -6.30578190e-01 -5.40251594e-01 -2.57062060e-01\n",
      "  -5.22155601e-01 -7.01261539e-01]\n",
      " [-5.39263745e-01 -1.36778497e+00  2.35732865e-01 -8.64345283e-02\n",
      "  -5.63961346e-01 -6.67379155e-01 -1.32553583e+00 -1.44169865e+00\n",
      "   1.76335481e-01 -6.18594379e-01]\n",
      " [-5.35205957e-01  1.22183575e-01  3.54395920e-02  6.09804789e-01\n",
      "  -8.59757909e-01 -5.70730520e-01  8.29404870e-02 -4.52168443e-01\n",
      "  -6.05084569e-01 -9.31817589e-02]\n",
      " [ 3.14327486e-01 -3.28253647e+00  2.46340251e+00 -1.07620351e+00\n",
      "  -1.51336526e+00 -4.51791353e+00 -1.42906056e-01 -4.91473613e+00\n",
      "  -3.58023843e+00  7.10365181e+01]\n",
      " [-8.06730431e-01 -3.43730805e+00 -1.60376566e-01 -1.42206357e+00\n",
      "   2.10253186e-01 -2.60046186e+00  1.00001983e+01  2.72348494e+01\n",
      "  -2.01032507e+00  1.24703445e+00]\n",
      " [-6.74579785e-01 -6.68817738e-01 -4.79229340e-01 -8.09935034e-02\n",
      "  -3.14617599e-01 -5.69994317e-01 -3.76146909e-01 -6.61764436e-01\n",
      "  -5.69789287e-01 -5.77001252e-01]\n",
      " [-5.81800874e-01 -2.45852420e-01  2.53545846e-01  1.67852910e+00\n",
      "  -3.03838915e+00 -1.20821668e-01 -1.63710819e+00 -3.27358000e+00\n",
      "  -4.54244529e+00 -5.19684926e+00]\n",
      " [-6.89344599e-01 -6.66074339e-01 -5.49459635e-01  4.82265451e-02\n",
      "  -5.43802287e-01 -6.59700409e-02 -8.97498441e-01 -5.68195696e-01\n",
      "   8.33152734e-01 -4.25015332e-01]\n",
      " [-1.41365258e-01 -1.38379979e+00 -6.09577900e-01 -1.84524789e+00\n",
      "   7.42520873e-01 -1.72105812e-01 -1.58014594e+00 -2.12553397e+00\n",
      "   2.46004938e+00 -2.42567935e-01]\n",
      " [-6.73559865e-01 -9.69596822e-01 -3.74884149e-01 -2.10853086e-01\n",
      "  -2.30611151e-01  8.07184019e-02 -8.42277010e-01 -6.49391054e-01\n",
      "  -6.17425578e-01 -3.74803587e-01]\n",
      " [ 1.80388380e+00 -4.96279492e+00  8.96010590e+01  3.80592149e+00\n",
      "   1.90919952e+00 -1.95333953e+00  2.50462447e+00 -1.42642432e+00\n",
      "  -1.00135107e+00 -2.56253079e+00]\n",
      " [-6.25967887e-01 -1.17154073e+00 -7.14341521e-02 -1.57900532e-02\n",
      "  -4.16216847e-01 -5.94683864e-01 -1.05803855e+00 -3.36149083e-01\n",
      "  -8.52851038e-01 -7.68829293e-01]\n",
      " [-3.85193561e-01 -8.25876704e-01 -4.76764321e-01  1.90441236e-03\n",
      "  -2.68665914e-01 -1.72897888e-01 -3.06333533e-01 -5.33548259e-01\n",
      "  -2.60365054e-01 -7.02454950e-01]\n",
      " [-7.17720651e-01 -9.81011413e-01 -7.03213388e-01 -3.16040812e-02\n",
      "  -5.92323461e-01  8.72749427e-01 -1.35282912e+00 -1.33090424e+00\n",
      "  -5.17278984e-01 -1.46270671e+00]\n",
      " [-5.94239061e-01 -1.41761934e+00 -8.55183080e-01 -1.51644268e-01\n",
      "  -2.10272671e-01 -1.98354123e-01  9.10177625e-01  1.32723256e+00\n",
      "  -7.53521881e-01  1.55332085e+00]\n",
      " [-7.11203079e-01  2.87726326e+00 -7.60097673e-02 -1.92759709e+00\n",
      "   4.44243660e-01 -1.30838172e-01 -9.21229498e-01  6.36821068e+00\n",
      "   6.76395145e+00 -2.26668106e-01]\n",
      " [-4.70388989e-01 -1.26003543e+00  3.08603629e-02  7.24644346e-01\n",
      "   1.23856888e-02 -4.36093854e-01 -4.42721282e-01  6.17857205e-01\n",
      "  -1.07379264e+00  4.14945136e+00]\n",
      " [-6.74998166e-01 -8.54406858e-01 -4.38161928e-01 -1.48981664e-01\n",
      "  -3.07437382e-01 -4.99084632e-01 -7.30826072e-01 -3.38632514e-01\n",
      "  -5.10319022e-01 -3.91201883e-01]\n",
      " [-6.82029589e-01 -8.84882570e-01 -7.30968418e-01 -1.32285211e-01\n",
      "  -7.60390019e-01 -8.90881355e-01  4.40735442e-01  2.60409130e-02\n",
      "   9.30108512e-02 -1.06075863e+00]\n",
      " [-4.02752049e-01  7.48372459e-02 -4.74901370e-01 -1.01517755e+00\n",
      "   1.00195993e+00 -4.04047249e-01 -4.27677633e-01 -9.90626918e-01\n",
      "  -3.96005158e-01 -4.21260461e-02]\n",
      " [-7.13413712e-01 -1.37866348e+00  2.26512173e-01 -4.34534969e-01\n",
      "   5.49645355e-02 -3.33503756e+00  2.31430679e+00 -3.07265404e+00\n",
      "  -1.35330355e+00  1.04994117e+00]\n",
      " [-5.68637119e-01 -1.08630146e+00 -7.34032057e-01  1.08031910e-01\n",
      "  -6.62286960e-01 -4.25570143e-02  8.01226691e-02 -1.33054458e+00\n",
      "   6.64618990e-01 -1.46806854e+00]\n",
      " [-5.40538663e-01  3.56215579e-02  1.37723417e-01 -2.33923883e-01\n",
      "  -2.83781503e-01  2.08869000e+00 -1.90645937e-01 -7.79924758e-01\n",
      "   8.86021969e-01 -6.73632874e-01]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  6\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "2.3369938985417913\n",
      "\n",
      " Coefficients \n",
      "[ 2.62801108 -0.26482997  2.21270033  0.51574514  0.31181843 -0.1253163\n",
      " -0.0501046  -0.33749333 -0.1800231   0.58270799]\n",
      "\n",
      " pop_polarity\n",
      "[4.96969086e-01 4.55202539e-01 7.38159641e-01 7.23550418e-01\n",
      " 4.06372108e-01 3.62417954e-01 4.59317506e-01 7.70467531e-01\n",
      " 8.40765808e-01 8.47899229e-01 3.18508507e-01 8.61477475e-01\n",
      " 7.85421174e-01 1.00000000e+00 2.81887361e-04 4.06372108e-01\n",
      " 5.85135327e-01 3.07603367e-01 6.21725540e-01 4.89373964e-01\n",
      " 1.00000000e+00 6.57624614e-01 5.64714639e-01 1.98132973e-01\n",
      " 4.22338527e-01 8.54119067e-03 9.87381787e-01 4.31557766e-01\n",
      " 1.54743226e-01 6.10619113e-01 9.64969986e-01 2.36958311e-01\n",
      " 6.13397217e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.83\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[10  4]\n",
      " [ 6 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.696969696969697\n",
      "recall:  0.6842105263157895\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.7647058823529411\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.67        14\n",
      "           1       0.76      0.68      0.72        19\n",
      "\n",
      "    accuracy                           0.70        33\n",
      "   macro avg       0.69      0.70      0.69        33\n",
      "weighted avg       0.71      0.70      0.70        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  6\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.81048889e-001 9.81674685e-001 9.93777933e-001 9.93218131e-001\n",
      " 9.81816659e-001 9.81974357e-001 9.69727629e-001 9.86737959e-001\n",
      " 7.01253491e-011 9.55457103e-001 9.80965581e-001 9.58512375e-001\n",
      " 9.69792663e-001 1.00000000e+000 5.21026703e-194 9.81816659e-001\n",
      " 5.11765595e-001 9.74172707e-001 9.38645899e-001 9.80851336e-001\n",
      " 5.41355671e-145 9.71708388e-001 9.91486507e-001 9.68618995e-001\n",
      " 8.61815377e-001 6.62184166e-023 9.99987784e-001 9.81504149e-001\n",
      " 9.56527107e-001 9.85616170e-001 3.74319318e-003 9.63883300e-001\n",
      " 8.50340536e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.59\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 2 12]\n",
      " [ 3 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5454545454545454\n",
      "recall:  0.8421052631578947\n",
      "specificity:  0.14285714285714285\n",
      "precision:  0.5714285714285714\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.14      0.21        14\n",
      "           1       0.57      0.84      0.68        19\n",
      "\n",
      "    accuracy                           0.55        33\n",
      "   macro avg       0.49      0.49      0.45        33\n",
      "weighted avg       0.50      0.55      0.48        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  6\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.84153459 0.44855928 0.74154953 0.919321   0.17559273 0.25964277\n",
      " 0.48837823 0.90759543 0.53603305 0.83086012 0.07624761 0.89830293\n",
      " 0.35895695 0.67658973 0.03567205 0.17559273 0.87084152 0.41618534\n",
      " 0.20922484 0.92741281 0.61381261 0.82886368 0.43840863 0.00779924\n",
      " 0.10896745 0.228399   0.63361318 0.77697454 0.03130993 0.80934811\n",
      " 0.36878487 0.00695455 0.91893166]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.93\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[13  1]\n",
      " [ 4 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8484848484848485\n",
      "recall:  0.7894736842105263\n",
      "specificity:  0.9285714285714286\n",
      "precision:  0.9375\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84        14\n",
      "           1       0.94      0.79      0.86        19\n",
      "\n",
      "    accuracy                           0.85        33\n",
      "   macro avg       0.85      0.86      0.85        33\n",
      "weighted avg       0.86      0.85      0.85        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  6\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.3s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[4.71209163e-01 4.39304869e-01 6.70765598e-01 6.59804608e-01\n",
      " 4.11083224e-01 3.82356947e-01 4.40778777e-01 7.20960606e-01\n",
      " 8.64306897e-01 7.99190984e-01 3.28643686e-01 8.14263423e-01\n",
      " 7.29790710e-01 1.00000000e+00 1.72955532e-05 4.11083224e-01\n",
      " 6.53687043e-01 3.42413398e-01 6.34089824e-01 4.77185017e-01\n",
      " 1.00000000e+00 5.97498787e-01 5.36823214e-01 2.64764568e-01\n",
      " 3.37565331e-01 1.16556935e-02 9.59094095e-01 4.18328271e-01\n",
      " 1.76107376e-01 5.98967572e-01 9.34483991e-01 2.93297983e-01\n",
      " 6.20857302e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.85\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[10  4]\n",
      " [ 4 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7575757575757576\n",
      "recall:  0.7894736842105263\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.7894736842105263\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        14\n",
      "           1       0.79      0.79      0.79        19\n",
      "\n",
      "    accuracy                           0.76        33\n",
      "   macro avg       0.75      0.75      0.75        33\n",
      "weighted avg       0.76      0.76      0.76        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  6\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:50:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:50:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.48271734 0.47968084 0.5757361  0.53720444 0.47099695 0.4845896\n",
      " 0.5661323  0.61481684 0.48789167 0.5847458  0.4175703  0.6016567\n",
      " 0.5246886  0.5017037  0.42552224 0.47099695 0.5268175  0.54720867\n",
      " 0.5196291  0.5467001  0.47852033 0.5857197  0.6431155  0.38376367\n",
      " 0.50577426 0.45886326 0.6172334  0.47968084 0.370171   0.587099\n",
      " 0.44128215 0.42079735 0.6056103 ]\n",
      "\n",
      " yhat\n",
      "[0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.73\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[ 8  6]\n",
      " [ 7 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6060606060606061\n",
      "recall:  0.631578947368421\n",
      "specificity:  0.5714285714285714\n",
      "precision:  0.6666666666666666\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.57      0.55        14\n",
      "           1       0.67      0.63      0.65        19\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.60      0.60      0.60        33\n",
      "weighted avg       0.61      0.61      0.61        33\n",
      "\n",
      "\n",
      "KFold:  7\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (295, 10)\n",
      "\n",
      "X_test:\n",
      " [[-2.89218824e-02  5.30546091e-01 -3.16568843e-01 -2.39898367e-01\n",
      "   3.02378703e-01  1.67739761e+00 -4.47090026e-01  3.24442453e-02\n",
      "   1.18826225e-01 -1.58475945e+00]\n",
      " [-6.30142571e-01 -7.81299521e-01 -3.13575441e-01 -1.12168699e-01\n",
      "  -3.82914000e-01 -1.37893176e-01 -8.15190185e-01 -6.93147393e-01\n",
      "  -1.65100284e-01 -6.01730093e-01]\n",
      " [-3.30959484e-01 -1.04487103e+00 -7.72116867e-01  8.51675881e-04\n",
      "  -8.28160836e-01  3.45796305e-01 -1.12231774e+00 -1.17113376e+00\n",
      "   2.06590272e+00  3.27727500e-01]\n",
      " [-8.06730431e-01 -3.43730805e+00 -1.60376566e-01 -1.42206357e+00\n",
      "   2.10253186e-01 -2.60046186e+00  1.00001983e+01  2.72348494e+01\n",
      "  -2.01032507e+00  1.24703445e+00]\n",
      " [-1.85801780e-01 -9.72480824e-01  1.37614075e-01  5.13441828e-02\n",
      "  -3.03166236e-01 -3.04980341e-01 -1.24327628e+00 -8.51670026e-01\n",
      "   1.59887201e+00  2.55738323e-01]\n",
      " [-5.62618615e-01  4.23937008e+00 -2.24466701e+00 -1.26974363e+01\n",
      "   1.66319177e+01 -2.10677648e+01  4.48519820e+01 -1.81199703e+01\n",
      "   7.29248049e+00 -2.00863249e+00]\n",
      " [ 2.39306569e-02  2.55136083e+00 -1.33504038e-01  2.24253961e+00\n",
      "  -5.12477254e+00 -1.36882893e+00  4.42906064e-01  5.05048261e-01\n",
      "   8.50894969e-01  5.95888970e-01]\n",
      " [-4.09144751e-01 -9.33637423e-01  1.01609390e+00 -3.43665162e-02\n",
      "  -3.26190410e-01 -5.98705387e-01 -7.97557602e-01 -7.31107625e-01\n",
      "  -6.73034584e-01 -7.05078526e-01]\n",
      " [-7.18064477e-01  6.64541111e-01 -3.69643024e-01 -8.65559157e-01\n",
      "   1.00062566e+00 -1.65287462e-02 -1.25619925e+00 -1.11568329e+00\n",
      "   1.07305655e+00 -8.17595929e-01]\n",
      " [-4.66225582e-01 -6.37001105e-01 -2.63398687e-01  3.34039831e-01\n",
      "  -3.00595302e-01 -5.90961002e-01 -7.52735477e-01 -3.26173984e-01\n",
      "  -7.49634088e-01  4.38023008e-01]\n",
      " [-6.67360549e-01 -8.61947584e-01 -4.06724041e-01 -1.47206857e-01\n",
      "  -2.55939354e-01 -4.50756271e-01 -7.79689096e-01 -4.24712272e-01\n",
      "  -4.84038748e-01 -3.41226748e-01]\n",
      " [-5.90851878e-01 -1.17247328e+00 -2.82287181e-01  3.79098554e-01\n",
      "  -9.46018506e-01 -4.24782420e-01 -1.15510242e+00 -1.20268878e+00\n",
      "   1.30932434e-01 -2.08805335e-01]\n",
      " [-7.17720651e-01 -9.81011413e-01 -7.03213388e-01 -3.16040812e-02\n",
      "  -5.92323461e-01  8.72749427e-01 -1.35282912e+00 -1.33090424e+00\n",
      "  -5.17278984e-01 -1.46270671e+00]\n",
      " [-6.37451462e-01 -1.14123649e+00 -4.20193488e-01  3.15971117e-01\n",
      "  -1.08214137e-01 -5.94759138e-01 -2.85111065e-01  9.89468097e-01\n",
      "  -5.27621779e-01 -5.36214185e-01]\n",
      " [-5.72054667e-01 -4.96560268e-01 -1.72302793e-01 -4.26196042e-01\n",
      "  -1.26407029e-01 -4.40639375e-01 -4.13607755e-01 -1.31193601e+00\n",
      "  -5.27606846e-02  8.42198441e-02]\n",
      " [-6.82029589e-01 -8.84882570e-01 -7.30968418e-01 -1.32285211e-01\n",
      "  -7.60390019e-01 -8.90881355e-01  4.40735442e-01  2.60409130e-02\n",
      "   9.30108512e-02 -1.06075863e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01  3.08166327e-01\n",
      "   1.39499301e+00 -6.60107186e-01  6.23534668e-01  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-3.07458258e-01 -2.11453792e+00 -3.64329336e-01 -9.39691863e-01\n",
      "  -1.75669359e-01  9.79026898e+00  2.21801083e+00 -4.41835282e+00\n",
      "  -4.08347538e-01 -2.14818689e+00]\n",
      " [-6.44104387e-01 -9.80992603e-01 -4.51766672e-01 -1.71028563e-01\n",
      "  -2.61815086e-01 -5.28237756e-01 -9.53440443e-01 -4.28884895e-01\n",
      "  -5.65729709e-01 -5.32598264e-01]\n",
      " [ 2.73932546e-01 -6.81460565e-01 -4.16342008e-01 -2.82645406e-01\n",
      "  -4.76347442e-01 -1.31647580e+00 -2.46480292e-01 -3.41273912e-01\n",
      "   3.01917268e+00  7.15870176e+00]\n",
      " [-5.10627609e-01  1.74462168e-01 -3.66432727e-01 -2.91626453e-01\n",
      "   1.43640148e-02 -9.28846643e-01  2.01864872e-02 -1.03003241e+00\n",
      "  -3.38724633e-01 -8.87501364e-01]\n",
      " [-5.23118242e-01 -1.07669088e+00 -7.91637496e-02 -1.08695943e-01\n",
      "  -3.77470914e-01 -5.19868571e-01 -9.74084733e-01 -7.65850112e-01\n",
      "  -3.39526669e-01 -7.59443304e-01]\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 -5.29046618e-01\n",
      "  -3.59634159e-01 -8.51907233e-01 -8.85718383e-01 -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-6.63379234e-01 -8.99732873e-01 -4.29743870e-01 -2.02146509e-01\n",
      "  -3.11536457e-01 -4.58442093e-01 -7.26736802e-01 -1.26523470e-01\n",
      "  -4.22275925e-01 -1.25921718e-01]\n",
      " [-2.09835561e-01 -1.89588783e+00 -4.33339821e-01 -2.22997888e-01\n",
      "  -3.50319979e-02  1.07289644e+00 -3.32625694e-01 -1.20317547e-01\n",
      "  -8.58457167e-01  2.15883682e+00]\n",
      " [-2.96303121e-01 -3.87016771e-01 -3.69453732e-01 -5.81797810e-01\n",
      "   3.34190352e-01 -6.00090376e-01 -7.79783113e-01 -7.51896068e-01\n",
      "  -3.31617178e-01 -6.01432266e-01]\n",
      " [-5.68637119e-01 -1.08630146e+00 -7.34032057e-01  1.08031910e-01\n",
      "  -6.62286960e-01 -4.25570143e-02  8.01226691e-02 -1.33054458e+00\n",
      "   6.64618990e-01 -1.46806854e+00]\n",
      " [-6.54108660e-01  8.11936295e-01  1.27361458e-01 -6.14206259e-01\n",
      "   3.96654768e-01 -3.71855288e-01 -1.31417850e+00 -3.47591621e-01\n",
      "  -1.21053148e+00 -3.70796153e-01]\n",
      " [-5.90597553e-01 -8.75848659e-01 -1.11218205e-01  1.75285986e-01\n",
      "  -2.59482814e-01 -6.10798592e-01  3.99822033e-01  5.37527568e-01\n",
      "  -8.36018316e-01 -8.07698187e-01]\n",
      " [-6.59150020e-01 -8.31603564e-01  8.23148247e-01 -2.23822656e-02\n",
      "  -3.43727299e-01 -6.90184283e-01 -4.78716435e-01 -1.83888595e-01\n",
      "  -6.99551748e-01 -7.12620214e-01]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-6.07861661e-01 -9.32399410e-01 -4.60404462e-01  1.98367188e-01\n",
      "  -1.16013784e-01 -4.35539133e-01 -9.48284772e-01 -5.29290665e-01\n",
      "   1.88940849e-01 -5.46868317e-01]\n",
      " [-4.59632539e-01 -9.40433376e-01  1.59826076e-01  5.12602610e-02\n",
      "  -6.75117806e-01 -2.92399061e-01 -9.54450806e-01 -7.29174701e-01\n",
      "  -2.79312158e-01 -7.51864704e-01]] \n",
      "Shape:  (33, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (295,)\n",
      "\n",
      "y_test:\n",
      " [1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1] \n",
      "Shape:  (33,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  7\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.99343412114845\n",
      "\n",
      " Coefficients \n",
      "[ 2.00258108 -0.26985181  2.40145822  0.48699041  0.28414452 -0.13849359\n",
      " -0.04905458 -0.35873423 -0.16278818  0.58883563]\n",
      "\n",
      " pop_polarity\n",
      "[4.56780352e-01 5.01547344e-01 4.52016961e-01 1.93237457e-04\n",
      " 9.20720143e-01 9.30063304e-02 7.04166313e-01 9.78864079e-01\n",
      " 3.01383141e-01 7.84507591e-01 4.74858239e-01 6.82910979e-01\n",
      " 1.96910061e-01 4.13491253e-01 7.18033640e-01 1.52283194e-01\n",
      " 4.28505858e-01 3.74664899e-01 4.44719226e-01 9.95904362e-01\n",
      " 4.83899613e-01 7.08621390e-01 2.24901309e-01 4.57082101e-01\n",
      " 9.04431817e-01 6.27108259e-01 2.23765295e-01 6.90670381e-01\n",
      " 5.80360038e-01 9.33722542e-01 1.87628133e-01 4.82428881e-01\n",
      " 8.16879580e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.88\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[ 9  2]\n",
      " [ 9 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6666666666666666\n",
      "recall:  0.5909090909090909\n",
      "specificity:  0.8181818181818182\n",
      "precision:  0.8666666666666667\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.82      0.62        11\n",
      "           1       0.87      0.59      0.70        22\n",
      "\n",
      "    accuracy                           0.67        33\n",
      "   macro avg       0.68      0.70      0.66        33\n",
      "weighted avg       0.74      0.67      0.68        33\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  7\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.30045096e-001 4.33559552e-001 4.81713882e-001 1.64910187e-169\n",
      " 8.99798989e-001 0.00000000e+000 2.30255097e-002 9.34565390e-001\n",
      " 1.02499582e-001 5.64260490e-001 4.35268253e-001 3.55158788e-001\n",
      " 4.05201378e-001 1.51469928e-001 4.29965525e-001 3.28726085e-001\n",
      " 1.42400814e-002 6.54757413e-022 4.04413896e-001 1.00000000e+000\n",
      " 2.57980343e-001 4.52613345e-001 4.30645164e-001 4.15108940e-001\n",
      " 9.67046864e-001 7.56623687e-001 4.50780060e-001 9.03954315e-002\n",
      " 1.95741296e-001 7.90590527e-001 2.45914406e-001 4.10971490e-001\n",
      " 5.86720600e-001]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.76\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[11  0]\n",
      " [13  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6060606060606061\n",
      "recall:  0.4090909090909091\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        11\n",
      "           1       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.73      0.70      0.60        33\n",
      "weighted avg       0.82      0.61      0.60        33\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  7\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.57174195 0.9130551  0.09509786 0.03088018 0.95595936 0.28385833\n",
      " 0.41322473 0.72760995 0.66881322 0.9001244  0.88620017 0.9138231\n",
      " 0.00988475 0.8725901  0.91323264 0.00867542 0.17877273 0.5425882\n",
      " 0.49309998 0.81753547 0.78833413 0.83424262 0.0730068  0.66450097\n",
      " 0.80101356 0.88018409 0.01362402 0.07711864 0.35418324 0.63754018\n",
      " 0.00998022 0.70863377 0.70382906]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[11  0]\n",
      " [ 2 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9393939393939394\n",
      "recall:  0.9090909090909091\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.91      0.95        22\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.92      0.95      0.93        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  7\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.3s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[4.16848861e-01 4.86820252e-01 4.38843548e-01 2.72602486e-04\n",
      " 7.93817946e-01 3.37085108e-01 5.74135463e-01 9.11071502e-01\n",
      " 4.01714647e-01 6.47577773e-01 4.58607833e-01 6.04761155e-01\n",
      " 3.02394131e-01 3.75566479e-01 6.42604753e-01 2.26935229e-01\n",
      " 3.84956233e-01 5.32411052e-01 4.35455704e-01 9.47018753e-01\n",
      " 4.73811194e-01 6.12213460e-01 3.01194741e-01 4.39944169e-01\n",
      " 7.35874894e-01 5.33344134e-01 3.04162683e-01 6.29100003e-01\n",
      " 4.93205139e-01 8.34458748e-01 2.69718706e-01 4.57168077e-01\n",
      " 6.98344217e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.88\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 9  2]\n",
      " [ 7 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7272727272727273\n",
      "recall:  0.6818181818181818\n",
      "specificity:  0.8181818181818182\n",
      "precision:  0.8823529411764706\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.82      0.67        11\n",
      "           1       0.88      0.68      0.77        22\n",
      "\n",
      "    accuracy                           0.73        33\n",
      "   macro avg       0.72      0.75      0.72        33\n",
      "weighted avg       0.78      0.73      0.74        33\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  7\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.52175295 0.6011578  0.5037042  0.4410594  0.6662331  0.4587436\n",
      " 0.52084845 0.5822723  0.46443188 0.62717336 0.4780392  0.5882122\n",
      " 0.3777005  0.61678016 0.5508454  0.37337792 0.4898759  0.45443383\n",
      " 0.5197239  0.5634155  0.51634145 0.53132606 0.42987996 0.4815409\n",
      " 0.5649776  0.5645113  0.4098131  0.43384996 0.52555954 0.48807123\n",
      " 0.37581038 0.6292696  0.512611  ]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.91\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[ 9  2]\n",
      " [ 5 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7878787878787878\n",
      "recall:  0.7727272727272727\n",
      "specificity:  0.8181818181818182\n",
      "precision:  0.8947368421052632\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.82      0.72        11\n",
      "           1       0.89      0.77      0.83        22\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.77      0.80      0.77        33\n",
      "weighted avg       0.81      0.79      0.79        33\n",
      "\n",
      "\n",
      "KFold:  8\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 ... -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01 ...  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01 ... -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (296, 10)\n",
      "\n",
      "X_test:\n",
      " [[-6.42000133e-01 -8.91259719e-01 -1.09231217e-01 -1.35874587e-01\n",
      "  -2.88635352e-01 -4.47418120e-01 -7.87996793e-01 -4.73857458e-01\n",
      "  -5.70504660e-01 -5.33987051e-01]\n",
      " [-6.92582049e-01 -3.66979814e-01 -8.16860757e-01 -1.91791942e-01\n",
      "  -4.72512251e-01  2.20023351e+00 -9.77961242e-02 -2.58114508e+00\n",
      "  -8.77536858e-01 -2.68672529e+00]\n",
      " [-6.61539900e-01 -1.46529854e+00 -4.64964921e-01 -1.09148046e-02\n",
      "  -9.05695583e-01 -3.20012220e-01 -8.03282442e-01 -6.64092574e-01\n",
      "  -1.23610033e+00 -1.46592261e+00]\n",
      " [-6.55546739e-01 -9.10450289e-01 -4.13118239e-01 -1.91760584e-01\n",
      "  -1.85474215e-01 -5.36776686e-01 -8.25318856e-01 -4.69203102e-01\n",
      "  -5.46541061e-01 -5.56728956e-01]\n",
      " [-6.41246576e-01 -6.76926278e-01 -4.20542780e-01 -4.68031964e-02\n",
      "  -4.64637625e-01 -1.67882558e-01  3.28000709e-01  7.43204198e-01\n",
      "   2.82043479e-01 -4.87509785e-01]\n",
      " [-1.41365258e-01 -1.38379979e+00 -6.09577900e-01 -1.84524789e+00\n",
      "   7.42520873e-01 -1.72105812e-01 -1.58014594e+00 -2.12553397e+00\n",
      "   2.46004938e+00 -2.42567935e-01]\n",
      " [-6.43215355e-01 -8.00154547e-01 -3.26720631e-01 -4.41403785e-01\n",
      "  -1.36890156e-02 -9.80637507e-02 -6.66030839e-01 -4.08753204e-02\n",
      "  -2.06885265e-01 -1.59929628e-01]\n",
      " [-6.57498507e-01 -9.40141565e-01 -4.68343203e-01 -9.75774248e-02\n",
      "  -1.73390175e-01 -5.02730174e-01 -6.53869701e-01 -2.50627934e-01\n",
      "  -4.14595743e-01 -4.77860038e-01]\n",
      " [-1.15702662e-01 -8.23761766e-01  4.10882631e-01 -5.79660991e+00\n",
      "   4.74777357e+00  4.38616305e+01  1.59263520e+01 -2.66924270e+00\n",
      "  -3.81322603e+00  7.50995644e-01]\n",
      " [-6.80104291e-01 -1.06766516e+00 -5.13045150e-01 -6.88473610e-02\n",
      "  -3.17141659e-01 -5.68964751e-01 -7.32124307e-01 -1.87837348e-01\n",
      "  -3.95847403e-01 -2.63949097e-01]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-6.46872912e-01 -1.20102973e+00 -6.01350554e-01  3.00326331e+00\n",
      "   1.07179860e+00  2.77847762e-01  2.75581687e-02  1.21512274e-02\n",
      "  -3.65995474e-01 -3.39262324e-01]\n",
      " [-6.38652265e-01 -8.66369007e-01  1.47228263e-01 -6.45410700e-02\n",
      "  -3.99822219e-01 -3.61727542e-01 -9.32669997e-01 -4.84506022e-01\n",
      "   6.32498351e-01 -5.14613065e-01]\n",
      " [-3.41465646e-01 -9.85182204e-01 -3.75136495e-01 -1.74193712e-02\n",
      "  -2.51776974e-01  2.06801939e-01 -2.41435550e-01  1.05848729e+00\n",
      "   3.80820190e+00  5.39443290e-01]\n",
      " [-6.76870023e-01 -9.78317227e-01 -3.91852406e-01 -2.19960669e-01\n",
      "  -2.52907915e-01 -4.40153475e-01 -5.28953920e-01  2.20497178e-01\n",
      "  -1.99098126e-01 -4.09978154e-01]\n",
      " [-7.63391489e-01 -9.75146073e-01 -6.64994880e-01  7.02653951e-01\n",
      "  -9.25213975e-01 -3.67635953e-01 -7.97287979e-01 -1.01962529e+00\n",
      "  -2.13386643e-01 -1.67371254e+00]\n",
      " [-5.69341905e-01 -1.06532359e+00 -3.76525632e-01 -1.57650901e-01\n",
      "  -2.94513151e-01 -6.93029214e-01 -1.27789449e+00 -8.05951941e-01\n",
      "  -6.16239146e-01  5.40003209e-01]\n",
      " [-6.81435708e-01 -9.41203175e-01 -3.79095289e-01 -1.64238871e-01\n",
      "  -3.10014792e-01 -5.18651303e-01 -7.91287751e-01 -4.01668480e-01\n",
      "  -5.06667010e-01 -4.74558287e-01]\n",
      " [-6.90099510e-01 -2.61172680e+00 -4.74634680e-01  3.59537483e+00\n",
      "   2.48527819e+00  5.02777700e-01 -4.08170217e-01 -3.58078440e+00\n",
      "  -2.32838098e+00 -1.89944574e+00]\n",
      " [-5.99156517e-01 -3.53128043e-01 -5.53797672e-01 -1.67346526e-01\n",
      "  -5.27565940e-01 -1.11610728e+00  1.23389070e+00  1.45765972e+00\n",
      "  -8.27375538e-01 -7.45590683e-01]\n",
      " [-7.17720651e-01 -9.81011413e-01 -7.03213388e-01 -3.16040812e-02\n",
      "  -5.92323461e-01  8.72749427e-01 -1.35282912e+00 -1.33090424e+00\n",
      "  -5.17278984e-01 -1.46270671e+00]\n",
      " [-6.54162955e-01 -1.08601351e+00 -7.28068907e-01 -8.72818136e-01\n",
      "   6.14973254e-02 -5.25774461e-01 -2.38335438e+00 -7.15780097e-01\n",
      "  -1.14545456e+00 -1.56061180e+00]\n",
      " [-5.94239061e-01 -1.41761934e+00 -8.55183080e-01 -1.51644268e-01\n",
      "  -2.10272671e-01 -1.98354123e-01  9.10177625e-01  1.32723256e+00\n",
      "  -7.53521881e-01  1.55332085e+00]\n",
      " [-3.30959484e-01 -1.04487103e+00 -7.72116867e-01  8.51675881e-04\n",
      "  -8.28160836e-01  3.45796305e-01 -1.12231774e+00 -1.17113376e+00\n",
      "   2.06590272e+00  3.27727500e-01]\n",
      " [-6.44616215e-01 -7.60385455e-01 -4.07901439e-01  4.60748091e-03\n",
      "  -3.95368762e-01 -3.88201850e-01 -9.10658310e-01 -6.39434063e-01\n",
      "  -2.32156511e-01 -5.89829946e-01]\n",
      " [-6.30965998e-01 -1.32033933e+00  1.07618950e+00  1.22902575e-01\n",
      "  -2.50992810e-01 -5.99783489e-01 -1.13631559e+00 -2.53311632e-01\n",
      "  -1.87122117e-01 -3.08256052e-01]\n",
      " [-6.82748432e-01 -7.50546933e-01 -4.78398149e-01 -9.12310125e-02\n",
      "  -3.70732979e-01 -4.76423429e-01 -8.25805592e-01 -4.52928261e-01\n",
      "  -5.08160624e-01 -5.70654345e-01]\n",
      " [-6.96386922e-01 -1.50255686e-01 -6.92051857e-01  4.11919290e-02\n",
      "  -1.68654673e+00 -4.60998106e-01  1.23520035e-01  4.46059928e-02\n",
      "   2.58045746e+00  6.68711269e-01]\n",
      " [-7.63391489e-01 -9.75146073e-01 -6.64994880e-01  7.02653951e-01\n",
      "  -9.25213975e-01 -3.67635953e-01 -7.97287979e-01 -1.01962529e+00\n",
      "  -2.13386643e-01 -1.67371254e+00]\n",
      " [-6.52886168e-01 -7.21596752e-01 -3.52196038e-01 -3.96052435e-01\n",
      "  -9.23054443e-03 -5.74949631e-01 -9.69961612e-01 -1.24478130e-01\n",
      "  -4.25296505e-01 -2.07360145e-01]\n",
      " [-8.94075989e-02  8.26310956e-01  8.44686173e-01 -9.32759775e-01\n",
      "   1.00618800e+00  1.68251929e-01 -1.98510907e+00  2.79463544e-01\n",
      "   1.47588338e+00  5.65116019e-01]\n",
      " [-6.31547919e-01 -8.85793801e-01 -3.26554803e-01 -8.96887361e-02\n",
      "  -3.51446426e-01 -2.58599102e-01 -7.95742880e-01 -5.08894529e-01\n",
      "  -1.95663868e-01 -3.74833440e-01]] \n",
      "Shape:  (32, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (296,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1] \n",
      "Shape:  (32,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  8\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.9372408186521932\n",
      "\n",
      " Coefficients \n",
      "[ 2.15450115 -0.2446142   2.12499545  0.73830894  0.44935463 -0.08127559\n",
      " -0.13370022 -0.5847634  -0.17362684  0.66737898]\n",
      "\n",
      " pop_polarity\n",
      "[0.61572214 0.1356379  0.31547178 0.44929168 0.22185905 0.62861534\n",
      " 0.44298569 0.40935312 0.08676801 0.40037743 0.19261514 0.88717313\n",
      " 0.69907452 0.40484812 0.34254333 0.24484993 0.74804072 0.44701664\n",
      " 0.99391726 0.1105358  0.24028754 0.19261514 0.32427662 0.53353268\n",
      " 0.46686376 0.96581605 0.38241443 0.15042051 0.24484993 0.46177389\n",
      " 0.96477428 0.5209843 ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.71\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[14  4]\n",
      " [ 8  6]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.625\n",
      "recall:  0.42857142857142855\n",
      "specificity:  0.7777777777777778\n",
      "precision:  0.6\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70        18\n",
      "           1       0.60      0.43      0.50        14\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.62      0.60      0.60        32\n",
      "weighted avg       0.62      0.62      0.61        32\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  8\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[5.14702091e-001 3.83203715e-001 4.87075672e-001 5.00693747e-001\n",
      " 1.99568247e-001 7.44555027e-001 4.72882764e-001 4.92318669e-001\n",
      " 1.85456010e-266 4.90578440e-001 2.87690827e-001 4.49906573e-001\n",
      " 5.30284363e-001 2.91109064e-002 4.17082386e-001 7.83149629e-001\n",
      " 5.55240709e-001 5.10008948e-001 3.30287205e-003 1.80891799e-002\n",
      " 5.41691830e-001 2.87690827e-001 2.45213993e-001 6.22417035e-001\n",
      " 5.18485717e-001 8.82940942e-001 5.30587629e-001 1.66304788e-001\n",
      " 7.83149629e-001 4.65457488e-001 9.72572634e-001 5.08911439e-001]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.46\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[11  7]\n",
      " [ 6  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.59375\n",
      "recall:  0.5714285714285714\n",
      "specificity:  0.6111111111111112\n",
      "precision:  0.5333333333333333\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63        18\n",
      "           1       0.53      0.57      0.55        14\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.59      0.59      0.59        32\n",
      "weighted avg       0.60      0.59      0.59        32\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  8\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.93187308 0.20045112 0.05911919 0.78066231 0.64874388 0.16186602\n",
      " 0.68307607 0.05337066 0.11793485 0.09080551 0.01564978 0.34770966\n",
      " 0.94512827 0.82904904 0.77639893 0.02054034 0.93016478 0.68066069\n",
      " 0.42394665 0.30684389 0.01306656 0.01564978 0.03440098 0.08852256\n",
      " 0.95722896 0.92227274 0.08187282 0.09257074 0.02054034 0.08216304\n",
      " 0.61651486 0.95694093]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[17  1]\n",
      " [ 2 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.90625\n",
      "recall:  0.8571428571428571\n",
      "specificity:  0.9444444444444444\n",
      "precision:  0.9230769230769231\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92        18\n",
      "           1       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.91      0.90      0.90        32\n",
      "weighted avg       0.91      0.91      0.91        32\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  8\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   15.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.57355175 0.21209653 0.32325775 0.43785807 0.24442992 0.66255436\n",
      " 0.43148429 0.40277924 0.2991461  0.39030647 0.22564479 0.81881093\n",
      " 0.65332509 0.42735617 0.34354695 0.27702758 0.69011248 0.43265357\n",
      " 0.98301326 0.13493922 0.28299605 0.22564479 0.29948251 0.55916702\n",
      " 0.46100291 0.92777939 0.3862484  0.19991583 0.27702758 0.44451543\n",
      " 0.94488666 0.5       ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.69\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[14  4]\n",
      " [ 8  6]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.625\n",
      "recall:  0.42857142857142855\n",
      "specificity:  0.7777777777777778\n",
      "precision:  0.6\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70        18\n",
      "           1       0.60      0.43      0.50        14\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.62      0.60      0.60        32\n",
      "weighted avg       0.62      0.62      0.61        32\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  8\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.62764513 0.4530416  0.40422678 0.53826797 0.56475437 0.49217612\n",
      " 0.52600616 0.4363432  0.48618594 0.44992274 0.38871336 0.47808695\n",
      " 0.67544985 0.6090388  0.4924161  0.42873907 0.63977665 0.49508178\n",
      " 0.47400224 0.45382965 0.40422678 0.38871336 0.48636702 0.51607084\n",
      " 0.6626458  0.62959796 0.43358028 0.45065582 0.42873907 0.4208958\n",
      " 0.5211386  0.62764513]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.94\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[16  2]\n",
      " [ 4 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8125\n",
      "recall:  0.7142857142857143\n",
      "specificity:  0.8888888888888888\n",
      "precision:  0.8333333333333334\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        18\n",
      "           1       0.83      0.71      0.77        14\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.82      0.80      0.81        32\n",
      "weighted avg       0.81      0.81      0.81        32\n",
      "\n",
      "\n",
      "KFold:  9\n",
      "\n",
      "X_train:\n",
      " [[-1.53559556e-01  3.47770655e+01  1.09985556e+00 ... -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-5.23037130e-01 -5.63399024e-02 -4.31134015e-01 ... -6.43059990e-01\n",
      "  -9.54990328e-01 -4.05314936e-01]\n",
      " [-6.98909441e-01 -1.17155936e+00 -5.92279390e-01 ... -8.32497366e-02\n",
      "  -3.42743993e-01 -4.96005248e-01]\n",
      " ...\n",
      " [-6.52886168e-01 -7.21596752e-01 -3.52196038e-01 ... -1.24478130e-01\n",
      "  -4.25296505e-01 -2.07360145e-01]\n",
      " [-8.94075989e-02  8.26310956e-01  8.44686173e-01 ...  2.79463544e-01\n",
      "   1.47588338e+00  5.65116019e-01]\n",
      " [-6.31547919e-01 -8.85793801e-01 -3.26554803e-01 ... -5.08894529e-01\n",
      "  -1.95663868e-01 -3.74833440e-01]] \n",
      "Shape:  (296, 10)\n",
      "\n",
      "X_test:\n",
      " [[-1.75992592e-01  7.40736644e-01  4.22283005e-01  1.15572347e+00\n",
      "   3.39857203e+00 -1.40887332e-02 -2.60211842e+00 -4.03711785e-01\n",
      "   1.23058339e+00 -1.67427562e-01]\n",
      " [-1.71650922e-02  8.64783922e+00  1.80672873e+00 -5.39300373e-01\n",
      "  -4.65324487e+00  6.58610632e+00 -3.22294288e+00  5.35035438e+00\n",
      "   5.20147583e+01  1.37084741e+00]\n",
      " [-3.30959484e-01 -1.04487103e+00 -7.72116867e-01  8.51675881e-04\n",
      "  -8.28160836e-01  3.45796305e-01 -1.12231774e+00 -1.17113376e+00\n",
      "   2.06590272e+00  3.27727500e-01]\n",
      " [-5.81800874e-01 -2.45852420e-01  2.53545846e-01  1.67852910e+00\n",
      "  -3.03838915e+00 -1.20821668e-01 -1.63710819e+00 -3.27358000e+00\n",
      "  -4.54244529e+00 -5.19684926e+00]\n",
      " [-1.53559556e-01  3.47770655e+01  1.09985556e+00  1.32459048e+01\n",
      "  -2.06416506e+01  2.42037503e-01  8.21267759e+00 -2.23825505e-02\n",
      "  -5.59321178e+00  5.67188890e-01]\n",
      " [-6.66377253e-01 -9.68466880e-01 -4.59067460e-01 -1.85842233e-01\n",
      "  -2.65091264e-01 -4.75564003e-01 -5.81013101e-01 -1.40137364e-02\n",
      "  -5.44620808e-01 -4.43717596e-01]\n",
      " [-1.90880835e-01 -4.23470081e-01 -5.30754732e-01 -2.81843127e-01\n",
      "   1.29246635e-01 -7.87517194e-02 -1.46153022e+00 -6.25069299e-01\n",
      "   4.41472528e-01 -5.64987698e-01]\n",
      " [-6.57498507e-01 -9.40141565e-01 -4.68343203e-01 -9.75774248e-02\n",
      "  -1.73390175e-01 -5.02730174e-01 -6.53869701e-01 -2.50627934e-01\n",
      "  -4.14595743e-01 -4.77860038e-01]\n",
      " [-2.77489490e-01  2.76739202e+00 -7.36408299e-01  1.99565349e+00\n",
      "  -4.96775531e+00 -5.30686378e-01 -2.00090825e-01 -1.39954231e+00\n",
      "  -4.79633835e-01  4.95730393e+00]\n",
      " [-5.15152462e-01  6.65992152e-01  1.59557030e-01 -1.38485201e-01\n",
      "  -2.86121124e-01  1.51959792e+00  8.75629795e-02 -1.52506159e+00\n",
      "   1.50635030e+00 -8.64862243e-01]\n",
      " [-6.27902325e-01  3.43750329e-01 -4.57942018e+00  7.22921673e+01\n",
      "   4.66124834e+01  2.50353668e+00  2.98307074e+00  1.47775255e+00\n",
      "   3.67011117e+00  1.26428480e+00]\n",
      " [-5.79608782e-01 -2.14018728e+00 -4.53461024e-01 -4.12979470e-01\n",
      "  -2.01911381e-01 -5.43075725e-01 -7.11739914e-01  1.15514746e+00\n",
      "  -2.11684000e+00 -2.02322492e+00]\n",
      " [-6.80104291e-01 -1.06766516e+00 -5.13045150e-01 -6.88473610e-02\n",
      "  -3.17141659e-01 -5.68964751e-01 -7.32124307e-01 -1.87837348e-01\n",
      "  -3.95847403e-01 -2.63949097e-01]\n",
      " [-6.50689695e-01 -9.06480879e-01 -2.78142975e-01 -1.18824184e-01\n",
      "  -4.21174874e-01 -4.97659042e-01 -5.66436880e-01 -1.89399604e-01\n",
      "  -4.63951901e-01 -3.36971284e-01]\n",
      " [-6.11732315e-01 -3.28632492e-01 -4.46802262e-01 -1.07867860e-02\n",
      "  -6.93896384e-01 -5.26999460e-01 -4.91736605e-01  3.94987349e-01\n",
      "  -3.43649241e-01  5.77562105e-02]\n",
      " [-6.67986299e-01 -9.04353841e-01 -4.92546522e-01 -1.21377976e-01\n",
      "  -3.85727800e-01 -3.76527459e-01 -9.50120854e-01 -6.99873828e-01\n",
      "  -4.14868140e-01 -6.99457130e-01]\n",
      " [-4.59947682e-01 -8.80565622e-01 -4.11680458e-01  2.04825453e-01\n",
      "  -2.47349155e-01 -5.75770835e-01 -9.20257150e-01 -5.07926126e-01\n",
      "  -5.30443042e-01 -6.25758756e-01]\n",
      " [-5.67912785e-01 -1.37099657e+00  1.66463702e+00  2.48455396e-01\n",
      "   4.38062164e-01  2.00508030e+00 -1.86064048e-01 -1.17788090e+00\n",
      "  -5.14378252e-01  1.30685932e-01]\n",
      " [-2.73209926e-01  6.85747703e-01  3.71898937e-02  1.04887604e+00\n",
      "  -1.29416181e+00 -7.37930097e-01 -6.12381465e-02 -1.75366212e+00\n",
      "   1.12411497e+00 -1.32538147e+00]\n",
      " [-6.65726416e-01 -5.52121705e-01 -4.40254868e-01 -2.43024797e-01\n",
      "  -2.28064693e-01 -4.07187440e-01 -7.19079213e-01 -1.34828838e-01\n",
      "  -5.34717838e-01 -1.72673222e-01]\n",
      " [-5.35205957e-01  1.22183575e-01  3.54395920e-02  6.09804789e-01\n",
      "  -8.59757909e-01 -5.70730520e-01  8.29404870e-02 -4.52168443e-01\n",
      "  -6.05084569e-01 -9.31817589e-02]\n",
      " [-6.70352554e-01 -1.02793370e+00 -3.96018714e-01 -1.99499402e-01\n",
      "  -1.98609293e-01  2.00183796e-01 -3.51155676e-01  2.40678863e-01\n",
      "  -6.11456430e-01  5.26675219e-01]\n",
      " [-6.82748432e-01 -7.50546933e-01 -4.78398149e-01 -9.12310125e-02\n",
      "  -3.70732979e-01 -4.76423429e-01 -8.25805592e-01 -4.52928261e-01\n",
      "  -5.08160624e-01 -5.70654345e-01]\n",
      " [-5.24647745e-01 -4.97546555e-01 -1.41694790e-01  3.84400238e-01\n",
      "  -1.86637845e-01  1.64989839e+00 -1.15998820e+00 -1.32259743e+00\n",
      "   2.54429669e+00 -2.09440537e-01]\n",
      " [-5.42551713e-01 -7.17622070e-01 -4.00496410e-01  1.91598899e-02\n",
      "   4.24618759e-01  6.74998160e-01 -8.56214080e-01 -1.15258266e+00\n",
      "  -4.03025011e-01  2.88412462e-02]\n",
      " [ 4.76066836e-02 -3.52138283e-01 -2.71332031e-01  1.19979122e-01\n",
      "   4.75961297e-02 -4.44050733e-01 -7.12784152e-01 -6.00651381e-01\n",
      "  -5.74923932e-01 -7.15547482e-01]\n",
      " [-6.61539900e-01 -1.46529854e+00 -4.64964921e-01 -1.09148046e-02\n",
      "  -9.05695583e-01 -3.20012220e-01 -8.03282442e-01 -6.64092574e-01\n",
      "  -1.23610033e+00 -1.46592261e+00]\n",
      " [-6.71213393e-01 -9.80286950e-01  1.45276159e-02 -1.55118773e-01\n",
      "  -1.56085091e-01  5.17122947e-01 -5.42769312e-01 -7.21086093e-01\n",
      "  -5.87573562e-01 -6.04384190e-01]\n",
      " [-6.54108660e-01  8.11936295e-01  1.27361458e-01 -6.14206259e-01\n",
      "   3.96654768e-01 -3.71855288e-01 -1.31417850e+00 -3.47591621e-01\n",
      "  -1.21053148e+00 -3.70796153e-01]\n",
      " [-5.54413749e-01 -1.50645695e+00 -8.44907129e-01 -5.29046618e-01\n",
      "  -3.59634159e-01 -8.51907233e-01 -8.85718383e-01 -1.71697516e+00\n",
      "  -1.40106357e-01 -1.59359283e+00]\n",
      " [-5.81810456e-01  6.47372631e-01 -2.15733580e-01  3.08166327e-01\n",
      "   1.39499301e+00 -6.60107186e-01  6.23534668e-01  1.35808328e+00\n",
      "  -9.72918726e-01 -1.19212764e+00]\n",
      " [-6.47898537e-01 -9.87327844e-01  5.14455679e-01  1.85590281e-01\n",
      "  -6.22942972e-01 -2.78748665e-01 -8.29479628e-01 -9.20842095e-01\n",
      "  -1.93548107e-01 -7.29082170e-01]] \n",
      "Shape:  (32, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1] \n",
      "Shape:  (296,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0] \n",
      "Shape:  (32,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  9\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "1.7159357874962775\n",
      "\n",
      " Coefficients \n",
      "[ 1.6099163  -0.24402876  2.17258107  0.4092003   0.1970003  -0.1166536\n",
      " -0.09227175 -0.4678481  -0.19774564  0.79114837]\n",
      "\n",
      " pop_polarity\n",
      "[9.66642508e-01 5.49333101e-05 5.14921005e-01 4.90471488e-01\n",
      " 7.61854003e-02 4.07603936e-01 5.42693260e-01 4.34233437e-01\n",
      " 9.72982847e-01 6.23333404e-01 1.00000000e+00 1.85072597e-01\n",
      " 4.42146278e-01 5.44329522e-01 4.34177356e-01 4.14148848e-01\n",
      " 5.81894654e-01 9.95848716e-01 7.32063001e-01 4.56137913e-01\n",
      " 7.85505085e-01 5.84303505e-01 4.11659073e-01 6.61484840e-01\n",
      " 7.07026060e-01 7.84765968e-01 3.36761600e-01 6.85042875e-01\n",
      " 6.98787993e-01 2.34936607e-01 3.07218034e-01 8.79325681e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.77\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[11  5]\n",
      " [ 3 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.75\n",
      "recall:  0.8125\n",
      "specificity:  0.6875\n",
      "precision:  0.7222222222222222\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73        16\n",
      "           1       0.72      0.81      0.76        16\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.75      0.75      0.75        32\n",
      "weighted avg       0.75      0.75      0.75        32\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  9\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[1.60893752e-003 1.10176639e-320 9.70797224e-001 5.99659917e-001\n",
      " 0.00000000e+000 9.54256371e-001 9.96979203e-001 9.60158611e-001\n",
      " 5.70962519e-003 5.65763940e-001 0.00000000e+000 6.43197315e-001\n",
      " 9.61199841e-001 9.59287427e-001 9.33863151e-001 9.63785686e-001\n",
      " 9.72479937e-001 9.99007476e-001 8.57909996e-001 9.58254500e-001\n",
      " 9.11184014e-001 9.64761381e-001 9.64502702e-001 5.47295355e-001\n",
      " 9.44636492e-001 9.99984668e-001 9.51278362e-001 9.63869615e-001\n",
      " 6.64904427e-001 9.55994067e-001 6.99573700e-002 9.85918079e-001]\n",
      "\n",
      " yhat\n",
      "[0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.58\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 4 12]\n",
      " [ 2 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5625\n",
      "recall:  0.875\n",
      "specificity:  0.25\n",
      "precision:  0.5384615384615384\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.25      0.36        16\n",
      "           1       0.54      0.88      0.67        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.60      0.56      0.52        32\n",
      "weighted avg       0.60      0.56      0.52        32\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  9\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.65962929 0.2183553  0.14680336 0.92995622 0.06465812 0.21917404\n",
      " 0.76643807 0.10908614 0.5017041  0.76179469 0.49174953 0.05360725\n",
      " 0.17945468 0.817498   0.69686998 0.41421357 0.94503041 0.86601864\n",
      " 0.75395885 0.18697122 0.34929116 0.81464711 0.12358905 0.91867737\n",
      " 0.94218034 0.88139192 0.05940944 0.88696606 0.12128511 0.0696644\n",
      " 0.22373343 0.48388304]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[15  1]\n",
      " [ 2 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.90625\n",
      "recall:  0.875\n",
      "specificity:  0.9375\n",
      "precision:  0.9333333333333333\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        16\n",
      "           1       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.91      0.91      0.91        32\n",
      "weighted avg       0.91      0.91      0.91        32\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  9\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    1.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.9s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n",
      "100%|██████████| 119/119 [00:00<00:00, 14914.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.95643795 0.00409968 0.5        0.67407308 0.2949116  0.37735005\n",
      " 0.54044333 0.40748255 0.921336   0.70689827 1.         0.17677956\n",
      " 0.40118503 0.5        0.38241912 0.41192185 0.54694593 0.99380558\n",
      " 0.77484071 0.42109741 0.74351381 0.49470132 0.39900764 0.69580527\n",
      " 0.67290716 0.75367446 0.3515307  0.67212447 0.69000871 0.28370458\n",
      " 0.29490281 0.86832882]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.79\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[11  5]\n",
      " [ 2 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.78125\n",
      "recall:  0.875\n",
      "specificity:  0.6875\n",
      "precision:  0.7368421052631579\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76        16\n",
      "           1       0.74      0.88      0.80        16\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.79      0.78      0.78        32\n",
      "weighted avg       0.79      0.78      0.78        32\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "nKFold round:  9\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.5374793  0.5        0.5212014  0.5265951  0.47841433 0.43844032\n",
      " 0.57478535 0.43844032 0.54651725 0.5211833  0.4945882  0.4256565\n",
      " 0.43844032 0.52807736 0.5274958  0.44745952 0.679807   0.6531104\n",
      " 0.52774966 0.42364258 0.5412881  0.51413196 0.45070058 0.5917953\n",
      " 0.63831264 0.6112348  0.38305372 0.5533833  0.44540358 0.45589513\n",
      " 0.50791174 0.4770936 ]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.88\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[12  4]\n",
      " [ 2 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8125\n",
      "recall:  0.875\n",
      "specificity:  0.75\n",
      "precision:  0.7777777777777778\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80        16\n",
      "           1       0.78      0.88      0.82        16\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.82      0.81      0.81        32\n",
      "weighted avg       0.82      0.81      0.81        32\n",
      "\n",
      "\n",
      " compare_final_result() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      "=====  Logistic baseline  =====\n",
      "accuracy =  0.75\n",
      "recall =  0.8125\n",
      "specificity =  0.6875\n",
      "precision =  0.7222222222222222\n",
      "auc =  0.77\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      "=====  GaussianNB  =====\n",
      "accuracy =  0.5625\n",
      "recall =  0.875\n",
      "specificity =  0.25\n",
      "precision =  0.5384615384615384\n",
      "auc =  0.58\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      "=====  Random forest  =====\n",
      "accuracy =  0.90625\n",
      "recall =  0.875\n",
      "specificity =  0.9375\n",
      "precision =  0.9333333333333333\n",
      "auc =  0.99\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      "=====  SVM  =====\n",
      "accuracy =  0.78125\n",
      "recall =  0.875\n",
      "specificity =  0.6875\n",
      "precision =  0.7368421052631579\n",
      "auc =  0.79\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: rama\n",
      "\n",
      "=====  XGBoost  =====\n",
      "accuracy =  0.8125\n",
      "recall =  0.875\n",
      "specificity =  0.75\n",
      "precision =  0.7777777777777778\n",
      "auc =  0.88\n",
      "\n",
      "\n",
      "====================================================\n",
      "\n",
      "Hospital name: siriraj-hospital\n",
      "\n",
      "====================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      ">>>>> Step: Read data for NLP process <<<<<\n",
      "\n",
      " load_dataset() is activated...\n",
      "\n",
      "\n",
      ">> Positive and negative dataset:\n",
      "     score                                                 en  polarity\n",
      "0        5  The nurse is very good, the doctor is polite, ...         1\n",
      "1        5  Use a consultative service for keloids on the ...         1\n",
      "2        5  It is a very good hospital. Used to treat uter...         1\n",
      "3        5  Siriraj Hospital. The doctors and nurses are v...         1\n",
      "4        5  Take Grandma to treat cancer. Good service, fa...         1\n",
      "..     ...                                                ...       ...\n",
      "126      5  The doctors and nurses are very cute, caring, ...         1\n",
      "127      5  Initially entered into ER because the mother f...         1\n",
      "128      5  I've been treated for cancer until I am health...         1\n",
      "130      4                                      Service is ok         1\n",
      "131      4  The place is cramped compared to the number of...         1\n",
      "\n",
      "[119 rows x 3 columns]\n",
      "\n",
      ">> Positive dataset:\n",
      "     score                                                 en  polarity\n",
      "0        5  The nurse is very good, the doctor is polite, ...         1\n",
      "1        5  Use a consultative service for keloids on the ...         1\n",
      "2        5  It is a very good hospital. Used to treat uter...         1\n",
      "3        5  Siriraj Hospital. The doctors and nurses are v...         1\n",
      "4        5  Take Grandma to treat cancer. Good service, fa...         1\n",
      "..     ...                                                ...       ...\n",
      "126      5  The doctors and nurses are very cute, caring, ...         1\n",
      "127      5  Initially entered into ER because the mother f...         1\n",
      "128      5  I've been treated for cancer until I am health...         1\n",
      "130      4                                      Service is ok         1\n",
      "131      4  The place is cramped compared to the number of...         1\n",
      "\n",
      "[113 rows x 3 columns]\n",
      "\n",
      ">> Negative dataset:\n",
      "    score                                                 en  polarity\n",
      "22      1  The doctor entered the fever, the surgery was ...         0\n",
      "25      1  In 2003, the doctor made me unable to walk unt...         0\n",
      "33      1  The broken bone doctor diagnosed without check...         0\n",
      "55      2  Mothers have to check from many doctors. And e...         0\n",
      "65      1  Doctor diagnosis Understand that doctors have ...         0\n",
      "72      2  The service is slow, the queue is too long, at...         0\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXwUlEQVR4nO3debRkZX3u8e9DMxhRQAW8NIgN2oKoeFVkoXEg4EoEDRqDRuLAUtZyjqJyURK9F++6GjROcRZQcMSgRgMKokHFq1ehu1EZBASaRptBIDIjQtO/+8feJykOp+tUd1WdOmf397PWWVV7rN9mN895z7v3fitVhSSpezaZdAGSpPEw4CWpowx4SeooA16SOsqAl6SOMuAlqaMMeM1LSf4+yfF9lu+c5LYkizZw/09Pckmf5Ucn+eKG7HtDJflUkncOsX0leeQoa9LCFu+Dl+4rydHAI6vqpRP6/H2BL1bVTuuxTQFLq+qysRWmBcUWvBacJJvOsjxJ/LetjZ7/E2jikrwtyVVJbk1ySZL9e7tIkixpux8OS/Ib4Ps98zZt1/lhkncn+QlwB7Brklckuajd78okr+75zH2TrJ6ltM2TfL7d/sIke/Vs/+j2M29qlx3Us+zAJL9qt7sqyRG9n9l2P92QZFWSl/Rsd2KS/5NkS+B0YHHbDXVbksVJ9k7y0/Yzr0nysSSbD38G1FUGvCYqyW7AG4AnV9UDgb8AVq1j9WcCj27XmcnLgFcBDwSuBK4DngtsBbwC+FCSJ65HeQcBXwG2AU4BPtbWvBlwKvBdYHvg74AvtccC8Bng1e3xPBb4fs8+/xuwLbAjcChwbM92AFTV7cABwNVV9YD252rgHuDN7fZPAfYHXrcex6ONjAGvSbsH2ALYI8lmVbWqqi5fx7pHV9XtVfWHdSw/saourKo1VXV3VX27qi6vxlk0gfz09ajtx1V1WlXdA3wBeHw7fx/gAcAxVXVXVX0f+BZwSLv87vZ4tqqqG6vq3Gn7fWdV/bGt6dvAiwYppqpWVNXP2uNbBXya5peeNCMDXhPVXhA8HDgauC7JV5IsXsfqv51ld/danuSAJD9L8vskNwEH0rR+mbbeS3q6Qk7vWXRtz/s7gPu1XUKLgd9W1dqe5VfStMoB/rr9rCuTnJXkKT3r3di20Hu3W9fxTq/zUUm+leTaJLcA75npeKQpBrwmrqq+XFVPAx4OFPDeda06266m3iTZAvg68H7goVW1DXAakBk+/0s9XSEHDFDy1cDDpl3I3Rm4qt3fsqp6Hk33zTeBk3vWe1Dbx9673dX9jqXHJ4GLae6U2Qr4+5mOR5piwGuikuyWZL82kO8E/kDTbTOszWm6fq4H1iQ5APjzEewX4GzgduDIJJu1tzT+JfCVJJu3fxFsXVV3A7dw3+N5V7ve02muEXx1hs/4HfCQJFv3zHtgu7/bkuwOvHZEx6OOMuA1aVsAxwA30HSJbE/TMh1KVd0KvJGm9Xwj8Lc0F0qHVlV30VyAPYCm7k8AL6+qi9tVXgasartRXgP03kt/bVvP1cCXgNf0bNf7GRcDJwEr27tmFgNHtMdxK3Ac8C+jOB51lw86aaOUZD/g+KradQ4/c1/W8+ElaRi24LWxeixwxaSLkMap7xOBUhcl+WeaLpZDJ12LNE520UhSR9lFI0kdNa+6aLbddttasmTJpMuQpAVjxYoVN1TVdjMtm1cBv2TJEpYvXz7pMiRpwUhy5bqW2UUjSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSR2066QJ6nX/VzSx5+7cnXYYkzZlVxzxnbPu2BS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUbMGfJKHJvlMktPb6T2SHDbAdp9Ncl2SC0ZRqCRp/QzSgj8ROANY3E7/Gjh8wO2evUFVSZKGNkjAb1tVJwNrAapqDXDPbBtV1Y+A3w9XniRpQw0S8LcneQhQAEn2AW4eVQFJXpVkeZLl99wxst1K0kZv0wHWeStwCvCIJD8BtgMOHlUBVXUscCzAFjssrVHtV5I2drMGfFWtSPJMYDcgwCVVdffYK5MkDWWQu2h+CRwJ3FlVFxjukrQwDNIHfxCwBjg5ybIkRyTZebaNkpwE/BTYLcnqQW6tlCSNzqwBX1VXVtX7qupJwN8CewJXDLDdIVW1Q1VtVlU7VdVnRlCvJGlAg1xkJckS4EXA39DcInnk+EqSJI3CrAGf5GxgM+CrwAurauXYq5IkDW2QFvyhVXXx2CuRJI3UOgM+yUur6ovAgUkOnL68qj441sokSUPp14Lfsn194AzLfCBJkua5dQZ8VX26ffvvVfWT3mVJ/nSsVUmShjbIffAfHXCeJGke6dcH/xTgqcB2Sd7Ss2grYNG4C5MkDadfH/zmwAPadXr74W9hhIONSZLGo18f/FnAWUlOrKor57AmSdII9Oui+XBVHQ58LMl97pqpqoPGWpkkaSj9umi+0L6+fy4KkSSNVr8umhXt61lT85I8CHhYVZ03B7VJkoYwyHjwP0yyVZIHA78ETkjiU6ySNM8Nch/81lV1C/AC4IR22OBnjbcsSdKwBgn4TZPsQDNc8LfGXI8kaUQGCfj/DZwBXF5Vy5LsClw63rIkScMa5Eu3v0ozFvzU9Ergr8dZlCRpeINcZN0pyTeSXJfkd0m+nmSnuShOkrThBumiOQE4BVgM7Aic2s6TJM1jgwT8dlV1QlWtaX9OBLYbc12SpCEN8pV9NyR5KXBSO30I8B/jKOZxO27N8mOeM45dS9JGZ5AW/CtpbpG8FriGZiTJV46zKEnS8AZpwd/hwGKStPCsswWf5C+TXA+cn2R1kqfOYV2SpCH166J5N/D0qtqB5r73f5ybkiRJo9Av4NdU1cUAVXU29/5WJ0nSPNevD377ad/Feq/pqnJESUmax/oF/HHcu9U+fVqSNI/1+8KPd81lIZKk0RrkPnjaB53+81WSNP8NFPDAW6a9SpLmuUEDfkrGUoUkaeTWN+AlSQuEAS9JHWXAS1JHDRrwv25fLxlXIZKk0Roo4Kvqxb2vkqT5b4O6aJLsPupCJEmjtaF98N8daRWSpJFb51AFST6yrkXANuMpR5I0Kv0GG3sF8FbgjzMsO2Q85UiSRqVfwC8DLqiq/zd9QZKjx1aRJGkk+gX8wcCdMy2oql3GU44kaVT6DRf8+7ksRJI0Wj7JKkkdZcBLUkcZ8JLUUf0uss4oyXuAm4Hjq+o/Rl+SJGkUNqQFfw6wBvjQiGuRJI3Qerfgq+qb4yhEkjRas7bgkzwqyZlJLmin90zyjvGXJkkaxiBdNMcBRwF3A1TVeYDDBkvSPDdIwN+/qs6ZNm/NOIqRJI3OIAF/Q5JHAAWQ5GDgmrFWJUka2iAXWV8PHAvsnuQq4ArgJWOtSpI0tEEC/sqqelaSLYFNqurWcRclSRreIF00VyQ5FtgHuG3M9UiSRmSQgN8N+HearporknwsydPGW5YkaVizBnxV/aGqTq6qFwBPALYCzhp7ZZKkoQw0VEGSZyb5BHAucD/gRWOtSpI0tFkvsia5AvgFcDLwP6rq9rFXJUka2iB30Ty+qm4ZeyWSpJFaZ8AnObKq3ge8O0lNX15VbxxrZZKkofRrwV/Uvi6fi0IkSaPV70u3T23f3lFVX+1dluSFY61KkjS0Qe6iOWrAeZKkeaRfH/wBwIHAjkk+0rNoKxxNUpLmvX598FfT9L8fBKzomX8r8OZxFiVJGl6/PvhfAr9M8uWqunsOa5IkjcAg98EvSfKPwB40T7ECUFW7jq0qSdLQBrnIegLwSZp+9z8DPg98YZxFSZKGN0jA/0lVnQmkqq6sqqOB/cZbliRpWIN00dyZZBPg0iRvAK4Cth9vWZKkYQ3Sgj8cuD/wRuBJwMuAQ8dZlCRpeKm6zzAzE7PFDktrh0M/PNQ+Vh3znBFVI0nzX5IVVbXXTMsGGS74VGD6b4Gbae6R/3RV3Tl8iZKkURuki2YlzXexHtf+3AL8DnhUOy1JmocGucj6hKp6Rs/0qUl+VFXPSHLhuAqTJA1nkBb8dkl2nppo32/bTt41lqokSUMbpAX/VuDHSS4HAuwCvC7JlsDnxlmcJGnDzRrwVXVakqXA7jQBf3HPhdXhbnmRJI3NIC14gKXAbjRj0eyZhKr6/PjKkiQNa5DbJP8XsC/NYGOnAQcAP6YZk0aSNE8NcpH1YGB/4NqqegXweGCLsVYlSRraIAH/h6paC6xJshVwHeBQwZI0zw3SB788yTY0DzWtoHno6ZyxViVJGtogd9G8rn37qSTfAbaqqvPGW5YkaVj9vnR75xlmrwVuSrJzVf1mfGVJkobVrwX/bZpBxtIzr4DtaMaDXzTGuiRJQ+r3pduP651OsgR4G/As4D1jrUqSNLRZ76JJsjTJicDpNBdZ96iqj467MEnScPr1wT8W+AfgMcD7gMOq6p65KkySNJx+ffC/BH5L0xe/N7B38l/d8VX1xvGWJkkaRr+Af+WcVSFJGrl+F1kdCliSFrBBhiogyZG9r5Kk+W+ggAdePO1VkjTPDRrwUzL7KpKk+WB9A369JHl2kkuSXJbk7eP8LEnSvY0t4JMsAj5O8wUhewCHJNljXJ8nSbq3cbbg9wYuq6qVVXUX8BXgeWP8PElSj0ED/oft6w/WY9870jwoNWV1O+9ekrwqyfIky++54+b12L0kqZ+BAr6q3tL7OqCZLsjWDPs+tqr2qqq9Ft1/6/XYvSSpn75f+JFkd5pulR1pwvlq4JSqumiAfa8GHtYzvVO7vSRpDqyzBZ/kbTT95qH5ir5l7fuTBrwjZhmwNMkuSTanuYf+lOFLliQNol8L/jDgMVV1d+/MJB8ELgSO6bfjqlqT5A3AGTRfDvLZqrpwyHolSQPqF/BrgcXAldPm79Aum1VVnQactmGlSZKG0S/gDwfOTHIp/3U3zM7AI4E3jLswSdJw+o0m+Z0kj6K5n31Hmv731cAyv/hDkua/vnfRVNVa4GdzVIskaYTGOhaNJGlyDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOsqAl6SOMuAlqaMMeEnqKANekjrKgJekjjLgJamjDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOqrvd7LOtcftuDXLj3nOpMuQpE6wBS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHpaomXcN/SnIrcMmk6xijbYEbJl3EGHX9+KD7x9j144PuHePDq2q7mRZsOteVzOKSqtpr0kWMS5LlHt/C1vVj7PrxwcZxjFPsopGkjjLgJamj5lvAHzvpAsbM41v4un6MXT8+2DiOEZhnF1klSaMz31rwkqQRMeAlqaPmRcAneXaSS5JcluTtk65nWEkeluQHSS5KcmGSN7XzH5zke0kubV8fNOlah5VkUZKfJ/lWO71LkrPbY/yXJJtPusYNlWSbJF9LcnF7Lp/StXOY5M3tv9ELkpyU5H4L+Rwm+WyS65Jc0DNvxnOWxkfa3DkvyRMnV/l4TDzgkywCPg4cAOwBHJJkj8lWNbQ1wFur6tHAPsDr22N6O3BmVS0FzmynF7o3ARf1TL8X+FB7jDcCh02kqtH4Z+A7VbU78Hia4+zMOUyyI/BGYK+qeiywCHgxC/scngg8e9q8dZ2zA4Cl7c+rgE/OUY1zZuIBD+wNXFZVK6vqLuArwPMmXNNQquqaqjq3fX8rTTDsSHNcn2tX+xzw/MlUOBpJdgKeAxzfTgfYD/hau8qCPcYkWwHPAD4DUFV3VdVNdOwc0jzs+CdJNgXuD1zDAj6HVfUj4PfTZq/rnD0P+Hw1fgZsk2SHual0bsyHgN8R+G3P9Op2XickWQI8ATgbeGhVXQPNLwFg+8lVNhIfBo4E1rbTDwFuqqo17fRCPpe7AtcDJ7RdUMcn2ZIOncOqugp4P/AbmmC/GVhBd87hlHWds05nD8yPgM8M8zpx72aSBwBfBw6vqlsmXc8oJXkucF1VreidPcOqC/Vcbgo8EfhkVT0BuJ0F3B0zk7Yv+nnALsBiYEuabovpFuo5nE2X/r3OaD4E/GrgYT3TOwFXT6iWkUmyGU24f6mq/rWd/bupPwHb1+smVd8I/ClwUJJVNN1q+9G06Ldp/9yHhX0uVwOrq+rsdvprNIHfpXP4LOCKqrq+qu4G/hV4Kt05h1PWdc46mT295kPALwOWtlfuN6e5yHPKhGsaStsX/Rngoqr6YM+iU4BD2/eHAv8217WNSlUdVVU7VdUSmnP2/ap6CfAD4OB2tQV7jFV1LfDbJLu1s/YHfkWHziFN18w+Se7f/pudOsZOnMMe6zpnpwAvb++m2Qe4eaorpzOqauI/wIHAr4HLgX+YdD0jOJ6n0fypdx7wi/bnQJo+6jOBS9vXB0+61hEd777At9r3uwLnAJcBXwW2mHR9QxzXfweWt+fxm8CDunYOgXcBFwMXAF8AtljI5xA4ieZ6wt00LfTD1nXOaLpoPt7mzvk0dxNN/BhG+eNQBZLUUfOhi0aSNAYGvCR1lAEvSR1lwEtSRxnwktRRBrzmRJJK8oGe6SOSHD2ifZ+Y5ODZ1xz6c17Yjir5g2nzN2lHJbwgyflJliXZZcy1rEqy7Tg/QwufAa+58kfgBfMtlNrRTAd1GPC6qvqzafP/huZR/z2r6nHAXwE3jahEaYMZ8Jora2i+C/PN0xdMb4Enua193TfJWUlOTvLrJMckeUmSc9qW8iN6dvOsJP+3Xe+57faLkvxT26I+L8mre/b7gyRfpnnAZXo9h7T7vyDJe9t5/5PmAbZPJfmnaZvsAFxTVWsBqmp1Vd3YbvfJJMvbMdff1fMZq5K8J8lP2+VPTHJGksuTvKanzh8l+UaSXyX5VJL7/D+b5KXtf5NfJPl0e9yL2v+uU39V3Oe/uzYCk37Syp+N4we4DdgKWAVsDRwBHN0uOxE4uHfd9nVfmpbwDjRPWF4FvKtd9ibgwz3bf4emwbKU5gnG+9GM8f2Odp0taJ5K3aXd7+3ALjPUuZjmEf7taAYc+z7w/HbZD5nhaUeaMUxW0Tyx/AHgCT3Lpp6aXNRuv2c7vQp4bfv+QzRPyz6w/dzreo7/TponSxcB35v679Ruvy3waOBUYLN2/ieAlwNPAr7XU8c2k/434M/c/9iC15ypZkTNz9N8ycSgllUzvv4faR4p/247/3xgSc96J1fV2qq6FFgJ7A78Oc1YI7+gGa75ITS/AADOqaorZvi8JwM/rGYArjXAl2jGhe93XKuB3YCjaIZOPjPJ/u3iFyU5F/g58BiaL7WZMjXm0vnA2VV1a1VdD9yZZJueOldW1T00j+E/bdrH708T5sva49yf5hfCSmDXJB9N8mygU6OZajCbzr6KNFIfBs4FTuiZt4a2u7Ad9Kr3K+L+2PN+bc/0Wu7973f6mBtFM9bI31XVGb0LkuxL04KfyUxDyM6q/QV0OnB6kt8Bz0+ykuYvlSdX1Y1JTqT5y2JK77FMP86pY5vpuKbX+7mqOuo+B5I8HvgL4PXAi4BXru9xaWGzBa85VVW/B07m3l8Dt4qmFQrN+OSbbcCuX9jezfIImhbsJcAZwGvboZtJ8qj2Szv6ORt4ZpJt2wuwhwBn9dug7T9f3L7fBNgTuJKmS+p24OYkD2XmsdZns3c70uomNBdzfzxt+ZnAwUm2bz//wUke3l7M3qSqvg68k2aoY21kbMFrEj4AvKFn+jjg35KcQxNY62pd93MJTRA/FHhNVd2Z5Hiabpxz278MrmeWr5+rqmuSHEUzZG6A06pqtuFytweOS7JFO30O8LG2hp8DF9J0mfxkA47rp8AxwOOAHwHfmFbvr5K8A/hu+0vgbpoW+x9ovo1qqhF3nxa+us/RJKV5qu1KOqKqnjvpWrQw2UUjSR1lC16SOsoWvCR1lAEvSR1lwEtSRxnwktRRBrwkddT/B2sFxy3/OvfgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 119\n",
      "Positive = 113\n",
      "Nagative = 6\n",
      "\n",
      "Dataframe size\n",
      "(119, 3)\n",
      "\n",
      " up_sample() is activated...\n",
      "\n",
      "\n",
      "Dataset after up sample\n",
      "\n",
      "     score                                                 en  polarity\n",
      "0        2  Mothers have to check from many doctors. And e...         0\n",
      "1        5  Good care, all care goes to the emergency depa...         1\n",
      "2        4  The place is cramped compared to the number of...         1\n",
      "3        1  The broken bone doctor diagnosed without check...         0\n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0\n",
      "..     ...                                                ...       ...\n",
      "221      2  The service is slow, the queue is too long, at...         0\n",
      "222      2  Mothers have to check from many doctors. And e...         0\n",
      "223      1  The broken bone doctor diagnosed without check...         0\n",
      "224      5  Service is excellent. Treats oneself as their ...         1\n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1\n",
      "\n",
      "[226 rows x 3 columns]\n",
      "\n",
      "Dataset after up sample group by class\n",
      "\n",
      "1    113\n",
      "0    113\n",
      "Name: polarity, dtype: int64\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 226\n",
      "Positive = 113\n",
      "Nagative = 113\n",
      "\n",
      "Dataframe size\n",
      "(226, 3)\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert sentense to token <<<<<\n",
      "\n",
      " gen_token() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:00<00:00, 795.10it/s]\n",
      "100%|██████████| 226/226 [00:00<00:00, 9064.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Mothers have to check from many doctors. And e...         0   \n",
      "1        5  Good care, all care goes to the emergency depa...         1   \n",
      "2        4  The place is cramped compared to the number of...         1   \n",
      "3        1  The broken bone doctor diagnosed without check...         0   \n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0   \n",
      "..     ...                                                ...       ...   \n",
      "221      2  The service is slow, the queue is too long, at...         0   \n",
      "222      2  Mothers have to check from many doctors. And e...         0   \n",
      "223      1  The broken bone doctor diagnosed without check...         0   \n",
      "224      5  Service is excellent. Treats oneself as their ...         1   \n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1   \n",
      "\n",
      "                                                 token  \n",
      "0    [Mothers, have, to, check, from, many, doctors...  \n",
      "1    [Good, care, ,, all, care, goes, to, the, emer...  \n",
      "2    [The, place, is, cramped, compared, to, the, n...  \n",
      "3    [The, broken, bone, doctor, diagnosed, without...  \n",
      "4    [Doctor, diagnosis, Understand, that, doctors,...  \n",
      "..                                                 ...  \n",
      "221  [The, service, is, slow, ,, the, queue, is, to...  \n",
      "222  [Mothers, have, to, check, from, many, doctors...  \n",
      "223  [The, broken, bone, doctor, diagnosed, without...  \n",
      "224  [Service, is, excellent, ., Treats, oneself, a...  \n",
      "225  [Bring, loved, ones, to, cure, diabetes, ., Is...  \n",
      "\n",
      "[226 rows x 4 columns]\n",
      "(226, 4)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert text to lowercase <<<<<\n",
      "\n",
      " lowercase_text() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Mothers have to check from many doctors. And e...         0   \n",
      "1        5  Good care, all care goes to the emergency depa...         1   \n",
      "2        4  The place is cramped compared to the number of...         1   \n",
      "3        1  The broken bone doctor diagnosed without check...         0   \n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0   \n",
      "..     ...                                                ...       ...   \n",
      "221      2  The service is slow, the queue is too long, at...         0   \n",
      "222      2  Mothers have to check from many doctors. And e...         0   \n",
      "223      1  The broken bone doctor diagnosed without check...         0   \n",
      "224      5  Service is excellent. Treats oneself as their ...         1   \n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Mothers, have, to, check, from, many, doctors...   \n",
      "1    [Good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [The, place, is, cramped, compared, to, the, n...   \n",
      "3    [The, broken, bone, doctor, diagnosed, without...   \n",
      "4    [Doctor, diagnosis, Understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [The, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [Mothers, have, to, check, from, many, doctors...   \n",
      "223  [The, broken, bone, doctor, diagnosed, without...   \n",
      "224  [Service, is, excellent, ., Treats, oneself, a...   \n",
      "225  [Bring, loved, ones, to, cure, diabetes, ., Is...   \n",
      "\n",
      "                                             lowercase  \n",
      "0    [mothers, have, to, check, from, many, doctors...  \n",
      "1    [good, care, ,, all, care, goes, to, the, emer...  \n",
      "2    [the, place, is, cramped, compared, to, the, n...  \n",
      "3    [the, broken, bone, doctor, diagnosed, without...  \n",
      "4    [doctor, diagnosis, understand, that, doctors,...  \n",
      "..                                                 ...  \n",
      "221  [the, service, is, slow, ,, the, queue, is, to...  \n",
      "222  [mothers, have, to, check, from, many, doctors...  \n",
      "223  [the, broken, bone, doctor, diagnosed, without...  \n",
      "224  [service, is, excellent, ., treats, oneself, a...  \n",
      "225  [bring, loved, ones, to, cure, diabetes, ., is...  \n",
      "\n",
      "[226 rows x 5 columns]\n",
      "(226, 5)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove special character <<<<<\n",
      "\n",
      " remove_spec_char() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Mothers have to check from many doctors. And e...         0   \n",
      "1        5  Good care, all care goes to the emergency depa...         1   \n",
      "2        4  The place is cramped compared to the number of...         1   \n",
      "3        1  The broken bone doctor diagnosed without check...         0   \n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0   \n",
      "..     ...                                                ...       ...   \n",
      "221      2  The service is slow, the queue is too long, at...         0   \n",
      "222      2  Mothers have to check from many doctors. And e...         0   \n",
      "223      1  The broken bone doctor diagnosed without check...         0   \n",
      "224      5  Service is excellent. Treats oneself as their ...         1   \n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Mothers, have, to, check, from, many, doctors...   \n",
      "1    [Good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [The, place, is, cramped, compared, to, the, n...   \n",
      "3    [The, broken, bone, doctor, diagnosed, without...   \n",
      "4    [Doctor, diagnosis, Understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [The, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [Mothers, have, to, check, from, many, doctors...   \n",
      "223  [The, broken, bone, doctor, diagnosed, without...   \n",
      "224  [Service, is, excellent, ., Treats, oneself, a...   \n",
      "225  [Bring, loved, ones, to, cure, diabetes, ., Is...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, ., treats, oneself, a...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, ., is...   \n",
      "\n",
      "                                         rem_spec_char  \n",
      "0    [mothers, have, to, check, from, many, doctors...  \n",
      "1    [good, care, , all, care, goes, to, the, emerg...  \n",
      "2    [the, place, is, cramped, compared, to, the, n...  \n",
      "3    [the, broken, bone, doctor, diagnosed, without...  \n",
      "4    [doctor, diagnosis, understand, that, doctors,...  \n",
      "..                                                 ...  \n",
      "221  [the, service, is, slow, , the, queue, is, too...  \n",
      "222  [mothers, have, to, check, from, many, doctors...  \n",
      "223  [the, broken, bone, doctor, diagnosed, without...  \n",
      "224  [service, is, excellent, , treats, oneself, as...  \n",
      "225  [bring, loved, ones, to, cure, diabetes, , isc...  \n",
      "\n",
      "[226 rows x 6 columns]\n",
      "(226, 6)\n",
      "\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word <<<<<\n",
      "\n",
      " remove_stop_word() is activated...\n",
      "\n",
      "\n",
      "stop_words:\n",
      "\n",
      "{'before', 'how', 'on', 'yourself', 'should', 'ours', 'more', 'aren', \"mustn't\", \"shouldn't\", 'no', 'being', \"needn't\", 'myself', 'are', 'too', \"mightn't\", 'o', 'ourselves', 'whom', 'who', 'down', \"should've\", 'from', 'during', 'shan', 'at', 'theirs', 'couldn', 'through', \"you've\", 'again', 'all', 'nor', \"you're\", 'into', 'this', 'weren', \"it's\", 'the', 'yourselves', 'while', 'haven', 'isn', 'themselves', 'why', 'until', 'under', 's', 'hasn', 'because', 'wasn', 'can', 'now', 'doing', 'with', \"don't\", 'my', \"aren't\", 'their', 'both', 'wouldn', 'we', 'in', 'or', 'hadn', 'up', 'by', 'yours', 'few', 'those', 'below', 'll', 'itself', 'and', 'than', 'own', \"that'll\", 'did', 'about', 'mustn', 'once', \"wasn't\", \"won't\", 'ma', 'don', 'some', \"shan't\", 'our', 'won', 'here', \"she's\", 'was', 'has', 'each', 'y', 'they', 'ain', 'is', 've', 'hers', 'such', 'against', 'only', 'above', 'shouldn', \"couldn't\", 'them', 'mightn', 'you', 'had', 't', 'there', 'its', 'any', 'will', 'that', 'a', 'needn', 'me', 'she', 'having', \"haven't\", 'so', 'which', 'for', 'be', 'after', 'further', 'i', 'am', 'most', 'these', 'himself', \"you'd\", 'over', 'just', 'very', \"wouldn't\", \"you'll\", 'were', 'been', 'd', 're', 'does', 'didn', 'as', \"isn't\", 'his', \"hasn't\", 'her', 'not', 'him', 'then', 'doesn', 'he', 'it', \"hadn't\", 'have', 'm', 'where', \"didn't\", 'out', 'other', 'when', 'but', 'your', 'herself', 'an', \"doesn't\", 'if', 'of', 'what', 'do', 'same', 'between', \"weren't\", 'to', 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [01:20<00:00,  2.79it/s]\n",
      "100%|██████████| 226/226 [00:00<00:00, 32279.26it/s]\n",
      "100%|██████████| 226/226 [00:00<00:00, 32375.17it/s]\n",
      "  0%|          | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Mothers have to check from many doctors. And e...         0   \n",
      "1        5  Good care, all care goes to the emergency depa...         1   \n",
      "2        4  The place is cramped compared to the number of...         1   \n",
      "3        1  The broken bone doctor diagnosed without check...         0   \n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0   \n",
      "..     ...                                                ...       ...   \n",
      "221      2  The service is slow, the queue is too long, at...         0   \n",
      "222      2  Mothers have to check from many doctors. And e...         0   \n",
      "223      1  The broken bone doctor diagnosed without check...         0   \n",
      "224      5  Service is excellent. Treats oneself as their ...         1   \n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Mothers, have, to, check, from, many, doctors...   \n",
      "1    [Good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [The, place, is, cramped, compared, to, the, n...   \n",
      "3    [The, broken, bone, doctor, diagnosed, without...   \n",
      "4    [Doctor, diagnosis, Understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [The, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [Mothers, have, to, check, from, many, doctors...   \n",
      "223  [The, broken, bone, doctor, diagnosed, without...   \n",
      "224  [Service, is, excellent, ., Treats, oneself, a...   \n",
      "225  [Bring, loved, ones, to, cure, diabetes, ., Is...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, ., treats, oneself, a...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, ., is...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, , all, care, goes, to, the, emerg...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, , the, queue, is, too...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, , treats, oneself, as...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, , isc...   \n",
      "\n",
      "                                             stop_word  \n",
      "0    [mothers, check, many, doctors, , linked, , ca...  \n",
      "1    [good, , goes, emergency, department, , everyt...  \n",
      "2    [place, cramped, compared, number, people, usi...  \n",
      "3    [broken, bone, doctor, diagnosed, without, che...  \n",
      "4    [doctor, diagnosis, understand, doctors, found...  \n",
      "..                                                 ...  \n",
      "221  [service, slow, , queue, long, , least, time, ...  \n",
      "222  [mothers, check, many, doctors, , linked, , ca...  \n",
      "223  [broken, bone, doctor, diagnosed, without, che...  \n",
      "224  [service, excellent, , treats, oneself, person...  \n",
      "225  [bring, loved, ones, cure, diabetes, , ischemi...  \n",
      "\n",
      "[226 rows x 7 columns]\n",
      "(226, 7)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word (Special) <<<<<\n",
      "\n",
      ">>>>> 've, ``, 's, n't, '', ' ' <<<<<\n",
      "\n",
      " remove_stop_word_spec() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Mothers have to check from many doctors. And e...         0   \n",
      "1        5  Good care, all care goes to the emergency depa...         1   \n",
      "2        4  The place is cramped compared to the number of...         1   \n",
      "3        1  The broken bone doctor diagnosed without check...         0   \n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0   \n",
      "..     ...                                                ...       ...   \n",
      "221      2  The service is slow, the queue is too long, at...         0   \n",
      "222      2  Mothers have to check from many doctors. And e...         0   \n",
      "223      1  The broken bone doctor diagnosed without check...         0   \n",
      "224      5  Service is excellent. Treats oneself as their ...         1   \n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Mothers, have, to, check, from, many, doctors...   \n",
      "1    [Good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [The, place, is, cramped, compared, to, the, n...   \n",
      "3    [The, broken, bone, doctor, diagnosed, without...   \n",
      "4    [Doctor, diagnosis, Understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [The, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [Mothers, have, to, check, from, many, doctors...   \n",
      "223  [The, broken, bone, doctor, diagnosed, without...   \n",
      "224  [Service, is, excellent, ., Treats, oneself, a...   \n",
      "225  [Bring, loved, ones, to, cure, diabetes, ., Is...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, ., treats, oneself, a...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, ., is...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, , all, care, goes, to, the, emerg...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, , the, queue, is, too...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, , treats, oneself, as...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, , isc...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [mothers, check, many, doctors, , linked, , ca...   \n",
      "1    [good, , goes, emergency, department, , everyt...   \n",
      "2    [place, cramped, compared, number, people, usi...   \n",
      "3    [broken, bone, doctor, diagnosed, without, che...   \n",
      "4    [doctor, diagnosis, understand, doctors, found...   \n",
      "..                                                 ...   \n",
      "221  [service, slow, , queue, long, , least, time, ...   \n",
      "222  [mothers, check, many, doctors, , linked, , ca...   \n",
      "223  [broken, bone, doctor, diagnosed, without, che...   \n",
      "224  [service, excellent, , treats, oneself, person...   \n",
      "225  [bring, loved, ones, cure, diabetes, , ischemi...   \n",
      "\n",
      "                                          stop_word_02  \n",
      "0    [mothers, check, many, doctors, , linked, , ca...  \n",
      "1    [good, , goes, emergency, department, , everyt...  \n",
      "2    [place, cramped, compared, number, people, usi...  \n",
      "3    [broken, bone, doctor, diagnosed, without, che...  \n",
      "4    [doctor, diagnosis, understand, doctors, found...  \n",
      "..                                                 ...  \n",
      "221  [service, slow, , queue, long, , least, time, ...  \n",
      "222  [mothers, check, many, doctors, , linked, , ca...  \n",
      "223  [broken, bone, doctor, diagnosed, without, che...  \n",
      "224  [service, excellent, , treats, oneself, person...  \n",
      "225  [bring, loved, ones, cure, diabetes, , ischemi...  \n",
      "\n",
      "[226 rows x 8 columns]\n",
      "(226, 8)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove single and space token <<<<<\n",
      "\n",
      " remove_single_token() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Mothers have to check from many doctors. And e...         0   \n",
      "1        5  Good care, all care goes to the emergency depa...         1   \n",
      "2        4  The place is cramped compared to the number of...         1   \n",
      "3        1  The broken bone doctor diagnosed without check...         0   \n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0   \n",
      "..     ...                                                ...       ...   \n",
      "221      2  The service is slow, the queue is too long, at...         0   \n",
      "222      2  Mothers have to check from many doctors. And e...         0   \n",
      "223      1  The broken bone doctor diagnosed without check...         0   \n",
      "224      5  Service is excellent. Treats oneself as their ...         1   \n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Mothers, have, to, check, from, many, doctors...   \n",
      "1    [Good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [The, place, is, cramped, compared, to, the, n...   \n",
      "3    [The, broken, bone, doctor, diagnosed, without...   \n",
      "4    [Doctor, diagnosis, Understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [The, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [Mothers, have, to, check, from, many, doctors...   \n",
      "223  [The, broken, bone, doctor, diagnosed, without...   \n",
      "224  [Service, is, excellent, ., Treats, oneself, a...   \n",
      "225  [Bring, loved, ones, to, cure, diabetes, ., Is...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, ., treats, oneself, a...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, ., is...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, , all, care, goes, to, the, emerg...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, , the, queue, is, too...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, , treats, oneself, as...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, , isc...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [mothers, check, many, doctors, , linked, , ca...   \n",
      "1    [good, , goes, emergency, department, , everyt...   \n",
      "2    [place, cramped, compared, number, people, usi...   \n",
      "3    [broken, bone, doctor, diagnosed, without, che...   \n",
      "4    [doctor, diagnosis, understand, doctors, found...   \n",
      "..                                                 ...   \n",
      "221  [service, slow, , queue, long, , least, time, ...   \n",
      "222  [mothers, check, many, doctors, , linked, , ca...   \n",
      "223  [broken, bone, doctor, diagnosed, without, che...   \n",
      "224  [service, excellent, , treats, oneself, person...   \n",
      "225  [bring, loved, ones, cure, diabetes, , ischemi...   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0    [mothers, check, many, doctors, , linked, , ca...   \n",
      "1    [good, , goes, emergency, department, , everyt...   \n",
      "2    [place, cramped, compared, number, people, usi...   \n",
      "3    [broken, bone, doctor, diagnosed, without, che...   \n",
      "4    [doctor, diagnosis, understand, doctors, found...   \n",
      "..                                                 ...   \n",
      "221  [service, slow, , queue, long, , least, time, ...   \n",
      "222  [mothers, check, many, doctors, , linked, , ca...   \n",
      "223  [broken, bone, doctor, diagnosed, without, che...   \n",
      "224  [service, excellent, , treats, oneself, person...   \n",
      "225  [bring, loved, ones, cure, diabetes, , ischemi...   \n",
      "\n",
      "                                       rem_single_char  \n",
      "0    [mothers, check, many, doctors, linked, causin...  \n",
      "1    [good, goes, emergency, department, everything...  \n",
      "2    [place, cramped, compared, number, people, usi...  \n",
      "3    [broken, bone, doctor, diagnosed, without, che...  \n",
      "4    [doctor, diagnosis, understand, doctors, found...  \n",
      "..                                                 ...  \n",
      "221  [service, slow, queue, long, least, time, quit...  \n",
      "222  [mothers, check, many, doctors, linked, causin...  \n",
      "223  [broken, bone, doctor, diagnosed, without, che...  \n",
      "224  [service, excellent, treats, oneself, personal...  \n",
      "225  [bring, loved, ones, cure, diabetes, ischemic,...  \n",
      "\n",
      "[226 rows x 9 columns]\n",
      "(226, 9)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Normalization (Lemmatization: root word) <<<<<\n",
      "\n",
      " lemmatize_token() is activated...\n",
      "\n",
      "\n",
      "Test POS:\n",
      "\n",
      "This is a book\n",
      "\n",
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('book', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 71.18it/s]\n",
      "100%|██████████| 226/226 [00:00<00:00, 6455.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Mothers have to check from many doctors. And e...         0   \n",
      "1        5  Good care, all care goes to the emergency depa...         1   \n",
      "2        4  The place is cramped compared to the number of...         1   \n",
      "3        1  The broken bone doctor diagnosed without check...         0   \n",
      "4        1  Doctor diagnosis Understand that doctors have ...         0   \n",
      "..     ...                                                ...       ...   \n",
      "221      2  The service is slow, the queue is too long, at...         0   \n",
      "222      2  Mothers have to check from many doctors. And e...         0   \n",
      "223      1  The broken bone doctor diagnosed without check...         0   \n",
      "224      5  Service is excellent. Treats oneself as their ...         1   \n",
      "225      5  Bring loved ones to cure diabetes. Ischemic st...         1   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Mothers, have, to, check, from, many, doctors...   \n",
      "1    [Good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [The, place, is, cramped, compared, to, the, n...   \n",
      "3    [The, broken, bone, doctor, diagnosed, without...   \n",
      "4    [Doctor, diagnosis, Understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [The, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [Mothers, have, to, check, from, many, doctors...   \n",
      "223  [The, broken, bone, doctor, diagnosed, without...   \n",
      "224  [Service, is, excellent, ., Treats, oneself, a...   \n",
      "225  [Bring, loved, ones, to, cure, diabetes, ., Is...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, ,, all, care, goes, to, the, emer...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, ,, the, queue, is, to...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, ., treats, oneself, a...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, ., is...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [mothers, have, to, check, from, many, doctors...   \n",
      "1    [good, care, , all, care, goes, to, the, emerg...   \n",
      "2    [the, place, is, cramped, compared, to, the, n...   \n",
      "3    [the, broken, bone, doctor, diagnosed, without...   \n",
      "4    [doctor, diagnosis, understand, that, doctors,...   \n",
      "..                                                 ...   \n",
      "221  [the, service, is, slow, , the, queue, is, too...   \n",
      "222  [mothers, have, to, check, from, many, doctors...   \n",
      "223  [the, broken, bone, doctor, diagnosed, without...   \n",
      "224  [service, is, excellent, , treats, oneself, as...   \n",
      "225  [bring, loved, ones, to, cure, diabetes, , isc...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [mothers, check, many, doctors, , linked, , ca...   \n",
      "1    [good, , goes, emergency, department, , everyt...   \n",
      "2    [place, cramped, compared, number, people, usi...   \n",
      "3    [broken, bone, doctor, diagnosed, without, che...   \n",
      "4    [doctor, diagnosis, understand, doctors, found...   \n",
      "..                                                 ...   \n",
      "221  [service, slow, , queue, long, , least, time, ...   \n",
      "222  [mothers, check, many, doctors, , linked, , ca...   \n",
      "223  [broken, bone, doctor, diagnosed, without, che...   \n",
      "224  [service, excellent, , treats, oneself, person...   \n",
      "225  [bring, loved, ones, cure, diabetes, , ischemi...   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0    [mothers, check, many, doctors, , linked, , ca...   \n",
      "1    [good, , goes, emergency, department, , everyt...   \n",
      "2    [place, cramped, compared, number, people, usi...   \n",
      "3    [broken, bone, doctor, diagnosed, without, che...   \n",
      "4    [doctor, diagnosis, understand, doctors, found...   \n",
      "..                                                 ...   \n",
      "221  [service, slow, , queue, long, , least, time, ...   \n",
      "222  [mothers, check, many, doctors, , linked, , ca...   \n",
      "223  [broken, bone, doctor, diagnosed, without, che...   \n",
      "224  [service, excellent, , treats, oneself, person...   \n",
      "225  [bring, loved, ones, cure, diabetes, , ischemi...   \n",
      "\n",
      "                                       rem_single_char  \\\n",
      "0    [mothers, check, many, doctors, linked, causin...   \n",
      "1    [good, goes, emergency, department, everything...   \n",
      "2    [place, cramped, compared, number, people, usi...   \n",
      "3    [broken, bone, doctor, diagnosed, without, che...   \n",
      "4    [doctor, diagnosis, understand, doctors, found...   \n",
      "..                                                 ...   \n",
      "221  [service, slow, queue, long, least, time, quit...   \n",
      "222  [mothers, check, many, doctors, linked, causin...   \n",
      "223  [broken, bone, doctor, diagnosed, without, che...   \n",
      "224  [service, excellent, treats, oneself, personal...   \n",
      "225  [bring, loved, ones, cure, diabetes, ischemic,...   \n",
      "\n",
      "                                            norm_lemma  \n",
      "0    [mother, check, many, doctor, link, cause, man...  \n",
      "1    [good, go, emergency, department, everything, ...  \n",
      "2    [place, cramped, compare, number, people, use,...  \n",
      "3    [broken, bone, doctor, diagnose, without, chec...  \n",
      "4    [doctor, diagnosis, understand, doctor, found,...  \n",
      "..                                                 ...  \n",
      "221  [service, slow, queue, long, least, time, quit...  \n",
      "222  [mother, check, many, doctor, link, cause, man...  \n",
      "223  [broken, bone, doctor, diagnose, without, chec...  \n",
      "224  [service, excellent, treat, oneself, personal,...  \n",
      "225  [bring, love, one, cure, diabetes, ischemic, s...  \n",
      "\n",
      "[226 rows x 10 columns]\n",
      "(226, 10)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF) <<<<<\n",
      "\n",
      " vec_tf_idf() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 1026\n",
      "\n",
      "\n",
      "\n",
      "['10', '100', '12', '15', '1973', '1st', '20', '2003', '2016', '25week', '28', '30', '300', '400', '4th', '50', '555', '60', '600', '70', '72', '7pm', 'abdomen', 'able', 'abnormal', 'abnormality', 'abroad', 'accept', 'accepted', 'accessibility', 'accommodate', 'accommodation', 'accord', 'accurately', 'ache', 'acne', 'act', 'actual', 'actually', 'addition', 'adjust', 'adjustment', 'admin', 'admission', 'admit', 'advance', 'advantage', 'advice', 'advisable', 'advise', 'affected', 'afraid', 'age', 'ago', 'air', 'ajarn', 'albinism', 'albino', 'alienate', 'allergic', 'allergy', 'allow', 'almost', 'aloud', 'already', 'although', 'always', 'analyze', 'annoy', 'annoyed', 'another', 'answer', 'anyone', 'anything', 'appear', 'applaud', 'appliance', 'apply', 'appoint', 'appointment', 'appropriate', 'area', 'arm', 'around', 'arrange', 'arrive', 'ask', 'asks', 'aspect', 'assistance', 'assistant', 'atmosphere', 'atrophy', 'attention', 'attentive', 'aunt', 'available', 'awake', 'aware', 'away', 'baby', 'back', 'bad', 'basis', 'basketball', 'bath', 'bathroom', 'bear', 'beautiful', 'become', 'bed', 'belief', 'believe', 'best', 'big', 'biopsy', 'birth', 'bit', 'bleed', 'blood', 'board', 'body', 'bone', 'book', 'boring', 'born', 'bowel', 'breast', 'breastfeeding', 'breathing', 'bring', 'broken', 'building', 'bumpy', 'burden', 'busy', 'buy', 'cafeteria', 'call', 'calm', 'calmly', 'camera', 'cancer', 'cancerous', 'capable', 'car', 'card', 'care', 'carpool', 'case', 'caught', 'cause', 'cell', 'cervical', 'cervix', 'cesarean', 'chalermprakiet', 'chance', 'change', 'chaotic', 'charge', 'cheaper', 'check', 'checked', 'chemist', 'chemo', 'chemotherapy', 'child', 'choose', 'cin', 'cin3', 'circulate', 'cirrhosis', 'civil', 'clarify', 'clarity', 'class', 'clay', 'clean', 'clear', 'clearly', 'clinic', 'clinical', 'clock', 'close', 'closely', 'cold', 'come', 'comfort', 'comfortable', 'committee', 'common', 'compare', 'complete', 'completely', 'complicate', 'complication', 'concerned', 'conclude', 'condition', 'conditioned', 'condo', 'cone', 'confident', 'confirm', 'confuse', 'confusion', 'consciousness', 'consecutive', 'consider', 'considerate', 'consideration', 'consultation', 'consultative', 'contact', 'continued', 'continuously', 'control', 'convenient', 'conveniently', 'cool', 'cope', 'cord', 'cost', 'cough', 'could', 'country', 'courteous', 'cramped', 'crazy', 'cream', 'crisis', 'criticize', 'cross', 'crowd', 'cry', 'cure', 'currently', 'customer', 'cut', 'cute', 'daily', 'dare', 'date', 'daughter', 'dawn', 'day', 'debt', 'decides', 'decision', 'deeply', 'default', 'definitely', 'delay', 'deliver', 'delivery', 'department', 'depression', 'description', 'deserves', 'despair', 'despite', 'detail', 'deterioration', 'determine', 'developed', 'diabetes', 'diagnose', 'diagnosis', 'different', 'difficult', 'disadvantage', 'disappear', 'disappointed', 'disaster', 'discharge', 'discourage', 'discus', 'disease', 'dispense', 'dispenses', 'dissect', 'distress', 'divide', 'dna', 'do', 'doctor', 'donate', 'donation', 'doubt', 'dr', 'drop', 'drug', 'duct', 'due', 'duration', 'duty', 'early', 'easily', 'easy', 'eat', 'effect', 'elbow', 'elder', 'eloquently', 'emergency', 'emotional', 'encounter', 'encourage', 'encouragement', 'enough', 'enter', 'equal', 'equally', 'equip', 'equipment', 'eradicates', 'escalator', 'especially', 'ethic', 'even', 'every', 'everyone', 'everything', 'exact', 'examination', 'examine', 'excellent', 'except', 'expect', 'expense', 'expensive', 'experience', 'experienced', 'expert', 'expertly', 'explain', 'explains', 'explanation', 'expression', 'extremely', 'eye', 'facial', 'facility', 'faint', 'fairly', 'faith', 'fall', 'family', 'famous', 'fan', 'far', 'fast', 'faster', 'father', 'fear', 'feature', 'february', 'fee', 'feel', 'fell', 'felt', 'female', 'fever', 'fibroid', 'fight', 'fill', 'final', 'find', 'finger', 'finish', 'first', 'fit', 'floor', 'flow', 'follow', 'food', 'forever', 'forget', 'fortunately', 'found', 'foundation', 'fracture', 'fret', 'friend', 'friendly', 'frighten', 'front', 'frustrate', 'frustration', 'full', 'fully', 'fussy', 'general', 'generally', 'gestational', 'gesture', 'get', 'girlfriend', 'give', 'glance', 'gland', 'go', 'gold', 'good', 'government', 'graduate', 'grandma', 'grandmother', 'grateful', 'great', 'greatly', 'group', 'grow', 'grown', 'growth', 'guard', 'guideline', 'guilty', 'gynecological', 'gynecologist', 'gynecology', 'habit', 'hair', 'half', 'hand', 'happen', 'happy', 'hard', 'harden', 'heal', 'health', 'healthy', 'heard', 'heart', 'heavy', 'help', 'helpful', 'hepatitis', 'hiccup', 'high', 'history', 'hn', 'home', 'hope', 'hopeless', 'hormone', 'hospital', 'hospitality', 'hour', 'housewife', 'humor', 'hundred', 'hurl', 'hurry', 'hvp', 'illness', 'immediately', 'important', 'importantly', 'impressed', 'impression', 'impressive', 'improve', 'improvement', 'incident', 'include', 'indirectly', 'infection', 'inflame', 'inflammatory', 'inform', 'information', 'inhaler', 'inhibit', 'initially', 'inject', 'injection', 'inquire', 'inquiry', 'inside', 'inspect', 'inspection', 'inspects', 'instead', 'institution', 'instruction', 'instructor', 'insufficient', 'intend', 'interested', 'internal', 'intestine', 'invade', 'investigate', 'invite', 'iq', 'irritability', 'irritate', 'irritation', 'ischemic', 'jam', 'jealousy', 'job', 'join', 'joint', 'kate', 'keep', 'keloid', 'keng', 'khun', 'kidney', 'kind', 'knee', 'know', 'knowledge', 'land', 'language', 'large', 'last', 'late', 'later', 'leaflet', 'least', 'leep', 'leg', 'lesion', 'less', 'level', 'lie', 'life', 'lift', 'lightly', 'like', 'line', 'link', 'listen', 'little', 'live', 'liver', 'living', 'location', 'lone', 'long', 'longer', 'look', 'loss', 'lot', 'lottery', 'love', 'lovely', 'low', 'lump', 'luo', 'luxury', 'lymph', 'lymphatic', 'maintain', 'make', 'manage', 'management', 'manner', 'many', 'master', 'matter', 'may', 'maybe', 'meaning', 'measure', 'meat', 'medical', 'medication', 'medicine', 'meet', 'meeting', 'member', 'memorize', 'menstruation', 'merciless', 'method', 'minute', 'misfortune', 'mixed', 'modern', 'mom', 'moment', 'monitor', 'month', 'morality', 'morning', 'mother', 'mouth', 'move', 'mri', 'much', 'must', 'nature', 'nearly', 'neck', 'need', 'needle', 'neglect', 'negligence', 'nerve', 'neuro', 'neurologist', 'never', 'new', 'newborn', 'news', 'next', 'night', 'node', 'normal', 'normally', 'nothing', 'notice', 'notify', 'nourish', 'numb', 'number', 'numbness', 'nurse', 'nursery', 'nursing', 'obstetrician', 'occur', 'officer', 'often', 'ok', 'okay', 'old', 'one', 'oneself', 'online', 'opd', 'open', 'opportunity', 'option', 'order', 'ordinary', 'organize', 'outpatient', 'outside', 'ovary', 'overall', 'owner', 'paid', 'pain', 'pap', 'parking', 'part', 'pas', 'pass', 'past', 'patient', 'pay', 'payment', 'pedestrian', 'pensioner', 'people', 'percent', 'perform', 'periodically', 'person', 'personal', 'personally', 'personnel', 'pharmacy', 'phayaban', 'phra', 'physical', 'physician', 'pick', 'picture', 'pillow', 'place', 'plan', 'play', 'pleasant', 'please', 'pm', 'point', 'polite', 'poor', 'possible', 'potential', 'pour', 'pre', 'precious', 'precisely', 'pregnancy', 'prematurely', 'prescribed', 'present', 'pressure', 'pretend', 'previously', 'price', 'prioritize', 'private', 'privilege', 'problem', 'procedure', 'process', 'processing', 'professional', 'professor', 'progress', 'project', 'promise', 'protein', 'provide', 'provider', 'province', 'psychiatric', 'psychiatrist', 'psychiatry', 'psychological', 'psychologist', 'psychotherapy', 'public', 'pull', 'punch', 'push', 'put', 'quality', 'question', 'queue', 'quick', 'quickly', 'quite', 'radiation', 'radiologist', 'radiotherapy', 'rain', 'raise', 'ran', 'rank', 'rarely', 'rat', 'rating', 'reach', 'read', 'reading', 'ready', 'really', 'receive', 'recommend', 'reduce', 'refer', 'regard', 'register', 'regular', 'reiterate', 'relative', 'reliable', 'reluctant', 'remember', 'remove', 'repair', 'report', 'require', 'research', 'reservation', 'reserve', 'residue', 'resource', 'respect', 'respond', 'rest', 'result', 'return', 'review', 'rich', 'right', 'rise', 'risk', 'road', 'room', 'rotation', 'round', 'rule', 'rumor', 'run', 'rush', 'safe', 'safety', 'sampran', 'satisfactory', 'satisfied', 'saw', 'say', 'scalp', 'scar', 'schedule', 'school', 'science', 'scream', 'screen', 'second', 'section', 'security', 'see', 'seem', 'select', 'send', 'sensitive', 'sent', 'separate', 'servant', 'service', 'several', 'severe', 'sex', 'share', 'shingle', 'shock', 'shoe', 'shortcoming', 'shout', 'show', 'siam', 'sick', 'side', 'similar', 'simply', 'since', 'siriraj', 'sirirat', 'sit', 'size', 'skilled', 'skin', 'sleep', 'slightly', 'slow', 'smart', 'smear', 'smile', 'smooth', 'sneaker', 'social', 'somdet', 'someone', 'sometimes', 'soon', 'sort', 'sound', 'spacious', 'speak', 'speaks', 'special', 'specialist', 'specify', 'speed', 'spend', 'spinal', 'spoke', 'spray', 'spread', 'sri', 'staff', 'stage', 'standard', 'star', 'start', 'state', 'status', 'stay', 'step', 'stick', 'still', 'stomach', 'stood', 'stop', 'straight', 'stretch', 'stroke', 'strong', 'student', 'submit', 'suddenly', 'suffer', 'sufficient', 'suffocate', 'suggest', 'summary', 'sunk', 'support', 'sure', 'surgeon', 'surgery', 'survey', 'survival', 'suthee', 'swell', 'symptom', 'symptomatic', 'system', 'systematic', 'take', 'talented', 'talk', 'taro', 'tea', 'teach', 'teacher', 'team', 'tease', 'technology', 'teen', 'teenager', 'tell', 'tenderness', 'term', 'test', 'thai', 'thalassemia', 'thank', 'thanked', 'thanks', 'therefore', 'thing', 'think', 'thirty', 'thorough', 'thoroughly', 'though', 'thought', 'thread', 'threw', 'throughout', 'time', 'tire', 'today', 'toe', 'together', 'told', 'top', 'total', 'touch', 'tourette', 'traffic', 'transfer', 'transplant', 'travel', 'treat', 'treatment', 'trust', 'try', 'tumor', 'turn', 'twice', 'two', 'type', 'ultrasound', 'unable', 'uncomfortable', 'undergo', 'understand', 'understands', 'understood', 'unit', 'up', 'update', 'upper', 'use', 'user', 'usually', 'uterine', 'uterus', 'vaccinate', 'vaginal', 'value', 'various', 'vein', 'view', 'visit', 'vocational', 'vomit', 'wait', 'wake', 'walk', 'want', 'warm', 'wash', 'waste', 'watch', 'water', 'watery', 'wave', 'way', 'weak', 'weakat', 'website', 'week', 'weekday', 'ween', 'weigh', 'weight', 'welcome', 'well', 'wet', 'wheelchair', 'whether', 'whole', 'wide', 'wipe', 'within', 'without', 'word', 'work', 'worried', 'worry', 'worth', 'would', 'wound', 'wrist', 'write', 'year', 'yes', 'yesterday', 'yet', 'yew', 'young']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (0, 79)\t0.3191872181605752\n",
      "  (0, 447)\t0.2519124387692394\n",
      "  (0, 151)\t0.334242410887073\n",
      "  (0, 535)\t0.37166680575190497\n",
      "  (0, 286)\t0.14633250469673145\n",
      "  (0, 562)\t0.6017553126254559\n",
      "  (0, 162)\t0.27881872299533084\n",
      "  (0, 590)\t0.3514867006392908\n",
      "  (1, 81)\t0.45901315975836054\n",
      "  (1, 948)\t0.1875625306555274\n",
      "  (1, 328)\t0.4342212926622149\n",
      "  (1, 323)\t0.2834787387191042\n",
      "  (1, 256)\t0.2762930780018336\n",
      "  (1, 305)\t0.45901315975836054\n",
      "  (1, 402)\t0.2605809699574378\n",
      "  (1, 404)\t0.3609508308186593\n",
      "  (2, 240)\t0.12969824251856021\n",
      "  (2, 322)\t0.16136417537191938\n",
      "  (2, 645)\t0.16883114081342018\n",
      "  (2, 69)\t0.23474554766530972\n",
      "  (2, 655)\t0.0857684841584719\n",
      "  (2, 850)\t0.13130452383195168\n",
      "  (2, 575)\t0.2181397551127615\n",
      "  (2, 862)\t0.13844515349369793\n",
      "  (2, 622)\t0.0909304722617829\n",
      "  :\t:\n",
      "  (225, 823)\t0.1499785785885013\n",
      "  (225, 130)\t0.1585416063590612\n",
      "  (225, 431)\t0.2999571571770026\n",
      "  (225, 631)\t0.14333657823568055\n",
      "  (225, 550)\t0.13790966879814504\n",
      "  (225, 443)\t0.1499785785885013\n",
      "  (225, 368)\t0.12584075900778877\n",
      "  (225, 167)\t0.13332128224711048\n",
      "  (225, 828)\t0.14285093912872385\n",
      "  (225, 132)\t0.11986767655834976\n",
      "  (225, 919)\t0.11727773123722886\n",
      "  (225, 436)\t0.23973535311669952\n",
      "  (225, 901)\t0.12270464067476437\n",
      "  (225, 530)\t0.13332128224711048\n",
      "  (225, 1012)\t0.12270464067476437\n",
      "  (225, 1020)\t0.07601385611539647\n",
      "  (225, 1002)\t0.06745082834483657\n",
      "  (225, 322)\t0.11727773123722886\n",
      "  (225, 862)\t0.10062043489583801\n",
      "  (225, 622)\t0.13217456058772062\n",
      "  (225, 246)\t0.07928809810231982\n",
      "  (225, 404)\t0.06233560336783532\n",
      "  (225, 447)\t0.12625879916651267\n",
      "  (225, 151)\t0.08376133714417253\n",
      "  (225, 286)\t0.0733420168226065\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "siriraj-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF), bigrams <<<<<\n",
      "\n",
      " vec_tf_idf_bigram() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 3114\n",
      "\n",
      "\n",
      "\n",
      "['10 good', '100 patient', '12 2016', '12 time', '15 year', '1973 found', '1st floor', '1st patient', '20 minute', '20 month', '20 year', '2003 doctor', '2016 checked', '25week first', '28 12', '30 70', '30 minute', '300 doctor', '400 pm', '4th floor', '50 30', '50 50', '555 personally', '60 accord', '60 last', '600 next', '70 cry', '72 year', '7pm back', '7pm finish', 'abdomen inspection', 'able anything', 'able find', 'able heal', 'able make', 'able see', 'able tell', 'able walk', 'abnormal go', 'abnormal menstruation', 'abnormality cin3', 'abnormality occur', 'abroad come', 'accept patient', 'accepted nearly', 'accessibility option', 'accommodate lot', 'accommodation treat', 'accord doctor', 'accord order', 'ache rise', 'acne famous', 'acne siriraj', 'acne someone', 'act master', 'act tire', 'actual incident', 'actually get', 'actually go', 'addition building', 'addition dr', 'addition various', 'adjust medicine', 'adjust organize', 'adjustment come', 'adjustment satisfactory', 'admin expense', 'admission patient', 'admit siriraj', 'admit without', 'advance nurse', 'advantage take', 'advice case', 'advice dispense', 'advice doctor', 'advice easy', 'advice encouragement', 'advice everything', 'advice follow', 'advice nurse', 'advice provide', 'advisable go', 'advise act', 'advise advise', 'advise dissect', 'advise go', 'advise good', 'advise know', 'advise teach', 'advise well', 'affected use', 'afraid go', 'afraid know', 'afraid meeting', 'afraid waste', 'age 20', 'age 25week', 'ago neck', 'air conditioned', 'air feel', 'ajarn ask', 'albinism doctor', 'alienate instead', 'allergic lymph', 'allergy doctor', 'allergy treatment', 'allergy vomit', 'allow find', 'allow get', 'allow live', 'allow relative', 'almost hundred', 'almost sunk', 'aloud control', 'already afraid', 'already impressed', 'already repair', 'already treat', 'although look', 'although many', 'although people', 'although time', 'although wait', 'always look', 'always want', 'always wave', 'always worried', 'analyze cause', 'analyze problem', 'analyze symptom', 'annoy patient', 'annoyed overall', 'another good', 'another hospital', 'another month', 'another unit', 'another week', 'answer detail', 'answer good', 'answer question', 'anyone book', 'anyone give', 'anyone interested', 'anything answer', 'anything help', 'anything thank', 'appear expect', 'appear hospital', 'applaud nurse', 'appliance help', 'apply patient', 'appoint day', 'appoint fill', 'appointment check', 'appointment doctor', 'appointment every', 'appointment examine', 'appointment go', 'appointment inform', 'appointment long', 'appointment look', 'appointment make', 'appointment measure', 'appointment medical', 'appointment must', 'appointment new', 'appointment next', 'appointment nurse', 'appointment provide', 'appointment queue', 'appointment regular', 'appointment see', 'appointment special', 'appointment surgery', 'appointment system', 'appointment time', 'appointment treat', 'appropriate medicine', 'area car', 'arm would', 'around 7pm', 'around building', 'around second', 'arrange appointment', 'arrive cafeteria', 'arrive hospital', 'arrive least', 'ask bathroom', 'ask big', 'ask blood', 'ask clearly', 'ask cut', 'ask doctor', 'ask go', 'ask history', 'ask hurry', 'ask matter', 'ask pay', 'ask symptom', 'asks symptom', 'aspect doctor', 'assistance aspect', 'assistant nurse', 'assistant service', 'atmosphere department', 'atrophy nourish', 'attention detail', 'attention every', 'attention examination', 'attention kind', 'attention patient', 'attention thank', 'attentive attentive', 'attentive every', 'attentive lot', 'attentive patient', 'attentive polite', 'aunt disappointed', 'aunt graduate', 'aunt suffer', 'available service', 'awake turn', 'aware doctor', 'away tire', 'baby quite', 'baby siriraj', 'back check', 'back everything', 'back fever', 'back first', 'back home', 'back rest', 'bad facial', 'bad manner', 'basis provide', 'basketball fall', 'bath wipe', 'bathroom ask', 'bathroom pharmacy', 'bear hospital', 'beautiful nurse', 'beautiful word', 'become patient', 'become rich', 'bed allow', 'believe doctor', 'best although', 'best way', 'big car', 'big problem', 'big question', 'biopsy examination', 'birth baby', 'birth child', 'birth late', 'birth receive', 'birth still', 'birth told', 'birth whole', 'bit slow', 'bleed surgery', 'blood cord', 'blood donation', 'blood nurse', 'blood result', 'blood siriraj', 'blood test', 'blood time', 'blood value', 'board call', 'body language', 'body pull', 'body surgery', 'body value', 'bone doctor', 'book queue', 'boring say', 'born hospital', 'born prematurely', 'bowel lie', 'breast cancer', 'breastfeeding nurse', 'breathing comfort', 'bring love', 'bring technology', 'broken bone', 'building 10', 'building 1st', 'building allow', 'building cafeteria', 'building doctor', 'building floor', 'building good', 'building make', 'building medical', 'building ordinary', 'building security', 'building siriraj', 'building staff', 'building walk', 'bumpy contact', 'burden anyone', 'busy even', 'busy like', 'buy medication', 'cafeteria push', 'cafeteria water', 'call arrange', 'call call', 'call clinic', 'call easily', 'call go', 'call leep', 'call number', 'call nurse', 'call see', 'call teacher', 'calm nurse', 'calm symptom', 'calmly speak', 'camera find', 'cancer cell', 'cancer cin', 'cancer duct', 'cancer final', 'cancer good', 'cancer healthy', 'cancer kidney', 'cancer liver', 'cancer occur', 'cancer reading', 'cancer spread', 'cancer use', 'cancerous abnormality', 'capable make', 'car large', 'car see', 'car stop', 'card appear', 'card do', 'card first', 'card front', 'card make', 'card online', 'card processing', 'card register', 'card told', 'card wait', 'card water', 'care impressed', 'care patient', 'care speak', 'care try', 'carpool doctor', 'case admission', 'case atrophy', 'case child', 'case deserves', 'case explain', 'case problem', 'caught cold', 'cause abnormality', 'cause change', 'cause confusion', 'cause disease', 'cause father', 'cause found', 'cause many', 'cause numbness', 'cause quality', 'cause thoroughly', 'cause today', 'cell invade', 'cell therefore', 'cervical cancer', 'cervical cut', 'cervix abnormal', 'cervix cut', 'cervix doctor', 'cesarean section', 'chalermprakiet building', 'chance tell', 'change life', 'change weak', 'chaotic everyone', 'chaotic therefore', 'charge liver', 'cheaper special', 'check 7pm', 'check appointment', 'check ask', 'check blood', 'check cervical', 'check condition', 'check consultation', 'check eye', 'check find', 'check gynecology', 'check hand', 'check hurry', 'check level', 'check many', 'check patient', 'check progress', 'check really', 'check result', 'check siriraj', 'check skin', 'check up', 'check water', 'checked appointment', 'chemist treatment', 'chemo continuously', 'chemo doctor', 'chemo lump', 'chemotherapy doctor', 'chemotherapy must', 'child birth', 'child check', 'child deliver', 'child doctor', 'child elder', 'child get', 'child give', 'child thank', 'choose treat', 'cin doctor', 'cin3 level', 'circulate forever', 'cirrhosis living', 'civil servant', 'clarify detail', 'clarity assistance', 'clay wait', 'clean doctor', 'clean good', 'clear advice', 'clear every', 'clearly include', 'clearly within', 'clinic appointment', 'clinic doctor', 'clinic go', 'clinic good', 'clinic gynecology', 'clinic hospital', 'clinic online', 'clinic outside', 'clinic part', 'clinic personally', 'clinic procedure', 'clinic siriraj', 'clinic thought', 'clinic wait', 'clinic work', 'clinical psychologist', 'clock morning', 'close nurse', 'close see', 'closely private', 'cold cold', 'cold modern', 'cold special', 'cold travel', 'come back', 'come clock', 'come doctor', 'come remove', 'come see', 'comfort spray', 'comfortable decides', 'comfortable staff', 'comfortable want', 'committee many', 'common room', 'compare number', 'compare private', 'complete next', 'complete pretend', 'complete treatment', 'completely eradicates', 'complicate nurse', 'complicate room', 'complicate spend', 'complication pregnancy', 'concerned much', 'conclude really', 'condition body', 'condition improve', 'condition thank', 'condition well', 'conditioned room', 'condo clay', 'cone call', 'confident treatment', 'confuse later', 'confuse various', 'confusion patient', 'consciousness siriraj', 'consecutive week', 'consider cost', 'consider satisfied', 'consider top', 'consider treat', 'consider whether', 'considerate provide', 'consideration excellent', 'consultation fee', 'consultation psychotherapy', 'consultative service', 'contact staff', 'continued heal', 'continuously consecutive', 'continuously due', 'continuously symptom', 'control feel', 'control fever', 'convenient hospital', 'convenient patient', 'convenient travel', 'convenient work', 'cool think', 'cope crisis', 'cord therefore', 'cord transplant', 'cost hepatitis', 'cost living', 'cost treatment', 'cough severe', 'could feel', 'could go', 'could last', 'country doctor', 'country lot', 'country think', 'courteous spoke', 'cramped compare', 'crazy siriraj', 'cream acne', 'cream keep', 'crisis include', 'criticize scar', 'cross always', 'cross road', 'crowd people', 'crowd service', 'cry crazy', 'cure diabetes', 'cure hospital', 'cure tea', 'currently never', 'customer feel', 'cut biopsy', 'cut cone', 'cut liver', 'cut meat', 'cut neck', 'cute blood', 'cute care', 'cute friendly', 'cute give', 'cute grandma', 'cute habit', 'cute inquire', 'cute really', 'cute understand', 'daily patient', 'dare say', 'date appointment', 'date time', 'daughter give', 'dawn patient', 'day appointment', 'day arrive', 'day back', 'day doctor', 'day encounter', 'day every', 'day full', 'day go', 'day lot', 'day nurse', 'day please', 'day raise', 'day sure', 'day without', 'debt experience', 'decides wound', 'decision undergo', 'deeply reach', 'default doctor', 'definitely misfortune', 'deliver siriraj', 'delivery room', 'department 4th', 'department cute', 'department everything', 'department go', 'department outside', 'department overall', 'department psychiatric', 'department quite', 'department siriraj', 'department special', 'department wait', 'depression nurse', 'description even', 'deserves surgery', 'despair really', 'despite lot', 'despite many', 'despite time', 'detail clearly', 'detail faith', 'detail hurl', 'detail make', 'detail refer', 'detail thorough', 'detail treat', 'deterioration therefore', 'determine duty', 'developed good', 'diabetes ischemic', 'diagnose cancer', 'diagnose precisely', 'diagnose well', 'diagnose without', 'diagnosis disease', 'diagnosis explain', 'diagnosis understand', 'different public', 'difficult appoint', 'disadvantage first', 'disappear consider', 'disappointed treatment', 'disaster calm', 'discharge arrive', 'discourage believe', 'discus whether', 'disease ask', 'disease control', 'disease cure', 'disease diagnose', 'disease dispense', 'disease expertly', 'disease final', 'disease medicine', 'disease meet', 'disease must', 'disease people', 'disease stage', 'disease treatment', 'dispense appropriate', 'dispense medicine', 'dispense service', 'dispenses still', 'dissect next', 'distress facial', 'divide class', 'divide hospital', 'dna body', 'do may', 'do must', 'do online', 'do quickly', 'doctor 30', 'doctor able', 'doctor abnormal', 'doctor accepted', 'doctor advise', 'doctor afraid', 'doctor already', 'doctor another', 'doctor arrange', 'doctor ask', 'doctor board', 'doctor calm', 'doctor cancer', 'doctor charge', 'doctor circulate', 'doctor clarify', 'doctor come', 'doctor concerned', 'doctor consider', 'doctor cut', 'doctor cute', 'doctor determine', 'doctor diagnose', 'doctor diagnosis', 'doctor disadvantage', 'doctor dispense', 'doctor doctor', 'doctor enter', 'doctor ethic', 'doctor examine', 'doctor expert', 'doctor explain', 'doctor explains', 'doctor fee', 'doctor feel', 'doctor found', 'doctor friend', 'doctor give', 'doctor go', 'doctor good', 'doctor greatly', 'doctor hand', 'doctor hormone', 'doctor hospital', 'doctor hurry', 'doctor include', 'doctor inform', 'doctor inspects', 'doctor instruction', 'doctor keng', 'doctor kind', 'doctor knee', 'doctor link', 'doctor long', 'doctor look', 'doctor lot', 'doctor make', 'doctor many', 'doctor modern', 'doctor monitor', 'doctor never', 'doctor nurse', 'doctor paid', 'doctor part', 'doctor pay', 'doctor polite', 'doctor professional', 'doctor provide', 'doctor psychiatrist', 'doctor question', 'doctor queue', 'doctor really', 'doctor receive', 'doctor recommend', 'doctor reliable', 'doctor room', 'doctor saw', 'doctor say', 'doctor service', 'doctor siriraj', 'doctor sit', 'doctor smile', 'doctor someone', 'doctor soon', 'doctor spoke', 'doctor staff', 'doctor surgery', 'doctor suthee', 'doctor tell', 'doctor thank', 'doctor thorough', 'doctor time', 'doctor treat', 'doctor treatment', 'doctor trust', 'doctor understands', 'doctor wait', 'doctor want', 'doctor young', 'donate blood', 'donate foundation', 'donation complete', 'donation room', 'doubt sent', 'dr suthee', 'dr weakat', 'drop play', 'drug use', 'duct cancer', 'due crowd', 'due liver', 'due neck', 'due new', 'due wrist', 'duration fast', 'duty patient', 'early see', 'easily difficult', 'easy understand', 'eat eat', 'eat little', 'eat normally', 'eat nourish', 'eat surgery', 'effect advisable', 'elbow stretch', 'elder person', 'eloquently security', 'emergency department', 'emergency kate', 'emotional psychological', 'encounter poor', 'encourage everyone', 'encouragement good', 'encouragement look', 'encouragement staff', 'enough come', 'enough experience', 'enough health', 'enough people', 'enough see', 'enter fever', 'enter mother', 'equal needle', 'equally friendly', 'equip convenient', 'equipment insufficient', 'eradicates old', 'escalator divide', 'escalator help', 'especially nurse', 'especially project', 'especially really', 'ethic speak', 'even default', 'even many', 'even private', 'even though', 'even travel', 'every day', 'every detail', 'every doctor', 'every half', 'every hour', 'every month', 'every patient', 'every step', 'every time', 'every week', 'everyone air', 'everyone cute', 'everyone equally', 'everyone go', 'everyone good', 'everyone help', 'everyone look', 'everyone professional', 'everyone show', 'everyone standard', 'everyone work', 'everything do', 'everything examine', 'everything good', 'everything mother', 'everything normal', 'everything ok', 'everything patient', 'everything systematic', 'everything today', 'exact cause', 'examination complete', 'examination doctor', 'examination everything', 'examination found', 'examination history', 'examination immediately', 'examination importantly', 'examination long', 'examination matter', 'examination normally', 'examination procedure', 'examination understand', 'examination wait', 'examine infection', 'examine intestine', 'examine liver', 'examine lot', 'examine lymphatic', 'examine say', 'examine siriraj', 'examine treat', 'examine well', 'excellent cause', 'excellent level', 'excellent next', 'excellent service', 'excellent treat', 'except 400', 'except treatment', 'except week', 'expect go', 'expense well', 'expensive call', 'expensive compare', 'expensive cost', 'experience must', 'experienced provide', 'expert level', 'expertly everyone', 'explain always', 'explain detail', 'explain everything', 'explain medical', 'explain step', 'explain symptom', 'explain treatment', 'explains procedure', 'explains treatment', 'explanation every', 'explanation great', 'explanation inform', 'expression patient', 'expression take', 'extremely impressed', 'eye birth', 'eye civil', 'eye examination', 'facial expression', 'facial feature', 'facility available', 'faint time', 'fairly doctor', 'faith doctor', 'fall treatment', 'family lot', 'famous use', 'fan go', 'far away', 'fast everyone', 'fast friendly', 'fast private', 'fast service', 'fast since', 'fast treatment', 'faster patient', 'faster service', 'father illness', 'fear lot', 'feature make', 'february 1973', 'fee cheaper', 'fee expensive', 'fee new', 'fee simply', 'feel alienate', 'feel awake', 'feel comfortable', 'feel frighten', 'feel guilty', 'feel like', 'feel must', 'feel people', 'feel return', 'feel safe', 'feel uncomfortable', 'fell high', 'felt good', 'female doctor', 'fever admin', 'fever rest', 'fever surgery', 'fibroid nurse', 'fill impressed', 'fill vein', 'final patient', 'final result', 'final stage', 'find cause', 'find exact', 'find patient', 'find place', 'find psychiatrist', 'find wheelchair', 'finger toe', 'finish aunt', 'finish doctor', 'finish examination', 'finish survey', 'first 1st', 'first appointment', 'first doctor', 'first first', 'first floor', 'first glance', 'first go', 'first heard', 'first large', 'first nurse', 'first order', 'first patient', 'first step', 'first thing', 'first think', 'first thought', 'first time', 'first visit', 'fit teen', 'floor chalermprakiet', 'floor chaotic', 'floor extremely', 'floor medicine', 'floor outpatient', 'floor receive', 'floor remember', 'flow staff', 'follow appointment', 'follow up', 'food price', 'forever full', 'forget send', 'forget traffic', 'fortunately allergy', 'found cancer', 'found cervix', 'found disease', 'found doubt', 'found lump', 'found morality', 'found normal', 'found patient', 'foundation sufficient', 'fracture albinism', 'fret patient', 'friend advise', 'friend check', 'friend front', 'friend good', 'friend talk', 'friend tease', 'friendly cute', 'friendly doctor', 'friendly friend', 'friendly nurse', 'friendly patient', 'friendly service', 'friendly smile', 'friendly understand', 'friendly use', 'friendly wash', 'frighten scar', 'front doctor', 'front lift', 'frustrate annoy', 'frustration especially', 'full inspect', 'full service', 'full time', 'fully equip', 'fully work', 'fussy wake', 'general service', 'generally good', 'gestational age', 'gesture body', 'get girlfriend', 'get patient', 'get queue', 'get treatment', 'get vaccinate', 'get well', 'girlfriend back', 'give advice', 'give birth', 'give chemo', 'give clear', 'give continuously', 'give delay', 'give explanation', 'give good', 'give hope', 'give knowledge', 'give lot', 'give low', 'give medicine', 'give nurse', 'give opportunity', 'give patient', 'give pay', 'give queue', 'give star', 'give treatment', 'give week', 'glance go', 'gland neck', 'go apply', 'go appointment', 'go arrive', 'go check', 'go clinic', 'go conveniently', 'go date', 'go doctor', 'go early', 'go emergency', 'go everything', 'go first', 'go friend', 'go get', 'go give', 'go health', 'go hospital', 'go maintain', 'go morning', 'go nursery', 'go opd', 'go present', 'go receive', 'go register', 'go reserve', 'go room', 'go screen', 'go see', 'go siam', 'go siriraj', 'go sleep', 'go state', 'go stay', 'go talk', 'go time', 'go treat', 'go ultrasound', 'go wait', 'go weekday', 'gold card', 'good advice', 'good attention', 'good body', 'good book', 'good call', 'good carpool', 'good child', 'good choose', 'good consciousness', 'good cross', 'good day', 'good debt', 'good description', 'good diagnosis', 'good doctor', 'good emergency', 'good especially', 'good except', 'good explanation', 'good facility', 'good first', 'good general', 'good give', 'good go', 'good good', 'good health', 'good hospital', 'good impressed', 'good information', 'good job', 'good keep', 'good like', 'good management', 'good many', 'good matter', 'good medicine', 'good option', 'good overall', 'good patient', 'good pay', 'good private', 'good question', 'good service', 'good siriraj', 'good speak', 'good speaks', 'good symptom', 'good system', 'good talk', 'good treatment', 'good use', 'government cause', 'government hospital', 'graduate siriraj', 'grandma doctor', 'grandma get', 'grandma knee', 'grandma strong', 'grandma treat', 'grandmother housewife', 'grateful yesterday', 'great help', 'great service', 'greatly improve', 'group clinical', 'grow give', 'grow side', 'grown fairly', 'growth radiotherapy', 'guard notice', 'guard staff', 'guideline well', 'guilty sneaker', 'gynecological examination', 'gynecologist department', 'gynecology clinic', 'gynecology first', 'gynecology part', 'habit radiation', 'hair loss', 'half day', 'half hour', 'hand card', 'hand lightly', 'hand patient', 'hand pay', 'hand say', 'happen doctor', 'happy meeting', 'hard considerate', 'hard personal', 'harden swell', 'heal doctor', 'heal illness', 'heal medicine', 'heal scalp', 'heal sure', 'heal thank', 'health check', 'health life', 'health option', 'health promise', 'healthy living', 'healthy personally', 'heard rumor', 'heart never', 'heart patient', 'heavy strong', 'help breastfeeding', 'help burden', 'help excellent', 'help find', 'help go', 'help good', 'help heal', 'help heavy', 'help impression', 'help patient', 'help sick', 'help thank', 'hepatitis reduce', 'hiccup cough', 'hiccup stop', 'high fever', 'history conclude', 'history never', 'history result', 'history take', 'history tenderness', 'history young', 'hn call', 'hn number', 'hn specify', 'home almost', 'home overall', 'hope say', 'hopeless enough', 'hormone doctor', 'hormone normal', 'hospital 72', 'hospital allow', 'hospital always', 'hospital analyze', 'hospital another', 'hospital appointment', 'hospital card', 'hospital cause', 'hospital clean', 'hospital confuse', 'hospital consider', 'hospital country', 'hospital developed', 'hospital doctor', 'hospital every', 'hospital examine', 'hospital far', 'hospital first', 'hospital follow', 'hospital fully', 'hospital go', 'hospital good', 'hospital impressed', 'hospital improve', 'hospital know', 'hospital like', 'hospital look', 'hospital lot', 'hospital make', 'hospital manage', 'hospital many', 'hospital never', 'hospital newborn', 'hospital often', 'hospital organize', 'hospital part', 'hospital pas', 'hospital past', 'hospital patient', 'hospital provide', 'hospital question', 'hospital scream', 'hospital service', 'hospital skin', 'hospital slow', 'hospital summary', 'hospital support', 'hospital take', 'hospital thank', 'hospital treatment', 'hospital use', 'hospital usually', 'hospital wait', 'hospital website', 'hospital well', 'hospital wide', 'hospital work', 'hospital would', 'hospital year', 'hospitality good', 'hour day', 'hour hour', 'hour impressed', 'hour inform', 'hour like', 'hour night', 'hour patient', 'hour see', 'hour well', 'humor understands', 'hundred percent', 'hurl ween', 'hurry check', 'hurry find', 'hurry finish', 'hurry hospital', 'hurry see', 'hvp infection', 'illness hospital', 'illness people', 'immediately report', 'important large', 'importantly doctor', 'importantly teach', 'importantly treat', 'impressed accessibility', 'impressed doctor', 'impressed everything', 'impressed hospitality', 'impressed impressed', 'impressed return', 'impressed service', 'impressed since', 'impressed talented', 'impressed thalassemia', 'impressed treat', 'impressed treatment', 'impressed view', 'impression doctor', 'impression make', 'impression treatment', 'impressive doctor', 'impressive nurse', 'impressive service', 'impressive siriraj', 'improve breathing', 'improve change', 'improve despite', 'improve lot', 'improve patient', 'improve periodically', 'improve problem', 'improve use', 'improvement service', 'incident select', 'include assistant', 'include food', 'include medicine', 'include nurse', 'include personal', 'include staff', 'include various', 'indirectly disease', 'infection cervix', 'infection spread', 'inflame allergic', 'inflammatory bowel', 'inform around', 'inform half', 'inform hn', 'inform patient', 'inform procedure', 'inform queue', 'inform wait', 'information answer', 'information call', 'inhaler improve', 'inhibit growth', 'initially enter', 'inject well', 'injection injection', 'injection several', 'injection taro', 'inquire anyone', 'inquire anything', 'inquiry treatment', 'inside yew', 'inspect building', 'inspect instead', 'inspection doctor', 'inspection rule', 'inspects convenient', 'instead friend', 'instead go', 'instead turn', 'institution addition', 'instruction symptom', 'instructor advise', 'insufficient treat', 'intend go', 'intend write', 'interested keloid', 'interested lump', 'internal ultrasound', 'intestine doctor', 'invade tumor', 'investigate cause', 'invite join', 'iq test', 'irritability bad', 'irritate irritation', 'irritation like', 'ischemic stroke', 'jam many', 'jealousy read', 'join group', 'join project', 'joint pain', 'joint place', 'kate gestational', 'keep good', 'keep ultrasound', 'keloid anyone', 'keloid siriraj', 'keloid upper', 'keng able', 'khun fan', 'kidney blood', 'kind advise', 'kind beautiful', 'kind despite', 'kind even', 'kind nothing', 'kind nurse', 'kind patient', 'kind person', 'kind pharmacy', 'kind right', 'knee doctor', 'knee joint', 'know cope', 'know government', 'know hopeless', 'know intend', 'know queue', 'know result', 'know staff', 'knowledge answer', 'knowledge explain', 'land child', 'language facial', 'large hospital', 'large number', 'large wheelchair', 'last long', 'last queue', 'last year', 'late everyone', 'later siriraj', 'leaflet forget', 'leaflet service', 'least affected', 'least half', 'least hour', 'least time', 'leep luo', 'leg step', 'lesion pre', 'less hour', 'level appointment', 'level feel', 'level impressed', 'level must', 'level professor', 'lie half', 'life like', 'life past', 'life precious', 'life thai', 'life treatment', 'life work', 'lift staff', 'lightly make', 'like advise', 'like already', 'like cancer', 'like discus', 'like doctor', 'like encouragement', 'like last', 'like lone', 'like meeting', 'like much', 'like normal', 'like nothing', 'like patient', 'like people', 'like relative', 'like siriraj', 'like special', 'like standard', 'like well', 'line long', 'line uterus', 'link cause', 'listen week', 'little expensive', 'little longer', 'little numbness', 'live normal', 'live well', 'liver 60', 'liver cancer', 'liver disease', 'liver february', 'liver grow', 'liver lump', 'liver make', 'liver next', 'liver sent', 'liver size', 'living life', 'living like', 'living quality', 'location convenient', 'lone condo', 'long appointment', 'long chemo', 'long go', 'long hospital', 'long least', 'long part', 'long queue', 'long still', 'long time', 'longer treatment', 'look attentive', 'look camera', 'look cervix', 'look chaotic', 'look doctor', 'look history', 'look like', 'look liver', 'look patient', 'look physical', 'look picture', 'look provide', 'look resource', 'look thank', 'look treatment', 'loss year', 'lot addition', 'lot advice', 'lot examination', 'lot humor', 'lot medication', 'lot patient', 'lot people', 'lot protein', 'lot status', 'lot time', 'lot told', 'lottery building', 'love currently', 'love daughter', 'love hospital', 'love one', 'love siriraj', 'lovely female', 'lovely kind', 'lovely love', 'lovely speak', 'lovely thanks', 'low rating', 'lump case', 'lump inhibit', 'lump liver', 'lump look', 'lump ready', 'luo treatment', 'luxury room', 'lymph node', 'lymphatic gland', 'maintain gold', 'make appointment', 'make aware', 'make bit', 'make boring', 'make comfortable', 'make confident', 'make customer', 'make diagnosis', 'make faster', 'make feel', 'make forget', 'make hospital', 'make impressed', 'make mri', 'make notice', 'make patient', 'make second', 'make sick', 'make sure', 'make think', 'make unable', 'make yet', 'manage various', 'management problem', 'management system', 'manner overall', 'many daily', 'many doctor', 'many hospital', 'many patient', 'many people', 'many place', 'many province', 'many side', 'many time', 'many user', 'many year', 'master explain', 'matter committee', 'matter government', 'matter many', 'matter respond', 'may appointment', 'may fast', 'may go', 'may occur', 'may wait', 'maybe go', 'maybe treatment', 'meaning chemo', 'meaning wait', 'measure long', 'measure pressure', 'meat inspection', 'medical clinic', 'medical equipment', 'medical instructor', 'medical professor', 'medical rotation', 'medical specialist', 'medical student', 'medication adjustment', 'medication continued', 'medication give', 'medication go', 'medication pick', 'medication prescribed', 'medication use', 'medication within', 'medicine 30', 'medicine back', 'medicine buy', 'medicine day', 'medicine disease', 'medicine first', 'medicine improve', 'medicine leaflet', 'medicine new', 'medicine room', 'medicine run', 'meet doctor', 'meet first', 'meeting doctor', 'meeting good', 'meeting quality', 'meeting trust', 'member raise', 'member speak', 'memorize divide', 'menstruation come', 'menstruation symptom', 'merciless doctor', 'method detail', 'method treatment', 'minute 600', 'minute examination', 'minute many', 'misfortune day', 'mixed vaginal', 'modern appliance', 'modern doctor', 'modern patient', 'mom project', 'moment year', 'monitor symptom', 'month advance', 'month check', 'month child', 'month come', 'month found', 'month menstruation', 'month pass', 'month treatment', 'morality care', 'morning doctor', 'morning service', 'morning time', 'mother check', 'mother fell', 'mother gynecology', 'mother staff', 'mother told', 'mother would', 'mouth leg', 'move patient', 'mri doctor', 'mri interested', 'much chance', 'much doctor', 'much impressive', 'much possible', 'much residue', 'much time', 'must blood', 'must definitely', 'must doctor', 'must heal', 'must medical', 'must month', 'must perform', 'must siriraj', 'must treat', 'must weigh', 'nature disease', 'nearly 100', 'neck check', 'neck day', 'neck get', 'neck pillow', 'neck twice', 'need worry', 'needle doctor', 'needle help', 'neglect patient', 'negligence risk', 'nerve slightly', 'neuro doctor', 'neurologist neuro', 'never discourage', 'never forget', 'never neglect', 'never pass', 'never thought', 'never treat', 'new adjustment', 'new patient', 'newborn baby', 'news relative', 'next appointment', 'next child', 'next month', 'next step', 'next time', 'next work', 'night feel', 'node abdomen', 'node treat', 'normal child', 'normal doctor', 'normal first', 'normal life', 'normal person', 'normal thank', 'normally sensitive', 'normally today', 'normally without', 'nothing go', 'nothing happen', 'nothing provide', 'nothing shoe', 'notice inspect', 'notice personnel', 'notify periodically', 'nourish cure', 'nourish lot', 'numb time', 'number call', 'number give', 'number patient', 'number people', 'number say', 'numbness dr', 'numbness overall', 'nurse advise', 'nurse arrange', 'nurse ask', 'nurse asks', 'nurse assistant', 'nurse attentive', 'nurse care', 'nurse cute', 'nurse delivery', 'nurse department', 'nurse doctor', 'nurse explain', 'nurse friendly', 'nurse go', 'nurse good', 'nurse important', 'nurse include', 'nurse inform', 'nurse kind', 'nurse lottery', 'nurse lovely', 'nurse make', 'nurse may', 'nurse medical', 'nurse nurse', 'nurse owner', 'nurse patient', 'nurse personnel', 'nurse public', 'nurse rarely', 'nurse really', 'nurse screen', 'nurse skilled', 'nurse smile', 'nurse speak', 'nurse spoke', 'nurse staff', 'nurse still', 'nurse take', 'nurse time', 'nurse well', 'nurse work', 'nursery room', 'nursing student', 'obstetrician found', 'occur disease', 'occur keloid', 'occur month', 'occur must', 'occur quite', 'officer good', 'officer history', 'officer include', 'often give', 'often make', 'often send', 'ok even', 'ok hospital', 'ok impressive', 'ok inquiry', 'ok poor', 'okay never', 'old belief', 'old building', 'old patient', 'old people', 'one cure', 'one home', 'oneself negligence', 'oneself personal', 'online go', 'online impressed', 'online schedule', 'opd building', 'open mouth', 'opportunity ask', 'opportunity patient', 'option although', 'option country', 'order start', 'order symptom', 'ordinary bed', 'organize busy', 'organize easy', 'organize system', 'organize systematic', 'outpatient building', 'outpatient clinic', 'outpatient except', 'outside first', 'outside hour', 'ovary doctor', 'ovary remove', 'overall consider', 'overall everyone', 'overall give', 'overall good', 'overall ok', 'overall okay', 'overall service', 'overall system', 'owner dare', 'paid attention', 'pain around', 'pain doctor', 'pap smear', 'parking convenient', 'parking nurse', 'part provide', 'part time', 'pas siriraj', 'pass doctor', 'pass grandma', 'pass point', 'pass time', 'past mother', 'past vocational', 'patient able', 'patient accord', 'patient although', 'patient ask', 'patient best', 'patient building', 'patient cancer', 'patient card', 'patient condition', 'patient day', 'patient doctor', 'patient emotional', 'patient even', 'patient everything', 'patient fast', 'patient finish', 'patient give', 'patient go', 'patient good', 'patient impressed', 'patient include', 'patient know', 'patient make', 'patient many', 'patient may', 'patient much', 'patient next', 'patient nurse', 'patient overall', 'patient prioritize', 'patient queue', 'patient refer', 'patient relative', 'patient room', 'patient safety', 'patient service', 'patient show', 'patient since', 'patient siriraj', 'patient smile', 'patient special', 'patient stay', 'patient still', 'patient student', 'patient suddenly', 'patient suggest', 'patient symptom', 'patient tell', 'patient therefore', 'patient time', 'patient transfer', 'patient treat', 'patient various', 'patient wait', 'patient well', 'pay attention', 'pay overall', 'pay respect', 'payment dispenses', 'pedestrian big', 'pensioner grandmother', 'people act', 'people annoyed', 'people busy', 'people doctor', 'people enough', 'people escalator', 'people every', 'people friendly', 'people impression', 'people many', 'people provide', 'people psychiatric', 'people regard', 'people smooth', 'people staff', 'people sure', 'people treat', 'people understand', 'people use', 'people wait', 'percent good', 'perform therefore', 'perform treatment', 'periodically back', 'periodically next', 'periodically treatment', 'person doctor', 'person everyone', 'person feel', 'person gynecological', 'person invite', 'personal advantage', 'personal problem', 'personal time', 'personally clinic', 'personally like', 'personally place', 'personnel full', 'personnel impressed', 'personnel quality', 'personnel work', 'pharmacy cute', 'pharmacy staff', 'phayaban helpful', 'phra sri', 'physical condition', 'physician nurse', 'physician regular', 'pick doctor', 'pick up', 'picture inside', 'pillow deterioration', 'place cramped', 'place felt', 'place first', 'place injection', 'place love', 'place treat', 'place wait', 'place without', 'plan doctor', 'plan meeting', 'play basketball', 'pleasant location', 'please update', 'pm go', 'point neck', 'point pay', 'point weight', 'polite doctor', 'polite friendly', 'polite hospital', 'polite reiterate', 'poor cut', 'poor patient', 'poor people', 'poor service', 'possible sleep', 'potential doctor', 'pour shock', 'pre cancerous', 'precious time', 'precisely complete', 'pregnancy specialist', 'prematurely siriraj', 'prescribed doctor', 'present card', 'pressure get', 'pressure told', 'pretend faint', 'previously quite', 'price doctor', 'price nurse', 'price room', 'prioritize visit', 'private hospital', 'private impressed', 'privilege use', 'problem atmosphere', 'problem complication', 'problem crowd', 'problem enough', 'problem government', 'problem occur', 'problem patient', 'problem symptom', 'procedure complicate', 'procedure make', 'procedure method', 'procedure surgery', 'process quick', 'process still', 'processing step', 'professional care', 'professional know', 'professional nurse', 'professor many', 'professor medical', 'progress line', 'project beautiful', 'project good', 'project hospital', 'project overall', 'project project', 'promise health', 'protein liver', 'provide clarity', 'provide even', 'provide excellent', 'provide explanation', 'provide fast', 'provide good', 'provide internal', 'provide knowledge', 'provide patient', 'provide quickly', 'provide service', 'provider treat', 'province thanked', 'psychiatric department', 'psychiatric unit', 'psychiatrist case', 'psychiatrist first', 'psychiatrist meet', 'psychiatrist scar', 'psychiatrist severe', 'psychiatry unit', 'psychological problem', 'psychological psychological', 'psychotherapy join', 'public hospital', 'pull blood', 'push mother', 'put joint', 'quality life', 'quality personnel', 'quality public', 'quality really', 'question answer', 'question ask', 'question detail', 'question even', 'question history', 'question well', 'question whether', 'queue 60', 'queue able', 'queue appointment', 'queue call', 'queue card', 'queue day', 'queue despite', 'queue examination', 'queue follow', 'queue go', 'queue inform', 'queue like', 'queue long', 'queue notify', 'queue quickly', 'queue since', 'queue siriraj', 'queue teacher', 'queue website', 'quick cost', 'quickly doctor', 'quickly good', 'quickly hospital', 'quite comfortable', 'quite confuse', 'quite day', 'quite fussy', 'quite good', 'quite often', 'quite scar', 'radiation plan', 'radiologist appoint', 'radiologist start', 'radiotherapy mri', 'rain go', 'rain saw', 'raise hand', 'ran blood', 'rank country', 'rarely recommend', 'rat require', 'rating big', 'reach heart', 'read review', 'reading ultrasound', 'ready surgery', 'really bath', 'really choose', 'really disappointed', 'really excellent', 'really good', 'really help', 'really impressed', 'really look', 'really merciless', 'really watery', 'receive blood', 'receive hn', 'receive medication', 'receive medicine', 'receive problem', 'receive treatment', 'recommend give', 'recommend sometimes', 'recommend well', 'reduce cirrhosis', 'reduce fear', 'reduce size', 'refer institution', 'refer radiologist', 'regard still', 'register hospital', 'register queue', 'regular basis', 'regular doctor', 'reiterate able', 'relative patient', 'relative really', 'relative watch', 'reluctant include', 'remember building', 'remove fracture', 'remove sex', 'report news', 'report symptom', 'require medication', 'research understood', 'reservation payment', 'reservation room', 'reserve special', 'resource well', 'respect staff', 'respond well', 'rest 4th', 'rest home', 'rest pain', 'result doctor', 'result faster', 'result found', 'result look', 'result nurse', 'result show', 'result summary', 'result tumor', 'return normal', 'return siriraj', 'review actual', 'review afraid', 'rich love', 'rich well', 'right liver', 'right normal', 'rise rest', 'rise stomach', 'risk doctor', 'road pedestrian', 'room accommodate', 'room ask', 'room attentive', 'room check', 'room clearly', 'room complicate', 'room cool', 'room doctor', 'room first', 'room like', 'room ok', 'room separate', 'room shortcoming', 'room size', 'room spacious', 'room specify', 'room staff', 'room stay', 'room time', 'room two', 'room wide', 'rotation medical', 'round call', 'round yes', 'rule right', 'rumor say', 'run cream', 'rush ask', 'rush make', 'rush pick', 'safe happy', 'safe treat', 'safe walk', 'safe warm', 'safety reservation', 'sampran area', 'satisfactory make', 'satisfied thank', 'saw condition', 'saw say', 'say breast', 'say chemotherapy', 'say get', 'say give', 'say good', 'say indirectly', 'say make', 'say nerve', 'say nothing', 'say quite', 'say send', 'say sort', 'say still', 'say treatment', 'say wait', 'scalp doctor', 'scar criticize', 'scar jealousy', 'scar people', 'scar research', 'scar scar', 'scar undergo', 'schedule appointment', 'school acne', 'science say', 'scream patient', 'screen patient', 'screen separate', 'screen unit', 'second round', 'section good', 'security consideration', 'security good', 'security guard', 'security officer', 'see allergy', 'see dna', 'see doctor', 'see neurologist', 'see nurse', 'see psychiatrist', 'see rush', 'see symptom', 'seem complicate', 'select siriraj', 'send medicine', 'send walk', 'sensitive deeply', 'sent chemist', 'sent special', 'sent surgeon', 'separate bathroom', 'separate medication', 'separate speed', 'servant pensioner', 'service although', 'service bumpy', 'service check', 'service clear', 'service doctor', 'service even', 'service excellent', 'service fast', 'service feel', 'service give', 'service good', 'service help', 'service hospital', 'service keloid', 'service level', 'service lovely', 'service make', 'service many', 'service may', 'service nurse', 'service ok', 'service organize', 'service outpatient', 'service patient', 'service personnel', 'service process', 'service project', 'service provider', 'service result', 'service similar', 'service siriraj', 'service slow', 'service smile', 'service staff', 'service still', 'service understand', 'service wait', 'several time', 'severe tourette', 'severe vomit', 'sex hormone', 'share room', 'shingle see', 'shock nothing', 'shoe wet', 'shortcoming know', 'shout sound', 'show aloud', 'show frustrate', 'show lesion', 'siam building', 'sick admit', 'sick help', 'sick person', 'side effect', 'side lump', 'side wait', 'similar private', 'similar thing', 'simply doctor', 'since birth', 'since card', 'since dawn', 'since first', 'since morning', 'since never', 'since officer', 'since security', 'siriraj adjust', 'siriraj bear', 'siriraj doctor', 'siriraj even', 'siriraj first', 'siriraj hospital', 'siriraj much', 'siriraj psychiatric', 'siriraj security', 'siriraj siriraj', 'siriraj team', 'siriraj tell', 'siriraj today', 'siriraj treatment', 'siriraj wait', 'siriraj well', 'sirirat thank', 'sit talk', 'sit wait', 'size grown', 'size surgery', 'size type', 'skilled capable', 'skilled experienced', 'skin clinic', 'skin department', 'sleep 555', 'sleep hospital', 'sleep share', 'sleep wait', 'slightly eat', 'slow generally', 'slow queue', 'slow rush', 'smart kind', 'smear obstetrician', 'smile accept', 'smile different', 'smile friendly', 'smile good', 'smile lovely', 'smile nurse', 'smile well', 'smooth clean', 'sneaker almost', 'social security', 'somdet phra', 'someone close', 'someone suggest', 'someone told', 'sometimes bad', 'sometimes long', 'sometimes patient', 'soon system', 'sort number', 'sound irritate', 'spacious cold', 'speak even', 'speak everyone', 'speak friendly', 'speak good', 'speak make', 'speak memorize', 'speak patient', 'speak stop', 'speaks well', 'special clinic', 'special may', 'special part', 'special room', 'special way', 'specialist doctor', 'specialist phayaban', 'specify date', 'specify doctor', 'specify price', 'speed escalator', 'spend lot', 'spinal cord', 'spoke eloquently', 'spoke well', 'spray medication', 'spread doctor', 'spread lymph', 'sri building', 'staff able', 'staff another', 'staff answer', 'staff clinic', 'staff courteous', 'staff cute', 'staff enough', 'staff fight', 'staff fully', 'staff give', 'staff good', 'staff hospital', 'staff hurry', 'staff look', 'staff member', 'staff move', 'staff physician', 'staff provide', 'staff ran', 'staff sometimes', 'staff stood', 'staff take', 'staff welcome', 'staff work', 'stage cancer', 'stage could', 'stage speak', 'stage treat', 'standard check', 'standard service', 'star straight', 'start first', 'start harden', 'start treatment', 'start whole', 'state hospital', 'status eye', 'stay close', 'stay despair', 'stay hospital', 'stay sampran', 'step fret', 'step good', 'step meaning', 'step submit', 'step wait', 'step water', 'stick open', 'still 20', 'still able', 'still check', 'still clear', 'still good', 'still live', 'still reservation', 'still smile', 'still unable', 'still wait', 'still worth', 'stomach ache', 'stomach start', 'stood told', 'stop every', 'stop first', 'stop treatment', 'straight away', 'stretch put', 'stroke siriraj', 'strong pass', 'strong walk', 'student diagnose', 'student feel', 'student friendly', 'student smart', 'student specialist', 'student use', 'submit matter', 'suddenly become', 'suffer shingle', 'sufficient help', 'suffocate hurry', 'suggest go', 'suggest waste', 'summary impressive', 'summary inflammatory', 'sunk must', 'support large', 'sure decision', 'sure doctor', 'sure parking', 'sure sure', 'sure would', 'surgeon rush', 'surgery best', 'surgery do', 'surgery doctor', 'surgery eat', 'surgery finish', 'surgery good', 'surgery inject', 'surgery like', 'surgery month', 'surgery overall', 'surgery patient', 'surgery scar', 'surgery surgery', 'surgery week', 'survey final', 'survival point', 'suthee good', 'suthee perform', 'swell rise', 'symptom 20', 'symptom answer', 'symptom cancer', 'symptom disease', 'symptom doctor', 'symptom drug', 'symptom every', 'symptom finger', 'symptom give', 'symptom go', 'symptom improve', 'symptom irritability', 'symptom medication', 'symptom still', 'symptom stomach', 'symptom suffocate', 'symptom together', 'symptom use', 'symptom well', 'symptomatic treatment', 'system doctor', 'system excellent', 'system first', 'system good', 'system previously', 'system screen', 'system separate', 'system various', 'system wait', 'systematic meaning', 'systematic way', 'take 1st', 'take accommodation', 'take aunt', 'take day', 'take friend', 'take good', 'take oneself', 'take place', 'take wait', 'talented doctor', 'talk doctor', 'talk love', 'talk normally', 'talk similar', 'talk someone', 'taro another', 'teach everything', 'teach medical', 'teacher ajarn', 'teacher throughout', 'team doctor', 'tease friend', 'technology improve', 'teen mom', 'teenager think', 'teenager want', 'tell 50', 'tell disease', 'tell treatment', 'tell use', 'tell well', 'tenderness patient', 'term receive', 'test check', 'test confirm', 'test consultation', 'test iq', 'thai people', 'thalassemia since', 'thank always', 'thank doctor', 'thank encouragement', 'thank heart', 'thank hospital', 'thank much', 'thank nurse', 'thank punch', 'thank siriraj', 'thanked doctor', 'thanks everyone', 'therefore anything', 'therefore ask', 'therefore cause', 'therefore donate', 'therefore make', 'therefore sent', 'thing impressive', 'thing wait', 'think first', 'think go', 'think management', 'think sleep', 'think teenager', 'thirty minute', 'thorough examination', 'thoroughly examine', 'though common', 'though know', 'though lot', 'though many', 'though part', 'though public', 'though wait', 'thought due', 'thought government', 'thought hair', 'thought siriraj', 'thread encourage', 'threw air', 'throughout survival', 'time 300', 'time actually', 'time addition', 'time afraid', 'time case', 'time caught', 'time clinic', 'time cost', 'time could', 'time depression', 'time doctor', 'time due', 'time equal', 'time even', 'time every', 'time examination', 'time fortunately', 'time give', 'time go', 'time impressed', 'time improve', 'time instead', 'time maybe', 'time medical', 'time much', 'time nurse', 'time ok', 'time pap', 'time physician', 'time price', 'time privilege', 'time quite', 'time reduce', 'time seem', 'time service', 'time since', 'time specify', 'time staff', 'time stay', 'time treatment', 'time understand', 'time wait', 'time without', 'time year', 'tire every', 'tire good', 'today completely', 'today doctor', 'today intend', 'today love', 'toe numb', 'together plan', 'told could', 'told doctor', 'told go', 'told recommend', 'told symptom', 'told wait', 'told water', 'top rank', 'total 12', 'tourette rat', 'traffic jam', 'transfer staff', 'transplant cause', 'travel abroad', 'travel doctor', 'travel hospital', 'treat acne', 'treat analyze', 'treat become', 'treat cancer', 'treat disaster', 'treat disease', 'treat every', 'treat everyone', 'treat first', 'treat give', 'treat healthy', 'treat hospital', 'treat hvp', 'treat illness', 'treat like', 'treat oneself', 'treat place', 'treat poor', 'treat queue', 'treat rich', 'treat shout', 'treat siriraj', 'treat sirirat', 'treat special', 'treat use', 'treat uterine', 'treat well', 'treatment advise', 'treatment area', 'treatment bleed', 'treatment chemotherapy', 'treatment department', 'treatment disappear', 'treatment do', 'treatment doctor', 'treatment donate', 'treatment every', 'treatment expensive', 'treatment explain', 'treatment family', 'treatment fee', 'treatment first', 'treatment go', 'treatment grandma', 'treatment guideline', 'treatment help', 'treatment hospital', 'treatment least', 'treatment little', 'treatment many', 'treatment medical', 'treatment medication', 'treatment method', 'treatment modern', 'treatment ok', 'treatment patient', 'treatment potential', 'treatment price', 'treatment question', 'treatment queue', 'treatment say', 'treatment skin', 'treatment spinal', 'treatment spoke', 'treatment stage', 'treatment standard', 'treatment take', 'treatment weight', 'trust person', 'trust treat', 'trust trust', 'try find', 'try see', 'tumor grow', 'tumor ovary', 'turn hand', 'turn hiccup', 'twice time', 'two luxury', 'type room', 'ultrasound check', 'ultrasound liver', 'ultrasound ovary', 'ultrasound result', 'unable help', 'unable walk', 'uncomfortable term', 'undergo surgery', 'understand bring', 'understand consider', 'understand doctor', 'understand every', 'understand like', 'understand old', 'understand patient', 'understand staff', 'understands nature', 'understands teenager', 'understood reduce', 'unit good', 'unit grateful', 'unit point', 'unit provide', 'up check', 'up good', 'up periodically', 'up service', 'up treatment', 'update service', 'upper arm', 'use adjust', 'use analyze', 'use ask', 'use case', 'use cervical', 'use clinic', 'use consultative', 'use cream', 'use gesture', 'use go', 'use gold', 'use heal', 'use hospital', 'use inflame', 'use inhaler', 'use service', 'use treat', 'use word', 'user frustration', 'usually well', 'usually write', 'uterine fibroid', 'uterus lovely', 'vaccinate fit', 'vaginal discharge', 'value eye', 'value nurse', 'various building', 'various quite', 'various system', 'various test', 'vein right', 'view talk', 'visit doctor', 'visit gynecologist', 'visit hospital', 'visit sometimes', 'vocational school', 'vomit eat', 'vomit occur', 'wait blood', 'wait check', 'wait day', 'wait department', 'wait doctor', 'wait examination', 'wait give', 'wait hospital', 'wait inspection', 'wait least', 'wait less', 'wait line', 'wait listen', 'wait little', 'wait long', 'wait lot', 'wait parking', 'wait patient', 'wait queue', 'wait room', 'wait see', 'wait time', 'wake often', 'walk 15', 'walk around', 'walk eat', 'walk hospital', 'walk stick', 'walk thank', 'walk walk', 'want find', 'want look', 'want make', 'want treatment', 'warm importantly', 'wash history', 'waste day', 'waste much', 'waste time', 'watch nurse', 'water flow', 'water mixed', 'water pour', 'water rain', 'water threw', 'watery doctor', 'watery sleep', 'wave car', 'way able', 'way patient', 'weak albino', 'weakat science', 'website actually', 'website receive', 'week another', 'week equal', 'week except', 'week monitor', 'week receive', 'week result', 'week total', 'week week', 'weekday treatment', 'ween pleasant', 'weigh measure', 'weight elbow', 'weight measure', 'weight must', 'weight weight', 'welcome say', 'welcome weight', 'well accurately', 'well although', 'well calmly', 'well check', 'well due', 'well especially', 'well even', 'well feel', 'well follow', 'well go', 'well good', 'well importantly', 'well impressive', 'well include', 'well investigate', 'well kind', 'well make', 'well moment', 'well need', 'well poor', 'well private', 'well report', 'well staff', 'well symptomatic', 'well wait', 'well welcome', 'well well', 'wet touch', 'wheelchair cross', 'wheelchair officer', 'wheelchair rain', 'wheelchair wheelchair', 'whether case', 'whether ok', 'whether undergo', 'whole duration', 'whole examination', 'wide cold', 'wide special', 'wipe applaud', 'within thirty', 'within wound', 'without appointment', 'without check', 'without distress', 'without reluctant', 'without symptom', 'without waste', 'word nursing', 'word polite', 'word speak', 'work closely', 'work hard', 'work hour', 'work land', 'work professional', 'work radiologist', 'work siriraj', 'work well', 'work without', 'worried side', 'worry disease', 'worth try', 'would able', 'would like', 'would look', 'would provide', 'wound doctor', 'wound injection', 'wrist drop', 'write review', 'write thread', 'year ago', 'year aunt', 'year continuously', 'year cost', 'year khun', 'year old', 'year pass', 'year time', 'year use', 'year visit', 'year well', 'yesterday go', 'yesterday wheelchair', 'yet appear', 'yew fill', 'young child', 'young enough']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (0, 1263)\t0.3550255464027329\n",
      "  (0, 1631)\t0.3550255464027329\n",
      "  (0, 367)\t0.3550255464027329\n",
      "  (0, 1522)\t0.3550255464027329\n",
      "  (0, 717)\t0.3550255464027329\n",
      "  (0, 1630)\t0.3430714645814871\n",
      "  (0, 401)\t0.3550255464027329\n",
      "  (0, 1720)\t0.3550255464027329\n",
      "  (1, 2832)\t0.3535533905932738\n",
      "  (1, 883)\t0.3535533905932738\n",
      "  (1, 1136)\t0.3535533905932738\n",
      "  (1, 847)\t0.3535533905932738\n",
      "  (1, 596)\t0.3535533905932738\n",
      "  (1, 793)\t0.3535533905932738\n",
      "  (1, 1088)\t0.3535533905932738\n",
      "  (1, 1142)\t0.3535533905932738\n",
      "  (2, 835)\t0.19715504084688554\n",
      "  (2, 1900)\t0.19715504084688554\n",
      "  (2, 131)\t0.19715504084688554\n",
      "  (2, 1985)\t0.19715504084688554\n",
      "  (2, 120)\t0.19715504084688554\n",
      "  (2, 1925)\t0.18320838353409016\n",
      "  (2, 1157)\t0.19715504084688554\n",
      "  (2, 2488)\t0.19715504084688554\n",
      "  (2, 1690)\t0.19715504084688554\n",
      "  :\t:\n",
      "  (225, 371)\t0.14766442255373957\n",
      "  (225, 1230)\t0.14766442255373957\n",
      "  (225, 2412)\t0.14766442255373957\n",
      "  (225, 1237)\t0.14766442255373957\n",
      "  (225, 839)\t0.14766442255373957\n",
      "  (225, 2705)\t0.14766442255373957\n",
      "  (225, 1591)\t0.14766442255373957\n",
      "  (225, 290)\t0.14766442255373957\n",
      "  (225, 1869)\t0.14766442255373957\n",
      "  (225, 27)\t0.14766442255373957\n",
      "  (225, 1258)\t0.14766442255373957\n",
      "  (225, 2580)\t0.14766442255373957\n",
      "  (225, 1430)\t0.14766442255373957\n",
      "  (225, 622)\t0.14766442255373957\n",
      "  (225, 547)\t0.14766442255373957\n",
      "  (225, 1872)\t0.14766442255373957\n",
      "  (225, 1585)\t0.29532884510747914\n",
      "  (225, 283)\t0.14766442255373957\n",
      "  (225, 2534)\t0.13721870891739277\n",
      "  (225, 962)\t0.12980735714618086\n",
      "  (225, 1826)\t0.13721870891739277\n",
      "  (225, 3102)\t0.13721870891739277\n",
      "  (225, 1271)\t0.12405866609924648\n",
      "  (225, 2433)\t0.169487892473688\n",
      "  (225, 726)\t0.17933193701433595\n",
      "\n",
      " reduce_feature() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      "Before reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "explained_variance_ratio_:\n",
      "[0.05330435 0.03575594 0.03308223 0.03166392 0.02830977 0.02710616\n",
      " 0.0244237  0.02286867 0.0206723  0.01894481]\n",
      "\n",
      "singular_values_:\n",
      "[111.17553149  91.05462717  87.58410522  85.68607073  81.02071278\n",
      "  79.27968245  75.25469525  72.81960394  69.23445082  66.27854743]\n",
      "\n",
      "Afte reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca, shape:  (226, 10)\n",
      "[[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]]\n",
      "\n",
      " kfold_train_test() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\\X_array_pca:\n",
      "\n",
      "[[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]]\n",
      "\n",
      "y_array:\n",
      "[0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0\n",
      " 0 0 1 1]\n",
      "\n",
      "KFold:  0\n",
      "\n",
      "X_train:\n",
      " [[-0.68408024  0.30143094  0.84115693 ...  0.60430735  2.7337661\n",
      "  -1.24445253]\n",
      " [-0.95212621 -1.10192389  3.58521586 ...  2.93142223 -0.35736958\n",
      "   1.39876352]\n",
      " [-0.46822464 -0.04755098  0.5730776  ... -0.19427838  1.02648902\n",
      "  -0.29360752]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (203, 10)\n",
      "\n",
      "X_test:\n",
      " [[-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-5.31077201e-01 -1.35686454e-01  1.12961327e+00 -1.53858455e+00\n",
      "  -4.23349496e-02 -1.52157796e-01  1.06642517e+00  5.34473188e-02\n",
      "   9.39702571e-01  5.89006956e-01]\n",
      " [-6.77459994e-01  1.27138546e+00  9.11390974e-01 -6.62522555e-01\n",
      "   2.07375193e-01 -4.25596418e-01 -1.25684854e+00  8.13818833e-01\n",
      "   1.52264304e+00 -9.30996825e-01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-5.58326427e-01 -1.62441970e-01  7.11010291e-01 -9.69476470e-01\n",
      "  -5.90354098e-02 -2.98469648e-01 -1.13554647e+00  2.95092269e-01\n",
      "   1.21274745e+00 -7.35752167e-01]\n",
      " [ 1.10061349e+02 -3.16504430e+00 -5.27318756e+00 -5.70767761e+00\n",
      "  -2.87279380e+00 -2.61822852e+00 -2.66902771e-02  2.68767459e-01\n",
      "  -8.00021628e-01  1.12288681e+00]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-5.81805242e-01 -1.47558753e-02  9.25246226e-01 -1.29279908e+00\n",
      "   1.03214023e+00 -3.78875386e-01 -9.26104624e-01  7.04023331e-01\n",
      "   2.27254249e+00 -2.45161410e+00]\n",
      " [-7.77458083e-01 -1.77170941e-01  5.34370895e-01 -1.31227488e+00\n",
      "  -2.71813030e-01 -2.05716188e-01 -1.21010401e+00 -1.77025505e-01\n",
      "   9.47578345e-01 -7.94925884e-01]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-6.82286114e-01 -4.09993980e-01  4.19763285e-01 -1.35242713e+00\n",
      "  -1.31778855e-01 -5.99056729e-03 -1.71096157e+00 -4.18759395e-01\n",
      "   8.69642916e-01 -1.27232294e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [ 1.05792341e+00 -1.91677484e-02  2.60053087e+00 -3.87304283e-01\n",
      "   2.89326385e-01 -6.80713715e-01 -1.60246287e+00 -6.48677296e-01\n",
      "   2.23950710e+00 -1.49888489e+00]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-5.76667682e-01 -1.78028820e-01  1.73866863e+00 -1.16203338e-01\n",
      "  -4.80843442e-01 -7.03633367e-01  2.00831017e-01  7.04379509e-02\n",
      "   1.80122150e+00 -5.28591202e-01]\n",
      " [-7.14779427e-01 -3.30218248e-01  1.25661439e+00 -9.08879216e-01\n",
      "  -2.55942552e-01  2.29704969e-01 -6.55847097e-01  1.02362492e-01\n",
      "   1.46983647e+00 -1.58175217e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-4.57255511e-01  1.58566688e+00  2.83959681e+00 -3.86196493e-01\n",
      "  -3.41877808e-01 -6.86808792e-01 -2.14031960e-01  2.29624083e+00\n",
      "   1.53164320e+00 -1.32882031e+00]] \n",
      "Shape:  (23, 10)\n",
      "\n",
      "y_train:\n",
      " [1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0\n",
      " 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (203,)\n",
      "\n",
      "y_test:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1] \n",
      "Shape:  (23,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  0\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "10.371647350496977\n",
      "\n",
      " Coefficients \n",
      "[4.24586451 6.23093651 1.18427881 2.87426103 0.91108526 1.33729461\n",
      " 0.05514718 3.07038096 0.84986753 1.44555041]\n",
      "\n",
      " pop_polarity\n",
      "[1.96315321e-01 9.97034444e-01 9.99999938e-01 7.34333903e-02\n",
      " 1.79421573e-02 3.36181297e-01 9.95512726e-01 1.00000000e+00\n",
      " 1.99345059e-02 9.97808601e-01 7.94283502e-01 3.36181297e-01\n",
      " 1.96315321e-01 2.53826060e-01 1.15157329e-10 9.99998900e-01\n",
      " 1.79421573e-02 9.99712490e-01 9.69817123e-01 1.96315321e-01\n",
      " 1.15157329e-10 1.15157329e-10 1.00000000e+00]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 1 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9090909090909091\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.96      0.95      0.96        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  0\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.94409608e-05 7.48709170e-02 3.15130583e-03 6.34454042e-05\n",
      " 1.12275339e-03 8.94094705e-05 4.85265988e-02 1.00000000e+00\n",
      " 1.56536014e-14 1.07117400e-01 8.40470580e-05 8.94094705e-05\n",
      " 9.94409608e-05 6.74963074e-04 1.14339913e-04 1.00000000e+00\n",
      " 1.12275339e-03 2.20307071e-02 7.18203298e-04 9.94409608e-05\n",
      " 1.14339913e-04 1.14339913e-04 9.96314437e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.89\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 8  3]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6521739130434783\n",
      "recall:  0.2727272727272727\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75        12\n",
      "           1       1.00      0.27      0.43        11\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.80      0.64      0.59        23\n",
      "weighted avg       0.79      0.65      0.60        23\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  0\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.01337745 0.96201744 1.         0.00854843 0.02511645 0.0503526\n",
      " 1.         0.74953442 0.02815334 0.9805828  0.68675872 0.0503526\n",
      " 0.01337745 0.92813195 0.00653448 1.         0.02511645 1.\n",
      " 0.975126   0.01337745 0.00653448 0.00653448 1.        ]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 0 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  0\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[2.36481631e-01 9.51425105e-01 9.99999975e-01 1.50218537e-01\n",
      " 2.36461485e-01 2.36483328e-01 9.29596129e-01 1.00000000e+00\n",
      " 2.36440492e-01 8.71336054e-01 6.14893025e-01 2.36483328e-01\n",
      " 2.36481631e-01 2.84441489e-01 1.23889651e-04 9.99999287e-01\n",
      " 2.36461485e-01 9.64426156e-01 7.17481675e-01 2.36481631e-01\n",
      " 1.23889651e-04 1.23889651e-04 1.00000000e+00]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 1 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9090909090909091\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.96      0.95      0.96        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  0\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.28271052 0.68226737 0.7445568  0.28271052 0.36916518 0.36599928\n",
      " 0.7445568  0.55014336 0.32669425 0.7081931  0.43758    0.36599928\n",
      " 0.28271052 0.5849577  0.28271052 0.7445568  0.36916518 0.7445568\n",
      " 0.69734704 0.28271052 0.28271052 0.28271052 0.7445568 ]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 1 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9090909090909091\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.96      0.95      0.96        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      "KFold:  1\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (203, 10)\n",
      "\n",
      "X_test:\n",
      " [[ -0.68408024   0.30143094   0.84115693  -0.94905528   1.22670159\n",
      "    1.45010222  -0.52796566   0.60430735   2.7337661   -1.24445253]\n",
      " [ -0.95212621  -1.10192389   3.58521586  -5.20035402  -3.86139089\n",
      "   -0.5904215   16.8976218    2.93142223  -0.35736958   1.39876352]\n",
      " [ -0.46822464  -0.04755098   0.5730776   -1.03033199  -0.16271837\n",
      "   -0.27349776  -1.4993138   -0.19427838   1.02648902  -0.29360752]\n",
      " [ -0.6971256   -0.25995546   0.76211928  -0.90785859  -0.24315805\n",
      "   -0.18795335  -2.05694075  -0.0741956    1.27702702  -0.39222008]\n",
      " [ -0.61356674  -0.44470682   0.35812899  -0.89201172  -0.09034231\n",
      "   -0.35998512  -1.27156228  -0.15287943   1.23381938  -0.62770529]\n",
      " [ -0.79574795  -0.32736546   1.01411227  -1.81204147  -0.06318644\n",
      "   -0.12950437  -1.17089527  -0.24810881   1.14284327  -1.06564077]\n",
      " [  0.1343311    1.92562644   2.56428196   0.42848681   0.0526078\n",
      "   -0.9725062   -3.3294256   -0.19749882   4.84303567  -9.44266122]\n",
      " [ -0.5224716   -0.48451139   0.42768742  -1.12326189  -0.23775667\n",
      "   -0.07024878  -1.50892049   0.49136678  -0.03669799  -0.40402209]\n",
      " [ -0.79574795  -0.32736546   1.01411227  -1.81204147  -0.06318644\n",
      "   -0.12950437  -1.17089527  -0.24810881   1.14284327  -1.06564077]\n",
      " [ -0.63671331  -0.1377557    0.55378944   0.44860246   0.86986096\n",
      "   -0.71943724  -2.2479052    1.12133481   3.68178786  -2.11698805]\n",
      " [ -0.79574795  -0.32736546   1.01411227  -1.81204147  -0.06318644\n",
      "   -0.12950437  -1.17089527  -0.24810881   1.14284327  -1.06564077]\n",
      " [ -0.95212621  -1.10192389   3.58521586  -5.20035402  -3.86139089\n",
      "   -0.5904215   16.8976218    2.93142223  -0.35736958   1.39876352]\n",
      " [ -0.27991726  -0.34778067   0.69171029  -1.28838439   0.14758846\n",
      "   -0.14351744  -0.75486422  -0.54180374   0.9858799   -1.15585213]\n",
      " [  0.01924731   0.64615933   1.34672018   0.59294408   2.93937599\n",
      "   -0.76502627  -4.10898674  -0.63821205   8.44706853  -9.99485131]\n",
      " [ -0.77376643  -4.66437087 -14.23809192  11.68739097   1.5024945\n",
      "   -1.30051153   3.26509557   0.25015673  -0.48165431   0.74386295]\n",
      " [ -0.77660667  -0.42127694   0.56889774  -1.40296555  -0.24845826\n",
      "    0.05915692  -1.64574943  -0.59638277   0.73536273  -0.73043712]\n",
      " [ -0.71578819  -0.4374966    0.21767375  -1.06623592  -0.10437426\n",
      "   -0.02492852  -1.37235401   0.15051712   1.12892543  -0.97347495]\n",
      " [ -0.95212621  -1.10192389   3.58521586  -5.20035402  -3.86139089\n",
      "   -0.5904215   16.8976218    2.93142223  -0.35736958   1.39876352]\n",
      " [ -0.39887834   1.63604606  -0.31833942  -1.25655032   0.04901617\n",
      "    0.03624827  -3.27056595   2.06884815   1.4166628   -2.95574938]\n",
      " [ -0.94042586  -0.87521532   0.70846427  -2.57522269  -1.50925286\n",
      "   -0.21439377  -3.25712027  -4.28924147 -10.26931695   4.49057796]\n",
      " [ -0.77660667  -0.42127694   0.56889774  -1.40296555  -0.24845826\n",
      "    0.05915692  -1.64574943  -0.59638277   0.73536273  -0.73043712]\n",
      " [ -0.62868544   0.02783548   1.64135992  -0.87078225  -0.30373277\n",
      "   -0.34865479  -2.5084298   -0.45997031   2.15951575  -1.55606518]\n",
      " [ -0.94042586  -0.87521532   0.70846427  -2.57522269  -1.50925286\n",
      "   -0.21439377  -3.25712027  -4.28924147 -10.26931695   4.49057796]] \n",
      "Shape:  (23, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0\n",
      " 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (203,)\n",
      "\n",
      "y_test:\n",
      " [1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0] \n",
      "Shape:  (23,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  1\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "10.472119113795504\n",
      "\n",
      " Coefficients \n",
      "[4.05823339 6.57638662 0.99594032 2.76002157 0.88055064 1.34901499\n",
      " 0.0445027  3.26415041 0.62116718 1.25489904]\n",
      "\n",
      " pop_polarity\n",
      "[9.99997781e-01 2.26726764e-02 9.93582669e-01 9.75551402e-01\n",
      " 8.59383298e-01 3.49540091e-01 9.99999933e-01 9.60608443e-01\n",
      " 3.49540091e-01 9.99992173e-01 3.49540091e-01 2.26726764e-02\n",
      " 8.14284053e-01 9.99942982e-01 1.62897109e-02 2.01913024e-01\n",
      " 8.51755010e-01 2.26726764e-02 9.99999997e-01 2.76226631e-10\n",
      " 2.01913024e-01 9.87544033e-01 2.76226631e-10]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[11  0]\n",
      " [ 0 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  1\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[2.96582872e-01 9.57759641e-15 4.08745640e-01 3.68766651e-05\n",
      " 4.36463761e-04 1.09312342e-05 1.00000000e+00 2.63229352e-02\n",
      " 1.09312342e-05 2.33179851e-03 1.09312342e-05 9.57759641e-15\n",
      " 9.99999584e-01 1.00000000e+00 1.09363808e-04 1.16924838e-05\n",
      " 3.32547012e-05 9.57759641e-15 9.99797533e-01 1.40915401e-05\n",
      " 1.16924838e-05 5.73108855e-04 1.40915401e-05]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[11  0]\n",
      " [ 8  4]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6521739130434783\n",
      "recall:  0.3333333333333333\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73        11\n",
      "           1       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.79      0.67      0.62        23\n",
      "weighted avg       0.80      0.65      0.61        23\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  1\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[1.00000000e+00 2.46257846e-04 1.00000000e+00 1.00000000e+00\n",
      " 9.90000000e-01 2.00076710e-03 1.00000000e+00 9.60246258e-01\n",
      " 2.00076710e-03 1.00000000e+00 2.00076710e-03 2.46257846e-04\n",
      " 9.40630798e-01 1.00000000e+00 1.19941384e-03 4.36769613e-04\n",
      " 9.70630798e-01 2.46257846e-04 1.00000000e+00 2.46257846e-04\n",
      " 4.36769613e-04 1.00000000e+00 2.46257846e-04]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[11  0]\n",
      " [ 0 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  1\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[9.99994632e-01 2.20226087e-01 9.54810506e-01 7.73312435e-01\n",
      " 5.91144809e-01 2.20278952e-01 1.00000000e+00 8.98015476e-01\n",
      " 2.20278952e-01 9.88639022e-01 2.20278952e-01 2.20226087e-01\n",
      " 7.73684888e-01 9.88705213e-01 2.20238636e-01 2.20273070e-01\n",
      " 6.46133070e-01 2.20226087e-01 1.00000000e+00 1.41211319e-04\n",
      " 2.20273070e-01 8.31362707e-01 1.41211319e-04]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[11  0]\n",
      " [ 0 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  1\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.73881227 0.32467705 0.73881227 0.73881227 0.69075537 0.41380766\n",
      " 0.73881227 0.6288144  0.41380766 0.73881227 0.41380766 0.32467705\n",
      " 0.6551389  0.73881227 0.37001193 0.28015918 0.69075537 0.32467705\n",
      " 0.6728161  0.28015918 0.28015918 0.73881227 0.28015918]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[11  0]\n",
      " [ 0 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      "KFold:  2\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (203, 10)\n",
      "\n",
      "X_test:\n",
      " [[-3.59378813e-01  1.17879671e+00  1.59272744e+00 -3.99520998e-01\n",
      "  -1.81772772e-01 -7.93745434e-01 -1.49999724e+00  2.04407932e-01\n",
      "   1.40882321e+00 -1.36843823e+00]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-7.04345176e-01  3.87640035e-01  1.49436864e+00 -6.21389966e-01\n",
      "   4.48121135e-01 -2.17046582e-01 -1.96516269e+00  1.79523239e-01\n",
      "   1.86510564e+00 -3.94665804e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.53963120e-01 -3.67697080e-01  5.12451158e-01 -1.42614868e+00\n",
      "  -3.00192806e-01 -4.10280984e-02 -1.00266233e+00 -3.71578428e-01\n",
      "   5.57414412e-01 -5.79400234e-01]\n",
      " [-7.32259358e-01 -3.62171614e-01  4.30138658e-01 -1.30562205e+00\n",
      "  -2.40301169e-01 -3.44715988e-02 -1.16657361e+00 -4.23132357e-01\n",
      "   5.07141507e-01 -6.05692510e-01]\n",
      " [-7.37535960e-01 -4.57555090e-01  6.25329951e-01 -1.13048522e+00\n",
      "  -3.42137017e-01 -1.76051121e-01 -3.80335721e-01 -4.65373130e-01\n",
      "   4.96668211e-01 -1.43281123e-01]\n",
      " [ 2.26535003e+00 -1.30902989e-01 -4.64593751e-01 -7.22238389e-01\n",
      "  -8.53238206e-01  1.78669563e+00 -1.62295444e+00 -1.00685566e-01\n",
      "   1.76115679e+00 -1.93227870e+00]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-4.11179379e-01 -1.19579344e-01  8.42613805e-01 -2.18583134e-01\n",
      "  -7.42998254e-02 -3.52537835e-01 -1.78959533e+00 -2.82846315e-01\n",
      "   3.02507023e+00  1.65698479e-02]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-3.38819550e-01  8.28988249e+00  1.92818273e+00  1.52684026e+00\n",
      "   9.58724627e+00 -2.16587106e+00 -1.31200050e+01  6.66039513e+01\n",
      "  -1.58365727e+01  8.41656213e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [ 1.43560284e-01  1.06034963e+00  1.21081812e+00 -6.15627022e-01\n",
      "   1.83836983e+00 -4.11996545e-01 -2.08971694e+00  7.02385414e-01\n",
      "   2.44401039e+00 -2.83752430e+00]\n",
      " [-8.30938045e-01  2.83304777e-01  1.05165162e+00 -6.54623715e-01\n",
      "   8.41698147e-01  8.60795902e-01 -2.63148227e+00  1.81992670e+00\n",
      "   3.06557963e+00 -2.23184530e+00]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.14843564e-01 -4.60771997e-01  2.99359484e-01 -1.14115046e+00\n",
      "  -2.39302442e-01 -3.48969414e-02 -1.08309919e+00 -5.35921531e-01\n",
      "   2.41791548e-01 -4.65556372e-01]] \n",
      "Shape:  (23, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (203,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1] \n",
      "Shape:  (23,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  2\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "8.034704995888717\n",
      "\n",
      " Coefficients \n",
      "[ 3.45970346  5.00735302  0.99557416  2.30552092  0.99023797  0.95773937\n",
      " -0.05382257  3.09116861  1.1059073   1.26768525]\n",
      "\n",
      " pop_polarity\n",
      "[9.99997634e-01 3.76788500e-01 1.04869371e-11 1.04869371e-11\n",
      " 9.99956944e-01 1.84397826e-01 3.22554696e-01 3.50406709e-01\n",
      " 4.13446379e-01 9.99998203e-01 1.83813732e-02 9.99801702e-01\n",
      " 7.39593875e-02 1.70164361e-02 1.00000000e+00 1.84397826e-01\n",
      " 1.84397826e-01 1.84397826e-01 9.99999928e-01 9.99999249e-01\n",
      " 3.76788500e-01 1.83813732e-02 2.19240379e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.95\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 4  7]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8260869565217391\n",
      "recall:  0.6363636363636364\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        12\n",
      "           1       1.00      0.64      0.78        11\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.88      0.82      0.82        23\n",
      "weighted avg       0.87      0.83      0.82        23\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  2\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.99984021e-001 6.40153171e-005 9.24935077e-007 9.24935077e-007\n",
      " 4.35022027e-004 6.49087287e-005 6.82555398e-005 9.77754790e-005\n",
      " 5.51309220e-005 1.00000000e+000 5.78191763e-004 9.94961763e-001\n",
      " 4.08905375e-005 1.96601416e-018 3.22977505e-108 6.49087287e-005\n",
      " 6.49087287e-005 6.49087287e-005 1.00000000e+000 1.07577201e-002\n",
      " 6.40153171e-005 5.78191763e-004 1.11794175e-004]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.79\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 7  4]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6956521739130435\n",
      "recall:  0.36363636363636365\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77        12\n",
      "           1       1.00      0.36      0.53        11\n",
      "\n",
      "    accuracy                           0.70        23\n",
      "   macro avg       0.82      0.68      0.65        23\n",
      "weighted avg       0.81      0.70      0.66        23\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  2\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[1.00000000e+00 2.99499866e-03 6.57319471e-04 6.57319471e-04\n",
      " 1.00000000e+00 4.59241416e-04 9.60217672e-01 9.50217672e-01\n",
      " 9.60439647e-01 1.00000000e+00 1.94851264e-03 1.00000000e+00\n",
      " 4.59241416e-04 6.57319471e-04 9.40000000e-01 4.59241416e-04\n",
      " 4.59241416e-04 4.59241416e-04 1.00000000e+00 9.60000000e-01\n",
      " 2.99499866e-03 1.94851264e-03 9.50439647e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 0 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  2\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[9.99999842e-01 2.38718861e-01 5.32476477e-07 5.32476477e-07\n",
      " 9.93191136e-01 2.38730170e-01 3.94544246e-01 4.34899511e-01\n",
      " 2.56231055e-01 1.00000000e+00 2.38772733e-01 9.57201815e-01\n",
      " 1.17850015e-01 3.58439563e-02 1.00000000e+00 2.38730170e-01\n",
      " 2.38730170e-01 2.38730170e-01 1.00000000e+00 1.00000000e+00\n",
      " 2.38718861e-01 2.38772733e-01 3.38742695e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 1 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9090909090909091\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.96      0.95      0.96        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  2\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.74247915 0.3732397  0.28714323 0.28714323 0.74247915 0.28714323\n",
      " 0.52901626 0.49914613 0.60830873 0.74247915 0.36049503 0.74247915\n",
      " 0.28714323 0.31701335 0.6988106  0.28714323 0.28714323 0.28714323\n",
      " 0.74247915 0.5983827  0.3732397  0.36049503 0.60830873]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 1 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9090909090909091\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.96      0.95      0.96        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      "KFold:  3\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (203, 10)\n",
      "\n",
      "X_test:\n",
      " [[ 2.71950668e+00  9.30623489e-01  3.67129626e+00  1.61657646e+00\n",
      "   6.99326542e-02 -2.60946505e-01 -2.62607429e+00  3.09761693e+00\n",
      "  -8.02665132e-01 -5.41951653e+00]\n",
      " [-9.99258962e-02  6.57286493e-02  2.20313622e+00 -5.61932034e-01\n",
      "   6.02225822e-01  6.01364639e-01 -1.96271184e+00  8.08107948e-01\n",
      "   1.27598947e+00 -7.59711532e-01]\n",
      " [-4.58684890e-01  7.20501781e-01  5.71985009e-01 -1.21275953e+00\n",
      "   1.74435910e-01 -2.47922900e-01 -1.65264435e+00  5.42970049e-01\n",
      "   1.93235094e+00  8.25605738e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-4.21456446e-01  1.73259021e+00  1.23966802e+00 -7.31506405e-01\n",
      "   2.18240389e+00  4.71941639e-01 -1.07593234e+00 -8.69821743e-01\n",
      "   2.25051820e+00 -4.88727758e-02]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-9.41678727e-01 -6.92109050e-02  5.10001301e-01 -1.93071871e+00\n",
      "  -2.21588257e-01 -1.80141949e-01  3.56908351e-01 -1.00827577e-02\n",
      "   2.35075310e+00 -1.60099803e+00]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-6.44855202e-01 -5.90295956e-01 -7.07870983e-01  1.53084313e+00\n",
      "  -4.10487450e-02 -1.11210231e+00 -1.94232331e+00 -3.05641341e-01\n",
      "   3.46960443e+00  4.84144491e-01]\n",
      " [-6.44546287e-01 -3.70381474e-02  5.83952853e-01 -1.50575759e+00\n",
      "  -9.65615316e-02 -1.68573765e-01 -2.50838767e+00  6.74422492e-01\n",
      "   1.90260854e+00 -2.79599797e-01]\n",
      " [-7.16198482e-01 -6.14643868e-01 -4.10500960e-02 -8.29071985e-01\n",
      "  -3.54402728e-01  2.26227779e-01 -7.21387182e-01 -2.64869028e-01\n",
      "   1.28204367e+00 -4.96347879e-01]\n",
      " [ 5.26624763e+00  1.10839028e+01  1.35943743e+01  2.15911706e+00\n",
      "   7.53982759e+01  8.92629591e+00  1.39220562e+01 -9.82056383e+00\n",
      "  -5.16910618e+00  3.66623802e+00]\n",
      " [-5.99190710e-01  8.24624581e-01  1.05023685e+00  1.20682870e-01\n",
      "   1.30737520e+00 -4.36008168e-01 -2.85655255e+00  2.57535639e-01\n",
      "   2.16886114e+00 -9.43236560e-01]\n",
      " [-4.21107611e-01 -4.93887236e-02  1.25499223e+00 -1.88059575e+00\n",
      "  -3.05095020e-01 -1.10230703e-01 -9.45397172e-01  8.61180788e-01\n",
      "   2.06835181e+00 -1.61927555e+00]\n",
      " [-4.90030396e-01  3.41230113e-03  5.03564103e-01  8.08253519e-02\n",
      "   1.33110202e-01 -6.04739933e-01 -1.48410707e+00 -5.24959655e-01\n",
      "   7.53429533e-01 -7.78682880e-01]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-7.95227939e-01 -3.28772167e-01  6.78977700e-01 -1.57399263e+00\n",
      "  -1.68136107e-01 -9.27145887e-02 -1.84583207e+00 -1.92644455e-02\n",
      "   3.43188408e-01 -2.40301371e-01]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [ 5.39119616e+00  8.29841942e-01  1.45253146e+01  2.52743029e+01\n",
      "  -1.28291421e+01  7.28379931e+01  1.78153170e+00  1.86589243e+00\n",
      "  -3.27786750e+00 -2.32669372e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-4.72558959e-01 -2.86986235e-01  6.51483189e-01 -7.73889573e-01\n",
      "   3.93869057e-01 -1.50089989e-01 -1.50094678e+00 -1.14112558e-01\n",
      "   3.52813527e-01 -3.00922212e-01]\n",
      " [-4.87833063e-01 -7.80919648e-02  6.32973539e-01 -1.09322570e+00\n",
      "  -2.97506119e-01 -3.25767947e-01 -1.40162346e+00 -3.47423299e-01\n",
      "   8.57638939e-01 -7.82876111e-01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]] \n",
      "Shape:  (23, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (203,)\n",
      "\n",
      "y_test:\n",
      " [1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0] \n",
      "Shape:  (23,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  3\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "10.233969147810337\n",
      "\n",
      " Coefficients \n",
      "[4.22795312 5.53896241 1.56978416 3.03508496 0.87859319 0.8045264\n",
      " 0.00846663 2.9637604  0.00600302 0.84367198]\n",
      "\n",
      " pop_polarity\n",
      "[1.         0.99999958 0.99999219 0.21215194 0.99999997 0.0196633\n",
      " 0.29046106 0.34330791 0.99825486 0.99441984 0.47231291 1.\n",
      " 0.99999971 0.99491394 0.99867685 0.0196633  0.6992355  0.34330791\n",
      " 1.         0.21215194 0.99291666 0.9606124  0.09602711]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 2 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9130434782608695\n",
      "recall:  0.875\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88         7\n",
      "           1       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.91        23\n",
      "   macro avg       0.89      0.94      0.90        23\n",
      "weighted avg       0.93      0.91      0.92        23\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  3\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[1.00000000e+00 1.00000000e+00 9.74207294e-01 1.73449166e-04\n",
      " 9.99937574e-01 1.87660921e-22 3.58797876e-04 1.60835983e-04\n",
      " 8.17891131e-03 3.51672449e-03 4.94915581e-04 1.00000000e+00\n",
      " 6.17176741e-02 9.98338377e-01 7.67549790e-01 1.87660921e-22\n",
      " 1.07918282e-04 1.60835983e-04 1.00000000e+00 1.73449166e-04\n",
      " 8.74507240e-01 7.43082736e-01 1.11739403e-04]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0]\n",
      "\n",
      " auc\n",
      "0.96\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 6 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7391304347826086\n",
      "recall:  0.625\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70         7\n",
      "           1       1.00      0.62      0.77        16\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.77      0.81      0.73        23\n",
      "weighted avg       0.86      0.74      0.75        23\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  3\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.94       1.         0.9512969  0.00424297 0.98       0.00555208\n",
      " 0.81       0.01681746 0.91449696 0.9812969  0.98060399 0.92\n",
      " 1.         0.94       0.98389297 0.00555208 0.49521933 0.01681746\n",
      " 0.95       0.00424297 1.         1.         0.00373644]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 1 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9375\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.94      0.97      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  3\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[1.         1.         0.99999961 0.23857718 0.99999999 0.00792528\n",
      " 0.12467874 0.23858329 0.91490418 0.98044186 0.4911877  1.\n",
      " 0.99999994 0.98194969 0.97289721 0.00792528 0.65748143 0.23858329\n",
      " 1.         0.23857718 0.96428172 0.87706606 0.1314596 ]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0]\n",
      "\n",
      " auc\n",
      "0.96\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 1 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9375\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.94      0.97      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  3\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:54:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:54:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.67387545 0.7359811  0.70036465 0.2786822  0.7359811  0.31159356\n",
      " 0.53506935 0.37961406 0.6902453  0.6674533  0.6902453  0.6749774\n",
      " 0.7359811  0.70036465 0.7359811  0.31159356 0.29690018 0.37961406\n",
      " 0.63936096 0.2786822  0.6532672  0.7359811  0.2786822 ]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0]\n",
      "\n",
      " auc\n",
      "0.96\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 1 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.9375\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.94      0.97      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      "KFold:  4\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (203, 10)\n",
      "\n",
      "X_test:\n",
      " [[-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [ 6.86732050e+00  1.27448928e+01  5.07776554e+01  5.82578562e+01\n",
      "  -1.02027783e+01 -2.81958062e+01  3.19535730e+00 -4.11479737e+00\n",
      "  -5.16867176e+00  3.71270091e-01]\n",
      " [ 2.00562955e+00  8.78557959e-01  3.26418588e+00  4.80209788e-02\n",
      "  -9.32422685e-01 -7.82384590e-01 -1.92544925e+00 -1.56364858e+00\n",
      "   5.37860141e+00 -3.17716434e+00]\n",
      " [-6.20291143e-01 -1.87683498e-01  2.60802626e-01 -6.06425981e-01\n",
      "  -3.08101104e-01 -4.60133694e-01 -9.18300748e-01  1.78812328e-01\n",
      "   3.31733170e+00  1.25644682e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-4.85217280e-01 -2.57733064e-01  7.34081008e-01  7.45381167e-01\n",
      "   1.28631122e-01 -1.57542510e-01 -2.02085977e+00  1.66598207e-01\n",
      "   3.36651001e+00  8.82662430e-01]\n",
      " [-7.08858010e-01 -3.92032645e-01 -3.69935825e-01 -7.24464721e-01\n",
      "  -1.13718053e-01 -2.59647312e-01 -4.72429824e-01  9.00210068e-01\n",
      "   7.18456119e-01 -2.75259486e-01]\n",
      " [ 2.34242783e-01  1.27506321e+00  1.60722953e+00 -2.06407647e-01\n",
      "  -7.10353922e-01 -9.94881362e-01 -1.96859094e+00 -7.75538199e-01\n",
      "   2.79643068e+00 -2.66139461e+00]\n",
      " [-5.89326580e-01 -1.58975919e-01  4.97699056e-01 -1.25358406e+00\n",
      "  -2.24288492e-01  3.56828770e-01 -1.60429485e+00 -2.66021296e-01\n",
      "   1.05109490e+00 -5.60921715e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-6.31332723e-01 -2.86859825e-01  6.68727029e-01 -1.10698822e+00\n",
      "  -2.13695889e-01 -2.29178253e-01 -1.09808356e+00  6.71807539e-02\n",
      "   1.14348612e+00 -7.19192294e-01]\n",
      " [ 1.36878831e+00  1.91032945e+00  4.10652250e+00  1.64349926e+00\n",
      "  -4.84022865e-01 -2.03307989e+00 -1.52463929e+00 -1.48198998e-01\n",
      "   4.60857905e+00 -9.70266210e-01]\n",
      " [ 1.95828282e-01  9.73453706e-01  4.80508582e+00  2.66008935e+00\n",
      "   2.20713744e+00 -2.55634558e+00 -9.82389511e-01  3.80310097e+00\n",
      "  -1.77054868e-01  3.06769214e-01]\n",
      " [ 1.40960595e-01  1.94927139e+00  3.77372343e-01  6.02547303e-01\n",
      "   2.44556683e-01 -9.08181198e-01 -4.15854686e+00 -1.33652325e+00\n",
      "   5.89887991e+00 -1.41994405e+01]\n",
      " [-6.11581171e-01 -3.47399751e-01  6.72947921e-01 -1.12960148e+00\n",
      "  -2.43123849e-01 -2.02761513e-01 -1.10241378e+00 -4.88497761e-01\n",
      "   7.11565770e-01 -3.38603548e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-5.68103092e-01  5.68243682e-01  1.55730334e+00 -1.03842301e+00\n",
      "   1.35368588e+00 -1.28985438e-02 -1.94308778e+00  4.09478815e-01\n",
      "   1.83622486e+00 -6.89474194e-01]\n",
      " [ 7.44195714e-01  1.01999490e-01  2.08731308e+00 -1.04308981e+00\n",
      "  -2.73243823e-01  2.77274651e+00  5.60992590e-01  2.42873520e+00\n",
      "   1.00152708e+00 -1.06019951e+00]\n",
      " [-5.05618793e-02  4.72336256e-01  1.27389443e+00 -1.08925211e+00\n",
      "   1.58826724e+00 -6.71399279e-02 -2.31209589e+00  1.36034238e+00\n",
      "   6.30483965e-01  4.35051082e-01]\n",
      " [-7.15431313e-01 -2.57057810e-01  7.11024012e-01 -1.37449829e+00\n",
      "  -1.56016109e-01 -1.26149046e-01 -9.48041556e-01 -2.75550896e-01\n",
      "   8.20628744e-01 -7.05817115e-01]] \n",
      "Shape:  (23, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (203,)\n",
      "\n",
      "y_test:\n",
      " [0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1] \n",
      "Shape:  (23,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  4\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "7.397377166037201\n",
      "\n",
      " Coefficients \n",
      "[ 3.11115764  4.53448918  0.91476618  2.09892505  0.80103412  0.89296697\n",
      " -0.05537078  2.63726472  0.73139386  1.05442045]\n",
      "\n",
      " pop_polarity\n",
      "[3.19367267e-09 1.00000000e+00 9.99999866e-01 9.97541476e-01\n",
      " 2.41082104e-02 9.99980821e-01 9.79525261e-01 9.99979401e-01\n",
      " 9.14562996e-01 2.41082104e-02 2.29065625e-01 9.13791911e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.76279976e-01 6.73564323e-01\n",
      " 2.41082104e-02 3.19367267e-09 3.19367267e-09 9.99967295e-01\n",
      " 9.99999987e-01 9.99999254e-01 6.71622009e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 0 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  4\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[5.11472364e-05 1.00000000e+00 1.00000000e+00 1.40751280e-03\n",
      " 1.01974608e-09 4.99651296e-01 6.74265115e-05 1.00000000e+00\n",
      " 1.11912760e-02 1.01974608e-09 3.34822306e-05 7.48918718e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.14747988e-03\n",
      " 1.01974608e-09 5.11472364e-05 5.11472364e-05 6.22789746e-02\n",
      " 1.00000000e+00 1.00000000e+00 7.06905032e-05]\n",
      "\n",
      " yhat\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[7 0]\n",
      " [8 8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6521739130434783\n",
      "recall:  0.5\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64         7\n",
      "           1       1.00      0.50      0.67        16\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.73      0.75      0.65        23\n",
      "weighted avg       0.84      0.65      0.66        23\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  4\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[5.50283919e-04 9.60000000e-01 9.90000000e-01 1.00000000e+00\n",
      " 1.60901555e-02 9.90000000e-01 1.00000000e+00 9.90000000e-01\n",
      " 9.90000000e-01 1.60901555e-02 2.20468890e-03 9.90000000e-01\n",
      " 1.00000000e+00 9.70000000e-01 9.90000000e-01 1.00000000e+00\n",
      " 1.60901555e-02 5.50283919e-04 5.50283919e-04 1.00000000e+00\n",
      " 9.80000000e-01 9.90000000e-01 9.60000000e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 0 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  4\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[1.99631827e-04 1.00000000e+00 1.00000000e+00 8.96212672e-01\n",
      " 2.24584667e-01 9.89131200e-01 9.45540315e-01 9.99999999e-01\n",
      " 8.80228812e-01 2.24584667e-01 2.24617707e-01 7.89913798e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999999e-01 5.76746460e-01\n",
      " 2.24584667e-01 1.99631827e-04 1.99631827e-04 9.99985591e-01\n",
      " 1.00000000e+00 9.99999992e-01 5.81979976e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 0 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  4\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:54:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:54:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.283896   0.63873446 0.74239486 0.74239486 0.36047423 0.74239486\n",
      " 0.6068407  0.74239486 0.6377252  0.36047423 0.283896   0.704824\n",
      " 0.74239486 0.66483563 0.74239486 0.6068407  0.36047423 0.283896\n",
      " 0.283896   0.74239486 0.704824   0.65270084 0.66982394]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[ 7  0]\n",
      " [ 0 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      "KFold:  5\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (203, 10)\n",
      "\n",
      "X_test:\n",
      " [[-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-2.52987706e-01  2.43430375e-01  1.04975581e+00 -2.03658841e+00\n",
      "  -8.01198126e-01 -3.83726572e-01 -1.40769271e-01 -3.82521072e-01\n",
      "   2.05934455e+00 -1.76354706e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-8.56137521e-01 -5.87315595e-01 -3.95990771e-01  2.88385475e-01\n",
      "   4.02502076e-01 -7.08981708e-01 -1.08946429e+00  1.89404395e+00\n",
      "   3.07069146e+00 -3.34763109e-01]\n",
      " [-5.28023924e-01  1.81009404e+00  5.11742797e+00  1.08188892e+00\n",
      "   1.91158239e+00 -7.02354046e-01 -2.22279774e+00  1.25241453e+00\n",
      "   4.98269434e+00 -1.43410228e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [ 9.01417443e-01  8.57701641e+01 -2.38284257e+01 -2.69194347e-01\n",
      "  -9.03982644e+00  1.07790393e+00  5.83069938e+00 -5.26976086e+00\n",
      "  -3.93945234e+00 -2.48302807e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-7.10297609e-01 -2.33570042e-01  8.14319976e-01 -1.19859173e+00\n",
      "   9.61254985e-02 -1.43139586e-01 -1.46913546e+00 -4.44597025e-01\n",
      "   1.09785796e+00 -4.43085862e-01]\n",
      " [-7.19957318e-01  8.49018741e-01 -3.90829925e-01 -4.23939103e-01\n",
      "   1.16381559e-01 -2.85399223e-01 -1.54277862e+00 -7.92149936e-02\n",
      "   5.62120440e-01 -7.48024255e-01]\n",
      " [ 1.80108535e+00 -5.92140446e-01  1.32498506e+00 -7.45888662e-01\n",
      "  -8.96344997e-01  3.11201978e+00 -2.61465900e+00  2.57835988e-01\n",
      "   1.08450303e+01 -1.67241385e+01]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.78211599e-01 -3.84139111e-01  6.94441423e-01 -1.61933165e+00\n",
      "  -4.09599789e-01 -9.59820254e-02 -1.90238482e-01 -1.21965179e-01\n",
      "   5.85206799e-01 -5.12229445e-01]\n",
      " [-6.15974111e-01  7.19975417e-01  1.49146268e+00 -7.16989814e-01\n",
      "   2.00777715e+00  9.90724774e-01 -3.74984717e+00  3.01067026e+00\n",
      "   3.33207559e+00 -4.85240079e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]] \n",
      "Shape:  (23, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (203,)\n",
      "\n",
      "y_test:\n",
      " [0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0] \n",
      "Shape:  (23,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  5\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "9.038358121052674\n",
      "\n",
      " Coefficients \n",
      "[ 3.4113353   5.64907029  1.058147    2.53847986  0.88823308  0.81263457\n",
      " -0.01108855  2.79806962  0.53143636  1.28730296]\n",
      "\n",
      " pop_polarity\n",
      "[3.40890887e-01 9.40147596e-02 2.40029841e-02 2.40029841e-02\n",
      " 9.02330915e-01 1.43657340e-08 9.99917868e-01 1.00000000e+00\n",
      " 2.10363479e-01 2.40029841e-02 2.40029841e-02 2.10363479e-01\n",
      " 9.40147596e-02 1.00000000e+00 1.43657340e-08 8.66377864e-01\n",
      " 9.99862465e-01 1.26048805e-01 2.40029841e-02 4.27611868e-01\n",
      " 9.99999971e-01 2.10363479e-01 2.10363479e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "0.96\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[14  0]\n",
      " [ 2  7]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9130434782608695\n",
      "recall:  0.7777777777777778\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        14\n",
      "           1       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.91        23\n",
      "   macro avg       0.94      0.89      0.90        23\n",
      "weighted avg       0.92      0.91      0.91        23\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  5\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[5.60771158e-05 3.80256721e-05 1.42785264e-04 1.42785264e-04\n",
      " 9.99999993e-01 2.60442190e-05 1.29869193e-04 9.71164933e-01\n",
      " 6.18239030e-05 1.42785264e-04 1.42785264e-04 6.18239030e-05\n",
      " 3.80256721e-05 1.00000000e+00 2.60442190e-05 1.66210958e-04\n",
      " 2.98339935e-04 1.00000000e+00 1.42785264e-04 3.59101349e-05\n",
      " 9.96680606e-01 6.18239030e-05 6.18239030e-05]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "0.87\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[14  0]\n",
      " [ 4  5]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8260869565217391\n",
      "recall:  0.5555555555555556\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       1.00      0.56      0.71         9\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.89      0.78      0.79        23\n",
      "weighted avg       0.86      0.83      0.81        23\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  5\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.22967723 0.10759257 0.22110397 0.22110397 0.88832248 0.06321202\n",
      " 0.539083   0.98199527 0.09301656 0.22110397 0.22110397 0.09301656\n",
      " 0.10759257 0.85103133 0.06321202 0.92818656 0.91651932 0.85259998\n",
      " 0.22110397 0.27273372 0.98199527 0.09301656 0.09301656]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[14  0]\n",
      " [ 1  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.8888888888888888\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.97      0.94      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  5\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[2.28398531e-01 1.34038791e-01 2.28345947e-01 2.28345947e-01\n",
      " 9.79199212e-01 5.85974006e-05 9.78346509e-01 1.00000000e+00\n",
      " 2.28386466e-01 2.28345947e-01 2.28345947e-01 2.28386466e-01\n",
      " 1.34038791e-01 1.00000000e+00 5.85974006e-05 6.22411046e-01\n",
      " 9.99999967e-01 9.99999997e-01 2.28345947e-01 4.54607617e-01\n",
      " 1.00000000e+00 2.28386466e-01 2.28386466e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[14  0]\n",
      " [ 0  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  5\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:54:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:54:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.3507007  0.28422266 0.37038898 0.37038898 0.711859   0.28422266\n",
      " 0.51186204 0.74822265 0.28422266 0.37038898 0.37038898 0.28422266\n",
      " 0.28422266 0.66385025 0.28422266 0.72187483 0.6806108  0.7002078\n",
      " 0.37038898 0.3393068  0.74822265 0.28422266 0.28422266]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "0.95\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[14  0]\n",
      " [ 1  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9565217391304348\n",
      "recall:  0.8888888888888888\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.96        23\n",
      "   macro avg       0.97      0.94      0.95        23\n",
      "weighted avg       0.96      0.96      0.96        23\n",
      "\n",
      "\n",
      "KFold:  6\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (204, 10)\n",
      "\n",
      "X_test:\n",
      " [[-5.09484763e-01  4.02080207e+00  2.77685218e+00  7.77890343e-01\n",
      "  -1.35456604e+00 -4.16958986e-02 -2.77343859e+00  3.85100897e-01\n",
      "   5.90539052e+00 -2.44755645e+00]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-2.39768539e-01  4.58355810e-01  1.57980164e+00 -1.07793812e+00\n",
      "   1.88491507e+00  2.80763464e-01 -2.09390234e+00  1.34000627e+00\n",
      "   2.17414407e+00 -2.77250926e+00]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-7.08157586e-01 -8.38535590e-02 -9.41455076e-01  4.47655913e-02\n",
      "   5.91177884e-01 -1.81081268e-01 -1.29030615e+00  9.54115892e-01\n",
      "   9.14163977e-01 -4.33710394e-02]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-1.82088226e-01 -4.92132600e-01  4.26292092e-01 -1.82351981e-01\n",
      "  -1.07787944e-01  3.40397630e-01 -1.33341218e+00 -5.04239756e-01\n",
      "   9.18828393e-01 -4.02657867e-01]\n",
      " [-4.03745929e-01  2.43380862e-01  8.81390372e-01 -7.79887513e-01\n",
      "   3.39874259e-01 -3.37417645e-01 -1.61031973e+00 -3.32515114e-03\n",
      "   1.57244490e+00 -3.44518740e-01]\n",
      " [ 4.12547131e-01  1.31149134e+00  1.71419823e+00  4.64104725e-01\n",
      "   4.00059864e+00 -2.08883570e-01 -3.83268010e+00  5.65319795e+00\n",
      "   3.40265085e+00 -8.50929256e+00]\n",
      " [-7.85281117e-01 -7.15290810e-01 -4.31479441e-01 -5.18712633e-01\n",
      "  -1.49987968e-01 -1.37495658e-01 -1.03100080e+00 -1.55926317e-01\n",
      "   1.09965813e+00 -5.99517370e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.30828575e-01 -2.47941767e-01  6.72696694e-01 -1.39295225e+00\n",
      "   8.20722262e-01  7.35490622e-02 -1.18131986e+00 -6.55915870e-01\n",
      "   7.16395158e-01 -8.90470905e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.80560019e-01 -4.23642580e-01  1.75846866e-01 -1.10224427e+00\n",
      "  -1.77579375e-01 -1.38337587e-01 -1.21195525e+00  2.65301952e-01\n",
      "   6.21331177e-01 -3.30331069e-01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [ 2.20519795e-01  1.97519890e-01 -1.44063845e-01  1.46272942e-01\n",
      "   7.62412157e-01 -2.82695067e-01 -1.70568061e+00  5.81701581e-01\n",
      "   2.18732787e+00  4.79634512e-02]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]] \n",
      "Shape:  (22, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0\n",
      " 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (204,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0] \n",
      "Shape:  (22,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  6\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "6.6376385395059465\n",
      "\n",
      " Coefficients \n",
      "[ 2.8565587   4.14803015  0.97359531  2.07893462  0.39582827  0.53139559\n",
      " -0.10785228  2.39363537  0.68615998  0.91604574]\n",
      "\n",
      " pop_polarity\n",
      "[1.00000000e+00 1.20888647e-01 2.69777745e-02 2.69777745e-02\n",
      " 9.99970521e-01 1.20888647e-01 9.98630127e-01 2.69777745e-02\n",
      " 9.69193127e-01 9.98661611e-01 1.00000000e+00 4.35319489e-01\n",
      " 2.36398985e-01 4.69481611e-01 2.36398985e-01 7.81773291e-01\n",
      " 1.20888647e-01 3.71311516e-01 1.67835025e-08 9.99990104e-01\n",
      " 1.82667127e-02 1.20888647e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 2  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.8\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.93      0.90      0.91        22\n",
      "weighted avg       0.92      0.91      0.91        22\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  6\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.96291331e-01 9.62147470e-06 7.68833396e-15 7.68833396e-15\n",
      " 1.00000000e+00 9.62147470e-06 5.27696747e-05 7.68833396e-15\n",
      " 1.00000000e+00 9.90187153e-01 1.00000000e+00 9.08532795e-06\n",
      " 1.49189341e-05 5.06271869e-05 1.49189341e-05 1.02157058e-05\n",
      " 9.62147470e-06 1.38350199e-05 1.13628998e-05 1.00000000e+00\n",
      " 1.03643825e-04 9.62147470e-06]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "0.87\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 4  6]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8181818181818182\n",
      "recall:  0.6\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        12\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.82        22\n",
      "   macro avg       0.88      0.80      0.80        22\n",
      "weighted avg       0.86      0.82      0.81        22\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  6\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[1.00000000e+00 0.00000000e+00 5.16624041e-04 5.16624041e-04\n",
      " 1.00000000e+00 0.00000000e+00 1.00000000e+00 5.16624041e-04\n",
      " 9.80000000e-01 1.00000000e+00 1.00000000e+00 6.80000000e-01\n",
      " 0.00000000e+00 8.40000000e-01 0.00000000e+00 6.40000000e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 0 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  6\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[1.00000000e+00 1.55397063e-01 2.31910913e-01 2.31910913e-01\n",
      " 9.99999907e-01 1.55397063e-01 9.94778167e-01 2.31910913e-01\n",
      " 9.73780695e-01 9.94801811e-01 1.00000000e+00 2.73564033e-01\n",
      " 2.31917930e-01 5.26731877e-01 2.31917930e-01 6.01606877e-01\n",
      " 1.55397063e-01 2.31896857e-01 7.23725356e-04 9.99999995e-01\n",
      " 2.31915515e-01 1.55397063e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 1  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9545454545454546\n",
      "recall:  0.9\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.96      0.95      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  6\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:54:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:54:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.74853396 0.3089472  0.3229023  0.3229023  0.74853396 0.3089472\n",
      " 0.7099574  0.3229023  0.66210365 0.74853396 0.74853396 0.44434655\n",
      " 0.2791085  0.616995   0.2791085  0.41323125 0.3089472  0.3541178\n",
      " 0.2791085  0.74853396 0.36533916 0.3089472 ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[12  0]\n",
      " [ 2  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.8\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.93      0.90      0.91        22\n",
      "weighted avg       0.92      0.91      0.91        22\n",
      "\n",
      "\n",
      "KFold:  7\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (204, 10)\n",
      "\n",
      "X_test:\n",
      " [[ 1.19970340e-01  2.56264468e-01  1.07111771e+00 -4.43942421e-01\n",
      "  -4.81037756e-01 -5.94060389e-01 -1.35068035e+00  1.83266021e-01\n",
      "   2.74242893e+00  7.75699011e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-2.88994501e-01  6.99737449e+00  2.60110651e+00  9.91454043e-01\n",
      "  -1.38527517e+00  1.69579998e+00 -8.36716440e+00 -1.71612054e+00\n",
      "   3.56112312e+01  5.27360372e+01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [ 9.09110153e-01  1.66905751e+00  2.64503018e+00 -1.04415777e+00\n",
      "   5.00430369e+00  7.04784538e-02 -1.32057970e+00 -1.36453321e+00\n",
      "   5.38759272e+00 -5.24791534e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-8.21650321e-01 -7.07689129e-02  1.10049812e+00 -1.36735534e+00\n",
      "   1.96115371e+00  2.74057772e-01 -4.18990342e-01  3.42770929e-02\n",
      "   6.47880204e+00  1.03481679e-01]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-1.48366002e-01 -1.85182935e-01  1.10204657e+00 -1.17146827e+00\n",
      "  -5.00859697e-01  2.03599447e-01 -2.28242037e+00 -3.61858165e-01\n",
      "   1.32339432e+00 -1.53632272e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-7.51611028e-01 -3.45188362e-01  6.63837400e-01 -1.53840075e+00\n",
      "  -3.99544204e-01 -6.01754929e-02 -3.48273927e-01 -1.56155760e-01\n",
      "   6.86398174e-01 -5.17484175e-01]\n",
      " [ 1.56127450e+00 -4.75760460e-01 -9.66092430e-01 -3.91670927e-01\n",
      "  -3.60247666e-01 -3.42984260e-01 -2.40562638e-01 -3.50696876e-01\n",
      "   1.14879065e+00 -1.43116625e+00]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-6.44259045e-01 -1.29296529e-01  1.21067425e+00 -1.38358716e+00\n",
      "   1.73248758e+00  7.00190198e-01 -1.47056417e+00 -4.39128475e-03\n",
      "   2.00519044e+00 -1.72515494e+00]\n",
      " [-7.73766434e-01 -4.66437087e+00 -1.42380919e+01  1.16873910e+01\n",
      "   1.50249450e+00 -1.30051153e+00  3.26509557e+00  2.50156731e-01\n",
      "  -4.81654306e-01  7.43862955e-01]\n",
      " [ 9.74484099e-01 -2.24348803e-01  3.17170726e-01 -4.83217735e-01\n",
      "  -2.94070108e-01  1.53021141e-01 -2.25715608e+00  6.23797651e-01\n",
      "   1.20038680e+00 -2.07037089e+00]] \n",
      "Shape:  (22, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (204,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1] \n",
      "Shape:  (22,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  7\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "7.1577019972396085\n",
      "\n",
      " Coefficients \n",
      "[ 2.97664365  4.38490244  1.00242743  2.17162181  0.64548811  0.81109203\n",
      " -0.06467287  2.4183613   0.71564549  1.01727379]\n",
      "\n",
      " pop_polarity\n",
      "[9.99986837e-01 2.41826113e-01 2.41826113e-01 2.41826113e-01\n",
      " 1.18817094e-01 2.41826113e-01 1.00000000e+00 1.18817094e-01\n",
      " 9.99999904e-01 2.41826113e-01 9.99860233e-01 2.41826113e-01\n",
      " 9.50891227e-01 9.68197971e-09 2.25422382e-02 5.08598979e-01\n",
      " 9.97329607e-01 2.25422382e-02 9.68197971e-09 9.87038941e-01\n",
      " 2.25422382e-02 9.99830922e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[13  0]\n",
      " [ 0  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  7\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[1.00000000e+00 5.70902619e-05 5.70902619e-05 5.70902619e-05\n",
      " 3.58530014e-05 5.70902619e-05 1.00000000e+00 3.58530014e-05\n",
      " 1.00000000e+00 5.70902619e-05 2.39795315e-04 5.70902619e-05\n",
      " 1.00000000e+00 2.86816537e-08 7.51158239e-04 5.20553342e-05\n",
      " 1.00000000e+00 7.51158239e-04 2.86816537e-08 7.97245961e-02\n",
      " 7.51158239e-04 1.00000000e+00]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.9\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[13  0]\n",
      " [ 3  6]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8636363636363636\n",
      "recall:  0.6666666666666666\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90        13\n",
      "           1       1.00      0.67      0.80         9\n",
      "\n",
      "    accuracy                           0.86        22\n",
      "   macro avg       0.91      0.83      0.85        22\n",
      "weighted avg       0.89      0.86      0.86        22\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  7\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[9.90000000e-01 3.70957105e-03 3.70957105e-03 3.70957105e-03\n",
      " 1.80313186e-03 3.70957105e-03 9.90000000e-01 1.80313186e-03\n",
      " 9.90000000e-01 3.70957105e-03 9.70000000e-01 3.70957105e-03\n",
      " 1.00000000e+00 1.24937531e-04 9.19350821e-03 9.49867926e-01\n",
      " 1.00000000e+00 9.19350821e-03 1.24937531e-04 9.90401284e-01\n",
      " 9.19350821e-03 1.00000000e+00]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[13  0]\n",
      " [ 0  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  7\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[9.99999726e-01 2.29055913e-01 2.29055913e-01 2.29055913e-01\n",
      " 1.44425013e-01 2.29055913e-01 1.00000000e+00 1.44425013e-01\n",
      " 1.00000000e+00 2.29055913e-01 4.46129057e-01 2.29055913e-01\n",
      " 9.63591023e-01 1.75050370e-04 2.29020077e-01 5.13480169e-01\n",
      " 9.99999996e-01 2.29020077e-01 1.75050370e-04 8.28667467e-01\n",
      " 2.29020077e-01 9.99999998e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[13  0]\n",
      " [ 0  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  7\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:55:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:55:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.7455502  0.2952565  0.2952565  0.2952565  0.2952565  0.2952565\n",
      " 0.7455502  0.2952565  0.7455502  0.2952565  0.52278066 0.2952565\n",
      " 0.7455502  0.2829775  0.37927383 0.5622929  0.69775504 0.37927383\n",
      " 0.2829775  0.7091866  0.37927383 0.7455502 ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[13  0]\n",
      " [ 0  9]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      "KFold:  8\n",
      "\n",
      "X_train:\n",
      " [[-0.77660667 -0.42127694  0.56889774 ... -0.59638277  0.73536273\n",
      "  -0.73043712]\n",
      " [-0.5310772  -0.13568645  1.12961327 ...  0.05344732  0.93970257\n",
      "   0.58900696]\n",
      " [-0.67745999  1.27138546  0.91139097 ...  0.81381883  1.52264304\n",
      "  -0.93099683]\n",
      " ...\n",
      " [-0.78892107 -0.5442683   0.25082049 ... -0.6705824   0.55520303\n",
      "  -0.70469169]\n",
      " [-0.46104002 -0.15239195  0.31620574 ... -0.38387836  1.35294565\n",
      "  -0.65484382]\n",
      " [-0.73323235  3.76186681  0.51850918 ...  4.41578448  2.64860055\n",
      "  -4.32907109]] \n",
      "Shape:  (204, 10)\n",
      "\n",
      "X_test:\n",
      " [[ -0.78892107  -0.5442683    0.25082049  -1.20906473  -0.23454327\n",
      "   -0.06595019  -1.45120016  -0.6705824    0.55520303  -0.70469169]\n",
      " [ -0.95212621  -1.10192389   3.58521586  -5.20035402  -3.86139089\n",
      "   -0.5904215   16.8976218    2.93142223  -0.35736958   1.39876352]\n",
      " [ -0.95212621  -1.10192389   3.58521586  -5.20035402  -3.86139089\n",
      "   -0.5904215   16.8976218    2.93142223  -0.35736958   1.39876352]\n",
      " [ -0.78693063   0.95267183   1.30088503  -1.8213538    0.32101012\n",
      "   -0.24130109  -2.33307493   0.93772753   1.09045461  -0.16983863]\n",
      " [ -0.95212621  -1.10192389   3.58521586  -5.20035402  -3.86139089\n",
      "   -0.5904215   16.8976218    2.93142223  -0.35736958   1.39876352]\n",
      " [ -0.67122582  -0.68474444  -0.20671906  -0.68454093  -0.24793127\n",
      "   -0.02807765  -0.51960507  -0.35749421   0.66922299  -0.70432165]\n",
      " [ -0.62684412  -0.65162231  -0.48647568  -0.4050863    0.10381955\n",
      "    0.54677771   0.07743397  -0.47542724   0.42664087  -0.56329394]\n",
      " [ -0.79579086   0.14017125   0.24140923  -1.22577725   0.30316951\n",
      "   -0.18350084  -0.96542378   0.30712722   1.28244975  -1.20340694]\n",
      " [ -0.79574795  -0.32736546   1.01411227  -1.81204147  -0.06318644\n",
      "   -0.12950437  -1.17089527  -0.24810881   1.14284327  -1.06564077]\n",
      " [ -0.79574795  -0.32736546   1.01411227  -1.81204147  -0.06318644\n",
      "   -0.12950437  -1.17089527  -0.24810881   1.14284327  -1.06564077]\n",
      " [ -0.62612772  -0.37840008   0.71984271  -1.18858122  -0.33482425\n",
      "   -0.23559121  -0.98284235  -0.37802501   0.75986595  -0.7235805 ]\n",
      " [ -0.94042586  -0.87521532   0.70846427  -2.57522269  -1.50925286\n",
      "   -0.21439377  -3.25712027  -4.28924147 -10.26931695   4.49057796]\n",
      " [ -0.94042586  -0.87521532   0.70846427  -2.57522269  -1.50925286\n",
      "   -0.21439377  -3.25712027  -4.28924147 -10.26931695   4.49057796]\n",
      " [ -0.75821371  -0.22304454   0.64481196  -1.62133458  -0.37153137\n",
      "   -0.06535544  -0.3502998   -0.14243429   0.81210676  -0.54763035]\n",
      " [ -0.78892107  -0.5442683    0.25082049  -1.20906473  -0.23454327\n",
      "   -0.06595019  -1.45120016  -0.6705824    0.55520303  -0.70469169]\n",
      " [ -0.95212621  -1.10192389   3.58521586  -5.20035402  -3.86139089\n",
      "   -0.5904215   16.8976218    2.93142223  -0.35736958   1.39876352]\n",
      " [ -0.78892107  -0.5442683    0.25082049  -1.20906473  -0.23454327\n",
      "   -0.06595019  -1.45120016  -0.6705824    0.55520303  -0.70469169]\n",
      " [ -0.77376643  -4.66437087 -14.23809192  11.68739097   1.5024945\n",
      "   -1.30051153   3.26509557   0.25015673  -0.48165431   0.74386295]\n",
      " [ -0.19925579  -0.10998456   1.03429834  -1.25073099  -0.38661398\n",
      "    0.28603945  -0.99873334   0.16311602   2.42087844   0.77124906]\n",
      " [ -0.94042586  -0.87521532   0.70846427  -2.57522269  -1.50925286\n",
      "   -0.21439377  -3.25712027  -4.28924147 -10.26931695   4.49057796]\n",
      " [ -0.94042586  -0.87521532   0.70846427  -2.57522269  -1.50925286\n",
      "   -0.21439377  -3.25712027  -4.28924147 -10.26931695   4.49057796]\n",
      " [ -0.94042586  -0.87521532   0.70846427  -2.57522269  -1.50925286\n",
      "   -0.21439377  -3.25712027  -4.28924147 -10.26931695   4.49057796]] \n",
      "Shape:  (22, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0\n",
      " 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (204,)\n",
      "\n",
      "y_test:\n",
      " [0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0] \n",
      "Shape:  (22,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  8\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "5.621887070692063\n",
      "\n",
      " Coefficients \n",
      "[ 2.54894975  3.60992933  0.98501673  1.8546591   0.70337091  0.02757543\n",
      " -0.16092452  2.58006544  0.91707792  0.92696135]\n",
      "\n",
      " pop_polarity\n",
      "[1.03715758e-01 2.15482670e-02 2.15482670e-02 9.99851548e-01\n",
      " 2.15482670e-02 2.52150216e-01 3.01411975e-01 9.63750312e-01\n",
      " 4.03847391e-01 4.03847391e-01 5.32833360e-01 8.56635163e-10\n",
      " 8.56635163e-10 5.43658414e-01 1.03715758e-01 2.15482670e-02\n",
      " 1.03715758e-01 1.55452408e-02 9.98731507e-01 8.56635163e-10\n",
      " 8.56635163e-10 8.56635163e-10]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.96\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[15  0]\n",
      " [ 2  5]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.7142857142857143\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.94      0.86      0.89        22\n",
      "weighted avg       0.92      0.91      0.90        22\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  8\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[8.27774351e-06 6.33448542e-15 6.33448542e-15 3.37082638e-05\n",
      " 6.33448542e-15 6.00386880e-05 9.47102749e-04 1.80290352e-05\n",
      " 1.18544436e-05 1.18544436e-05 2.83336758e-04 3.39505581e-05\n",
      " 3.39505581e-05 1.18812494e-05 8.27774351e-06 6.33448542e-15\n",
      " 8.27774351e-06 5.22822436e-05 1.00000000e+00 3.39505581e-05\n",
      " 3.39505581e-05 3.39505581e-05]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.83\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[15  0]\n",
      " [ 6  1]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7272727272727273\n",
      "recall:  0.14285714285714285\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        15\n",
      "           1       1.00      0.14      0.25         7\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.86      0.57      0.54        22\n",
      "weighted avg       0.81      0.73      0.65        22\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  8\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[6.05492438e-04 1.11986070e-02 1.11986070e-02 8.15543116e-01\n",
      " 1.11986070e-02 9.60421687e-01 9.60952872e-01 8.83371771e-01\n",
      " 8.02610584e-03 8.02610584e-03 9.72100554e-01 9.74578225e-04\n",
      " 9.74578225e-04 1.00000000e+00 6.05492438e-04 1.11986070e-02\n",
      " 6.05492438e-04 4.18463608e-03 1.00000000e+00 9.74578225e-04\n",
      " 9.74578225e-04 9.74578225e-04]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[15  0]\n",
      " [ 0  7]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  8\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[1.06767085e-01 2.11153480e-01 2.11153480e-01 9.99999933e-01\n",
      " 2.11153480e-01 3.90505025e-01 7.96382539e-01 9.67712264e-01\n",
      " 2.11196242e-01 2.11196242e-01 5.00000000e-01 2.40702552e-06\n",
      " 2.40702552e-06 6.46231009e-01 1.06767085e-01 2.11153480e-01\n",
      " 1.06767085e-01 2.11155715e-01 9.99994333e-01 2.40702552e-06\n",
      " 2.40702552e-06 2.40702552e-06]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[15  0]\n",
      " [ 0  7]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  8\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:55:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:55:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.28607243 0.32991344 0.32991344 0.4706694  0.32991344 0.6333133\n",
      " 0.64420795 0.49769294 0.36981267 0.36981267 0.6507953  0.28607243\n",
      " 0.28607243 0.6851717  0.28607243 0.32991344 0.28607243 0.37098208\n",
      " 0.7121953  0.28607243 0.28607243 0.28607243]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[15  0]\n",
      " [ 2  5]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.7142857142857143\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.94      0.86      0.89        22\n",
      "weighted avg       0.92      0.91      0.90        22\n",
      "\n",
      "\n",
      "KFold:  9\n",
      "\n",
      "X_train:\n",
      " [[ -0.77660667  -0.42127694   0.56889774 ...  -0.59638277   0.73536273\n",
      "   -0.73043712]\n",
      " [ -0.5310772   -0.13568645   1.12961327 ...   0.05344732   0.93970257\n",
      "    0.58900696]\n",
      " [ -0.67745999   1.27138546   0.91139097 ...   0.81381883   1.52264304\n",
      "   -0.93099683]\n",
      " ...\n",
      " [ -0.94042586  -0.87521532   0.70846427 ...  -4.28924147 -10.26931695\n",
      "    4.49057796]\n",
      " [ -0.94042586  -0.87521532   0.70846427 ...  -4.28924147 -10.26931695\n",
      "    4.49057796]\n",
      " [ -0.94042586  -0.87521532   0.70846427 ...  -4.28924147 -10.26931695\n",
      "    4.49057796]] \n",
      "Shape:  (204, 10)\n",
      "\n",
      "X_test:\n",
      " [[-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-6.50195054e-01 -4.70711031e-01  7.24155426e-02 -7.42148927e-01\n",
      "   7.25062908e-01  5.87101435e-02 -1.19081122e+00  2.26041193e-01\n",
      "   9.21089142e-01 -1.35821452e+00]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-8.57846145e-01  3.77941141e-02  4.44476296e-01 -1.12429381e+00\n",
      "  -1.28588871e-01 -2.85861520e-01 -1.95462971e+00 -7.35557215e-01\n",
      "   1.78691145e+00 -6.67384463e-01]\n",
      " [-1.47056805e-01 -7.13100123e-01 -1.30669483e+00  5.59364433e-01\n",
      "   4.17763376e-01  3.65105543e-01 -8.46961738e-01  5.44810463e-01\n",
      "   1.13374211e+00 -5.44235971e-01]\n",
      " [-7.22731630e-01  4.44018807e-01  1.15513480e+00 -8.31855800e-01\n",
      "   9.17967269e-01 -3.02881958e-01 -1.67181410e+00 -6.73154735e-02\n",
      "   8.68423502e-01 -7.52134498e-01]\n",
      " [-7.18633087e-01  1.29324573e-01  7.00612501e-01 -7.70239505e-01\n",
      "   5.63446837e-01  9.61785190e-01 -1.21300056e+00  4.09977431e-01\n",
      "   1.64136464e-01 -5.11531261e-01]\n",
      " [-9.52126209e-01 -1.10192389e+00  3.58521586e+00 -5.20035402e+00\n",
      "  -3.86139089e+00 -5.90421501e-01  1.68976218e+01  2.93142223e+00\n",
      "  -3.57369578e-01  1.39876352e+00]\n",
      " [-7.62073701e-01 -3.49818260e-01  5.80796013e-01 -1.46487970e+00\n",
      "  -2.75422962e-01 -5.88838082e-02 -9.93660607e-01 -2.74147278e-01\n",
      "   6.39757251e-01 -6.08349245e-01]\n",
      " [-6.22339909e-01 -4.62224430e-01  6.46125026e-01 -1.49474940e+00\n",
      "  -4.87165064e-01 -1.52339033e-01  8.93061073e-02 -2.12135348e-01\n",
      "   4.56171803e-01 -4.71168508e-01]\n",
      " [-2.64051871e-01  5.31950878e-01  5.60294222e-01 -8.42369990e-01\n",
      "   3.67712280e-01 -5.62406704e-01 -2.97961173e+00  3.38760487e+00\n",
      "   2.52596366e+00 -1.12835216e+00]\n",
      " [ 6.45183799e-01  1.61650557e+00  2.47436045e+00  1.46295821e+00\n",
      "   1.42209474e+00 -1.11347830e+00 -1.23949647e-01 -5.09984341e-01\n",
      "   4.17071235e+00  2.04790656e+00]\n",
      " [-9.40425865e-01 -8.75215324e-01  7.08464272e-01 -2.57522269e+00\n",
      "  -1.50925286e+00 -2.14393775e-01 -3.25712027e+00 -4.28924147e+00\n",
      "  -1.02693169e+01  4.49057796e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.58080711e-01 -4.34637531e-01  2.85998868e-01 -1.11558619e+00\n",
      "   8.24234335e-02 -2.40988744e-01 -1.15944295e+00 -2.07114437e-01\n",
      "   7.11631579e-01 -6.86879451e-01]\n",
      " [-7.95747947e-01 -3.27365464e-01  1.01411227e+00 -1.81204147e+00\n",
      "  -6.31864432e-02 -1.29504370e-01 -1.17089527e+00 -2.48108807e-01\n",
      "   1.14284327e+00 -1.06564077e+00]\n",
      " [-7.76606673e-01 -4.21276942e-01  5.68897740e-01 -1.40296555e+00\n",
      "  -2.48458256e-01  5.91569175e-02 -1.64574943e+00 -5.96382773e-01\n",
      "   7.35362730e-01 -7.30437123e-01]\n",
      " [-7.88921070e-01 -5.44268297e-01  2.50820485e-01 -1.20906473e+00\n",
      "  -2.34543269e-01 -6.59501940e-02 -1.45120016e+00 -6.70582400e-01\n",
      "   5.55203033e-01 -7.04691692e-01]\n",
      " [-4.61040023e-01 -1.52391946e-01  3.16205738e-01 -1.08760495e+00\n",
      "  -1.37991260e-01 -1.05058862e-01 -1.60678969e+00 -3.83878358e-01\n",
      "   1.35294565e+00 -6.54843822e-01]\n",
      " [-7.33232345e-01  3.76186681e+00  5.18509179e-01 -2.81158333e+00\n",
      "  -5.16293895e-01 -1.00528335e-02 -4.47009201e+00  4.41578448e+00\n",
      "   2.64860055e+00 -4.32907109e+00]] \n",
      "Shape:  (22, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0] \n",
      "Shape:  (204,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1] \n",
      "Shape:  (22,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  9\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n",
      "\n",
      " Intercept \n",
      "7.149200110223139\n",
      "\n",
      " Coefficients \n",
      "[ 2.97599163  4.40537739  1.05343737  2.21942783  0.71259204  0.89271012\n",
      " -0.05147041  2.51491217  0.77733824  1.03576104]\n",
      "\n",
      " pop_polarity\n",
      "[2.80401980e-09 8.88723416e-01 1.04179976e-01 2.80401980e-09\n",
      " 1.04179976e-01 7.92061744e-01 9.96951364e-01 9.98530818e-01\n",
      " 9.98586395e-01 1.96686977e-02 4.20893124e-01 3.70365623e-01\n",
      " 9.99999942e-01 1.00000000e+00 2.80401980e-09 2.21550003e-01\n",
      " 5.06968003e-01 3.64887308e-01 2.21550003e-01 1.04179976e-01\n",
      " 9.10816461e-01 1.00000000e+00]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[10  0]\n",
      " [ 2 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9090909090909091\n",
      "recall:  0.8333333333333334\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.92      0.92      0.91        22\n",
      "weighted avg       0.92      0.91      0.91        22\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  9\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[2.11139655e-05 3.73023152e-04 8.95433867e-06 2.11139655e-05\n",
      " 8.95433867e-06 1.12310278e-05 1.00000000e+00 6.27284636e-05\n",
      " 1.76334908e-03 3.71550677e-15 1.27365672e-05 2.33189365e-04\n",
      " 9.99999992e-01 1.00000000e+00 2.11139655e-05 1.38887007e-05\n",
      " 1.23331383e-05 1.27141124e-05 1.38887007e-05 8.95433867e-06\n",
      " 5.75205461e-01 4.94199953e-01]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[10  0]\n",
      " [ 8  4]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6363636363636364\n",
      "recall:  0.3333333333333333\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71        10\n",
      "           1       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.78      0.67      0.61        22\n",
      "weighted avg       0.80      0.64      0.60        22\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  9\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.         0.98       0.00140637 0.         0.00140637 0.81\n",
      " 0.99       1.         1.         0.00177386 0.96       0.95092543\n",
      " 1.         0.98       0.         0.         0.91131556 0.00113063\n",
      " 0.         0.00140637 1.         0.99      ]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[10  0]\n",
      " [ 0 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  9\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n",
      "100%|██████████| 316/316 [00:00<00:00, 24374.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[5.82997769e-06 8.23936152e-01 1.10383888e-01 5.82997769e-06\n",
      " 1.10383888e-01 4.64190872e-01 9.99993394e-01 9.87120776e-01\n",
      " 9.99996637e-01 2.06871729e-01 4.12138994e-01 4.53522177e-01\n",
      " 1.00000000e+00 1.00000000e+00 5.82997769e-06 2.06910214e-01\n",
      " 3.73395775e-01 2.06921248e-01 2.06910214e-01 1.10383888e-01\n",
      " 8.86394296e-01 1.00000000e+00]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[10  0]\n",
      " [ 0 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "nKFold round:  9\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:55:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:55:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.28648376 0.671176   0.3124097  0.28648376 0.3124097  0.5579919\n",
      " 0.671176   0.71917146 0.66825414 0.28648376 0.51993644 0.50083226\n",
      " 0.74572366 0.74572366 0.28648376 0.28648376 0.6080283  0.3687357\n",
      " 0.28648376 0.3124097  0.74572366 0.6839869 ]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[10  0]\n",
      " [ 0 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  1.0\n",
      "recall:  1.0\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n",
      "\n",
      " compare_final_result() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      "=====  Logistic baseline  =====\n",
      "accuracy =  0.9090909090909091\n",
      "recall =  0.8333333333333334\n",
      "specificity =  1.0\n",
      "precision =  1.0\n",
      "auc =  1.0\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      "=====  GaussianNB  =====\n",
      "accuracy =  0.6363636363636364\n",
      "recall =  0.3333333333333333\n",
      "specificity =  1.0\n",
      "precision =  1.0\n",
      "auc =  0.86\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      "=====  Random forest  =====\n",
      "accuracy =  1.0\n",
      "recall =  1.0\n",
      "specificity =  1.0\n",
      "precision =  1.0\n",
      "auc =  1.0\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      "=====  SVM  =====\n",
      "accuracy =  1.0\n",
      "recall =  1.0\n",
      "specificity =  1.0\n",
      "precision =  1.0\n",
      "auc =  1.0\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: siri\n",
      "\n",
      "=====  XGBoost  =====\n",
      "accuracy =  1.0\n",
      "recall =  1.0\n",
      "specificity =  1.0\n",
      "precision =  1.0\n",
      "auc =  1.0\n",
      "\n",
      "\n",
      "====================================================\n",
      "\n",
      "Hospital name: king-chulalongkorn-memorial-hospital\n",
      "\n",
      "====================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      ">>>>> Step: Read data for NLP process <<<<<\n",
      "\n",
      " load_dataset() is activated...\n",
      "\n",
      "\n",
      ">> Positive and negative dataset:\n",
      "     score                                                 en  polarity\n",
      "0        5  The matter is that there is no fever but being...         1\n",
      "1        4  The service is quite good. The doctor was very...         1\n",
      "2        4  Went to get a blood test in urine Have to rese...         1\n",
      "3        5  Good service But waiting in a long queue But a...         1\n",
      "4        5  Have food poisoning and go to treatment at thi...         1\n",
      "..     ...                                                ...       ...\n",
      "349      5  Large hospital, lots of people but doctors and...         1\n",
      "350      5  The evening of 26 October 2016, the event that...         1\n",
      "351      5  What to do for this review, but we went to Chu...         1\n",
      "352      5  The hospital service is very patient, the pati...         1\n",
      "354      4  On April 7, 2016, I felt that I didn't have th...         1\n",
      "\n",
      "[316 rows x 3 columns]\n",
      "\n",
      ">> Positive dataset:\n",
      "     score                                                 en  polarity\n",
      "0        5  The matter is that there is no fever but being...         1\n",
      "1        4  The service is quite good. The doctor was very...         1\n",
      "2        4  Went to get a blood test in urine Have to rese...         1\n",
      "3        5  Good service But waiting in a long queue But a...         1\n",
      "4        5  Have food poisoning and go to treatment at thi...         1\n",
      "..     ...                                                ...       ...\n",
      "349      5  Large hospital, lots of people but doctors and...         1\n",
      "350      5  The evening of 26 October 2016, the event that...         1\n",
      "351      5  What to do for this review, but we went to Chu...         1\n",
      "352      5  The hospital service is very patient, the pati...         1\n",
      "354      4  On April 7, 2016, I felt that I didn't have th...         1\n",
      "\n",
      "[241 rows x 3 columns]\n",
      "\n",
      ">> Negative dataset:\n",
      "     score                                                 en  polarity\n",
      "34       1  Medical students are very good. Ask about the ...         0\n",
      "36       2  It takes a long time at every point to contact...         0\n",
      "37       1  In December, the birth of the first child at C...         0\n",
      "49       2  I am the osteoporosis patient. And hip deterio...         0\n",
      "52       1  The first person arrives, shocked! Cue leaves ...         0\n",
      "..     ...                                                ...       ...\n",
      "320      1  Was sent from another hospital, had a delivery...         0\n",
      "322      2  Financial Room Service, 9th Floor, Very Sassy ...         0\n",
      "329      2  The doctor and nurses were always in good serv...         0\n",
      "332      1  24/05/58 Go to the doctor because of illness. ...         0\n",
      "334      1  Waiting for a long time does not work at all. ...         0\n",
      "\n",
      "[75 rows x 3 columns]\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAb/ElEQVR4nO3de7xd853/8dc7iVDiMprQJELcb0Wrmh+jRfFrXTr4+dFShmLaGlS1NUovM9qZonphelF1jbvqqI5OqbYZZSiRxDVKhEgkpO4i6hr5zB/f72Fl5+x91jnO2vucrPfz8TiPve7r8/2etT977e9a+7sUEZiZWX0M6XQAZmbWXk78ZmY148RvZlYzTvxmZjXjxG9mVjNO/GZmNePEXzFJsyXt2s30+yXt1OZYPi3plj6uO15SSBpWYtmdJM3ry356GVOfy1M3kl6StF6J5Vr+nztR55K+Kum8d7B+t+/BOuvxTWzViIjNOx2D1UdEjOh0DH0VEad0DUsaDzwKLBcRizoV02DnM36rvTLfYgarZbls1ndO/G0kaRNJj0o6oPj1U9LJkq6SdLGkhbkZaJvCeltLuivP+4Wkn0v6txb7GSfpl5KelvSspB83zP+epOdzLLsXpi/xlTjHdWmTfRwm6YEc0yxJn2sRz6aS/ijphVy2vQrzJkr6iaTf5G1NlrR+Yf5HJc2QtEDSWZJukvQPTfbzXUm3SFpV0hBJX5c0R9JTuW5Xzct1NWccIekx4L8L0w6V9JikZyR9rUWZupY/TNLcXJ9HSvqgpHtzWRvr/fBcZ89LukHSOoV5IekoSTNzPfyrpPUl3SbpxXx8DC8s/xlJD0t6TtK1ksY0bOtoSTOBmYVpG+ThPfPx9GKO/eRm5WxR/mbH0Jgcz3M5vs8U5k2QNDXv90lJP2ioy89KekLSfElfLqxXPA5vzq8vKDVfbZfr6b/zsf6MpMskrdbbMtVKRPivwj9gNrArsDXwGPDx4vQ8fDLwKrAHMBQ4Fbg9zxsOzAG+ACwH7Au8Dvxbk/0NBe4BzgBWAlYAPpTnfRp4A/hMXu4fgScANcZUiOvSPDweCGBYHt8TWB8QsCPwMrB1nrcTMC8PLwc8DHw1l2VnYCGwcZ4/EXgOmEBqerwMuDLPGwm8mMs8LNfBG8A/FMpzC+kE5lzgBmDFPO/wvN/1gBHAL4FLGspyca6jdxWmnZvHtwJeAzZtUs9dy5+d6/ij+X/4K2ANYCzwFLBjXn6fHM+muSxfB/5U2F4A1wKrAJvnfU/K8a8K/Bk4NC+7M/AM6ZhaHvgRcHPDtn4PrA68qzBtg8L/Z4tcb1sCTwL7dPd/7qbcn6b1MXQTcFauk/cBTwO75Hm3AX+fh0cA2zbs84r8/9gir1d8f3R7HOZpGwD/N9fFKNKHw5mN78FO54KB9NfxAJb1v3zQfROYB3ykYXrxwP5DYd5mwCt5eAfg8a43Vp52C80T/3b5TbPUGze/aR8ujK+Y30TvaYypEFfTN1zDtn8FfCEP78Tbif/DwF+AIYVlrwBOzsMTgfMK8/YAHszDhwC3FeYJmMuSiX8y8HPgamB4YdlJwFGF8Y1JCWtYoSzrFeZ3TVurMO0O4IAm5e1afmxh2rPAJwvjVwPH5eHrgSMK84aQPizXyeMBbF+YPw34SmH8++RkBpwPnF6YNyKXbXxhWzs3xPtW4u+mLGcCZ5T8Pzc9hoBxwJvAyoX5pwIT8/DNpPfCyCZ1uUlh2unA+b09DvMy+wB3dfde81/6c1NPexxJOru7scUyfykMvwysoNQ+OwZ4PPIRnM3tGpB0ff7K+5Kkg0hvvjnR/MLXW/uJiJfzYK8v/EnaXdLt+Sv9C6SEPbKbRccAcyNicWHaHNIZ8VIxkcreFc8YCmXNddB4t9AGwN7ANyPi9Yb9zmnY5zBgzcK0uSyt21gKdfySpLULyzxZGH6lm/GusqwD/HtuAnqB9C1HLFkPZbe1RNki4iXSh05xW92VjVyW/yPpRqWmwAWk43Op/52kDxfKfH9hVrNjaAzwXEQsLCxb/F8fAWwEPChpiqSPN+xybsN6YyhB0hqSrpT0uKQXgUu7K4+9zYm/PY4E1pZ0Rh/WnQ+MlaTCtHFdAxGxe0SMyH+Xkd48a6tvF/X+SjqD6/Ke7haStDzpbPZ7wJoRsRpwHSmRNXoCGCepeKytTfoW05P5wFqF/ao4nj0AHAZcL2njhv2uUxhfG1jEksm0dNe0hToeERGPlV2vYC7wuYhYrfD3roj4Ux+2tUTZJK0EvJsl67RV2S4nNSuNi4hVSc1VS/3vIuJ/CmUucxfaE8DqklYuTHvrfx0RMyPiQFJT2HeA/8ixdxnXsN4T3eyju3KdmqdvGRGrAAd3Vx57mxN/eywEdgN2kHRaL9e9jfT1+RhJwyTtTWoPb+YOUsI8TdJKklaQtH3Jfd0NHCBpOaWLy/s1WW44qT31aWBRvrj30SbLTiZ9oJyQt7sT8HfAlSXi+Q2whaR98gfZ0XTzYRQRV5CuIfxBb18YvgL4oqR1JY0ATgF+3uKbUNXOBk6StDmA0gXo/fu4rcuBwyS9L38InwJMjojZJddfmXRm/qqkCcCn+hjHEiJiLvAn4NR83G1JOsu/DEDSwZJG5W9/L+TV3ixs4huSVsx1dBipCa/R08Bi0rWPYnleIl3wHQv8U3+UZ1nmxN8mEfEC6QLU7pL+tRfrvU66uHkE6c1yMPBfpIt/3S3/JimxbkC6mDwP+GTJ3X2DdMH2eVJb7OVN9rEQOBa4Ki/7KdIZZLP49wJ2J12QPAs4JCIe7CmYiHgG2J/U3vss6drHVLope0RcBHyLfIcOcAFwCald+VHShdfP97TPqkTENaSz3Ctzc8R0Up30ZVuTSP+rq0kf8usDB/RiE0cB35K0EPhn0v+xvxxIaod/ArgG+JeI+H2etxtwv6SXgH8nXT95tbDuTaQL4JOA70XE7xo3npuWvg3cmpvNtiUdq1sDC0gnC7/sx/Isk7quxNsgImkycHZEXNjpWNopNxfNAw7q4XqJDSLyj7Lazmf8g4CkHSW9Jzf1HEq6Be+3nY6rHSR9TNJquUnjq6S229s7HJbZoOZf9Q0OG5O+jo8AHgH2i4j5nQ2pbbYjNTkNJ93Lvk9EvNLZkMwGNzf1mJnVjJt6zMxqZkA19YwcOTLGjx/f6TDMzAaNadOmPRMRo3qzzoBK/OPHj2fq1KmdDsPMbNCQNKfnpZbkph4zs5px4jczqxknfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5px4jczqxknfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5px4jczqxknfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5px4jczqxknfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5px4jczq5lhnQ6g6L7HFzD+xN90Ogwzs7aZfdqebd+nz/jNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqpsfEL2lNSedLuj6PbybpiBLrXSDpKUnT+yNQMzPrH2XO+CcCNwBj8vhDwHEl19utT1GZmVllyiT+kRFxFbAYICIWAW/2tFJE3Aw8987CMzOz/lYm8f9V0ruBAJC0LbCgvwKQ9FlJUyVNffPlftusmZk1MazEMl8GrgXWl3QrMArYr78CiIhzgHMAlh+9YfTXds3MrHs9Jv6ImCZpR2BjQMCMiHij8sjMzKwSZe7quQc4AXg1IqY76ZuZDW5l2vj3AhYBV0maIul4SWv3tJKkK4DbgI0lzStzC6iZmVWvx8QfEXMi4vSI+ADwKWBL4NES6x0YEaMjYrmIWCsizu+HeM3M7B0qc3EXSeOBTwCfJN3KeUJ1IZmZWZV6TPySJgPLAb8A9o+IWZVHZWZmlSlzxn9oRDxYeSRmZtYWTRO/pIMj4lJgD0l7NM6PiB9UGpmZmVWi1Rn/Svl15W7m+YdWZmaDVNPEHxE/y4N/iIhbi/MkbV9pVGZmVpky9/H/qOQ0MzMbBFq18W8H/C0wStKXCrNWAYZWHZiZmVWjVRv/cGBEXqbYzv8i/dhJm5mZtVerNv6bgJskTYyIOW2MyczMKtSqqefMiDgO+LGkpe7iiYi9Ko3MzMwq0aqp55L8+r12BGJmZu3RqqlnWn69qWuapL8BxkXEvW2IzczMKlCmP/4/SlpF0urAPcCFkvyrXTOzQarMffyrRsSLwL7Ahbl75l2rDcvMzKpSJvEPkzSa1C3zf1Ucj5mZVaxM4v8WcAPwSERMkbQeMLPasMzMrCplHrb+C1Jf/F3js4D/X2VQZmZWnTIXd9eSdI2kpyQ9KelqSWu1IzgzM+t/ZZp6LgSuBcYAY4Ff52lmZjYIlUn8oyLiwohYlP8mAqMqjsvMzCpS5tGLz0g6GLgijx8IPFtFMFuMXZWpp+1ZxabNzCwrc8Z/OOlWzr8A80k9cx5eZVBmZladMmf8L7tDNjOzZUfTM35JfyfpaeA+SfMk/W0b4zIzs4q0aur5NvDhiBhNum//1PaEZGZmVWqV+BdFxIMAETGZJZ/CZWZmg1SrNv41Gp61u8R4RLiHTjOzQahV4j+XJc/yG8fNzGwQavUglm+2MxAzM2uPMvfxk3/A9darmZkNXqUSP/ClhlczMxukyib+LqokCjMza5veJn4zMxvknPjNzGrGid/MrGbKJv6H8uuMqgIxM7P2KJX4I+KA4quZmQ1efWrqkbRJfwdiZmbt0dc2/t/1axRmZtY2TbtskPTDZrOA1aoJx8zMqtaqk7bDgC8Dr3Uz78BqwjEzs6q1SvxTgOkR8afGGZJOriwiMzOrVKvEvx/wanczImLdasIxM7OqteqW+bl2BmJmZu3hX+6amdWME7+ZWc048ZuZ1Uyri7vdknQKsAA4LyKe7f+QzMysSn05478DWASc0c+xmJlZG/T6jD8iflVFIGZm1h49nvFL2kjSJEnT8/iWkr5efWhmZlaFMk095wInAW8ARMS9gLtnNjMbpMok/hUj4o6GaYuqCMbMzKpXJvE/I2l9IAAk7QfMrzQqMzOrTJmLu0cD5wCbSHoceBQ4qNKozMysMmUS/5yI2FXSSsCQiFhYdVBmZladMk09j0o6B9gWeKnieMzMrGJlEv/GwB9ITT6PSvqxpA9VG5aZmVWlx8QfEa9ExFURsS/wfmAV4KbKIzMzs0qU6rJB0o6SzgLuBFYAPlFpVGZmVpkeL+5KehS4G7gK+KeI+GvlUZmZWWXK3NWzVUS8WHkkZmbWFk0Tv6QTIuJ04NuSonF+RBxbaWRmZlaJVmf8D+TXqe0IxMzM2qPVw9Z/nQdfjohfFOdJ2r/SqMzMrDJl7uo5qeQ0MzMbBFq18e8O7AGMlfTDwqxVcO+cZmaDVqs2/idI7ft7AdMK0xcCX6wyKDMzq06rNv57gHskXR4Rb7QxJjMzq1CZ+/jHSzoV2Iz0q10AImK9yqIyM7PKlLm4eyHwU1K7/keAi4FLqgzKzMyqUybxvysiJgGKiDkRcTKwc7VhmZlZVco09bwqaQgwU9IxwOPAGtWGZWZmVSlzxn8csCJwLPAB4O+BQ6sMyszMqqOIpbrh6ZjlR28Yow89s9NhGDD7tD07HYKZlSBpWkRs05t1ynTL/Gug8dNhAeke/59FxKu92aGZmXVWmaaeWaRn7Z6b/14EngQ2yuNmZjaIlLm4+/6I2KEw/mtJN0fEDpLuryowMzOrRpkz/lGS1u4aycMj8+jrlURlZmaVKXPG/2XgFkmPAALWBY6StBJwUZXBmZlZ/+sx8UfEdZI2BDYhJf4HCxd0fQuOmdkgU+aMH2BDYGNSXz1bSiIiLq4uLDMzq0qZ2zn/BdiJ1EnbdcDuwC2kPnvMzGyQKXNxdz9gF+AvEXEYsBWwfKVRmZlZZcok/lciYjGwSNIqwFOAu2Q2MxukyrTxT5W0GunHWtNIP+a6o9KozMysMmXu6jkqD54t6bfAKhFxb7VhmZlZVVo9bH3tbiYvBl6QtHZEPFZdWGZmVpVWZ/y/IXXOpsK0AEaR+uMfWmFcZmZWkVYPW9+iOC5pPPAVYFfglEqjMjOzyvR4V4+kDSVNBK4nXdzdLCJ+VHVgZmZWjVZt/O8FvgZsDpwOHBERb7YrMDMzq0arNv57gLmktv4JwATp7eb+iDi22tDMzKwKrRL/4W2LwszM2qbVxV13uWxmtgwq02UDkk4ovpqZ2eBVKvEDBzS8mpnZIFU28XdRz4uYmdlA1tvE3yuSdpM0Q9LDkk6scl9mZlZOZYlf0lDgJ6QHt2wGHChps6r2Z2Zm5VR5xj8BeDgiZkXE68CVwN4V7s/MzEoom/j/mF9v7MW2x5J+ANZlXp62BEmflTRV0tQ3X17Qi82bmVlflEr8EfGl4mtJ3V0Ijm62fU5EbBMR2wxdcdVebN7MzPqi5YNYJG1Cap4ZS0raTwDXRsQDJbY9DxhXGF8rr29mZh3U9Ixf0ldI7fIiPWpxSh6+ouQdOlOADSWtK2k46TcA177zkM3M7J1odcZ/BLB5RLxRnCjpB8D9wGmtNhwRiyQdA9xAemjLBRFx/zuM18zM3qFWiX8xMAaY0zB9dJ7Xo4i4Driub6GZmVkVWiX+44BJkmby9t05awMbAMdUHZiZmVWjVe+cv5W0Eel+/LGk9v15wBQ/kMXMbPBqeVdPRCwGbm9TLGZm1gaV9tVjZmYDjxO/mVnNOPGbmdWME7+ZWc048ZuZ1YwTv5lZzTjxm5nVjBO/mVnNOPGbmdWME7+ZWc048ZuZ1YwTv5lZzTjxm5nVjBO/mVnNOPGbmdWME7+ZWc048ZuZ1YwTv5lZzTjxm5nVTMtn7rbbFmNXZeppe3Y6DDOzZZrP+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZpz4zcxqxonfzKxmnPjNzGrGid/MrGac+M3MasaJ38ysZhQRnY7hLZIWAjM6HccAMBJ4ptNBDACuh8T1kLgeksZ6WCciRvVmA8P6N553bEZEbNPpIDpN0lTXg+uhi+shcT0k/VEPbuoxM6sZJ34zs5oZaIn/nE4HMEC4HhLXQ+J6SFwPyTuuhwF1cdfMzKo30M74zcysYk78ZmY1MyASv6TdJM2Q9LCkEzsdTztJmi3pPkl3S5qap60u6feSZubXv+l0nFWQdIGkpyRNL0zrtuxKfpiPkXslbd25yPtXk3o4WdLj+bi4W9IehXkn5XqYIeljnYm6f0kaJ+lGSQ9Iul/SF/L0Oh4Pzeqi/46JiOjoHzAUeARYDxgO3ANs1um42lj+2cDIhmmnAyfm4ROB73Q6zorKvgOwNTC9p7IDewDXAwK2BSZ3Ov6K6+Fk4Phult0sv0eWB9bN752hnS5DP9TBaGDrPLwy8FAuax2Ph2Z10W/HxEA4458APBwRsyLideBKYO8Ox9RpewMX5eGLgH06GEtlIuJm4LmGyc3KvjdwcSS3A6tJGt2eSKvVpB6a2Ru4MiJei4hHgYdJ76FBLSLmR8SdeXgh8AAwlnoeD83qopleHxMDIfGPBeYWxufRupDLmgB+J2mapM/maWtGxHxIBwGwRseia79mZa/jcXJMbsa4oNDct8zXg6TxwPuBydT8eGioC+inY2IgJH51M61O95huHxFbA7sDR0vaodMBDVB1O05+CqwPvA+YD3w/T1+m60HSCOBq4LiIeLHVot1MW2bqAbqti347JgZC4p8HjCuMrwU80aFY2i4insivTwHXkL6iPdn1tTW/PtW5CNuuWdlrdZxExJMR8WZELAbO5e2v7stsPUhajpToLouIX+bJtTweuquL/jwmBkLinwJsKGldScOBA4BrOxxTW0haSdLKXcPAR4HppPIfmhc7FPjPzkTYEc3Kfi1wSL6bY1tgQVcTwLKoob36/5GOC0j1cICk5SWtC2wI3NHu+PqbJAHnAw9ExA8Ks2p3PDSri349Jjp9BTvevkL/EOlq9Nc6HU8by70e6Wr8PcD9XWUH3g1MAmbm19U7HWtF5b+C9JX1DdJZyxHNyk76OvuTfIzcB2zT6fgrrodLcjnvzW/s0YXlv5brYQawe6fj76c6+BCpeeJe4O78t0dNj4dmddFvx4S7bDAzq5mB0NRjZmZt5MRvZlYzTvxmZjXjxG9mVjNO/GZmNePEb20hKSR9vzB+vKST+2nbEyXt1x/b6mE/++ceE29smD4k9xQ5Xamn1Sn5fuoqY5ktaWSV+7BllxO/tctrwL4DLVlJGtqLxY8AjoqIjzRM/yQwBtgyIrYg/bjmhX4K0azfOfFbuywiPSv0i40zGs/YJb2UX3eSdJOkqyQ9JOk0SQdJuiOfWa9f2Myukv4nL/fxvP5QSd/NZ+D3SvpcYbs3Srqc9IOYxngOzNufLuk7edo/k35Yc7ak7zasMhqYH+mn9ETEvIh4Pq/3U0lTc7/q3yzsY7akUyTdludvLekGSY9IOrIQ582SrpH0Z0lnS1rqPSvp4Fwnd0v6WS730FyvXd9Clqp3q69hnQ7AauUnwL2STu/FOlsBm5K6LZ4FnBcRE5QeTvF54Li83HhgR1InVjdK2gA4hPRT/g9KWh64VdLv8vITgPdG6sb2LZLGAN8BPgA8T+o5dZ+I+JaknUn9oU9tiPEq4BZJHyb9uvTSiLgrz/taRDyXv1lMkrRlRNyb582NiO0knQFMBLYHViD9ivvsQpybAXOA3wL7Av9RiHdT0jeO7SPiDUlnAQflbYyNiPfm5VYrUddWEz7jt7aJ1MPgxcCxvVhtSqT+yV8j/SS9K3HfR0r2Xa6KiMURMZP0AbEJqe+jQyTdTerW9t2kfkwA7mhM+tkHgT9GxNMRsQi4jPSglFblmgdsDJwELCYl+F3y7E9IuhO4C9iclMS7dPVJdR/pQSILI+Jp4NVCor4j0rMq3iR17fChht3vQvqQmpLLuQupK5BZwHqSfiRpN6BVT5dWMz7jt3Y7E7gTuLAwbRH5JCR3UDW8MO+1wvDiwvhiljx+G/seCVJ/Lp+PiBuKMyTtBPy1SXzddXHbo/zBdD1wvaQngX0kzQKOBz4YEc9Lmkg6o+9SLEtjObvK1l25GuO9KCJOWqog0lbAx4CjgU8Ah/e2XLZs8hm/tVVEPEdqGjmiMHk26awV0tOEluvDpvfPd9esTzrjnQHcAPyjUhe3SNpIqRfUViYDO0oamZtnDgRuarVCbp8fk4eHAFuSmmZWIX3ALJC0JumZC701Qann2iGkJp1bGuZPAvaTtEbe/+qS1skX0YdExNXAN0iPdjQDfMZvnfF94JjC+LnAf0q6g5TImp2NtzKDlKDXBI6MiFclnUdqDrozf5N4mh4eYxkR8yWdBNxIOpu+LiJ66hZ7DeDcfB0BUpe4P84x3EVqb58F3NqHct0GnAZsAdxMemZDMd4/S/o66VrEEFIPn0cDrwAXFi4GL/WNwOrLvXOaDVC5Ser4iPh4p2OxZYubeszMasZn/GZmNeMzfjOzmnHiNzOrGSd+M7OaceI3M6sZJ34zs5r5X3+Lsb34SegnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 316\n",
      "Positive = 241\n",
      "Nagative = 75\n",
      "\n",
      "Dataframe size\n",
      "(316, 3)\n",
      "\n",
      " up_sample() is activated...\n",
      "\n",
      "\n",
      "Dataset after up sample\n",
      "\n",
      "     score                                                 en  polarity\n",
      "0        1                                          Very long         0\n",
      "1        5  Doctor Keng, good management system, convenien...         1\n",
      "2        5                               The best of service.         1\n",
      "3        5  Would like to say thank you to the doctors and...         1\n",
      "4        5  Slow but sure !!! Please come and use the serv...         1\n",
      "..     ...                                                ...       ...\n",
      "477      4                                      A little more         1\n",
      "478      5  Vast, expansive, shady trees, lots of building...         1\n",
      "479      4  The doctors and nurses take good care, underst...         1\n",
      "480      5       Very good service, good speech, good manners         1\n",
      "481      1  Do not want to see the sick, do not want to go...         0\n",
      "\n",
      "[482 rows x 3 columns]\n",
      "\n",
      "Dataset after up sample group by class\n",
      "\n",
      "1    241\n",
      "0    241\n",
      "Name: polarity, dtype: int64\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 236/482 [00:00<00:00, 2339.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 482\n",
      "Positive = 241\n",
      "Nagative = 241\n",
      "\n",
      "Dataframe size\n",
      "(482, 3)\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert sentense to token <<<<<\n",
      "\n",
      " gen_token() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:00<00:00, 2402.87it/s]\n",
      "100%|██████████| 482/482 [00:00<00:00, 37089.81it/s]\n",
      "  1%|          | 4/482 [00:00<00:13, 34.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1                                          Very long         0   \n",
      "1        5  Doctor Keng, good management system, convenien...         1   \n",
      "2        5                               The best of service.         1   \n",
      "3        5  Would like to say thank you to the doctors and...         1   \n",
      "4        5  Slow but sure !!! Please come and use the serv...         1   \n",
      "..     ...                                                ...       ...   \n",
      "477      4                                      A little more         1   \n",
      "478      5  Vast, expansive, shady trees, lots of building...         1   \n",
      "479      4  The doctors and nurses take good care, underst...         1   \n",
      "480      5       Very good service, good speech, good manners         1   \n",
      "481      1  Do not want to see the sick, do not want to go...         0   \n",
      "\n",
      "                                                 token  \n",
      "0                                         [Very, long]  \n",
      "1    [Doctor, Keng, ,, good, management, system, ,,...  \n",
      "2                          [The, best, of, service, .]  \n",
      "3    [Would, like, to, say, thank, you, to, the, do...  \n",
      "4    [Slow, but, sure, !, !, !, Please, come, and, ...  \n",
      "..                                                 ...  \n",
      "477                                  [A, little, more]  \n",
      "478  [Vast, ,, expansive, ,, shady, trees, ,, lots,...  \n",
      "479  [The, doctors, and, nurses, take, good, care, ...  \n",
      "480  [Very, good, service, ,, good, speech, ,, good...  \n",
      "481  [Do, not, want, to, see, the, sick, ,, do, not...  \n",
      "\n",
      "[482 rows x 4 columns]\n",
      "(482, 4)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert text to lowercase <<<<<\n",
      "\n",
      " lowercase_text() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1                                          Very long         0   \n",
      "1        5  Doctor Keng, good management system, convenien...         1   \n",
      "2        5                               The best of service.         1   \n",
      "3        5  Would like to say thank you to the doctors and...         1   \n",
      "4        5  Slow but sure !!! Please come and use the serv...         1   \n",
      "..     ...                                                ...       ...   \n",
      "477      4                                      A little more         1   \n",
      "478      5  Vast, expansive, shady trees, lots of building...         1   \n",
      "479      4  The doctors and nurses take good care, underst...         1   \n",
      "480      5       Very good service, good speech, good manners         1   \n",
      "481      1  Do not want to see the sick, do not want to go...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0                                         [Very, long]   \n",
      "1    [Doctor, Keng, ,, good, management, system, ,,...   \n",
      "2                          [The, best, of, service, .]   \n",
      "3    [Would, like, to, say, thank, you, to, the, do...   \n",
      "4    [Slow, but, sure, !, !, !, Please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [A, little, more]   \n",
      "478  [Vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [The, doctors, and, nurses, take, good, care, ...   \n",
      "480  [Very, good, service, ,, good, speech, ,, good...   \n",
      "481  [Do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                             lowercase  \n",
      "0                                         [very, long]  \n",
      "1    [doctor, keng, ,, good, management, system, ,,...  \n",
      "2                          [the, best, of, service, .]  \n",
      "3    [would, like, to, say, thank, you, to, the, do...  \n",
      "4    [slow, but, sure, !, !, !, please, come, and, ...  \n",
      "..                                                 ...  \n",
      "477                                  [a, little, more]  \n",
      "478  [vast, ,, expansive, ,, shady, trees, ,, lots,...  \n",
      "479  [the, doctors, and, nurses, take, good, care, ...  \n",
      "480  [very, good, service, ,, good, speech, ,, good...  \n",
      "481  [do, not, want, to, see, the, sick, ,, do, not...  \n",
      "\n",
      "[482 rows x 5 columns]\n",
      "(482, 5)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove special character <<<<<\n",
      "\n",
      " remove_spec_char() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1                                          Very long         0   \n",
      "1        5  Doctor Keng, good management system, convenien...         1   \n",
      "2        5                               The best of service.         1   \n",
      "3        5  Would like to say thank you to the doctors and...         1   \n",
      "4        5  Slow but sure !!! Please come and use the serv...         1   \n",
      "..     ...                                                ...       ...   \n",
      "477      4                                      A little more         1   \n",
      "478      5  Vast, expansive, shady trees, lots of building...         1   \n",
      "479      4  The doctors and nurses take good care, underst...         1   \n",
      "480      5       Very good service, good speech, good manners         1   \n",
      "481      1  Do not want to see the sick, do not want to go...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0                                         [Very, long]   \n",
      "1    [Doctor, Keng, ,, good, management, system, ,,...   \n",
      "2                          [The, best, of, service, .]   \n",
      "3    [Would, like, to, say, thank, you, to, the, do...   \n",
      "4    [Slow, but, sure, !, !, !, Please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [A, little, more]   \n",
      "478  [Vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [The, doctors, and, nurses, take, good, care, ...   \n",
      "480  [Very, good, service, ,, good, speech, ,, good...   \n",
      "481  [Do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, ,, good, management, system, ,,...   \n",
      "2                          [the, best, of, service, .]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, !, !, !, please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, ,, good, speech, ,, good...   \n",
      "481  [do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                         rem_spec_char  \n",
      "0                                         [very, long]  \n",
      "1    [doctor, keng, , good, management, system, , c...  \n",
      "2                           [the, best, of, service, ]  \n",
      "3    [would, like, to, say, thank, you, to, the, do...  \n",
      "4    [slow, but, sure, , , , please, come, and, use...  \n",
      "..                                                 ...  \n",
      "477                                  [a, little, more]  \n",
      "478  [vast, , expansive, , shady, trees, , lots, of...  \n",
      "479  [the, doctors, and, nurses, take, good, care, ...  \n",
      "480  [very, good, service, , good, speech, , good, ...  \n",
      "481  [do, not, want, to, see, the, sick, , do, not,...  \n",
      "\n",
      "[482 rows x 6 columns]\n",
      "(482, 6)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word <<<<<\n",
      "\n",
      " remove_stop_word() is activated...\n",
      "\n",
      "\n",
      "stop_words:\n",
      "\n",
      "{'before', 'how', 'on', 'yourself', 'should', 'ours', 'more', 'aren', \"mustn't\", \"shouldn't\", 'no', 'being', \"needn't\", 'myself', 'are', 'too', \"mightn't\", 'o', 'ourselves', 'whom', 'who', 'down', \"should've\", 'from', 'during', 'shan', 'at', 'theirs', 'couldn', 'through', \"you've\", 'again', 'all', 'nor', \"you're\", 'into', 'this', 'weren', \"it's\", 'the', 'yourselves', 'while', 'haven', 'isn', 'themselves', 'why', 'until', 'under', 's', 'hasn', 'because', 'wasn', 'can', 'now', 'doing', 'with', \"don't\", 'my', \"aren't\", 'their', 'both', 'wouldn', 'we', 'in', 'or', 'hadn', 'up', 'by', 'yours', 'few', 'those', 'below', 'll', 'itself', 'and', 'than', 'own', \"that'll\", 'did', 'about', 'mustn', 'once', \"wasn't\", \"won't\", 'ma', 'don', 'some', \"shan't\", 'our', 'won', 'here', \"she's\", 'was', 'has', 'each', 'y', 'they', 'ain', 'is', 've', 'hers', 'such', 'against', 'only', 'above', 'shouldn', \"couldn't\", 'them', 'mightn', 'you', 'had', 't', 'there', 'its', 'any', 'will', 'that', 'a', 'needn', 'me', 'she', 'having', \"haven't\", 'so', 'which', 'for', 'be', 'after', 'further', 'i', 'am', 'most', 'these', 'himself', \"you'd\", 'over', 'just', 'very', \"wouldn't\", \"you'll\", 'were', 'been', 'd', 're', 'does', 'didn', 'as', \"isn't\", 'his', \"hasn't\", 'her', 'not', 'him', 'then', 'doesn', 'he', 'it', \"hadn't\", 'have', 'm', 'where', \"didn't\", 'out', 'other', 'when', 'but', 'your', 'herself', 'an', \"doesn't\", 'if', 'of', 'what', 'do', 'same', 'between', \"weren't\", 'to', 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [02:10<00:00,  3.69it/s]\n",
      "100%|██████████| 482/482 [00:00<00:00, 37051.07it/s]\n",
      "100%|██████████| 482/482 [00:00<00:00, 40136.88it/s]\n",
      "  3%|▎         | 13/482 [00:00<00:04, 106.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1                                          Very long         0   \n",
      "1        5  Doctor Keng, good management system, convenien...         1   \n",
      "2        5                               The best of service.         1   \n",
      "3        5  Would like to say thank you to the doctors and...         1   \n",
      "4        5  Slow but sure !!! Please come and use the serv...         1   \n",
      "..     ...                                                ...       ...   \n",
      "477      4                                      A little more         1   \n",
      "478      5  Vast, expansive, shady trees, lots of building...         1   \n",
      "479      4  The doctors and nurses take good care, underst...         1   \n",
      "480      5       Very good service, good speech, good manners         1   \n",
      "481      1  Do not want to see the sick, do not want to go...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0                                         [Very, long]   \n",
      "1    [Doctor, Keng, ,, good, management, system, ,,...   \n",
      "2                          [The, best, of, service, .]   \n",
      "3    [Would, like, to, say, thank, you, to, the, do...   \n",
      "4    [Slow, but, sure, !, !, !, Please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [A, little, more]   \n",
      "478  [Vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [The, doctors, and, nurses, take, good, care, ...   \n",
      "480  [Very, good, service, ,, good, speech, ,, good...   \n",
      "481  [Do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, ,, good, management, system, ,,...   \n",
      "2                          [the, best, of, service, .]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, !, !, !, please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, ,, good, speech, ,, good...   \n",
      "481  [do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                           [the, best, of, service, ]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, , , , please, come, and, use...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, of...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, , good, speech, , good, ...   \n",
      "481  [do, not, want, to, see, the, sick, , do, not,...   \n",
      "\n",
      "                                             stop_word  \n",
      "0                                               [long]  \n",
      "1    [doctor, keng, , good, management, system, , c...  \n",
      "2                                    [best, service, ]  \n",
      "3    [would, like, say, thank, doctors, nurses, obs...  \n",
      "4           [slow, sure, , , , please, use, service, ]  \n",
      "..                                                 ...  \n",
      "477                                           [little]  \n",
      "478  [vast, , expansive, , shady, trees, , lots, bu...  \n",
      "479  [doctors, nurses, good, , understand, patients...  \n",
      "480   [good, service, , good, speech, , good, manners]  \n",
      "481    [see, sick, , go, hospital, , work, must, seen]  \n",
      "\n",
      "[482 rows x 7 columns]\n",
      "(482, 7)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word (Special) <<<<<\n",
      "\n",
      ">>>>> 've, ``, 's, n't, '', ' ' <<<<<\n",
      "\n",
      " remove_stop_word_spec() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1                                          Very long         0   \n",
      "1        5  Doctor Keng, good management system, convenien...         1   \n",
      "2        5                               The best of service.         1   \n",
      "3        5  Would like to say thank you to the doctors and...         1   \n",
      "4        5  Slow but sure !!! Please come and use the serv...         1   \n",
      "..     ...                                                ...       ...   \n",
      "477      4                                      A little more         1   \n",
      "478      5  Vast, expansive, shady trees, lots of building...         1   \n",
      "479      4  The doctors and nurses take good care, underst...         1   \n",
      "480      5       Very good service, good speech, good manners         1   \n",
      "481      1  Do not want to see the sick, do not want to go...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0                                         [Very, long]   \n",
      "1    [Doctor, Keng, ,, good, management, system, ,,...   \n",
      "2                          [The, best, of, service, .]   \n",
      "3    [Would, like, to, say, thank, you, to, the, do...   \n",
      "4    [Slow, but, sure, !, !, !, Please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [A, little, more]   \n",
      "478  [Vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [The, doctors, and, nurses, take, good, care, ...   \n",
      "480  [Very, good, service, ,, good, speech, ,, good...   \n",
      "481  [Do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, ,, good, management, system, ,,...   \n",
      "2                          [the, best, of, service, .]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, !, !, !, please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, ,, good, speech, ,, good...   \n",
      "481  [do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                           [the, best, of, service, ]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, , , , please, come, and, use...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, of...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, , good, speech, , good, ...   \n",
      "481  [do, not, want, to, see, the, sick, , do, not,...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0                                               [long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                                    [best, service, ]   \n",
      "3    [would, like, say, thank, doctors, nurses, obs...   \n",
      "4           [slow, sure, , , , please, use, service, ]   \n",
      "..                                                 ...   \n",
      "477                                           [little]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, bu...   \n",
      "479  [doctors, nurses, good, , understand, patients...   \n",
      "480   [good, service, , good, speech, , good, manners]   \n",
      "481    [see, sick, , go, hospital, , work, must, seen]   \n",
      "\n",
      "                                          stop_word_02  \n",
      "0                                               [long]  \n",
      "1    [doctor, keng, , good, management, system, , c...  \n",
      "2                                    [best, service, ]  \n",
      "3    [would, like, say, thank, doctors, nurses, obs...  \n",
      "4           [slow, sure, , , , please, use, service, ]  \n",
      "..                                                 ...  \n",
      "477                                           [little]  \n",
      "478  [vast, , expansive, , shady, trees, , lots, bu...  \n",
      "479  [doctors, nurses, good, , understand, patients...  \n",
      "480   [good, service, , good, speech, , good, manners]  \n",
      "481    [see, sick, , go, hospital, , work, must, seen]  \n",
      "\n",
      "[482 rows x 8 columns]\n",
      "(482, 8)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove single and space token <<<<<\n",
      "\n",
      " remove_single_token() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1                                          Very long         0   \n",
      "1        5  Doctor Keng, good management system, convenien...         1   \n",
      "2        5                               The best of service.         1   \n",
      "3        5  Would like to say thank you to the doctors and...         1   \n",
      "4        5  Slow but sure !!! Please come and use the serv...         1   \n",
      "..     ...                                                ...       ...   \n",
      "477      4                                      A little more         1   \n",
      "478      5  Vast, expansive, shady trees, lots of building...         1   \n",
      "479      4  The doctors and nurses take good care, underst...         1   \n",
      "480      5       Very good service, good speech, good manners         1   \n",
      "481      1  Do not want to see the sick, do not want to go...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0                                         [Very, long]   \n",
      "1    [Doctor, Keng, ,, good, management, system, ,,...   \n",
      "2                          [The, best, of, service, .]   \n",
      "3    [Would, like, to, say, thank, you, to, the, do...   \n",
      "4    [Slow, but, sure, !, !, !, Please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [A, little, more]   \n",
      "478  [Vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [The, doctors, and, nurses, take, good, care, ...   \n",
      "480  [Very, good, service, ,, good, speech, ,, good...   \n",
      "481  [Do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, ,, good, management, system, ,,...   \n",
      "2                          [the, best, of, service, .]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, !, !, !, please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, ,, good, speech, ,, good...   \n",
      "481  [do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                           [the, best, of, service, ]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, , , , please, come, and, use...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, of...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, , good, speech, , good, ...   \n",
      "481  [do, not, want, to, see, the, sick, , do, not,...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0                                               [long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                                    [best, service, ]   \n",
      "3    [would, like, say, thank, doctors, nurses, obs...   \n",
      "4           [slow, sure, , , , please, use, service, ]   \n",
      "..                                                 ...   \n",
      "477                                           [little]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, bu...   \n",
      "479  [doctors, nurses, good, , understand, patients...   \n",
      "480   [good, service, , good, speech, , good, manners]   \n",
      "481    [see, sick, , go, hospital, , work, must, seen]   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0                                               [long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                                    [best, service, ]   \n",
      "3    [would, like, say, thank, doctors, nurses, obs...   \n",
      "4           [slow, sure, , , , please, use, service, ]   \n",
      "..                                                 ...   \n",
      "477                                           [little]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, bu...   \n",
      "479  [doctors, nurses, good, , understand, patients...   \n",
      "480   [good, service, , good, speech, , good, manners]   \n",
      "481    [see, sick, , go, hospital, , work, must, seen]   \n",
      "\n",
      "                                       rem_single_char  \n",
      "0                                               [long]  \n",
      "1    [doctor, keng, good, management, system, conve...  \n",
      "2                                      [best, service]  \n",
      "3    [would, like, say, thank, doctors, nurses, obs...  \n",
      "4                   [slow, sure, please, use, service]  \n",
      "..                                                 ...  \n",
      "477                                           [little]  \n",
      "478  [vast, expansive, shady, trees, lots, building...  \n",
      "479  [doctors, nurses, good, understand, patients, ...  \n",
      "480       [good, service, good, speech, good, manners]  \n",
      "481        [see, sick, go, hospital, work, must, seen]  \n",
      "\n",
      "[482 rows x 9 columns]\n",
      "(482, 9)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Normalization (Lemmatization: root word) <<<<<\n",
      "\n",
      " lemmatize_token() is activated...\n",
      "\n",
      "\n",
      "Test POS:\n",
      "\n",
      "This is a book\n",
      "\n",
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('book', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:04<00:00, 97.20it/s] \n",
      "100%|██████████| 482/482 [00:00<00:00, 8185.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        1                                          Very long         0   \n",
      "1        5  Doctor Keng, good management system, convenien...         1   \n",
      "2        5                               The best of service.         1   \n",
      "3        5  Would like to say thank you to the doctors and...         1   \n",
      "4        5  Slow but sure !!! Please come and use the serv...         1   \n",
      "..     ...                                                ...       ...   \n",
      "477      4                                      A little more         1   \n",
      "478      5  Vast, expansive, shady trees, lots of building...         1   \n",
      "479      4  The doctors and nurses take good care, underst...         1   \n",
      "480      5       Very good service, good speech, good manners         1   \n",
      "481      1  Do not want to see the sick, do not want to go...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0                                         [Very, long]   \n",
      "1    [Doctor, Keng, ,, good, management, system, ,,...   \n",
      "2                          [The, best, of, service, .]   \n",
      "3    [Would, like, to, say, thank, you, to, the, do...   \n",
      "4    [Slow, but, sure, !, !, !, Please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [A, little, more]   \n",
      "478  [Vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [The, doctors, and, nurses, take, good, care, ...   \n",
      "480  [Very, good, service, ,, good, speech, ,, good...   \n",
      "481  [Do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, ,, good, management, system, ,,...   \n",
      "2                          [the, best, of, service, .]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, !, !, !, please, come, and, ...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, ,, expansive, ,, shady, trees, ,, lots,...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, ,, good, speech, ,, good...   \n",
      "481  [do, not, want, to, see, the, sick, ,, do, not...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0                                         [very, long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                           [the, best, of, service, ]   \n",
      "3    [would, like, to, say, thank, you, to, the, do...   \n",
      "4    [slow, but, sure, , , , please, come, and, use...   \n",
      "..                                                 ...   \n",
      "477                                  [a, little, more]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, of...   \n",
      "479  [the, doctors, and, nurses, take, good, care, ...   \n",
      "480  [very, good, service, , good, speech, , good, ...   \n",
      "481  [do, not, want, to, see, the, sick, , do, not,...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0                                               [long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                                    [best, service, ]   \n",
      "3    [would, like, say, thank, doctors, nurses, obs...   \n",
      "4           [slow, sure, , , , please, use, service, ]   \n",
      "..                                                 ...   \n",
      "477                                           [little]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, bu...   \n",
      "479  [doctors, nurses, good, , understand, patients...   \n",
      "480   [good, service, , good, speech, , good, manners]   \n",
      "481    [see, sick, , go, hospital, , work, must, seen]   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0                                               [long]   \n",
      "1    [doctor, keng, , good, management, system, , c...   \n",
      "2                                    [best, service, ]   \n",
      "3    [would, like, say, thank, doctors, nurses, obs...   \n",
      "4           [slow, sure, , , , please, use, service, ]   \n",
      "..                                                 ...   \n",
      "477                                           [little]   \n",
      "478  [vast, , expansive, , shady, trees, , lots, bu...   \n",
      "479  [doctors, nurses, good, , understand, patients...   \n",
      "480   [good, service, , good, speech, , good, manners]   \n",
      "481    [see, sick, , go, hospital, , work, must, seen]   \n",
      "\n",
      "                                       rem_single_char  \\\n",
      "0                                               [long]   \n",
      "1    [doctor, keng, good, management, system, conve...   \n",
      "2                                      [best, service]   \n",
      "3    [would, like, say, thank, doctors, nurses, obs...   \n",
      "4                   [slow, sure, please, use, service]   \n",
      "..                                                 ...   \n",
      "477                                           [little]   \n",
      "478  [vast, expansive, shady, trees, lots, building...   \n",
      "479  [doctors, nurses, good, understand, patients, ...   \n",
      "480       [good, service, good, speech, good, manners]   \n",
      "481        [see, sick, go, hospital, work, must, seen]   \n",
      "\n",
      "                                            norm_lemma  \n",
      "0                                               [long]  \n",
      "1    [doctor, keng, good, management, system, conve...  \n",
      "2                                      [best, service]  \n",
      "3    [would, like, say, thank, doctor, nurse, obste...  \n",
      "4                   [slow, sure, please, use, service]  \n",
      "..                                                 ...  \n",
      "477                                           [little]  \n",
      "478  [vast, expansive, shady, tree, lot, building, ...  \n",
      "479  [doctor, nurse, good, understand, patient, che...  \n",
      "480        [good, service, good, speech, good, manner]  \n",
      "481         [see, sick, go, hospital, work, must, see]  \n",
      "\n",
      "[482 rows x 10 columns]\n",
      "(482, 10)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF) <<<<<\n",
      "\n",
      " vec_tf_idf() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 1351\n",
      "\n",
      "\n",
      "\n",
      "['05', '10', '100', '100th', '1021', '1030', '1130', '1200', '1320', '13th', '14', '17', '1700', '1711', '17800', '1817', '1st', '20', '2010', '2014', '2015', '2016', '2017', '21st', '23', '24', '2555', '26', '28', '29', '2nd', '30', '300', '35', '3rd', '47', '4th', '500', '530', '55', '555', '58', '5th', '600', '6th', '730', '800', '830', '900', '900000', '945', '9th', 'a10', 'abak', 'ability', 'able', 'abroad', 'absolutely', 'accept', 'acceptable', 'access', 'accident', 'accord', 'accuracy', 'accurate', 'accurately', 'ache', 'acknowledge', 'act', 'acting', 'action', 'addition', 'additional', 'admit', 'adulyadej', 'advice', 'advise', 'afraid', 'afternoon', 'again_and', 'age', 'agree', 'air', 'allergic', 'allow', 'almost', 'alone', 'along', 'already', 'although', 'always', 'amen', 'amount', 'amputate', 'analyze', 'ancient', 'angry', 'anniversary', 'annoy', 'annoyance', 'annual', 'another', 'answer', 'antenatal', 'anus', 'anymore', 'anyone', 'anything', 'anywhere', 'aphinan', 'appear', 'appendix', 'appoint', 'appointment', 'appreciate', 'apprentice', 'approach', 'appropriately', 'april', 'arad', 'area', 'around', 'arrange', 'arrive', 'arrives', 'artery', 'asawawitoonthip', 'ask', 'asks', 'aspect', 'assistance', 'assistant', 'assoc', 'ataya', 'atmin', 'atmosphere', 'atrophy', 'attention', 'attentive', 'auditory', 'aunt', 'auntie', 'authority', 'aware', 'away', 'awesome', 'awkward', 'baby', 'bachelor', 'back', 'bad', 'badly', 'badwhat', 'bag', 'baht', 'balloon', 'band', 'bang', 'bangkok', 'bank', 'basic', 'bathroom', 'beam', 'beautiful', 'beautifully', 'become', 'bed', 'begin', 'behind', 'believe', 'belly', 'benefit', 'best', 'bhumibol', 'biggerthe', 'birth', 'bit', 'black', 'blame', 'blanket', 'bleed', 'bleeding', 'blood', 'blossom', 'blue', 'blurry', 'bobcat', 'body', 'boil', 'bold', 'bone', 'book', 'boonyakanok', 'bore', 'bottom', 'bought', 'bow', 'box', 'boyfriend', 'brain', 'brawny', 'break', 'briefly', 'brightens', 'bring', 'broken', 'brother', 'brought', 'brutal', 'bts', 'building', 'bullying', 'burden', 'buri', 'burning', 'bury', 'bus', 'busy', 'buy', 'cabinet', 'call', 'calmness', 'calorie', 'cancer', 'car', 'card', 'care', 'career', 'careful', 'carefully', 'carpool', 'carry', 'cart', 'case', 'cash', 'cataract', 'caught', 'cause', 'center', 'central', 'certain', 'certificate', 'cesarean', 'cha', 'chance', 'change', 'chaotic', 'characteristic', 'chareon', 'charge', 'chart', 'chase', 'chaung', 'cheaper', 'check', 'checked', 'cheer', 'cheerful', 'child', 'chon', 'choose', 'chose', 'chronic', 'chula', 'chulalongkorn', 'citizen', 'city', 'civil', 'class', 'clean', 'clearly', 'clinic', 'clock', 'close', 'clothes', 'cod', 'cold', 'collect', 'collection', 'combine', 'come', 'comfortable', 'commission', 'common', 'compare', 'compassion', 'complain', 'complaint', 'complete', 'completely', 'compliment', 'computer', 'conclude', 'conclusion', 'condition', 'conditioner', 'confidence', 'confident', 'confine', 'confuse', 'conjunction', 'connect', 'conserve', 'consider', 'consult', 'consultation', 'contact', 'continue', 'continued', 'contrary', 'control', 'convenient', 'conveniently', 'convince', 'cook', 'cool', 'cooler', 'coordination', 'coronary', 'cost', 'costume', 'could', 'counter', 'courtesy', 'cover', 'cradle', 'crash', 'crazy', 'credibly', 'credit', 'cross', 'crowd', 'cry', 'cue', 'cure', 'current', 'currently', 'curtain', 'curtly', 'cut', 'cute', 'dad', 'daeng', 'damage', 'date', 'daughter', 'day', 'dead', 'death', 'dec', 'december', 'decide', 'decision', 'decisive', 'dedicate', 'dee', 'deep', 'deeply', 'degree', 'delayed', 'delivery', 'dental', 'department', 'depend', 'depends', 'describe', 'despite', 'detail', 'detailed', 'detect', 'deterioration', 'develop', 'developed', 'development', 'device', 'di', 'diagnose', 'diagnosis', 'diarrhea', 'different', 'differently', 'difficult', 'diligent', 'directly', 'director', 'dirty', 'disappear', 'disappears', 'disappointed', 'discourage', 'discriminatory', 'disease', 'displayed', 'dissection', 'distract', 'dizzy', 'do', 'doctor', 'document', 'dog', 'donate', 'doorbell', 'dormitory', 'downstairs', 'dr', 'drain', 'drama', 'draw', 'drill', 'drive', 'driver', 'drove', 'drug', 'due', 'dumped', 'duplicate', 'duty', 'ear', 'early', 'ease', 'easily', 'easy', 'eat', 'economical', 'education', 'effectively', 'egg', 'either', 'elder', 'electric', 'elevator', 'eloquently', 'else', 'emergency', 'emotion', 'employee', 'encounter', 'encourage', 'encouragement', 'encourages', 'endoscopic', 'energy', 'enough', 'enter', 'enthral', 'entire', 'equal', 'equally', 'equip', 'equipment', 'escape', 'especially', 'etiquette', 'even', 'event', 'ever', 'every', 'everyday', 'everyone', 'everything', 'everywhere', 'examination', 'examine', 'example', 'excellent', 'exchange', 'executive', 'expand', 'expansive', 'expect', 'expensive', 'experience', 'experienced', 'expert', 'expertise', 'explain', 'explanation', 'expression', 'extra', 'extreme', 'extremely', 'face', 'facial', 'facility', 'faculty', 'faint', 'fairy', 'family', 'famous', 'fan', 'far', 'fast', 'faster', 'fastif', 'father', 'fee', 'feel', 'feeling', 'felt', 'female', 'fever', 'fierce', 'fight', 'file', 'financial', 'find', 'fine', 'finger', 'finish', 'first', 'fit', 'five', 'flicker', 'flood', 'floor', 'flow', 'flower', 'follow', 'food', 'foot', 'footballer', 'forever', 'forget', 'forgotten', 'form', 'former', 'forth', 'fortune', 'found', 'four', 'fracture', 'free', 'friend', 'friendly', 'friendship', 'frighten', 'front', 'frustrate', 'frustration', 'full', 'fully', 'garbage', 'garden', 'gastritis', 'gathering', 'general', 'gentle', 'get', 'giggle', 'girlfriend', 'give', 'glass', 'gloomy', 'go', 'god', 'gold', 'golf', 'good', 'goodbye', 'goodness', 'goodwant', 'government', 'grace', 'gradually', 'grandma', 'grant', 'great', 'ground', 'guarantee', 'guard', 'guest', 'guidance', 'guy', 'gynecology', 'habit', 'haha', 'hahaha', 'hahahahahahaha', 'half', 'hand', 'handle', 'handsome', 'happen', 'happily', 'happy', 'hard', 'head', 'headache', 'heal', 'health', 'healthy', 'hear', 'heard', 'heart', 'heavy', 'heck', 'help', 'helpful', 'hidden', 'high', 'hip', 'history', 'hit', 'hmmm', 'hold', 'hole', 'home', 'hope', 'horizontally', 'hospital', 'hot', 'hour', 'house', 'housewife', 'however', 'hr', 'hug', 'hurry', 'hurt', 'husband', 'icu', 'id', 'ie', 'illness', 'image', 'immediately', 'implies', 'importance', 'importantly', 'impressed', 'impressive', 'improve', 'improvement', 'in', 'include', 'inconvenience', 'inconvenient', 'increase', 'indefinitely', 'indicate', 'inform', 'information', 'inject', 'inpatient', 'insert', 'inside', 'inspect', 'inspection', 'instead', 'institute', 'institution', 'instruct', 'insufficient', 'insult', 'intelligence', 'interested', 'intern', 'internal', 'international', 'intestinal', 'introduction', 'irritated', 'issue', 'jaidee', 'jam', 'jan', 'january', 'jiran', 'job', 'july', 'jump', 'june', 'kampol', 'kantakarn', 'kasetsart', 'keep', 'keng', 'kept', 'kesaraporn', 'key', 'kiat', 'kidney', 'kind', 'king', 'knee', 'knew', 'know', 'knowledge', 'language', 'large', 'last', 'late', 'later', 'layer', 'leaf', 'leave', 'leg', 'less', 'let', 'leukemia', 'level', 'lie', 'life', 'lift', 'light', 'like', 'line', 'linen', 'little', 'live', 'liver', 'living', 'll', 'locate', 'location', 'lol', 'long', 'longer', 'look', 'lose', 'losing', 'lot', 'loud', 'love', 'lovely', 'low', 'luck', 'luckily', 'lump', 'lung', 'luxury', 'maintain', 'make', 'male', 'manage', 'management', 'manner', 'many', 'march', 'marrow', 'match', 'matter', 'may', 'maybe', 'meal', 'meaning', 'measure', 'medical', 'medication', 'medicine', 'mee', 'meet', 'meeting', 'melodious', 'member', 'memorial', 'memory', 'mention', 'metaphor', 'meter', 'method', 'midday', 'mind', 'minute', 'miracle', 'miss', 'mistake', 'mobile', 'modern', 'mom', 'moment', 'money', 'month', 'mood', 'moreover', 'morning', 'morphine', 'mother', 'motorcycle', 'mouse', 'move', 'mp', 'mr', 'mrt', 'much', 'mum', 'murmur', 'must', 'national', 'natured', 'nawamin', 'near', 'nearly', 'necessary', 'need', 'negative', 'network', 'never', 'new', 'next', 'night', 'noise', 'non', 'nong', 'noon', 'normal', 'normally', 'nothing', 'nov', 'nowadays', 'number', 'nurse', 'nursing', 'nutrition', 'observation', 'obstetrics', 'obtain', 'obtrusive', 'occasion', 'october', 'offer', 'office', 'officer', 'official', 'often', 'ok', 'okay', 'old', 'ongoing', 'open', 'operating', 'operation', 'ophthalmology', 'opinion', 'opportunity', 'optimistic', 'option', 'order', 'organize', 'original', 'orthopedic', 'osteoporosis', 'others', 'outside', 'overall', 'page', 'paid', 'pain', 'pale', 'pamper', 'paper', 'park', 'parking', 'part', 'party', 'pas', 'pass', 'passageway', 'past', 'path', 'patience', 'patient', 'patrol', 'pay', 'payment', 'peace', 'pediatric', 'people', 'perform', 'period', 'persistence', 'person', 'personality', 'personnel', 'phai', 'phanitkij', 'pharmacist', 'pharmacy', 'phat', 'phayabab', 'phimonkul', 'phone', 'phor', 'phrapharod', 'phraphit', 'physical', 'pick', 'picture', 'piece', 'pig', 'pill', 'pity', 'place', 'plan', 'play', 'please', 'plug', 'plus', 'pm', 'point', 'poison', 'police', 'polite', 'politely', 'poor', 'poorly', 'post', 'postpone', 'power', 'powerful', 'practice', 'praise', 'pregnancy', 'pregnant', 'prenatal', 'prepare', 'preposter', 'prescription', 'press', 'pressure', 'pretty', 'previously', 'price', 'private', 'privilege', 'probably', 'problem', 'procedure', 'process', 'product', 'profession', 'professor', 'profile', 'program', 'prohibit', 'protection', 'provide', 'province', 'public', 'push', 'put', 'quality', 'question', 'queue', 'quick', 'quicker', 'quickly', 'quiet', 'quite', 'race', 'racha', 'rain', 'raise', 'rama', 'ran', 'random', 'ratchaburi', 'ratchada', 'rate', 'rating', 'ray', 'raya', 'rayong', 'rays', 're', 'reach', 'reaction', 'read', 'reading', 'ready', 'real', 'really', 'reason', 'reasonable', 'reborn', 'receive', 'recently', 'receptionist', 'recommend', 'recommendation', 'recommends', 'reconcile', 'record', 'recover', 'red', 'reduce', 'refer', 'refresh', 'regardless', 'registration', 'regular', 'regularly', 'related', 'relation', 'relative', 'relief', 'relieve', 'rely', 'remember', 'repair', 'repeat', 'reply', 'report', 'reputation', 'request', 'require', 'reservation', 'reserve', 'respectfully', 'respiratory', 'respond', 'responsible', 'rest', 'restaurant', 'restriction', 'result', 'retreat', 'return', 'review', 'rice', 'ride', 'right', 'ring', 'rip', 'riyabha', 'room', 'root', 'ror', 'rotterdam', 'round', 'rpp', 'rule', 'run', 'rungsak', 'rupture', 'rush', 'safe', 'safety', 'saga', 'sala', 'salary', 'salt', 'sameif', 'sanitary', 'sarar', 'sarcastic', 'sasi', 'sassy', 'satisfied', 'save', 'saw', 'sawasdee', 'say', 'scar', 'schedule', 'school', 'screen', 'second', 'secretly', 'secure', 'security', 'see', 'seem', 'seize', 'seizure', 'self', 'sell', 'send', 'senior', 'sense', 'sent', 'separate', 'seriously', 'serve', 'service', 'shady', 'share', 'shift', 'shit', 'shock', 'shoot', 'short', 'shortly', 'shoulder', 'shout', 'show', 'shy', 'sibling', 'sick', 'side', 'sidewalk', 'sigh', 'since', 'sit', 'situation', 'six', 'size', 'skilled', 'skin', 'skull', 'sky', 'slang', 'sle', 'sleep', 'slept', 'slot', 'slow', 'slowly', 'small', 'smelly', 'smile', 'snack', 'sneeze', 'social', 'society', 'solution', 'something', 'sometimes', 'somsri', 'sore', 'sorry', 'sort', 'speak', 'speaks', 'special', 'specialist', 'specialized', 'speech', 'spent', 'spite', 'split', 'spoke', 'spoken', 'spot', 'staff', 'staffnotice', 'stamp', 'stand', 'standard', 'star', 'start', 'starve', 'state', 'station', 'stay', 'step', 'sterilization', 'stiff', 'still', 'stink', 'stomach', 'stood', 'stop', 'story', 'strength', 'stress', 'strong', 'stuck', 'student', 'study', 'stun', 'style', 'sub', 'submit', 'subway', 'successfully', 'suddenly', 'suffer', 'suggest', 'suitable', 'summary', 'supervise', 'supervisor', 'support', 'sure', 'surgery', 'surin', 'surround', 'survive', 'suwannaphon', 'swipe', 'sympathetic', 'sympathy', 'symptom', 'system', 'systematic', 'systematically', 'table', 'take', 'talented', 'talk', 'talksometimes', 'taste', 'tate', 'tax', 'taxi', 'teacher', 'team', 'teeth', 'tell', 'teller', 'telling', 'ten', 'tend', 'term', 'terrible', 'test', 'thai', 'thailand', 'thanapong', 'thank', 'thankful', 'thanks', 'thapra', 'thawatchai', 'theory', 'therefore', 'thing', 'think', 'thorough', 'thoroughly', 'though', 'thought', 'thousand', 'three', 'throughout', 'thyroid', 'tidy', 'time', 'timely', 'timemy', 'timethe', 'tire', 'today', 'toe', 'together', 'toilet', 'told', 'tomorrow', 'tonight', 'tool', 'tooth', 'top', 'torture', 'touch', 'tower', 'traffic', 'train', 'training', 'transcript', 'transportation', 'travel', 'treat', 'treatment', 'tree', 'true', 'trust', 'try', 'tumor', 'turn', 'turtle', 'twice', 'twin', 'two', 'type', 'unable', 'unbearable', 'unchecked', 'uncle', 'unclear', 'undergo', 'undergone', 'understand', 'understands', 'understood', 'university', 'unknown', 'unlike', 'unnecessarily', 'unnoticed', 'untreated', 'up', 'upset', 'upside', 'urgent', 'urine', 'use', 'user', 'usually', 'utmost', 'vaccinate', 'vaccine', 'value', 'various', 'vast', 'verb', 'vertical', 'visit', 'volunteer', 'wait', 'walk', 'want', 'ward', 'wash', 'waste', 'watch', 'water', 'way', 'wear', 'week', 'weekday', 'weekend', 'welcome', 'well', 'wheelchair', 'whether', 'white', 'whole', 'wife', 'willingness', 'wipe', 'wisdom', 'wish', 'withdraw', 'within', 'without', 'woke', 'woman', 'wood', 'word', 'work', 'worker', 'workplace', 'world', 'worried', 'worry', 'worth', 'would', 'wound', 'wrinkle', 'write', 'writhe', 'wrong', 'wrongly', 'year', 'yell', 'yellow', 'yesterday', 'yet', 'young', 'yourselfcall']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (0, 716)\t1.0\n",
      "  (1, 449)\t0.39842546840405796\n",
      "  (1, 747)\t0.2679279132877789\n",
      "  (1, 566)\t0.36480931740196676\n",
      "  (1, 1250)\t0.4349613379925815\n",
      "  (1, 311)\t0.3300842577801825\n",
      "  (1, 1184)\t0.21951483145712414\n",
      "  (1, 735)\t0.3152332315198845\n",
      "  (1, 557)\t0.14663094051215167\n",
      "  (1, 676)\t0.38538525211049934\n",
      "  (1, 397)\t0.14372815249113124\n",
      "  (2, 1074)\t0.4764251945231486\n",
      "  (2, 172)\t0.8792150101218585\n",
      "  (3, 76)\t0.151908325381707\n",
      "  (3, 138)\t0.151908325381707\n",
      "  (3, 718)\t0.11065576043635458\n",
      "  (3, 1211)\t0.18826699031853955\n",
      "  (3, 280)\t0.10205730261769448\n",
      "  (3, 457)\t0.18826699031853955\n",
      "  (3, 332)\t0.1681499316860051\n",
      "  (3, 1058)\t0.18826699031853955\n",
      "  (3, 389)\t0.18826699031853955\n",
      "  (3, 73)\t0.14803287305347065\n",
      "  (3, 921)\t0.18826699031853955\n",
      "  (3, 1253)\t0.09261263964641178\n",
      "  :\t:\n",
      "  (477, 708)\t1.0\n",
      "  (478, 1254)\t0.4325927301496267\n",
      "  (478, 468)\t0.4325927301496267\n",
      "  (478, 1294)\t0.4325927301496267\n",
      "  (478, 1075)\t0.40555329936957407\n",
      "  (478, 724)\t0.3863685179194107\n",
      "  (478, 721)\t0.21928140293437837\n",
      "  (478, 210)\t0.21793413606687764\n",
      "  (478, 811)\t0.17104636172746263\n",
      "  (479, 257)\t0.7255655625231838\n",
      "  (479, 1272)\t0.4625609008379627\n",
      "  (479, 861)\t0.2723676622000405\n",
      "  (479, 811)\t0.28688727529333286\n",
      "  (479, 557)\t0.22930860280497875\n",
      "  (479, 397)\t0.22476908158923603\n",
      "  (480, 1127)\t0.6244423600048858\n",
      "  (480, 736)\t0.4603390238198771\n",
      "  (480, 1074)\t0.2182619427160509\n",
      "  (480, 557)\t0.5920485170506776\n",
      "  (481, 1088)\t0.424927629770862\n",
      "  (481, 787)\t0.3899392933388204\n",
      "  (481, 1061)\t0.6989209387158664\n",
      "  (481, 1330)\t0.27470425466634585\n",
      "  (481, 609)\t0.19429182042332302\n",
      "  (481, 553)\t0.25628429405070735\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "king-chulalongkorn-memorial-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF), bigrams <<<<<\n",
      "\n",
      " vec_tf_idf_bigram() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 4645\n",
      "\n",
      "\n",
      "\n",
      "['05 58', '10 clock', '10 people', '100 meter', '100th anniversary', '1021 clock', '1030 hr', '1130 medical', '1200 hr', '1320 hr', '13th floor', '14 day', '14 year', '17 jan', '1700 1817', '1711 cod', '17800 cash', '1817 unchecked', '1st floor', '1st place', '20 minute', '20 year', '2010 sense', '2014 today', '2015 appointment', '2016 check', '2016 event', '2016 felt', '2017 go', '21st june', '23 july', '24 05', '24 hour', '24 week', '2555 use', '26 october', '28 year', '29 march', '2nd doctor', '2nd surgery', '2nd time', '30 baht', '300 baht', '35 complete', '35 go', '35 table', '3rd floor', '47 time', '4th floor', '4th year', '500 day', '530 order', '555 kind', '58 go', '58 woman', '5th floor', '600 900', '6th floor', '730 830', '730 hr', '800 1130', '830 hr', '900 clock', '900000 baht', '945 appointment', '945 work', '9th floor', 'a10 full', 'abak say', 'ability level', 'able bury', 'able give', 'able look', 'able maintain', 'able meet', 'able stand', 'able sympathetic', 'able talk', 'abroad tire', 'absolutely guarantee', 'accept queue', 'acceptable size', 'access doctor', 'accident motorcycle', 'accident physical', 'accord disease', 'accord style', 'accuracy choose', 'accurate diagnosis', 'accurately start', 'ache much', 'act mention', 'act service', 'acting repeat', 'action do', 'addition old', 'addition people', 'addition skilled', 'addition wait', 'additional check', 'admit chula', 'admit chulalongkorn', 'admit discourage', 'admit hospital', 'admit still', 'adulyadej government', 'advice answer', 'advice ask', 'advice doctor', 'advice impressed', 'advice introduction', 'advice kind', 'advice mr', 'advice recommend', 'advice respond', 'advice since', 'advice specialized', 'advice staff', 'advice well', 'advise first', 'advise go', 'advise step', 'advise use', 'advise wait', 'afraid another', 'afraid waste', 'afternoon clinic', 'again_and often', 'age 28', 'agree improve', 'air conditioner', 'air cooler', 'allergic private', 'allow return', 'allow share', 'allow time', 'almost do', 'almost every', 'almost faint', 'almost month', 'almost return', 'almost year', 'alone difficult', 'along doctor', 'along suggest', 'already book', 'already follow', 'already full', 'already paid', 'already say', 'already schedule', 'already tire', 'although lot', 'although wait', 'always felt', 'always good', 'always hand', 'always maintain', 'always rely', 'always smile', 'always talk', 'always thought', 'always treat', 'amen excellent', 'amount amount', 'amount calorie', 'analyze diagnosis', 'analyze disease', 'analyze symptom', 'ancient wound', 'angry expression', 'angry husband', 'angry told', 'anniversary program', 'annoy displayed', 'annoyance di', 'annual health', 'annual kidney', 'another famous', 'another half', 'another hospital', 'another nurse', 'another patient', 'another round', 'answer call', 'answer feel', 'answer give', 'answer husband', 'answer much', 'answer press', 'answer question', 'answer ratchaburi', 'answer recommend', 'antenatal chula', 'antenatal clinic', 'antenatal complete', 'antenatal hospital', 'anus since', 'anymore scar', 'anyone comfortable', 'anyone know', 'anyone receive', 'anything else', 'anything everything', 'anything know', 'anything manage', 'anything slow', 'anything special', 'anywhere despite', 'aphinan orthopedic', 'appear tire', 'appendix rupture', 'appoint appointment', 'appoint time', 'appointment 1030', 'appointment 730', 'appointment card', 'appointment citizen', 'appointment contact', 'appointment day', 'appointment depends', 'appointment doctor', 'appointment fit', 'appointment follow', 'appointment inspection', 'appointment language', 'appointment necessary', 'appointment nurse', 'appointment round', 'appointment time', 'appointment undergo', 'appointment wood', 'appreciate miss', 'appreciate visit', 'apprentice come', 'apprentice doctor', 'apprentice good', 'approach doctor', 'appropriately accord', 'april 2016', 'arad hospital', 'area lol', 'around lot', 'around story', 'arrange queue', 'arrange system', 'arrive 2nd', 'arrive hospital', 'arrive relative', 'arrives shock', 'artery disease', 'asawawitoonthip always', 'ask anyone', 'ask anything', 'ask ask', 'ask bottom', 'ask buy', 'ask complain', 'ask courtesy', 'ask diarrhea', 'ask doctor', 'ask hospital', 'ask hour', 'ask hurry', 'ask illness', 'ask lot', 'ask moment', 'ask need', 'ask nurse', 'ask order', 'ask parking', 'ask please', 'ask question', 'ask re', 'ask relief', 'ask rice', 'ask sleep', 'ask sure', 'ask sympathy', 'ask symptom', 'ask would', 'asks blanket', 'asks help', 'asks hospital', 'asks kind', 'aspect pamper', 'assistance problem', 'assistant friendly', 'assoc doctor', 'assoc part', 'ataya good', 'atmin think', 'atmosphere good', 'atrophy doctor', 'attention floor', 'attention mother', 'attention patient', 'attention treatment', 'attentive advise', 'attentive may', 'attentive patient', 'attentive well', 'auditory ear', 'aunt press', 'aunt say', 'aunt wear', 'auntie stood', 'authority example', 'aware persistence', 'away doctor', 'away internal', 'away part', 'away sometimes', 'awesome doctor', 'awesome service', 'awesome word', 'awkward know', 'baby ache', 'baby fever', 'baby give', 'baby guard', 'baby understand', 'baby week', 'bachelor degree', 'back chulalongkorn', 'back forth', 'back original', 'back people', 'back saw', 'back thank', 'back true', 'bad ask', 'bad bad', 'bad consider', 'bad habit', 'bad hospital', 'bad like', 'bad lose', 'bad nurse', 'bad person', 'bad staff', 'bad terrible', 'bad thank', 'bad thing', 'bad treat', 'bad wait', 'badly bad', 'badly much', 'badly patient', 'badly staff', 'badly time', 'badly wait', 'badwhat good', 'bag answer', 'baht gathering', 'baht student', 'baht treat', 'balloon chula', 'band like', 'bang hurt', 'bang phai', 'bangkok chose', 'bangkok doctor', 'bangkok first', 'bank raise', 'basic room', 'basic treatment', 'bathroom 3rd', 'bathroom place', 'beam good', 'beautiful nurse', 'beautiful return', 'beautifully appointment', 'become angry', 'become enthral', 'become large', 'become nurse', 'become pale', 'bed dormitory', 'bed feel', 'bed full', 'bed linen', 'bed patient', 'bed wheelchair', 'begin belly', 'begin lung', 'behind bought', 'believe chula', 'believe doctor', 'belly give', 'belly personnel', 'benefit everyone', 'best hospital', 'best medical', 'best service', 'best specialist', 'best thailand', 'best thank', 'best treatment', 'best value', 'bhumibol adulyadej', 'biggerthe system', 'birth baby', 'birth chula', 'birth control', 'birth daughter', 'birth dec', 'birth even', 'birth first', 'birth home', 'birth hospital', 'birth impressed', 'birth include', 'birth mother', 'birth say', 'birth service', 'birth spent', 'birth therefore', 'birth young', 'bit doctor', 'bit good', 'bit old', 'bit sarcastic', 'bit short', 'bit slow', 'bit small', 'bit stun', 'black blanket', 'blame blame', 'blame charge', 'blanket clothes', 'blanket guy', 'blanket say', 'bleed birth', 'bleeding band', 'bleeding nurse', 'bleeding result', 'blood blood', 'blood change', 'blood check', 'blood collection', 'blood come', 'blood doctor', 'blood flood', 'blood flow', 'blood full', 'blood get', 'blood husband', 'blood long', 'blood pressure', 'blood shock', 'blood side', 'blood test', 'blossom woman', 'blue line', 'blurry talk', 'bobcat first', 'body analyze', 'body front', 'body mind', 'body think', 'boil egg', 'bold air', 'bone marrow', 'book doctor', 'book queue', 'boonyakanok chulalongkorn', 'bottom profile', 'bought flower', 'bow mention', 'box maybe', 'boyfriend 2nd', 'brain damage', 'brain drain', 'brain surgery', 'brain tumor', 'brawny people', 'break cataract', 'break feel', 'briefly hidden', 'brightens thank', 'bring another', 'bring bad', 'bring boyfriend', 'bring child', 'bring father', 'bring girlfriend', 'bring grandma', 'bring person', 'bring profession', 'broken point', 'broken repair', 'brother car', 'brother girlfriend', 'brother hospital', 'brought child', 'brought chulalongkorn', 'brutal 555', 'bts bts', 'bts government', 'bts mrt', 'bts station', 'building almost', 'building far', 'building girlfriend', 'building good', 'building hour', 'building impressive', 'building lovely', 'building may', 'building morning', 'building new', 'building perform', 'building phor', 'building ror', 'building rule', 'building smelly', 'building spoke', 'building staff', 'building supervisor', 'building surround', 'building taxi', 'bullying examination', 'buri suddenly', 'burning burning', 'burning writhe', 'bury birth', 'bury consult', 'bury free', 'bus bts', 'busy plus', 'busy refer', 'buy please', 'cabinet time', 'call card', 'call carpool', 'call follow', 'call golf', 'call guard', 'call hospital', 'call husband', 'call meet', 'call morning', 'call nurse', 'call patient', 'call queue', 'call reserve', 'call star', 'calmness like', 'calorie say', 'cancer doctor', 'cancer institute', 'cancer thyroid', 'cancer well', 'car chula', 'car crash', 'car elevator', 'car go', 'car husband', 'car let', 'car parking', 'car people', 'car push', 'car say', 'car sleep', 'card 730', 'card accept', 'card antenatal', 'card bring', 'card continue', 'card cost', 'card early', 'card feel', 'card file', 'card first', 'card gold', 'card kind', 'card late', 'card make', 'card morning', 'card must', 'card pick', 'card plug', 'card reduce', 'card screen', 'card self', 'card sit', 'card slot', 'card social', 'card submit', 'card treatment', 'card use', 'card wait', 'care baby', 'care give', 'care patient', 'care since', 'career believe', 'careful disease', 'carefully analyze', 'carpool staff', 'carry child', 'cart lose', 'cart pick', 'cart tell', 'case effectively', 'case emergency', 'case father', 'cash commission', 'cash moreover', 'cataract service', 'caught traffic', 'cause doctor', 'cause everyone', 'cause go', 'cause walk', 'central operating', 'certain level', 'certificate bullying', 'certificate month', 'cesarean doctor', 'cha fan', 'chance admit', 'chance go', 'change almost', 'change bed', 'change clothes', 'change quickly', 'change system', 'change tire', 'chaotic health', 'characteristic patient', 'chareon somsri', 'charge pay', 'charge system', 'chart reading', 'chase like', 'chaung service', 'cheaper assistance', 'cheaper economical', 'check 20', 'check almost', 'check answer', 'check bring', 'check chula', 'check department', 'check diagnose', 'check doctor', 'check document', 'check every', 'check fight', 'check girlfriend', 'check hospital', 'check in', 'check nearly', 'check necessary', 'check new', 'check observation', 'check patient', 'check privilege', 'check queue', 'check really', 'check right', 'check salt', 'check time', 'check visit', 'check well', 'check within', 'checked addition', 'checked doctor', 'checked mother', 'checked teeth', 'cheer doctor', 'child accident', 'child building', 'child check', 'child chulalongkorn', 'child department', 'child doctor', 'child father', 'child fever', 'child fight', 'child heal', 'child help', 'child husband', 'child nurse', 'child october', 'child pale', 'child park', 'child province', 'child room', 'child still', 'child throughout', 'child time', 'child vaccinate', 'child withdraw', 'child young', 'chon buri', 'choose act', 'choose delivery', 'choose doctor', 'choose trust', 'choose use', 'chose hospital', 'chronic coronary', 'chula 1320', 'chula continue', 'chula disappears', 'chula doctor', 'chula good', 'chula hospital', 'chula reach', 'chulalongkorn hospital', 'chulalongkorn memorial', 'chulalongkorn refer', 'citizen submit', 'city center', 'civil service', 'class hospital', 'clean convenient', 'clean ever', 'clean place', 'clean tidy', 'clearly patient', 'clinic bobcat', 'clinic book', 'clinic clinic', 'clinic dirty', 'clinic doctor', 'clinic government', 'clinic impressed', 'clinic medical', 'clinic outside', 'clinic pay', 'clinic private', 'clinic skin', 'clinic staff', 'clinic still', 'clinic weekend', 'clock 10', 'clock ask', 'clock call', 'clock check', 'clock morning', 'clock next', 'clock pm', 'clock still', 'clock time', 'close good', 'close home', 'close keep', 'close sky', 'close unchecked', 'clothes bleeding', 'clothes fever', 'clothes work', 'cod long', 'cold fever', 'cold hahahahahahaha', 'cold short', 'cold sneeze', 'collection officer', 'collection wait', 'combine many', 'come able', 'come check', 'come doctor', 'come every', 'come feel', 'come know', 'come lose', 'come profile', 'come receive', 'come say', 'come see', 'come speak', 'come surgery', 'come talk', 'come today', 'come told', 'come tomorrow', 'come treat', 'come wait', 'come work', 'comfortable go', 'comfortable headache', 'comfortable hospital', 'comfortable relieve', 'commission slow', 'common personality', 'common room', 'compare place', 'compare private', 'compare service', 'compassion former', 'complain lot', 'complain unlike', 'complain waste', 'complaint plus', 'complete bachelor', 'complete different', 'complete pressure', 'complete story', 'complete wait', 'complete would', 'completely different', 'completely heal', 'completely thank', 'computer system', 'conclude service', 'conclusion child', 'conclusion like', 'conclusion mother', 'condition everything', 'condition good', 'condition unbearable', 'conditioner broken', 'conditioner cold', 'confidence although', 'confident quality', 'confine pay', 'confuse elder', 'confuse many', 'conjunction doctor', 'connect way', 'consider good', 'consider long', 'consider ok', 'consider timely', 'consider treatment', 'consult doctor', 'consult social', 'consultation say', 'contact ask', 'contact back', 'contact include', 'contact number', 'continue provide', 'continue ride', 'continue sleep', 'continue talk', 'continued improve', 'contrary white', 'control impressed', 'control pill', 'convenient drive', 'convenient fast', 'convenient find', 'convenient offer', 'convenient patient', 'convenient receive', 'convenient restaurant', 'convenient ride', 'convenient transportation', 'conveniently locate', 'convince wait', 'cook cook', 'cook say', 'cool matter', 'cooler cool', 'coordination probably', 'coordination registration', 'coronary artery', 'cost high', 'cost much', 'cost pay', 'cost thousand', 'cost treatment', 'costume executive', 'could find', 'could handle', 'could move', 'could read', 'counter say', 'courtesy etiquette', 'cover think', 'cradle bring', 'crash brain', 'crazy person', 'credibly staff', 'credit card', 'cross society', 'crowd chaotic', 'cry everyday', 'cry front', 'cry reconcile', 'cue leaf', 'cure first', 'cure leukemia', 'cure many', 'current disease', 'currently treat', 'curtain afraid', 'curtain think', 'curtain told', 'curtly yell', 'cut horizontally', 'cut lot', 'cut need', 'cut second', 'cut vertical', 'cute doctor', 'cute friendly', 'cute give', 'cute however', 'cute lot', 'cute nurse', 'dad cold', 'daeng bts', 'damage touch', 'date travel', 'daughter 14', 'daughter hospital', 'daughter include', 'daughter suffer', 'daughter survive', 'day almost', 'day bleed', 'day clock', 'day encourage', 'day feel', 'day food', 'day get', 'day hospital', 'day inspection', 'day know', 'day make', 'day morphine', 'day never', 'day pay', 'day rain', 'day report', 'day staff', 'day still', 'day surgery', 'day test', 'day time', 'day today', 'day without', 'dead bring', 'death almost', 'death patient', 'death reborn', 'dec 2nd', 'december birth', 'decide stop', 'decision choose', 'decision maintain', 'decision sure', 'decisive decision', 'dedicate body', 'dee good', 'deep hospital', 'deeply root', 'degree kasetsart', 'delayed many', 'delivery certificate', 'delivery document', 'delivery nursing', 'delivery room', 'dental department', 'department care', 'department good', 'department gynecology', 'department include', 'department look', 'department number', 'department ongoing', 'department receive', 'department result', 'department rip', 'department say', 'department split', 'department understands', 'department wait', 'depend treatment', 'depend various', 'depends time', 'describe treat', 'despite blood', 'despite doctor', 'despite issue', 'despite lot', 'detail ask', 'detail found', 'detail like', 'detail tool', 'detail well', 'detailed consultation', 'detailed everyone', 'detailed examination', 'detailed nurse', 'detect cancer', 'deterioration easy', 'develop duplicate', 'develop lot', 'developed especially', 'development medical', 'device modern', 'di find', 'di relative', 'diagnose disease', 'diagnosis disease', 'diagnosis health', 'diagnosis sick', 'diagnosis wait', 'different private', 'different service', 'different treat', 'differently cause', 'difficult case', 'difficult doctor', 'difficult find', 'difficult hit', 'difficult traffic', 'difficult understand', 'difficult various', 'diligent saw', 'directly understand', 'director chula', 'dirty management', 'disappear completely', 'disappears plus', 'discourage secretly', 'discriminatory treatment', 'disease accurately', 'disease begin', 'disease credibly', 'disease doctor', 'disease heart', 'disease however', 'disease interested', 'disease medical', 'disease nurse', 'disease often', 'disease recently', 'disease sle', 'disease small', 'disease specialized', 'disease thoroughly', 'disease treat', 'displayed like', 'dissection ancient', 'distract characteristic', 'dizzy cold', 'do ask', 'do card', 'do compare', 'do patient', 'do slowly', 'do symptom', 'do well', 'doctor answer', 'doctor appoint', 'doctor appointment', 'doctor apprentice', 'doctor baby', 'doctor blood', 'doctor care', 'doctor cha', 'doctor check', 'doctor checked', 'doctor chula', 'doctor clinic', 'doctor come', 'doctor consider', 'doctor cure', 'doctor cut', 'doctor cute', 'doctor day', 'doctor dee', 'doctor detailed', 'doctor do', 'doctor doctor', 'doctor especially', 'doctor every', 'doctor everyone', 'doctor everything', 'doctor examine', 'doctor explain', 'doctor fee', 'doctor feel', 'doctor fever', 'doctor fight', 'doctor finish', 'doctor first', 'doctor found', 'doctor gentle', 'doctor give', 'doctor go', 'doctor god', 'doctor good', 'doctor half', 'doctor handsome', 'doctor hospital', 'doctor illness', 'doctor immediately', 'doctor impressed', 'doctor impressive', 'doctor inform', 'doctor instruct', 'doctor jaidee', 'doctor kampol', 'doctor keng', 'doctor kind', 'doctor king', 'doctor knew', 'doctor know', 'doctor look', 'doctor make', 'doctor many', 'doctor medicine', 'doctor meet', 'doctor must', 'doctor nurse', 'doctor officer', 'doctor open', 'doctor operating', 'doctor professor', 'doctor provide', 'doctor province', 'doctor ready', 'doctor regularly', 'doctor right', 'doctor say', 'doctor service', 'doctor shoulder', 'doctor speaks', 'doctor specialized', 'doctor spoke', 'doctor staff', 'doctor stand', 'doctor successfully', 'doctor support', 'doctor take', 'doctor talk', 'doctor team', 'doctor tell', 'doctor thanapong', 'doctor thank', 'doctor told', 'doctor turtle', 'doctor use', 'doctor walk', 'doctor well', 'doctor write', 'document check', 'document hospital', 'document like', 'document send', 'document wipe', 'dog act', 'donate new', 'doorbell woke', 'dormitory heal', 'downstairs say', 'downstairs wait', 'dr assoc', 'dr jiran', 'dr keng', 'dr rungsak', 'dr surin', 'dr thawatchai', 'drain chase', 'drain skull', 'drama nutrition', 'draw blood', 'drill bone', 'drive car', 'drive parking', 'driver stuck', 'drove front', 'drug heart', 'drug use', 'due inconvenience', 'due many', 'dumped 1st', 'duplicate system', 'duty clock', 'ear examination', 'early morning', 'early order', 'ease unnoticed', 'easily respectfully', 'easy get', 'easy parking', 'easy return', 'easy treat', 'easy understand', 'easy walk', 'eat even', 'eat everything', 'eat non', 'eat say', 'economical compare', 'education department', 'egg cost', 'egg day', 'egg egg', 'either side', 'elder brother', 'elder gradually', 'elder hospital', 'electric train', 'elevator 3rd', 'elevator phor', 'elevator told', 'eloquently easy', 'eloquently explain', 'else bring', 'else urgent', 'emergency consider', 'emergency page', 'emergency people', 'emergency preposter', 'emergency room', 'emergency surgery', 'emergency time', 'emotion reason', 'employee ground', 'encounter blood', 'encourage child', 'encourage even', 'encourage everyone', 'encouragement many', 'encouragement patient', 'encouragement thai', 'encouragement treatment', 'encourages everyone', 'endoscopic room', 'energy walk', 'enough front', 'enough wait', 'enough way', 'enter delivery', 'enthral deeply', 'entire medical', 'equal image', 'equal standard', 'equip convenient', 'equipment allergic', 'equipment well', 'escape haha', 'especially 4th', 'especially access', 'especially blue', 'especially dr', 'especially officer', 'especially profile', 'especially sawasdee', 'etiquette always', 'etiquette well', 'even 26', 'even appointment', 'even clinic', 'even impressive', 'even lift', 'even pay', 'even poor', 'even special', 'even stay', 'even though', 'even try', 'even work', 'event day', 'ever come', 'ever mother', 'ever nurse', 'ever patrol', 'ever since', 'every class', 'every day', 'every department', 'every floor', 'every meal', 'every medical', 'every month', 'every nurse', 'every point', 'every step', 'every three', 'every time', 'every year', 'everyday come', 'everyone good', 'everyone know', 'everyone make', 'everyone patient', 'everyone polite', 'everyone ran', 'everyone really', 'everyone receive', 'everyone second', 'everyone seem', 'everyone try', 'everyone use', 'everyone work', 'everything ask', 'everything doctor', 'everything excellent', 'everything smile', 'everything sorry', 'everywhere doctor', 'everywhere patient', 'examination check', 'examination confident', 'examination disease', 'examination doctor', 'examination every', 'examination finish', 'examination good', 'examination result', 'examination room', 'examination tate', 'examination teacher', 'examination told', 'examination within', 'examine body', 'examine early', 'examine follow', 'examine hour', 'examine patient', 'example doctor', 'excellent doctor', 'excellent service', 'excellent special', 'excellent staff', 'exchange medication', 'executive agree', 'expand building', 'expand convenient', 'expansive shady', 'expect department', 'expect good', 'expensive 900000', 'expensive acceptable', 'expensive collect', 'expensive doctor', 'expensive expensive', 'expensive food', 'expensive suitable', 'expensive thought', 'experience cesarean', 'experienced expert', 'expert question', 'expert system', 'expertise treatment', 'explain long', 'explain much', 'explain understood', 'explain verb', 'explain well', 'explanation conclude', 'explanation unclear', 'expression facial', 'expression like', 'expression stood', 'extra fever', 'extreme go', 'extremely extreme', 'extremely hot', 'face appear', 'facial expression', 'facial reaction', 'facility large', 'faculty dedicate', 'faculty medicine', 'faint many', 'fairy costume', 'family despite', 'family treat', 'family use', 'famous hospital', 'fan medical', 'far away', 'far tell', 'fast absolutely', 'fast examination', 'fast queue', 'fast reasonable', 'fast service', 'fastif free', 'father break', 'father come', 'father condition', 'father difficult', 'father give', 'father go', 'father heal', 'father kidney', 'father say', 'father suffer', 'father time', 'father use', 'father wish', 'father worry', 'fee doctor', 'feel anything', 'feel bad', 'feel comfortable', 'feel disappointed', 'feel ease', 'feel everyone', 'feel first', 'feel good', 'feel happy', 'feel heard', 'feel home', 'feel impressed', 'feel irritated', 'feel miracle', 'feel pity', 'feel safe', 'feel satisfied', 'feel sore', 'feel well', 'feeling treatment', 'felt chulalongkorn', 'felt dizzy', 'felt felt', 'felt good', 'felt like', 'felt staff', 'felt strength', 'felt way', 'female staff', 'fever asks', 'fever bring', 'fever cold', 'fever confine', 'fever drain', 'fever headache', 'fever measure', 'fever serve', 'fierce place', 'fight child', 'fight doctor', 'fight piece', 'fight survive', 'file 945', 'file building', 'file downstairs', 'file file', 'file level', 'file sent', 'file top', 'financial room', 'find cause', 'find good', 'find parking', 'find path', 'find patient', 'find place', 'find relative', 'find respiratory', 'find way', 'fine know', 'finger call', 'finish eat', 'finish examination', 'finish examine', 'finish go', 'finish matter', 'finish story', 'first admit', 'first child', 'first come', 'first flicker', 'first floor', 'first hospital', 'first know', 'first matter', 'first morning', 'first person', 'first step', 'first thing', 'first thought', 'first time', 'first tooth', 'first worried', 'fit person', 'five clock', 'flicker light', 'flood leg', 'floor air', 'floor building', 'floor long', 'floor many', 'floor overall', 'floor phrapharod', 'floor phraphit', 'floor please', 'floor really', 'floor sassy', 'floor small', 'floor social', 'floor turn', 'floor wrong', 'flow chart', 'flow non', 'flower get', 'follow advice', 'follow call', 'follow prescription', 'follow up', 'follow wait', 'follow well', 'food 14', 'food eat', 'food pay', 'food poison', 'food sell', 'foot get', 'foot staff', 'footballer ten', 'forever mr', 'forever patient', 'forget kind', 'forget salary', 'forgotten blurry', 'form send', 'former patient', 'forth angry', 'fortune teller', 'fortune telling', 'found doctor', 'found everywhere', 'found explain', 'found hospital', 'found service', 'four half', 'fracture first', 'free bed', 'free charge', 'free cost', 'free wait', 'friend behind', 'friend ok', 'friendly 20', 'friendly doctor', 'friendly fierce', 'friendly friendly', 'friendly impressed', 'friendly patient', 'friendly personality', 'friendly service', 'friendly specialist', 'frighten well', 'front building', 'front cart', 'front central', 'front elevator', 'front emergency', 'front examination', 'front icu', 'front much', 'frustration upset', 'full check', 'full nurse', 'full special', 'fully equip', 'garbage collection', 'garden say', 'gastritis always', 'gastritis check', 'gathering relative', 'general auditory', 'general state', 'gentle inject', 'get answer', 'get anything', 'get bed', 'get blood', 'get car', 'get card', 'get chance', 'get close', 'get dental', 'get facial', 'get hospital', 'get hurry', 'get information', 'get lot', 'get pain', 'get pregnancy', 'get queue', 'get sala', 'get shit', 'get sick', 'get surgery', 'giggle lot', 'girlfriend annual', 'girlfriend become', 'girlfriend blood', 'girlfriend go', 'girlfriend saw', 'give advice', 'give birth', 'give child', 'give easily', 'give encouragement', 'give excellent', 'give good', 'give importance', 'give lot', 'give medicine', 'give new', 'give pain', 'give patient', 'give think', 'give treat', 'give workplace', 'glass 4th', 'gloomy reply', 'go abroad', 'go alone', 'go antenatal', 'go ask', 'go building', 'go bury', 'go call', 'go check', 'go choose', 'go chula', 'go doctor', 'go duty', 'go elevator', 'go examination', 'go feel', 'go find', 'go first', 'go get', 'go history', 'go home', 'go hospital', 'go husband', 'go impressed', 'go intern', 'go live', 'go many', 'go new', 'go next', 'go part', 'go physical', 'go press', 'go ray', 'go raya', 'go receive', 'go regular', 'go see', 'go service', 'go since', 'go stand', 'go strong', 'go study', 'go subway', 'go table', 'go treat', 'go treatment', 'go use', 'go wait', 'go walk', 'go ward', 'god death', 'gold card', 'golf cart', 'good accurate', 'good advice', 'good analyze', 'good answer', 'good antenatal', 'good ask', 'good atmosphere', 'good badwhat', 'good bold', 'good brutal', 'good call', 'good check', 'good child', 'good condition', 'good consider', 'good consultation', 'good cute', 'good diagnosis', 'good doctor', 'good easy', 'good etiquette', 'good ever', 'good every', 'good excellent', 'good fast', 'good father', 'good feel', 'good fortune', 'good friendly', 'good friendship', 'good give', 'good good', 'good guidance', 'good habit', 'good half', 'good handsome', 'good hospital', 'good image', 'good impressed', 'good impressive', 'good information', 'good kind', 'good know', 'good knowledge', 'good like', 'good make', 'good management', 'good manner', 'good many', 'good may', 'good measure', 'good modern', 'good mood', 'good national', 'good natured', 'good nurse', 'good nursing', 'good opinion', 'good park', 'good parking', 'good patient', 'good pay', 'good people', 'good place', 'good quality', 'good queue', 'good recommend', 'good recommendation', 'good right', 'good separate', 'good service', 'good speech', 'good step', 'good story', 'good system', 'good talented', 'good teacher', 'good thank', 'good therefore', 'good thing', 'good though', 'good treatment', 'good understand', 'good use', 'good volunteer', 'good wait', 'good welcome', 'good work', 'good young', 'goodbye let', 'goodness cause', 'goodwant use', 'government hospital', 'government office', 'grace faculty', 'gradually explain', 'gradually say', 'grandma doctor', 'grandma father', 'grandma treat', 'grandma wait', 'grant use', 'great attention', 'great grace', 'great medical', 'great service', 'great smile', 'ground floor', 'guarantee doctor', 'guarantee many', 'guard come', 'guard request', 'guard see', 'guard wait', 'guest another', 'guidance procedure', 'guy black', 'guy busy', 'gynecology department', 'gynecology never', 'habit back', 'haha ran', 'hahaha queue', 'half day', 'half hour', 'half improvement', 'half star', 'half ten', 'half worry', 'hand give', 'handle doctor', 'handsome nurse', 'happen wait', 'happily forever', 'happy advise', 'happy healthy', 'happy impressed', 'hard beam', 'hard find', 'hard stomach', 'head away', 'head sidewalk', 'head toe', 'headache bad', 'headache wait', 'heal feeling', 'heal nov', 'heal pain', 'heal take', 'heal walk', 'heal well', 'heal yet', 'health check', 'health get', 'health good', 'health people', 'healthy back', 'healthy work', 'hear term', 'heard people', 'heard time', 'heart ask', 'heart balloon', 'heart disease', 'heart four', 'heart make', 'heart mr', 'heavy enough', 'heavy overall', 'heavy still', 'heck pay', 'help call', 'help complain', 'help coordination', 'help drill', 'help finish', 'help help', 'help improve', 'help mother', 'help people', 'help request', 'help ring', 'help see', 'help surgery', 'helpful doctor', 'helpful helpful', 'hidden distract', 'high inconvenient', 'high please', 'high standard', 'hip deterioration', 'history complete', 'history do', 'history history', 'history kind', 'history measure', 'history order', 'history recommend', 'history yet', 'hmmm seriously', 'hold baby', 'hold child', 'hole go', 'home again_and', 'home baby', 'home easy', 'home employee', 'home front', 'home house', 'home mother', 'home must', 'home often', 'home safety', 'home use', 'hope become', 'hope post', 'horizontally feel', 'hospital addition', 'hospital age', 'hospital almost', 'hospital already', 'hospital another', 'hospital anymore', 'hospital appointment', 'hospital attention', 'hospital aunt', 'hospital awesome', 'hospital bang', 'hospital bangkok', 'hospital benefit', 'hospital best', 'hospital bore', 'hospital chronic', 'hospital chulalongkorn', 'hospital city', 'hospital close', 'hospital combine', 'hospital compare', 'hospital convenient', 'hospital conveniently', 'hospital date', 'hospital day', 'hospital delivery', 'hospital despite', 'hospital doctor', 'hospital dr', 'hospital easy', 'hospital energy', 'hospital ever', 'hospital every', 'hospital feel', 'hospital follow', 'hospital fully', 'hospital give', 'hospital go', 'hospital good', 'hospital government', 'hospital grant', 'hospital heart', 'hospital high', 'hospital impressed', 'hospital improve', 'hospital inform', 'hospital late', 'hospital like', 'hospital look', 'hospital lose', 'hospital lot', 'hospital lump', 'hospital maintain', 'hospital management', 'hospital many', 'hospital match', 'hospital meaning', 'hospital medical', 'hospital minute', 'hospital mother', 'hospital much', 'hospital never', 'hospital nurse', 'hospital passageway', 'hospital past', 'hospital people', 'hospital place', 'hospital please', 'hospital pregnant', 'hospital private', 'hospital probably', 'hospital provide', 'hospital queue', 'hospital receive', 'hospital refer', 'hospital run', 'hospital seize', 'hospital send', 'hospital sent', 'hospital service', 'hospital sick', 'hospital social', 'hospital special', 'hospital staff', 'hospital still', 'hospital submit', 'hospital system', 'hospital take', 'hospital tell', 'hospital thai', 'hospital thailand', 'hospital thank', 'hospital think', 'hospital thought', 'hospital today', 'hospital torture', 'hospital treat', 'hospital treatment', 'hospital try', 'hospital use', 'hospital volunteer', 'hospital wait', 'hospital walk', 'hospital watch', 'hospital weekday', 'hospital whole', 'hospital wife', 'hospital work', 'hospital year', 'hospital yesterday', 'hour blood', 'hour call', 'hour check', 'hour day', 'hour fever', 'hour full', 'hour half', 'hour husband', 'hour know', 'hour mother', 'hour patient', 'hour see', 'hour sit', 'hour wait', 'house ratchada', 'housewife male', 'however give', 'however much', 'hr card', 'hr inspect', 'hr order', 'hr today', 'hr welcome', 'hug cry', 'hurry know', 'hurry like', 'hurry mistake', 'hurt wound', 'husband ask', 'husband asks', 'husband call', 'husband carry', 'husband come', 'husband decide', 'husband drove', 'husband go', 'husband hold', 'husband home', 'husband nurse', 'husband retreat', 'husband scar', 'husband take', 'husband think', 'icu room', 'id card', 'ie vaccine', 'illness make', 'illness request', 'image forever', 'image phayabab', 'immediately need', 'implies common', 'importance treatment', 'importantly cost', 'impressed clean', 'impressed cute', 'impressed department', 'impressed detail', 'impressed doctor', 'impressed every', 'impressed give', 'impressed good', 'impressed hospital', 'impressed many', 'impressed medical', 'impressed quality', 'impressed service', 'impressed since', 'impressed sub', 'impressed university', 'impressive doctor', 'impressive get', 'impressive job', 'impressive nurse', 'impressive quality', 'impressive service', 'impressive wait', 'improve know', 'improve look', 'improve manner', 'improve old', 'improve queue', 'improve service', 'improve staff', 'improve system', 'in queue', 'include 4th', 'include birth', 'include doctor', 'include hospital', 'include nurse', 'include ray', 'include restriction', 'inconvenience watch', 'inconvenient swipe', 'increase every', 'increase salary', 'indefinitely really', 'indicate annoyance', 'inform ask', 'inform less', 'inform medical', 'inform medication', 'information coordination', 'information friendly', 'information need', 'information really', 'information time', 'inject feel', 'inpatient hospital', 'insert card', 'inside detailed', 'inside reach', 'inside staff', 'inspect 1200', 'inspect building', 'inspection rays', 'inspection staff', 'instead thank', 'institute building', 'institution although', 'instruct go', 'insufficient personnel', 'insult go', 'intelligence allow', 'interested expand', 'interested say', 'intern doctor', 'internal examination', 'international standard', 'intestinal disease', 'introduction get', 'irritated found', 'irritated treatment', 'irritated wife', 'issue complete', 'issue whole', 'jaidee checked', 'jam service', 'jam today', 'jan 2017', 'january doctor', 'jiran aphinan', 'july 58', 'jump car', 'jump mouse', 'june come', 'kampol suwannaphon', 'kantakarn department', 'kasetsart university', 'keep come', 'keep doctor', 'keng arad', 'keng daughter', 'keng experienced', 'keng good', 'kept look', 'kesaraporn kiat', 'key service', 'kiat phanitkij', 'kidney examination', 'kidney surgery', 'kind compassion', 'kind cute', 'kind decisive', 'kind describe', 'kind friendly', 'kind give', 'kind lovely', 'kind press', 'kind provide', 'kind service', 'kind want', 'kind work', 'king bhumibol', 'king chulalongkorn', 'knee deep', 'knew everyone', 'knew intestinal', 'know advise', 'know anyone', 'know anything', 'know appoint', 'know day', 'know directly', 'know doctor', 'know encourages', 'know give', 'know go', 'know guy', 'know happen', 'know insult', 'know live', 'know long', 'know much', 'know patient', 'know please', 'know postpone', 'know professor', 'know say', 'know sigh', 'know step', 'know sterilization', 'know still', 'know symptom', 'know system', 'know thanks', 'know whether', 'knowledge expertise', 'knowledge medical', 'knowledge speaks', 'language work', 'large hospital', 'large number', 'large patient', 'large size', 'last hour', 'last october', 'last queue', 'last three', 'late irritated', 'late night', 'late travel', 'later time', 'layer tell', 'leaf plug', 'leave baby', 'leave card', 'leave may', 'leg reply', 'less day', 'less minute', 'let jump', 'let lie', 'let people', 'let user', 'let walk', 'leukemia chulalongkorn', 'level go', 'level layer', 'level still', 'level tell', 'lie push', 'lie staff', 'life everyone', 'life healthy', 'life hospital', 'life money', 'life next', 'life thank', 'lift service', 'lift various', 'light brightens', 'like ask', 'like aunt', 'like dead', 'like develop', 'like find', 'like friend', 'like gastritis', 'like go', 'like good', 'like government', 'like heard', 'like helpful', 'like hospital', 'like implies', 'like know', 'like long', 'like many', 'like much', 'like need', 'like nurse', 'like pas', 'like people', 'like pig', 'like praise', 'like private', 'like put', 'like real', 'like reply', 'like review', 'like say', 'like service', 'like sick', 'like slept', 'like social', 'like tell', 'like today', 'like wait', 'like yesterday', 'line long', 'line medical', 'linen wash', 'little bit', 'little confuse', 'little difficult', 'little insufficient', 'little longer', 'little parking', 'little polite', 'little talk', 'live bangkok', 'live life', 'live many', 'liver detect', 'living normal', 'll ask', 'locate next', 'location personnel', 'location reputation', 'lol doctor', 'long 800', 'long addition', 'long come', 'long doctor', 'long enough', 'long especially', 'long heal', 'long queue', 'long time', 'long timemy', 'long timethe', 'long wait', 'long well', 'longer 20', 'look attentive', 'look irritated', 'look like', 'look much', 'look nursing', 'look police', 'look really', 'look service', 'look staffnotice', 'look thank', 'look thoroughly', 'look time', 'look understands', 'look well', 'lose encouragement', 'lose forgotten', 'lose lot', 'lose ran', 'losing money', 'lot blood', 'lot building', 'lot burden', 'lot check', 'lot convenient', 'lot doctor', 'lot health', 'lot increase', 'lot information', 'lot lot', 'lot medicine', 'lot money', 'lot patient', 'lot people', 'lot queue', 'lot smile', 'lot staff', 'lot work', 'loud know', 'love hospital', 'love living', 'lovely everyone', 'lovely nurse', 'lovely staff', 'low acting', 'luck family', 'luckily nurse', 'lump anus', 'lump become', 'lump original', 'lung disease', 'luxury car', 'maintain good', 'maintain health', 'maintain place', 'maintain standard', 'maintain well', 'make angry', 'make appointment', 'make cheer', 'make easy', 'make face', 'make feel', 'make heart', 'make month', 'make noise', 'make patient', 'make queue', 'make recover', 'make request', 'make treatment', 'male nurse', 'manage many', 'management look', 'management system', 'manner good', 'manner seriously', 'manner training', 'many building', 'many disease', 'many doctor', 'many family', 'many floor', 'many hospital', 'many hour', 'many issue', 'many medical', 'many need', 'many occasion', 'many patience', 'many patient', 'many people', 'many place', 'many question', 'many receive', 'many round', 'many specialized', 'many state', 'many step', 'many time', 'many way', 'march 2015', 'marrow atrophy', 'marrow doctor', 'marrow expensive', 'match match', 'matter annoy', 'matter fever', 'matter gradually', 'matter long', 'matter much', 'matter optimistic', 'may able', 'may bit', 'may bus', 'may goodness', 'may hospital', 'may little', 'may look', 'may sick', 'may speak', 'may stiff', 'may wait', 'maybe since', 'meal thank', 'meaning go', 'measure blood', 'measure heart', 'measure look', 'measure pressure', 'medical certificate', 'medical clinic', 'medical department', 'medical development', 'medical device', 'medical equipment', 'medical facility', 'medical faculty', 'medical institution', 'medical record', 'medical school', 'medical staff', 'medical student', 'medical team', 'medical treatment', 'medication cure', 'medication treatment', 'medication use', 'medicine along', 'medicine bag', 'medicine conjunction', 'medicine doctor', 'medicine fee', 'medicine home', 'medicine many', 'medicine nurse', 'medicine pay', 'medicine well', 'mee chance', 'meet appointment', 'meet doctor', 'meet say', 'meeting authority', 'melodious word', 'member registration', 'memorial hospital', 'memory bad', 'mention much', 'mention rating', 'mention riyabha', 'metaphor hear', 'meter queue', 'method many', 'method throughout', 'midday wait', 'mind close', 'mind intelligence', 'mind please', 'mind terrible', 'minute away', 'minute doctor', 'minute hospital', 'minute pass', 'minute sigh', 'minute wait', 'miracle receive', 'miss good', 'mistake cause', 'mistake murmur', 'mobile phone', 'modern doctor', 'modern excellent', 'modern medical', 'modern tool', 'modern treatment', 'mom go', 'moment 20', 'money already', 'money everywhere', 'money give', 'money many', 'money probably', 'money staff', 'month appointment', 'month government', 'month know', 'month like', 'month receive', 'month service', 'month stay', 'mood always', 'moreover vertical', 'morning 17', 'morning 1711', 'morning answer', 'morning card', 'morning clock', 'morning could', 'morning doctor', 'morning go', 'morning king', 'morning open', 'morning person', 'morning run', 'morning since', 'morning surgery', 'morphine know', 'morphine medicine', 'mother able', 'mother admit', 'mother annual', 'mother conclusion', 'mother could', 'mother elder', 'mother enter', 'mother felt', 'mother get', 'mother good', 'mother hospital', 'mother medical', 'mother must', 'mother patient', 'mother sent', 'mother take', 'mother think', 'mother told', 'mother treat', 'mother way', 'mother well', 'motorcycle strong', 'mouse short', 'move car', 'move hold', 'move hospital', 'mp cover', 'mr kesaraporn', 'mr medicine', 'mr sasi', 'mr theory', 'mrt fast', 'much able', 'much another', 'much appreciate', 'much aspect', 'much bleeding', 'much blood', 'much brother', 'much cheaper', 'much cry', 'much even', 'much explanation', 'much found', 'much patience', 'much people', 'much run', 'much take', 'much think', 'much time', 'much treatment', 'much unknown', 'much well', 'mum give', 'murmur really', 'must child', 'must eat', 'must frustrate', 'must go', 'must life', 'must refer', 'must say', 'must see', 'must starve', 'must wait', 'national footballer', 'national hospital', 'national standard', 'natured frustration', 'natured staff', 'nawamin building', 'near death', 'nearly 500', 'nearly noon', 'necessary careful', 'necessary encouragement', 'need another', 'need draw', 'need guarantee', 'need help', 'need let', 'need make', 'need queue', 'need use', 'negative term', 'never change', 'never developed', 'never do', 'never forget', 'never know', 'never mind', 'never receive', 'never see', 'never treat', 'never use', 'new clean', 'new life', 'new mother', 'new nurse', 'new patient', 'new queue', 'next bts', 'next matter', 'next station', 'next time', 'next year', 'night need', 'night please', 'noise talk', 'non discriminatory', 'non slang', 'non stop', 'nong fight', 'noon blame', 'noon ray', 'normal general', 'normal life', 'normal relative', 'normally hospital', 'nothing please', 'nov 47', 'nowadays still', 'number much', 'number patient', 'number senior', 'number side', 'number split', 'nurse 13th', 'nurse 9th', 'nurse action', 'nurse advise', 'nurse always', 'nurse ask', 'nurse assistant', 'nurse ataya', 'nurse attentive', 'nurse call', 'nurse care', 'nurse change', 'nurse check', 'nurse child', 'nurse chula', 'nurse contrary', 'nurse cute', 'nurse doctor', 'nurse especially', 'nurse expect', 'nurse friendly', 'nurse give', 'nurse good', 'nurse half', 'nurse heck', 'nurse hospital', 'nurse housewife', 'nurse improve', 'nurse kind', 'nurse knowledge', 'nurse look', 'nurse lot', 'nurse lovely', 'nurse low', 'nurse luxury', 'nurse make', 'nurse may', 'nurse nurse', 'nurse obstetrics', 'nurse officer', 'nurse pay', 'nurse perform', 'nurse personnel', 'nurse public', 'nurse recommend', 'nurse reply', 'nurse request', 'nurse rest', 'nurse say', 'nurse service', 'nurse shout', 'nurse smile', 'nurse speak', 'nurse spoke', 'nurse staff', 'nurse suggest', 'nurse supervise', 'nurse take', 'nurse tell', 'nurse walk', 'nurse well', 'nursing 5th', 'nursing building', 'nursing home', 'nursing service', 'nursing staff', 'nutrition department', 'observation conclusion', 'obstetrics gynecology', 'obtain ask', 'obtrusive please', 'october 2014', 'october 2016', 'october common', 'offer good', 'office around', 'office hour', 'officer chula', 'officer good', 'officer happy', 'officer ready', 'officer smile', 'officer talk', 'official continue', 'official may', 'official take', 'often extra', 'often get', 'often go', 'often tire', 'often understand', 'often without', 'ok basic', 'ok get', 'ok service', 'okay find', 'okay run', 'old donate', 'old must', 'old nurse', 'old others', 'old people', 'old run', 'old take', 'old terrible', 'ongoing follow', 'open cabinet', 'open clock', 'open curtain', 'open everyone', 'open opportunity', 'open service', 'operating room', 'operation daughter', 'operation sleep', 'ophthalmology kind', 'opinion province', 'opportunity patient', 'opportunity see', 'optimistic try', 'option receive', 'order continue', 'order get', 'order go', 'order receive', 'organize queue', 'original hospital', 'original lump', 'orthopedic department', 'orthopedic doctor', 'osteoporosis patient', 'others acknowledge', 'others really', 'outside office', 'overall emergency', 'overall good', 'overall impressed', 'page wash', 'paid rice', 'pain every', 'pain memory', 'pain official', 'pain want', 'pale therefore', 'pale yellow', 'pamper every', 'paper afternoon', 'paper clean', 'park front', 'parking bit', 'parking difficult', 'parking expensive', 'parking lot', 'parking parking', 'parking staff', 'parking tire', 'parking worth', 'part asks', 'part decision', 'part staff', 'part time', 'party best', 'pas standard', 'pass still', 'passageway husband', 'past never', 'past round', 'path ward', 'patience calmness', 'patience every', 'patience patience', 'patience year', 'patient 24', 'patient admit', 'patient almost', 'patient already', 'patient appropriately', 'patient arrive', 'patient ask', 'patient best', 'patient briefly', 'patient card', 'patient check', 'patient cheerful', 'patient close', 'patient come', 'patient confidence', 'patient detail', 'patient detailed', 'patient doctor', 'patient encourage', 'patient equally', 'patient every', 'patient fast', 'patient felt', 'patient friendly', 'patient front', 'patient give', 'patient go', 'patient god', 'patient good', 'patient hip', 'patient history', 'patient hurry', 'patient husband', 'patient id', 'patient importantly', 'patient increase', 'patient interested', 'patient know', 'patient knowledge', 'patient level', 'patient long', 'patient look', 'patient lot', 'patient lump', 'patient medicine', 'patient mind', 'patient mr', 'patient must', 'patient new', 'patient nurse', 'patient option', 'patient pain', 'patient patient', 'patient pay', 'patient place', 'patient plus', 'patient question', 'patient queue', 'patient quite', 'patient rayong', 'patient really', 'patient receive', 'patient record', 'patient reduce', 'patient relative', 'patient seizure', 'patient shift', 'patient shy', 'patient smile', 'patient sometimes', 'patient staff', 'patient talk', 'patient thank', 'patient throughout', 'patient tidy', 'patient time', 'patient understand', 'patient use', 'patient wait', 'patient walk', 'patient well', 'patient worry', 'patrol child', 'pay 14', 'pay attention', 'pay cash', 'pay examination', 'pay expensive', 'pay food', 'pay great', 'pay nearly', 'pay pity', 'pay process', 'pay time', 'pay travel', 'pay yourselfcall', 'payment half', 'peace mind', 'pediatric department', 'people always', 'people arrive', 'people change', 'people check', 'people choose', 'people come', 'people complain', 'people crowd', 'people doctor', 'people found', 'people get', 'people go', 'people good', 'people home', 'people improve', 'people kind', 'people last', 'people love', 'people money', 'people much', 'people near', 'people never', 'people obtrusive', 'people old', 'people province', 'people queue', 'people satisfied', 'people say', 'people see', 'people sell', 'people service', 'people sometimes', 'people talk', 'people together', 'people use', 'people wait', 'perform patient', 'perform verb', 'period many', 'period normal', 'period service', 'period treatment', 'persistence want', 'person allow', 'person arrives', 'person come', 'person doctor', 'person leave', 'person please', 'person push', 'person really', 'person wife', 'personality apprentice', 'personality forget', 'personnel even', 'personnel give', 'personnel good', 'personnel pay', 'personnel quality', 'personnel understand', 'phai hospital', 'phanitkij good', 'pharmacist could', 'pharmacy recommends', 'phat impressed', 'phayabab chareon', 'phimonkul take', 'phone badly', 'phone sick', 'phor go', 'phor phor', 'phor ror', 'phrapharod tower', 'phraphit building', 'physical education', 'physical examination', 'pick building', 'pick car', 'pick equipment', 'pick system', 'picture work', 'piece money', 'pig good', 'pill chula', 'pity father', 'place ability', 'place area', 'place cheaper', 'place clean', 'place expand', 'place nurse', 'place price', 'place quiet', 'place reason', 'place require', 'place try', 'place work', 'plan impressive', 'plan never', 'play mobile', 'play phone', 'please ask', 'please doctor', 'please everyone', 'please go', 'please help', 'please little', 'please pay', 'please speak', 'please staff', 'please tell', 'please use', 'please year', 'plug number', 'plug ten', 'plus auntie', 'plus make', 'plus patient', 'plus price', 'pm yet', 'point contact', 'point cut', 'point detail', 'point even', 'point feel', 'point finger', 'point prohibit', 'point really', 'point screen', 'poison go', 'poison symptom', 'police hospital', 'police queue', 'polite even', 'polite polite', 'polite respectfully', 'polite speaks', 'polite staff', 'politely include', 'politely patient', 'poorly even', 'poorly staff', 'post others', 'post reach', 'postpone appointment', 'postpone indefinitely', 'power give', 'powerful treatment', 'practice doctor', 'praise student', 'pregnancy give', 'pregnant 24', 'pregnant nursing', 'prenatal information', 'prepare run', 'preposter speak', 'prescription ie', 'prescription pharmacist', 'press anything', 'press many', 'press open', 'press queue', 'press rate', 'pressure another', 'pressure draw', 'pressure obtain', 'pretty wrinkle', 'previously admit', 'price expensive', 'private car', 'private child', 'private hospital', 'private treatment', 'privilege see', 'probably improve', 'probably lot', 'probably many', 'probably read', 'problem people', 'procedure go', 'procedure good', 'procedure patient', 'process little', 'process meeting', 'product today', 'profession help', 'professor assoc', 'professor help', 'profile file', 'profile history', 'profile room', 'program king', 'prohibit picture', 'protection responsible', 'provide advice', 'provide good', 'provide king', 'provide lot', 'provide prenatal', 'provide service', 'province able', 'province clock', 'province especially', 'province like', 'province live', 'province sent', 'province waste', 'public hospital', 'public relation', 'push back', 'push car', 'push di', 'push emergency', 'push inside', 'put appointment', 'put smile', 'quality 1st', 'quality develop', 'quality life', 'quality service', 'quality think', 'question ask', 'question disease', 'question even', 'question part', 'question payment', 'question public', 'question question', 'question way', 'queue 10', 'queue accurate', 'queue advise', 'queue call', 'queue card', 'queue doctor', 'queue examination', 'queue feel', 'queue first', 'queue get', 'queue good', 'queue half', 'queue hour', 'queue keep', 'queue long', 'queue lot', 'queue many', 'queue must', 'queue overall', 'queue patient', 'queue point', 'queue quite', 'queue receive', 'queue reservation', 'queue screen', 'queue second', 'queue shortly', 'queue sit', 'queue slow', 'queue system', 'queue systematically', 'queue talk', 'queue time', 'queue wait', 'quick treatment', 'quicker patient', 'quickly approach', 'quickly take', 'quickly told', 'quiet conserve', 'quite difficult', 'quite good', 'quite long', 'racha chon', 'rain traffic', 'raise salary', 'rama submit', 'ran insert', 'ran put', 'ran together', 'random talk', 'ratchaburi hospital', 'ratchada thapra', 'rate people', 'rating a10', 'rating bank', 'ray blood', 'ray noon', 'ray room', 'ray well', 'raya pay', 'rayong hospital', 'rays liver', 're still', 'reach chula', 'reach director', 'reach inside', 'reaction indicate', 'read clearly', 'reading difficult', 'ready give', 'ready patient', 'ready well', 'real escape', 'real person', 'really appreciate', 'really bad', 'really explain', 'really fast', 'really good', 'really impressive', 'really like', 'really old', 'really terrible', 'really want', 'really waste', 'reason terrible', 'reason think', 'reasonable restaurant', 'reborn saga', 'receive arrange', 'receive bad', 'receive best', 'receive break', 'receive card', 'receive care', 'receive chulalongkorn', 'receive equal', 'receive good', 'receive hospital', 'receive long', 'receive medicine', 'receive queue', 'receive quick', 'receive salary', 'receive service', 'receive treatment', 'receive wrong', 'recently start', 'receptionist like', 'recommend basic', 'recommend go', 'recommend really', 'recommend well', 'recommends take', 'reconcile nurse', 'record good', 'record staff', 'recover accident', 'recover sick', 'red cross', 'reduce process', 'reduce stress', 'refer another', 'refer chula', 'refer doctor', 'refer document', 'refresh everyone', 'regardless question', 'registration point', 'registration room', 'regular clinic', 'regularly sometimes', 'relation officer', 'relation short', 'relative due', 'relative help', 'relative know', 'relative many', 'relative old', 'relative patient', 'relative point', 'relative push', 'relative receive', 'relative room', 'relative well', 'relief ever', 'relieve treatment', 'remember even', 'remember well', 'repeat people', 'reply doctor', 'reply wait', 'reply wheelchair', 'reply would', 'report food', 'reputation well', 'request blood', 'request file', 'request maintain', 'request medical', 'request wheelchair', 'require money', 'reservation system', 'reserve queue', 'reserve service', 'respectfully bow', 'respiratory system', 'respond differently', 'respond great', 'respond patient', 'responsible goodbye', 'rest good', 'restaurant building', 'restriction drug', 'result checked', 'result lot', 'result modern', 'retreat bed', 'return convenient', 'return home', 'return life', 'review everyone', 'review go', 'rice 14', 'rice boil', 'ride electric', 'ride still', 'right 30', 'right away', 'right bad', 'right bit', 'right go', 'right medicine', 'right patient', 'right place', 'right social', 'right staff', 'right treatment', 'ring doorbell', 'rip late', 'riyabha nawamin', 'room 35', 'room 5th', 'room air', 'room asks', 'room bad', 'room call', 'room check', 'room close', 'room comfortable', 'room curtain', 'room doctor', 'room financial', 'room good', 'room kind', 'room know', 'room make', 'room nurse', 'room officer', 'room ok', 'room patient', 'room pick', 'room service', 'room speak', 'room spoke', 'room staff', 'room thorough', 'room wait', 'root negative', 'ror 23', 'ror building', 'ror like', 'rotterdam 1021', 'round plan', 'round postpone', 'round say', 'round staff', 'round use', 'rule police', 'run 100', 'run addition', 'run elder', 'run like', 'run run', 'run time', 'run water', 'rungsak specialist', 'rupture work', 'rush pick', 'safe secure', 'safety today', 'saga first', 'sala daeng', 'salary let', 'salary see', 'salary tax', 'salt water', 'sameif pay', 'sanitary amount', 'sarar short', 'sarcastic loud', 'sasi boonyakanok', 'sassy ophthalmology', 'satisfied good', 'satisfied lot', 'save belly', 'save life', 'saw already', 'saw condition', 'saw father', 'saw follow', 'saw hospital', 'sawasdee building', 'say afraid', 'say appointment', 'say badly', 'say bed', 'say blanket', 'say child', 'say cost', 'say delivery', 'say doctor', 'say drama', 'say encouragement', 'say file', 'say fine', 'say form', 'say friend', 'say go', 'say government', 'say history', 'say hospital', 'say jump', 'say leave', 'say ll', 'say make', 'say move', 'say must', 'say nurse', 'say okay', 'say person', 'say please', 'say say', 'say sent', 'say slang', 'say stay', 'say survive', 'say taste', 'say thank', 'say want', 'say word', 'say worry', 'say would', 'scar much', 'schedule examination', 'school therefore', 'screen nurse', 'screen point', 'screen talk', 'second child', 'second person', 'second round', 'secretly cry', 'secure thank', 'security building', 'security far', 'security guard', 'security hospital', 'security open', 'see anything', 'see anywhere', 'see clock', 'see doctor', 'see feel', 'see hospital', 'see lie', 'see mother', 'see service', 'see sick', 'see symptom', 'seem morphine', 'seem prepare', 'seize way', 'seizure plan', 'self losing', 'sell product', 'sell sanitary', 'send back', 'send chula', 'send rama', 'send see', 'send woman', 'senior patient', 'sense great', 'sent 945', 'sent another', 'sent chula', 'sent file', 'sent hospital', 'sent treatment', 'sent yet', 'separate disease', 'separate service', 'seriously work', 'serve look', 'service 20', 'service 9th', 'service anyone', 'service arrive', 'service attentive', 'service become', 'service call', 'service certain', 'service clean', 'service comfortable', 'service different', 'service doctor', 'service due', 'service equal', 'service especially', 'service everyone', 'service excellent', 'service expert', 'service facial', 'service flow', 'service friendly', 'service give', 'service go', 'service good', 'service hospital', 'service husband', 'service impressed', 'service impressive', 'service kind', 'service king', 'service large', 'service level', 'service like', 'service location', 'service lot', 'service lovely', 'service many', 'service modern', 'service mother', 'service much', 'service nurse', 'service part', 'service patient', 'service pay', 'service pediatric', 'service people', 'service personnel', 'service play', 'service polite', 'service provide', 'service queue', 'service quite', 'service receive', 'service room', 'service save', 'service see', 'service service', 'service something', 'service sort', 'service speak', 'service staff', 'service state', 'service sure', 'service system', 'service systematic', 'service terrible', 'service think', 'service thought', 'service time', 'service twice', 'service understand', 'service wait', 'service well', 'service wife', 'service willingness', 'service work', 'shady call', 'shady tree', 'share post', 'shift operation', 'shit ask', 'shit talk', 'shock cue', 'shock hug', 'shoot like', 'short answer', 'short bleeding', 'short go', 'short spoken', 'short think', 'short time', 'shortly staff', 'shoulder come', 'shout old', 'shout point', 'show complaint', 'shy turn', 'sibling take', 'sick appointment', 'sick friend', 'sick go', 'sick hospital', 'sick may', 'sick people', 'sick take', 'sick thank', 'side cut', 'side medicine', 'side skilled', 'side talk', 'sidewalk like', 'sigh system', 'since 530', 'since 600', 'since always', 'since begin', 'since birth', 'since call', 'since clock', 'since five', 'since heavy', 'since january', 'since take', 'since treat', 'sit ask', 'sit look', 'sit wait', 'situation believe', 'six file', 'six top', 'size do', 'size exchange', 'skilled doctor', 'skilled skilled', 'skilled usually', 'skin clinic', 'skin since', 'skull fracture', 'sky train', 'slang current', 'slang food', 'sle always', 'sleep day', 'sleep despite', 'sleep emergency', 'sleep like', 'sleep sleep', 'sleep take', 'sleep wait', 'slept like', 'slept official', 'slot still', 'slow lot', 'slow ok', 'slow patient', 'slow quickly', 'slow sure', 'slow wait', 'slowly accord', 'slowly mother', 'small body', 'small child', 'small see', 'smelly paper', 'smile answer', 'smile doctor', 'smile give', 'smile help', 'smile hmmm', 'smile speak', 'smile spite', 'smile well', 'sneeze follow', 'social network', 'social protection', 'social security', 'social worker', 'society undergo', 'solution case', 'something else', 'something emergency', 'sometimes check', 'sometimes confuse', 'sometimes may', 'sometimes queue', 'sometimes wait', 'somsri building', 'sore get', 'sorry mother', 'sort patient', 'speak bad', 'speak guard', 'speak guest', 'speak health', 'speak little', 'speak patient', 'speak politely', 'speak poorly', 'speak well', 'speaks well', 'special clinic', 'special first', 'special room', 'specialist brain', 'specialist good', 'specialist heart', 'specialized disease', 'specialized doctor', 'speech good', 'spent 17800', 'spite many', 'split tooth', 'split wisdom', 'spoke badly', 'spoke beautifully', 'spoke eloquently', 'spoke good', 'spoke lot', 'spoke poorly', 'spoke service', 'spoke well', 'spoken like', 'spot staff', 'staff 6th', 'staff always', 'staff answer', 'staff convenient', 'staff counter', 'staff diligent', 'staff doctor', 'staff emergency', 'staff even', 'staff friendly', 'staff front', 'staff get', 'staff go', 'staff good', 'staff history', 'staff include', 'staff little', 'staff look', 'staff manner', 'staff may', 'staff member', 'staff non', 'staff nurse', 'staff often', 'staff party', 'staff provide', 'staff push', 'staff random', 'staff ratchaburi', 'staff regardless', 'staff respond', 'staff right', 'staff rush', 'staff say', 'staff slept', 'staff spoke', 'staff take', 'staff train', 'staff treat', 'staff unnecessarily', 'staff work', 'staffnotice long', 'stamp tell', 'stand carpool', 'stand check', 'stand story', 'standard bad', 'standard forever', 'standard patient', 'standard service', 'star half', 'start doctor', 'start treat', 'start use', 'starve waste', 'state hospital', 'station connect', 'stay hospital', 'stay inpatient', 'stay week', 'step appointment', 'step make', 'step nurse', 'step service', 'step sometimes', 'step staff', 'sterilization mother', 'stiff short', 'still able', 'still feel', 'still get', 'still lot', 'still many', 'still open', 'still remember', 'still strong', 'still time', 'still untreated', 'still use', 'still work', 'still worried', 'still wrong', 'stink paper', 'stomach burning', 'stood give', 'stood shout', 'stop go', 'stop hole', 'stop hospital', 'stop work', 'story bad', 'story finish', 'story never', 'story room', 'strength become', 'stress frighten', 'strong upside', 'strong use', 'strong world', 'stuck official', 'student come', 'student good', 'student hospital', 'student include', 'student know', 'student province', 'study etiquette', 'stun think', 'style doctor', 'sub clinic', 'submit appointment', 'submit card', 'submit document', 'submit right', 'subway drive', 'subway get', 'subway impressed', 'successfully nurse', 'suddenly caught', 'suffer bone', 'suffer disease', 'suggest basic', 'suggest wound', 'suitable child', 'suitable service', 'summary thank', 'supervise child', 'supervisor ror', 'support difficult', 'sure patient', 'sure please', 'sure rating', 'sure recommend', 'surgery 2010', 'surgery do', 'surgery doctor', 'surgery first', 'surgery heal', 'surgery last', 'surgery midday', 'surgery october', 'surgery receive', 'surgery room', 'surgery side', 'surgery thank', 'surgery today', 'surgery without', 'surin asawawitoonthip', 'surround brawny', 'survive first', 'suwannaphon phimonkul', 'swipe credit', 'sympathetic thank', 'sympathy 14', 'symptom continued', 'symptom detail', 'symptom disappear', 'symptom examination', 'symptom like', 'symptom medication', 'symptom thoroughly', 'symptom usually', 'symptom well', 'system bad', 'system blood', 'system complete', 'system convenient', 'system delayed', 'system developed', 'system especially', 'system faster', 'system like', 'system modern', 'system nurse', 'system patient', 'system people', 'system really', 'system related', 'system right', 'system separate', 'system submit', 'system systematic', 'system thank', 'system use', 'system well', 'system work', 'systematic queue', 'systematic talk', 'systematically get', 'systematically patient', 'table help', 'table saw', 'take along', 'take attentive', 'take child', 'take day', 'take even', 'take good', 'take grandma', 'take head', 'take history', 'take less', 'take long', 'take move', 'take patient', 'take people', 'take quite', 'take right', 'take time', 'talented lot', 'talk box', 'talk curtly', 'talk doctor', 'talk dog', 'talk encourage', 'talk giggle', 'talk like', 'talk metaphor', 'talk patient', 'talk symptom', 'talk terrible', 'talk unable', 'talk wait', 'talk well', 'talk without', 'talksometimes walk', 'taste quite', 'tate dr', 'tax summary', 'taxi tell', 'teacher doctor', 'teacher dr', 'teacher phat', 'team call', 'team carefully', 'team kept', 'team many', 'team medical', 'team operation', 'team take', 'teeth contact', 'teeth every', 'tell chula', 'tell could', 'tell everyone', 'tell excellent', 'tell file', 'tell go', 'tell head', 'tell move', 'tell nong', 'tell rpp', 'tell thank', 'teller friendly', 'telling system', 'ten thousand', 'ten year', 'tend good', 'term service', 'term surgery', 'terrible biggerthe', 'terrible extremely', 'terrible look', 'terrible management', 'terrible nurse', 'terrible old', 'terrible patient', 'terrible personnel', 'terrible please', 'terrible push', 'terrible service', 'test change', 'test take', 'test urine', 'thai people', 'thai red', 'thailand government', 'thailand wear', 'thanapong good', 'thank doctor', 'thank dr', 'thank every', 'thank everyone', 'thank heart', 'thank help', 'thank hospital', 'thank much', 'thank nurse', 'thank pay', 'thank room', 'thank save', 'thank staff', 'thank teacher', 'thank training', 'thank work', 'thankful doctor', 'thanks compliment', 'thapra husband', 'thawatchai nurse', 'theory allow', 'therefore inform', 'therefore need', 'therefore sleep', 'therefore tool', 'thing forever', 'thing give', 'thing tend', 'thing without', 'think already', 'think best', 'think chula', 'think come', 'think doctor', 'think get', 'think go', 'think like', 'think make', 'think much', 'think service', 'think small', 'think whether', 'think would', 'think wrong', 'think wrongly', 'thorough examination', 'thoroughly key', 'thoroughly politely', 'though already', 'though crazy', 'though give', 'though many', 'though mother', 'though never', 'though patient', 'though wait', 'thought expensive', 'thought gastritis', 'thought hospital', 'thought impressed', 'thought public', 'thought staff', 'thought would', 'thousand ask', 'thousand baht', 'three month', 'three year', 'throughout already', 'throughout appointment', 'throughout period', 'thyroid chula', 'tidy clean', 'tidy shady', 'time 10', 'time 1700', 'time ask', 'time bed', 'time birth', 'time bit', 'time blossom', 'time call', 'time change', 'time check', 'time chula', 'time clinic', 'time come', 'time completely', 'time contact', 'time cook', 'time doctor', 'time even', 'time every', 'time examination', 'time father', 'time feel', 'time felt', 'time first', 'time found', 'time girlfriend', 'time go', 'time good', 'time hahaha', 'time hit', 'time hospital', 'time hour', 'time husband', 'time impressed', 'time like', 'time luckily', 'time many', 'time matter', 'time mother', 'time never', 'time patient', 'time pay', 'time people', 'time period', 'time poor', 'time probably', 'time race', 'time right', 'time sameif', 'time seem', 'time service', 'time show', 'time sleep', 'time snack', 'time something', 'time still', 'time system', 'time talk', 'time thank', 'time treat', 'time uncle', 'time understand', 'time wait', 'time word', 'time work', 'timely waste', 'timemy shit', 'timethe staff', 'tire enough', 'tire hospital', 'tire instead', 'tire must', 'tire people', 'tire use', 'tire wait', 'today 29', 'today bring', 'today child', 'today computer', 'today female', 'today go', 'today know', 'today see', 'today service', 'today still', 'today submit', 'today surgery', 'today thankful', 'toe inside', 'together hope', 'together many', 'toilet stink', 'told brain', 'told busy', 'told detail', 'told go', 'told husband', 'told medicine', 'told need', 'told send', 'told term', 'told wait', 'tomorrow travel', 'tonight travel', 'tool even', 'tool give', 'tool modern', 'tooth broken', 'tooth two', 'top six', 'torture like', 'touch time', 'tower daughter', 'traffic heavy', 'traffic jam', 'train little', 'train subway', 'training thank', 'training think', 'transcript appointment', 'transportation great', 'transportation may', 'travel atmin', 'travel chulalongkorn', 'travel convenient', 'travel get', 'travel hospital', 'travel province', 'travel racha', 'treat back', 'treat badly', 'treat cancer', 'treat chula', 'treat chulalongkorn', 'treat conclusion', 'treat doctor', 'treat every', 'treat hope', 'treat hospital', 'treat impressed', 'treat luck', 'treat mother', 'treat nurse', 'treat pain', 'treat patient', 'treat recover', 'treat skin', 'treat time', 'treat use', 'treat utmost', 'treat well', 'treatment appreciate', 'treatment bone', 'treatment cost', 'treatment do', 'treatment doctor', 'treatment every', 'treatment follow', 'treatment free', 'treatment give', 'treatment good', 'treatment government', 'treatment hospital', 'treatment matter', 'treatment melodious', 'treatment mention', 'treatment method', 'treatment nurse', 'treatment previously', 'treatment quicker', 'treatment receive', 'treatment send', 'treatment staff', 'treatment thank', 'treatment time', 'treatment today', 'treatment use', 'treatment wait', 'treatment whether', 'treatment would', 'tree lot', 'true story', 'trust leave', 'trust use', 'try arrange', 'try foot', 'try go', 'try service', 'try think', 'tumor surgery', 'turn dumped', 'turn head', 'turn wait', 'turtle walk', 'twin hard', 'two would', 'type wound', 'unable remember', 'unbearable brought', 'unchecked nurse', 'unchecked terrible', 'uncle security', 'unclear speak', 'unclear word', 'undergo general', 'undergo surgery', 'undergone brain', 'understand accuracy', 'understand aunt', 'understand lot', 'understand many', 'understand orthopedic', 'understand patient', 'understand question', 'understand say', 'understand staff', 'understand thailand', 'understand unclear', 'understands hahaha', 'understands patient', 'understood easily', 'university would', 'unknown would', 'unlike private', 'unnecessarily people', 'unnoticed nurse', 'untreated people', 'up child', 'up treatment', 'upset impressive', 'upside completely', 'urgent solution', 'urine reserve', 'use 55', 'use drug', 'use emotion', 'use endoscopic', 'use give', 'use go', 'use gold', 'use heal', 'use kantakarn', 'use lift', 'use mp', 'use never', 'use new', 'use normal', 'use patience', 'use patient', 'use people', 'use practice', 'use press', 'use private', 'use right', 'use service', 'use staff', 'use surgery', 'use transcript', 'use treatment', 'use use', 'use wheelchair', 'user press', 'usually case', 'usually symptom', 'utmost power', 'vaccinate apprentice', 'vaccine additional', 'vaccine vaccine', 'value may', 'various driver', 'various service', 'various situation', 'vast expansive', 'verb badly', 'verb like', 'vertical dissection', 'vertical type', 'visit check', 'visit take', 'volunteer nurse', 'volunteer queue', 'wait 10', 'wait advise', 'wait appendix', 'wait bit', 'wait building', 'wait call', 'wait cart', 'wait check', 'wait child', 'wait clock', 'wait day', 'wait death', 'wait doctor', 'wait examine', 'wait file', 'wait free', 'wait front', 'wait give', 'wait guard', 'wait half', 'wait hour', 'wait internal', 'wait last', 'wait late', 'wait later', 'wait line', 'wait long', 'wait minute', 'wait morning', 'wait next', 'wait nothing', 'wait open', 'wait patient', 'wait period', 'wait queue', 'wait receive', 'wait relative', 'wait result', 'wait sarar', 'wait service', 'wait since', 'wait waste', 'walk around', 'walk hospital', 'walk inspect', 'walk many', 'walk measure', 'walk night', 'walk often', 'walk person', 'walk sit', 'walk terrible', 'walk thing', 'walk use', 'want amputate', 'want answer', 'want consult', 'want eat', 'ward cute', 'ward security', 'wash blood', 'wash history', 'wash much', 'waste money', 'waste much', 'waste time', 'watch 100th', 'watch young', 'water nursing', 'water wash', 'way attentive', 'way back', 'way emergency', 'way felt', 'way help', 'way make', 'way phor', 'way travel', 'wear glass', 'wear white', 'week gloomy', 'week old', 'week twin', 'weekday even', 'welcome fast', 'welcome grandma', 'well anything', 'well care', 'well career', 'well day', 'well depend', 'well doctor', 'well entire', 'well everyone', 'well expect', 'well explanation', 'well feel', 'well felt', 'well find', 'well impressed', 'well kind', 'well like', 'well make', 'well new', 'well number', 'well nurse', 'well organize', 'well people', 'well pharmacy', 'well please', 'well polite', 'well province', 'well queue', 'well receptionist', 'well refresh', 'well right', 'well say', 'well service', 'well since', 'well smile', 'well spot', 'well suitable', 'well take', 'well thank', 'well think', 'well treat', 'well use', 'well wait', 'well waste', 'wheelchair go', 'wheelchair often', 'wheelchair say', 'wheelchair service', 'wheelchair staff', 'whether get', 'whether gold', 'whether nowadays', 'white clothes', 'white fairy', 'whole family', 'whole queue', 'wife almost', 'wife go', 'wife sick', 'wife tire', 'wife today', 'willingness bathroom', 'wipe right', 'wisdom teeth', 'wish happy', 'within 300', 'within curtain', 'without even', 'without know', 'without work', 'without worry', 'woke smile', 'woman bit', 'woman nurse', 'woman pregnant', 'wood system', 'word doctor', 'word heard', 'word improve', 'word point', 'word work', 'work antenatal', 'work ask', 'work awkward', 'work badly', 'work civil', 'work contact', 'work either', 'work happily', 'work hard', 'work heart', 'work heavy', 'work like', 'work many', 'work must', 'work official', 'work patient', 'work play', 'work question', 'work quickly', 'work receive', 'work rotterdam', 'work service', 'work shoot', 'work system', 'work systematically', 'work talksometimes', 'work tire', 'work write', 'worker department', 'workplace stop', 'world anymore', 'worried patient', 'worried would', 'worry doctor', 'worry still', 'worry travel', 'worth treatment', 'would check', 'would expensive', 'would garden', 'would know', 'would let', 'would like', 'would please', 'would slow', 'would stop', 'wound beautiful', 'wound pretty', 'wound procedure', 'wound push', 'wrinkle cut', 'write mistake', 'write prescription', 'writhe help', 'wrong ask', 'wrong choose', 'wrong decision', 'wrong thought', 'wrongly knew', 'year 2555', 'year best', 'year bury', 'year come', 'year complete', 'year daughter', 'year encounter', 'year long', 'year medical', 'year old', 'year see', 'year tell', 'yell father', 'yellow body', 'yesterday make', 'yesterday say', 'yet ask', 'yet checked', 'yet money', 'yet need', 'young child', 'young good', 'young sibling', 'young smile', 'yourselfcall fastif']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (1, 2453)\t0.32045144274889165\n",
      "  (1, 1770)\t0.35878949259536835\n",
      "  (1, 4234)\t0.35878949259536835\n",
      "  (1, 853)\t0.336363171084401\n",
      "  (1, 3928)\t0.336363171084401\n",
      "  (1, 2392)\t0.24734497604267472\n",
      "  (1, 1712)\t0.35878949259536835\n",
      "  (1, 2148)\t0.35878949259536835\n",
      "  (1, 1103)\t0.3081093474001187\n",
      "  (2, 394)\t1.0\n",
      "  (3, 298)\t0.15792035606036808\n",
      "  (3, 2319)\t0.15792035606036808\n",
      "  (3, 1108)\t0.15792035606036808\n",
      "  (3, 4057)\t0.15792035606036808\n",
      "  (3, 4201)\t0.15792035606036808\n",
      "  (3, 778)\t0.14104595308211906\n",
      "  (3, 1283)\t0.15792035606036808\n",
      "  (3, 883)\t0.15792035606036808\n",
      "  (3, 3496)\t0.15792035606036808\n",
      "  (3, 1023)\t0.15792035606036808\n",
      "  (3, 102)\t0.15792035606036808\n",
      "  (3, 3111)\t0.15792035606036808\n",
      "  (3, 4282)\t0.15792035606036808\n",
      "  (3, 1227)\t0.15792035606036808\n",
      "  (3, 1600)\t0.148049463096035\n",
      "  :\t:\n",
      "  (476, 1621)\t0.12639013206568372\n",
      "  (476, 4603)\t0.1378496966902331\n",
      "  (478, 508)\t0.38127702032754507\n",
      "  (478, 2339)\t0.38127702032754507\n",
      "  (478, 4294)\t0.38127702032754507\n",
      "  (478, 3616)\t0.38127702032754507\n",
      "  (478, 1331)\t0.38127702032754507\n",
      "  (478, 4386)\t0.38127702032754507\n",
      "  (478, 2360)\t0.3574451043459578\n",
      "  (479, 2856)\t0.5157206734522619\n",
      "  (479, 4326)\t0.5157206734522619\n",
      "  (479, 1748)\t0.5157206734522619\n",
      "  (479, 2695)\t0.3504004066073579\n",
      "  (479, 1114)\t0.28163117009882754\n",
      "  (480, 3747)\t0.5285934770548991\n",
      "  (480, 1737)\t0.5285934770548991\n",
      "  (480, 1713)\t0.49555347028301094\n",
      "  (480, 3562)\t0.3331969448571103\n",
      "  (480, 1736)\t0.29083401805561915\n",
      "  (481, 2608)\t0.42224207912785633\n",
      "  (481, 4574)\t0.42224207912785633\n",
      "  (481, 1990)\t0.42224207912785633\n",
      "  (481, 3639)\t0.42224207912785633\n",
      "  (481, 3512)\t0.42224207912785633\n",
      "  (481, 1634)\t0.32948161264162446\n",
      "\n",
      " reduce_feature() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      "Before reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "explained_variance_ratio_:\n",
      "[0.0359889  0.01766502 0.01507806 0.01445365 0.01415047 0.01382886\n",
      " 0.01287526 0.01260383 0.01228177 0.01188338]\n",
      "\n",
      "singular_values_:\n",
      "[153.086012   107.25270345  99.08864461  97.01523288  95.99235917\n",
      "  94.89521936  91.56494829  90.59464888  89.4296848   87.96728781]\n",
      "\n",
      "Afte reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca, shape:  (482, 10)\n",
      "[[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]]\n",
      "\n",
      " kfold_train_test() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\\X_array_pca:\n",
      "\n",
      "[[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]]\n",
      "\n",
      "y_array:\n",
      "[0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1\n",
      " 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
      " 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1\n",
      " 0]\n",
      "\n",
      "KFold:  0\n",
      "\n",
      "X_train:\n",
      " [[ 9.61089701e-01  3.46517289e+01  1.12487693e-03 ...  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-5.34108642e-01 -1.45125273e+00  2.91507248e+00 ...  7.16433766e-01\n",
      "  -1.38822533e+00 -4.69669646e-01]\n",
      " [-6.05499161e-01 -3.54963517e-01 -3.66185613e-01 ... -9.25233795e-02\n",
      "   1.44934399e+00  2.46461664e+00]\n",
      " ...\n",
      " [-4.99681039e-01 -1.12401472e+00 -4.43422291e-01 ...  3.49925466e-01\n",
      "  -4.23520096e-01 -3.71353075e-01]\n",
      " [-5.46301493e-01 -1.10530070e+00 -5.03789434e-01 ...  1.56476830e-01\n",
      "  -2.63946361e-01 -2.96769427e-01]\n",
      " [-4.71176023e-01 -8.47788122e-01 -3.55145799e-01 ... -6.25061270e-02\n",
      "  -4.42810951e-01 -1.60835889e-01]] \n",
      "Shape:  (433, 10)\n",
      "\n",
      "X_test:\n",
      " [[-5.31434259e-01 -9.78786392e-01 -4.96828505e-01 -5.88473119e-01\n",
      "  -3.59261823e-01 -1.64984790e-01 -4.09299905e-01  9.53164916e-02\n",
      "  -3.20729999e-01 -2.67154372e-01]\n",
      " [-5.54663841e-01 -1.06422276e+00 -2.70783989e-03 -5.92476300e-01\n",
      "   8.85137670e-02 -4.36860524e-01 -5.45300841e-01  5.06478704e-01\n",
      "  -5.65821635e-01 -5.09171036e-01]\n",
      " [-5.32468586e-01 -1.03230548e+00 -4.16895603e-01 -4.15295782e-01\n",
      "   4.14596306e-02 -6.30753655e-01 -5.63323006e-01  2.32434728e-01\n",
      "  -4.65315186e-01 -3.54795868e-01]\n",
      " [ 7.86628521e-03 -3.82581778e+00  5.21682494e+00  1.86755812e+00\n",
      "   4.19363947e+00  6.93662398e-01  2.56966326e+01  6.09459448e+01\n",
      "   5.28138322e+01  2.32839751e+00]\n",
      " [-4.34715531e-01 -1.26124142e+00 -7.43280325e-01  7.85489958e-01\n",
      "  -1.80554625e-01 -3.45331920e-01 -6.22399177e-01 -5.55291207e-01\n",
      "   2.11565001e-01 -4.47729602e-02]\n",
      " [-3.15015711e-01 -6.13440347e-01  3.96247943e-01 -2.38510002e-01\n",
      "   6.98345884e-01 -2.30372930e+00  8.25243927e-01 -1.46077359e+00\n",
      "   1.08102573e+00  1.83489831e-01]\n",
      " [-3.76562697e-01  1.93059380e+00 -3.72485112e-01 -1.98278692e-02\n",
      "   3.27172983e-02 -1.40342685e+00 -6.15313340e-01  8.76819642e-01\n",
      "   5.71375175e-01 -8.79919546e-01]\n",
      " [-5.13140328e-01 -1.04610752e+00 -3.21710020e-01 -5.40960610e-01\n",
      "   6.77047016e-02 -7.28643966e-01 -3.23261709e-01  7.99284187e-01\n",
      "  -5.31786356e-03 -3.41283864e-01]\n",
      " [-5.28457230e-01 -1.01125698e+00 -4.41212178e-01 -4.37039060e-01\n",
      "  -2.18613681e-03 -6.48076114e-01 -4.95544506e-01  1.98951449e-01\n",
      "  -3.78408123e-01 -3.12157534e-01]\n",
      " [-3.93545230e-01 -6.84808109e-01 -4.74861820e-01 -5.74791507e-01\n",
      "   3.35083104e-01 -9.59697262e-01 -5.12070609e-01 -2.70749929e-01\n",
      "  -2.49105777e-02 -1.27902339e-01]\n",
      " [-3.15015711e-01 -6.13440347e-01  3.96247943e-01 -2.38510002e-01\n",
      "   6.98345884e-01 -2.30372930e+00  8.25243927e-01 -1.46077359e+00\n",
      "   1.08102573e+00  1.83489831e-01]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-3.24983708e-01  4.34182514e-01  4.05828251e-01 -1.78065309e-01\n",
      "   1.36181216e-01 -8.24309657e-01 -7.26865723e-01 -7.68876340e-01\n",
      "   2.63265049e-01  2.09952578e-01]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [ 6.57217391e-02  6.83179447e-01 -2.86231642e-01 -7.33692323e-02\n",
      "   6.32873765e-01 -9.96981825e-01  1.52947637e+00 -9.93644890e-01\n",
      "   5.47929509e-01 -6.77409704e-01]\n",
      " [ 1.48858368e-02  1.56866353e-01 -1.99042767e+00  3.83015314e+00\n",
      "  -6.03786887e-01 -9.99335883e-01  2.32138588e-01 -7.77973408e-01\n",
      "  -9.30952865e-01 -9.19938396e-01]\n",
      " [ 1.54990529e+00 -1.14187085e+00  1.54080148e+00  5.22956986e-03\n",
      "   2.41345228e-01 -1.24179369e+00 -1.83316678e-01  4.78102702e-01\n",
      "  -1.78928801e+00 -1.76129784e+00]\n",
      " [-3.02993433e-01  1.15594609e+00 -7.82271277e-01 -2.23098595e-01\n",
      "  -6.90721517e-01 -5.25233224e-01 -6.21184529e-01  4.44692847e-01\n",
      "  -7.60067436e-01 -8.43495206e-01]\n",
      " [-5.55668099e-01 -1.31318608e+00  3.88282212e-01 -5.30570916e-01\n",
      "  -4.27654214e-01 -1.60810213e-01 -3.47559674e-01  4.04428747e-01\n",
      "  -8.57018376e-02 -3.89089219e-01]\n",
      " [-3.01210978e-01 -1.09835864e+00  4.28623588e-01  3.60554555e+00\n",
      "  -1.91471277e+00  5.50975174e-01 -7.52485727e-02 -5.98095403e-01\n",
      "  -2.67816019e+00 -5.58537845e-01]\n",
      " [-5.31434259e-01 -9.78786392e-01 -4.96828505e-01 -5.88473119e-01\n",
      "  -3.59261823e-01 -1.64984790e-01 -4.09299905e-01  9.53164916e-02\n",
      "  -3.20729999e-01 -2.67154372e-01]\n",
      " [-2.71112597e-01 -8.53244129e-01 -2.45455996e-01 -2.64949570e-01\n",
      "   2.13630418e-01 -7.49266373e-01 -4.98900937e-01  1.03768286e-02\n",
      "  -4.77224947e-01 -4.83061962e-01]\n",
      " [-4.45753566e-01 -6.04535540e-01 -4.23330811e-01 -6.07918804e-01\n",
      "  -2.14239894e-03 -4.83844782e-01 -4.40611414e-01  4.16813177e-02\n",
      "  -2.36878557e-01 -3.32638532e-01]\n",
      " [-4.14666009e-01 -7.38340593e-01 -4.61124795e-01 -7.11731373e-01\n",
      "  -1.06483429e-01 -4.93717617e-01 -4.75328391e-01  2.37918386e-01\n",
      "  -5.21149125e-01 -3.64510570e-01]\n",
      " [ 7.24796023e-02  1.30806155e+00  2.93913841e+00  1.78478654e+00\n",
      "  -1.79534247e+00  1.48337847e+00  7.28454373e-01  1.03958966e+01\n",
      "  -6.69373407e+00  5.40153909e+00]\n",
      " [-4.51263714e-01 -1.90941889e+00  1.50065226e+00  2.06607684e+00\n",
      "  -1.19033144e+00 -6.83617790e-01  1.36706846e+00 -2.73071252e+00\n",
      "   3.29149405e+00 -7.81277124e-01]\n",
      " [-4.72185945e-01 -9.76668714e-01 -6.64707410e-01 -9.80846555e-01\n",
      "  -3.74621810e-01 -2.57444624e-01 -1.55846059e-01 -4.23744944e-01\n",
      "  -5.52984853e-02 -1.72609392e-02]\n",
      " [-4.29354128e-01 -1.39758448e-01 -8.09701343e-01 -1.10490174e+00\n",
      "   2.32097206e+00 -8.14187384e-01  1.63721526e+00 -6.58008315e-01\n",
      "   4.29326511e+00 -5.49150417e-02]\n",
      " [-4.81335617e-01 -1.09332860e+00 -4.19399395e-01  1.73468789e-01\n",
      "  -8.80095661e-01  5.76201188e-02  2.60822504e-01  1.17318331e+00\n",
      "  -1.42477547e+00 -4.58917726e-01]\n",
      " [-4.85263763e-01  3.08501048e-01 -2.36440997e-01 -8.67896793e-01\n",
      "  -5.72020658e-01 -3.46996531e-02 -4.10156957e-01  2.64629041e-01\n",
      "  -4.08591649e-01  2.52680318e-01]\n",
      " [ 2.26860170e-01  1.82338257e+00  1.47032621e+00  1.31802872e-02\n",
      "   8.26965067e+00  3.41409129e+00  5.63549159e+00  1.72619952e+01\n",
      "   7.50060134e+00 -2.29523419e+00]\n",
      " [-5.10629678e-01 -1.53949862e+00  4.44722663e+00 -3.62754114e-01\n",
      "  -3.28543009e-01 -1.54708604e+00 -2.98479875e-01  1.89859487e+00\n",
      "  -7.94182938e-01  9.12266604e-01]\n",
      " [-1.01886612e-02 -5.59642058e+00 -7.73617564e+00  4.76476551e+01\n",
      "  -1.41209605e+01  1.82085571e+01 -5.72862712e+00 -7.05213012e-01\n",
      "   2.75722648e+00  1.30739869e+00]\n",
      " [-3.07979384e-01  1.64451674e+00 -6.08414590e-01  7.45689460e-01\n",
      "  -5.09515091e-01  2.38432102e-01  4.11880753e-03  2.36577845e-01\n",
      "  -6.43464664e-01  4.73240157e-01]\n",
      " [-5.13303634e-01  1.20623291e+00 -2.35081236e-01 -4.03663644e-01\n",
      "   3.63031021e-02 -7.81132291e-01 -5.85774224e-01  4.53578788e-01\n",
      "  -5.08075366e-01 -3.80712732e-01]\n",
      " [-6.72121634e-02  1.26950232e+00  5.67899955e+00  6.92997922e-01\n",
      "   1.90368815e+00  3.64700801e-01 -9.99722724e-01  2.20658365e+00\n",
      "   1.24779001e+00 -4.75525704e-01]\n",
      " [-4.44617977e-02  4.87663651e-01  1.88324912e+00 -5.94209321e-01\n",
      "  -8.13453411e-02 -1.22122782e+00 -6.08769476e-01  7.08829033e-02\n",
      "  -2.14790907e-01  2.22959530e+00]\n",
      " [-5.79080652e-01 -3.37294805e-01 -4.28950140e-01 -9.30142973e-01\n",
      "  -5.64821329e-01 -1.14363977e-01 -4.90320498e-01  2.82461571e-01\n",
      "  -5.81064976e-01 -6.99095867e-02]\n",
      " [-5.29709128e-01 -1.07424409e+00 -4.55626021e-01 -3.40860777e-01\n",
      "   4.09448211e-03 -6.24947568e-01 -5.39898762e-01  2.45454570e-01\n",
      "  -3.72116247e-01 -3.23105648e-01]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [ 5.49941829e-02 -8.97507190e-01  2.01534972e+00 -9.26042715e-01\n",
      "   1.20404987e+00  9.05852204e-01 -6.43734184e-01  1.83743814e+00\n",
      "  -7.02918521e-01  8.83494082e-01]\n",
      " [-3.27914023e-01  3.88678161e-01 -4.96554104e-02 -3.97643643e-01\n",
      "   8.19609321e-02 -6.14087871e-01 -1.08788745e+00  2.69695548e-01\n",
      "  -1.22420761e+00 -4.87001841e-01]\n",
      " [-5.28457230e-01 -1.01125698e+00 -4.41212178e-01 -4.37039060e-01\n",
      "  -2.18613681e-03 -6.48076114e-01 -4.95544506e-01  1.98951449e-01\n",
      "  -3.78408123e-01 -3.12157534e-01]\n",
      " [-6.24786101e-01 -1.72717034e+00 -3.75870047e-01 -4.67479515e-01\n",
      "   3.78595500e-01 -9.77508755e-01 -9.24453073e-01  1.25767587e+00\n",
      "  -1.14183391e+00 -7.24570027e-01]\n",
      " [-4.58827213e-01  9.84624876e-01  4.61575923e-01 -2.22540389e-01\n",
      "  -2.13622645e-01 -7.90937835e-01 -5.22538154e-01  2.04050654e-01\n",
      "  -6.30100150e-01  4.39148259e-01]\n",
      " [-3.15015711e-01 -6.13440347e-01  3.96247943e-01 -2.38510002e-01\n",
      "   6.98345884e-01 -2.30372930e+00  8.25243927e-01 -1.46077359e+00\n",
      "   1.08102573e+00  1.83489831e-01]\n",
      " [-4.03889396e-01 -1.23054498e+00 -4.76638386e-01  7.77511123e-01\n",
      "  -4.42396931e-01 -2.89500024e-01 -7.61954666e-01 -3.93833127e-01\n",
      "   3.57763291e-01 -3.54129795e-01]\n",
      " [-5.28407450e-01 -9.14905042e-01 -2.98118670e-01 -5.69338313e-01\n",
      "   6.29295075e-02 -5.86296679e-01 -4.62099439e-02  1.08608800e+00\n",
      "   6.32934952e-01 -8.16787297e-02]\n",
      " [ 3.94769544e-01 -5.94605590e-01 -9.59946749e-01 -7.72610328e-01\n",
      "  -1.26632000e-01 -6.03058888e-01 -7.74465480e-01 -6.94679087e-01\n",
      "   1.16353593e+00  1.63831062e-01]] \n",
      "Shape:  (49, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
      " 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (433,)\n",
      "\n",
      "y_test:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0] \n",
      "Shape:  (49,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  0\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.0075197940257516445\n",
      "\n",
      " Coefficients \n",
      "[ 0.01832776 -0.43403451  0.17149528 -0.01680847  0.43535867  0.23815053\n",
      "  0.20067263  0.56573332  0.28172607  0.06072027]\n",
      "\n",
      " pop_polarity\n",
      "[5.04200959e-01 5.96291264e-01 5.28707202e-01 1.00000000e+00\n",
      " 4.65876952e-01 4.37885286e-01 3.22841592e-01 6.51836733e-01\n",
      " 5.25152010e-01 4.68137246e-01 4.37885286e-01 2.99768355e-07\n",
      " 3.21858903e-01 2.99768355e-07 3.91850966e-01 1.57287409e-01\n",
      " 5.56676380e-01 2.32476281e-01 6.29392944e-01 2.05440945e-01\n",
      " 5.04200959e-01 4.97947816e-01 4.82863429e-01 4.89898493e-01\n",
      " 9.81228620e-01 4.94736055e-01 4.53443440e-01 8.72033119e-01\n",
      " 5.78288485e-01 3.89147184e-01 9.99999947e-01 8.54396924e-01\n",
      " 1.00208754e-01 2.66648464e-01 3.19431322e-01 9.37237335e-01\n",
      " 4.48818538e-01 4.26950926e-01 5.37598402e-01 2.99768355e-07\n",
      " 9.05947100e-01 3.27441372e-01 5.25152010e-01 6.85995753e-01\n",
      " 3.17131018e-01 4.37885286e-01 4.70394890e-01 7.34907782e-01\n",
      " 4.28438338e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0\n",
      " 0 1 0 1 0 1 1 0 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.72\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[18  6]\n",
      " [11 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6530612244897959\n",
      "recall:  0.56\n",
      "specificity:  0.75\n",
      "precision:  0.7\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68        24\n",
      "           1       0.70      0.56      0.62        25\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.66      0.66      0.65        49\n",
      "weighted avg       0.66      0.65      0.65        49\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  0\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[7.19991569e-002 8.56226053e-002 7.76289673e-002 0.00000000e+000\n",
      " 4.27547872e-002 4.01898916e-002 1.44245208e-004 6.88733789e-002\n",
      " 7.58946879e-002 6.04581309e-002 4.01898916e-002 0.00000000e+000\n",
      " 2.07409371e-002 0.00000000e+000 1.88621514e-002 4.67100509e-003\n",
      " 9.99976824e-001 3.50392236e-003 8.19454741e-002 3.10345333e-003\n",
      " 7.19991569e-002 6.94871333e-002 6.51624485e-002 6.66481268e-002\n",
      " 3.33552837e-008 2.06847460e-003 5.34381803e-002 4.95519819e-003\n",
      " 6.01259912e-002 2.65856420e-002 3.29838449e-025 9.98380516e-001\n",
      " 1.23397873e-192 4.79168418e-004 3.16434248e-003 9.99678191e-001\n",
      " 4.00589695e-001 6.44355019e-002 7.56942819e-002 0.00000000e+000\n",
      " 5.25450332e-001 2.69109502e-002 7.58946879e-002 5.03098072e-002\n",
      " 8.63188688e-003 4.01898916e-002 4.30479311e-002 6.03033754e-002\n",
      " 1.73124383e-001]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.65\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[24  0]\n",
      " [21  4]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5714285714285714\n",
      "recall:  0.16\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70        24\n",
      "           1       1.00      0.16      0.28        25\n",
      "\n",
      "    accuracy                           0.57        49\n",
      "   macro avg       0.77      0.58      0.49        49\n",
      "weighted avg       0.77      0.57      0.48        49\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  0\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.1784715  0.91742204 0.89317079 0.75912905 0.46327987 0.11317306\n",
      " 0.18550958 0.95172279 0.86842713 0.47235676 0.11317306 0.02149414\n",
      " 0.26121837 0.02149414 0.20884778 0.02018058 0.69513274 0.00135234\n",
      " 0.71768994 0.09674296 0.1784715  0.23645317 0.47329853 0.65836086\n",
      " 0.21039069 0.51958868 0.07619139 0.08635745 0.61569197 0.58263605\n",
      " 0.5643969  0.64530647 0.18798746 0.25289626 0.68689856 0.66765375\n",
      " 0.63731322 0.2545902  0.93551212 0.02149414 0.86082998 0.84534445\n",
      " 0.86842713 0.69524876 0.64735594 0.11317306 0.05064881 0.87371356\n",
      " 0.0925535 ]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1\n",
      " 0 1 0 1 1 1 1 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.91\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[21  3]\n",
      " [ 5 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8367346938775511\n",
      "recall:  0.8\n",
      "specificity:  0.875\n",
      "precision:  0.8695652173913043\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        24\n",
      "           1       0.87      0.80      0.83        25\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.84      0.84      0.84        49\n",
      "weighted avg       0.84      0.84      0.84        49\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  0\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   27.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.5        0.5        0.5        0.49203207 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5       ]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 1 0 1 0 1 1 0 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.48\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12 12]\n",
      " [ 7 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6122448979591837\n",
      "recall:  0.72\n",
      "specificity:  0.5\n",
      "precision:  0.6\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56        24\n",
      "           1       0.60      0.72      0.65        25\n",
      "\n",
      "    accuracy                           0.61        49\n",
      "   macro avg       0.62      0.61      0.61        49\n",
      "weighted avg       0.62      0.61      0.61        49\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  0\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:58:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:58:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.479284   0.60047925 0.6472798  0.5031605  0.3953159  0.42294186\n",
      " 0.47202373 0.6642364  0.6642364  0.50042015 0.42294186 0.40606213\n",
      " 0.4489492  0.40606213 0.42553246 0.34313187 0.5125645  0.4258357\n",
      " 0.5157808  0.40096423 0.479284   0.5214753  0.5485897  0.616813\n",
      " 0.41996336 0.42507556 0.37628812 0.38874948 0.50683135 0.4921834\n",
      " 0.4996203  0.45456642 0.44204035 0.41531473 0.58136994 0.5145454\n",
      " 0.5169936  0.4660158  0.6472798  0.40606213 0.5530558  0.5354517\n",
      " 0.6642364  0.51844174 0.44315067 0.42294186 0.39942673 0.5500801\n",
      " 0.38266346]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1\n",
      " 0 1 0 1 1 1 1 0 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.78\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[20  4]\n",
      " [ 8 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7551020408163265\n",
      "recall:  0.68\n",
      "specificity:  0.8333333333333334\n",
      "precision:  0.8095238095238095\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        24\n",
      "           1       0.81      0.68      0.74        25\n",
      "\n",
      "    accuracy                           0.76        49\n",
      "   macro avg       0.76      0.76      0.75        49\n",
      "weighted avg       0.76      0.76      0.75        49\n",
      "\n",
      "\n",
      "KFold:  1\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (433, 10)\n",
      "\n",
      "X_test:\n",
      " [[ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-5.34108642e-01 -1.45125273e+00  2.91507248e+00 -7.21278207e-01\n",
      "   1.83302178e+00  6.75166161e-01 -1.26575438e+00  7.16433766e-01\n",
      "  -1.38822533e+00 -4.69669646e-01]\n",
      " [-6.05499161e-01 -3.54963517e-01 -3.66185613e-01 -2.01272163e+00\n",
      "  -3.50962108e-01 -3.92599039e-01  9.88928820e-01 -9.25233795e-02\n",
      "   1.44934399e+00  2.46461664e+00]\n",
      " [-4.06212767e-01 -1.10494058e+00 -4.98819053e-01 -5.42953305e-01\n",
      "   1.76467945e-01 -7.84720319e-01 -4.75270487e-01  2.58458957e-02\n",
      "  -2.55672748e-01  4.26474045e-02]\n",
      " [-4.71176023e-01 -8.47788122e-01 -3.55145799e-01 -4.27245456e-01\n",
      "   7.68549771e-02 -6.27612085e-01 -4.15699571e-01 -6.25061270e-02\n",
      "  -4.42810951e-01 -1.60835889e-01]\n",
      " [-7.26431409e-01  1.65355661e+00 -2.05094632e+00 -1.68067701e+01\n",
      "  -1.99736868e+01  2.70030734e+01  5.32303718e+00 -3.40877951e+00\n",
      "   2.85885781e+00  1.01894711e+00]\n",
      " [-2.71112597e-01 -8.53244129e-01 -2.45455996e-01 -2.64949570e-01\n",
      "   2.13630418e-01 -7.49266373e-01 -4.98900937e-01  1.03768286e-02\n",
      "  -4.77224947e-01 -4.83061962e-01]\n",
      " [-2.78121759e-01 -1.43200908e+00 -1.54140531e+00  9.71628625e-01\n",
      "   5.99106340e+00 -2.04158556e+00  2.57382166e+00 -1.80371798e+01\n",
      "   1.84640913e+01 -4.99685687e+00]\n",
      " [-5.10897833e-01 -1.12619884e+00 -4.09438757e-01 -3.79173668e-01\n",
      "  -1.52458817e-01 -2.75117811e-01 -5.13018129e-01  2.07317069e-01\n",
      "  -4.05061868e-01 -3.58481525e-01]\n",
      " [-1.66954970e-01 -3.84221839e-01 -1.27725455e-01 -1.40412166e+00\n",
      "  -2.82167662e-01  5.70601250e-01 -7.09995000e-01  1.27591391e+00\n",
      "  -1.11241028e+00 -7.33361333e-01]\n",
      " [-5.36901926e-01 -1.04381026e+00 -2.59920656e-01 -5.76558067e-01\n",
      "  -6.33496480e-02 -3.53055289e-01 -4.38313545e-01  1.66898183e-01\n",
      "  -6.24957552e-01 -4.63817630e-01]\n",
      " [-7.26431409e-01  1.65355661e+00 -2.05094632e+00 -1.68067701e+01\n",
      "  -1.99736868e+01  2.70030734e+01  5.32303718e+00 -3.40877951e+00\n",
      "   2.85885781e+00  1.01894711e+00]\n",
      " [-5.44385354e-01 -9.82237458e-01 -4.20624716e-01 -1.72288758e-01\n",
      "  -7.46256971e-02 -6.19120767e-01 -6.19272171e-01  1.70886934e-01\n",
      "  -3.00914645e-01 -3.58167001e-01]\n",
      " [-4.77588851e-01 -9.99238344e-01 -2.71118847e-01 -3.73245291e-01\n",
      "   1.98642106e-01 -9.43828633e-01 -6.70183032e-01 -3.76460547e-01\n",
      "  -3.45399921e-02  6.75883465e-02]\n",
      " [-4.16817209e-01  7.01326545e-02 -7.07251640e-01 -1.22150439e+00\n",
      "  -1.92622459e+00  1.84158439e+00 -3.46285426e-01  8.60031439e-02\n",
      "  -3.88119821e-01 -4.66108250e-01]\n",
      " [-4.28433683e-01  7.55270600e-02 -5.15000861e-01 -7.23203910e-01\n",
      "  -5.28349206e-02  1.76938169e-01 -4.25586302e-01 -4.29727655e-01\n",
      "  -2.94728510e-01 -3.58973320e-01]\n",
      " [-5.12849253e-01 -1.14089071e+00 -4.69282334e-01 -2.95781030e-01\n",
      "   5.90828575e-02 -8.57368505e-01  1.14699489e+00 -2.52793803e-03\n",
      "  -9.82884822e-01 -3.14327790e-01]\n",
      " [-4.82045010e-01 -1.24936270e+00 -6.00142568e-01 -7.59949749e-01\n",
      "  -2.75209393e-01 -4.10344946e-01 -5.93201207e-01  7.27487764e-02\n",
      "  -5.64286879e-01 -3.53117867e-01]\n",
      " [-5.39510106e-01 -9.75777880e-01 -3.25922427e-01 -4.36065042e-01\n",
      "   2.55828897e-01 -6.65794695e-01 -7.00811291e-01  4.89060949e-02\n",
      "  -8.55042502e-01  3.28308423e-01]\n",
      " [-5.47187796e-01 -1.25759267e+00 -3.84221769e-01 -7.82456634e-01\n",
      "   3.16297333e-01 -1.32089223e+00 -4.81551473e-01  6.81468476e-01\n",
      "  -9.70352649e-01 -1.04425896e-01]\n",
      " [ 4.81036433e-02 -4.96174757e-01 -3.55339737e-01  2.13323651e-01\n",
      "  -1.22449322e-01 -1.10491609e+00  2.88178491e-01  6.60615894e-02\n",
      "  -5.87434383e-01 -5.11938129e-01]\n",
      " [-5.38385283e-01 -7.54885128e-01 -5.63628079e-01 -1.32390371e+00\n",
      "   1.50964041e-01 -8.25541030e-01 -9.62651637e-01  3.38113372e-01\n",
      "  -8.94265953e-01 -5.98617741e-01]\n",
      " [-5.39393417e-01  1.03957152e-02 -7.18281938e-02  2.83873424e+00\n",
      "  -1.01287589e+00  2.30208997e-01 -8.01775713e-01  7.78180999e-01\n",
      "  -3.90494227e-01 -5.19768663e-01]\n",
      " [-3.33776909e-01  6.55420074e-01 -2.99646167e-01 -2.25882008e-01\n",
      "  -3.36888817e-02 -2.75135652e-01 -5.13577135e-01  5.62133846e-01\n",
      "  -7.13633393e-01  2.10222694e-01]\n",
      " [-5.42268297e-01 -1.13496453e+00  1.67661376e-01 -5.58730348e-01\n",
      "   5.55448074e-01 -4.07015903e-01 -5.73984817e-01  3.52664408e-01\n",
      "  -6.76014652e-01 -3.97363179e-01]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-4.71176023e-01 -8.47788122e-01 -3.55145799e-01 -4.27245456e-01\n",
      "   7.68549771e-02 -6.27612085e-01 -4.15699571e-01 -6.25061270e-02\n",
      "  -4.42810951e-01 -1.60835889e-01]\n",
      " [-4.95731984e-01 -9.23898068e-01  2.45453664e+00 -9.03818267e-01\n",
      "  -3.87891283e-01 -4.70548064e-01 -1.15330934e+00  1.11534785e+00\n",
      "  -1.29046854e+00 -4.10995906e-02]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-1.87917594e-01 -7.65245393e-01 -5.65865950e-01 -5.66646371e-01\n",
      "  -1.35482389e-01 -8.44130646e-01 -8.71333026e-01  1.76265392e-01\n",
      "  -5.30747005e-01 -7.01307256e-02]\n",
      " [-3.14825590e-01 -1.24627602e+00 -2.01481394e-01 -5.88950564e-01\n",
      "   3.07263210e-01 -6.71113449e-01 -3.77615533e-01  3.84622235e-01\n",
      "  -3.47444169e-01  4.46187748e-01]\n",
      " [-4.83709139e-01 -1.12286485e+00 -4.37216657e-01 -4.44849593e-01\n",
      "   1.39901514e-01 -6.61239957e-01 -2.66540640e-01  3.52002166e-01\n",
      "  -5.02801758e-01 -2.85205927e-01]\n",
      " [ 2.01460675e+00 -2.01508513e+00  8.33094224e-01  9.28302544e-01\n",
      "   6.43788285e+00  6.37473997e-01  5.68836306e+00 -2.81270124e+00\n",
      "   1.66679462e+00  3.46348307e+00]\n",
      " [-4.52272490e-01 -3.12782568e-01 -1.93741665e-01 -6.89633663e-01\n",
      "   8.94420203e-02  2.61647764e-01 -3.81636419e-01  2.43839428e-01\n",
      "  -4.55534406e-03 -3.65328351e-01]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-4.88314354e-01 -1.16199637e+00 -4.72870554e-01 -2.59379457e-01\n",
      "  -9.12195329e-03 -6.46242297e-01 -5.35253717e-01  3.74165625e-01\n",
      "  -3.13376762e-01 -3.59629004e-01]\n",
      " [-4.36651717e-01 -5.39167296e-01 -3.76222068e-01 -2.30566522e-01\n",
      "   3.58909287e-03 -9.25204385e-01 -6.69333175e-01  3.13202406e-01\n",
      "  -3.65547130e-01 -3.42068195e-01]\n",
      " [-3.31606631e-01  1.14066788e+00 -3.29769617e-01 -4.32121446e-01\n",
      "   8.35679081e-01  1.79406357e-01 -3.66121455e-01  1.05352042e-01\n",
      "  -1.00950486e-01 -3.37217349e-01]\n",
      " [-1.69458716e-01 -5.35803906e-01 -2.32371737e-01 -6.04121833e-01\n",
      "   1.26450754e-01 -4.98683508e-01 -7.11209384e-01  4.20750224e-01\n",
      "  -6.25007140e-01 -2.98901855e-01]\n",
      " [-4.29354128e-01 -1.39758448e-01 -8.09701343e-01 -1.10490174e+00\n",
      "   2.32097206e+00 -8.14187384e-01  1.63721526e+00 -6.58008315e-01\n",
      "   4.29326511e+00 -5.49150417e-02]\n",
      " [-5.16091527e-01 -7.04972222e-01 -5.84668004e-01 -3.02782737e-02\n",
      "  -2.98573281e-01 -3.70371846e-01 -7.08107493e-01  4.14753287e-01\n",
      "  -4.48687525e-01 -5.05226763e-01]\n",
      " [-5.22839401e-01 -9.66971872e-01 -4.43772077e-01 -5.14491274e-01\n",
      "  -4.37665942e-03 -6.60722055e-01 -4.38366122e-01  1.44617086e-01\n",
      "  -3.26050044e-01 -2.49890836e-01]\n",
      " [-4.77187690e-01 -1.47849563e+00 -4.78531225e-02 -2.69162749e-01\n",
      "  -4.20534531e-01 -4.21134946e-01 -6.32893918e-01 -5.83552005e-01\n",
      "  -8.62705127e-02 -4.41792224e-01]\n",
      " [-4.29354128e-01 -1.39758448e-01 -8.09701343e-01 -1.10490174e+00\n",
      "   2.32097206e+00 -8.14187384e-01  1.63721526e+00 -6.58008315e-01\n",
      "   4.29326511e+00 -5.49150417e-02]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-5.10340284e-01 -1.28035817e+00  2.59756451e-01 -5.74407147e-01\n",
      "   3.45159813e-01 -3.81441413e-01 -4.78923333e-01  4.74188477e-01\n",
      "   1.27863008e-02 -2.70723274e-02]\n",
      " [-3.73176240e-01 -1.77610380e-01 -7.40763200e-01 -9.75121574e-01\n",
      "  -1.58317232e-01 -7.95803787e-01  5.93285580e-02 -1.02061261e-01\n",
      "  -6.22775711e-01  1.27222632e+00]\n",
      " [-4.36548207e-01 -2.17072756e-01 -4.76196729e-01 -4.59611334e-01\n",
      "  -1.32480498e-02 -7.89854192e-01 -4.03204443e-01  1.27221119e-01\n",
      "  -7.04091361e-01 -3.22118774e-01]] \n",
      "Shape:  (49, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
      " 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (433,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 1 1 0 1] \n",
      "Shape:  (49,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  1\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.04615536209024204\n",
      "\n",
      " Coefficients \n",
      "[ 0.01849864 -0.38795064  0.18867967 -0.03062592  0.42577918  0.23461797\n",
      "  0.1941933   0.49600572  0.29114976  0.05486044]\n",
      "\n",
      " pop_polarity\n",
      "[1.41768476e-06 8.56911255e-01 6.51810416e-01 5.32271990e-01\n",
      " 4.87105875e-01 8.17484723e-02 4.97986355e-01 2.69493925e-01\n",
      " 5.35967282e-01 5.87983467e-01 5.22545573e-01 8.17484723e-02\n",
      " 5.05816946e-01 4.81301382e-01 3.46143335e-01 3.89747824e-01\n",
      " 5.35407726e-01 4.88936779e-01 4.94134910e-01 5.63752308e-01\n",
      " 4.36396711e-01 4.55469611e-01 4.11559638e-01 4.10969807e-01\n",
      " 6.25046445e-01 5.20364200e-01 5.20364200e-01 4.87105875e-01\n",
      " 6.36900800e-01 5.20364200e-01 4.38871516e-01 6.26675770e-01\n",
      " 5.66891461e-01 9.86203322e-01 5.66757683e-01 5.20364200e-01\n",
      " 5.55227434e-01 4.67037338e-01 4.69957117e-01 5.08648607e-01\n",
      " 8.81762359e-01 4.74160789e-01 5.16177044e-01 4.67685526e-01\n",
      " 8.81762359e-01 5.20364200e-01 6.90388440e-01 3.99753404e-01\n",
      " 4.05572567e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 0 0 1 1 0 1 0 1 1 1 0 0]\n",
      "\n",
      " auc\n",
      "0.76\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[16  4]\n",
      " [ 7 22]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7755102040816326\n",
      "recall:  0.7586206896551724\n",
      "specificity:  0.8\n",
      "precision:  0.8461538461538461\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74        20\n",
      "           1       0.85      0.76      0.80        29\n",
      "\n",
      "    accuracy                           0.78        49\n",
      "   macro avg       0.77      0.78      0.77        49\n",
      "weighted avg       0.78      0.78      0.78        49\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  1\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[0.00000000e+00 3.00532492e-01 2.81454716e-02 7.71007057e-03\n",
      " 8.75871434e-03 1.57795552e-22 8.32110763e-03 9.90076468e-01\n",
      " 8.72476512e-03 6.86210586e-03 9.32692333e-03 1.57795552e-22\n",
      " 9.95532235e-03 8.91034609e-03 4.16712708e-03 4.85867988e-03\n",
      " 1.25513056e-02 7.37766205e-03 1.06549998e-02 8.57155686e-03\n",
      " 1.09233591e-02 8.91104000e-03 1.41805409e-03 2.36884276e-03\n",
      " 1.08802740e-02 9.25696557e-03 9.25696557e-03 8.75871434e-03\n",
      " 1.39201869e-01 9.25696557e-03 8.54992016e-03 7.67741886e-03\n",
      " 8.44129824e-03 1.00000000e+00 7.42948750e-03 9.25696557e-03\n",
      " 8.57651570e-03 8.80883690e-03 7.92139294e-04 8.38543621e-03\n",
      " 1.30297339e-02 1.02292032e-02 9.14786135e-03 6.65841356e-03\n",
      " 1.30297339e-02 9.25696557e-03 9.54814178e-03 9.16663355e-03\n",
      " 7.01843470e-03]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.54\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[19  1]\n",
      " [28  1]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.40816326530612246\n",
      "recall:  0.034482758620689655\n",
      "specificity:  0.95\n",
      "precision:  0.5\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.95      0.57        20\n",
      "           1       0.50      0.03      0.06        29\n",
      "\n",
      "    accuracy                           0.41        49\n",
      "   macro avg       0.45      0.49      0.32        49\n",
      "weighted avg       0.46      0.41      0.27        49\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  1\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.02637824 0.91142656 0.11283764 0.6217547  0.40860617 0.12181635\n",
      " 0.28346233 0.14171789 0.67987684 0.67224957 0.74161734 0.12181635\n",
      " 0.67035222 0.23812658 0.34975727 0.48891937 0.46680369 0.16275447\n",
      " 0.51017256 0.72714058 0.1532542  0.32342379 0.59205706 0.81120112\n",
      " 0.93127217 0.59291565 0.59291565 0.40860617 0.75608822 0.59291565\n",
      " 0.43948224 0.91906475 0.95594527 0.61764735 0.83000654 0.59291565\n",
      " 0.81312075 0.69943789 0.64045343 0.85852967 0.17550897 0.28749406\n",
      " 0.44865745 0.15329513 0.17550897 0.59291565 0.83769711 0.0459405\n",
      " 0.61630154]\n",
      "\n",
      " yhat\n",
      "[0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[20  0]\n",
      " [ 2 27]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9591836734693877\n",
      "recall:  0.9310344827586207\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.96        49\n",
      "   macro avg       0.95      0.97      0.96        49\n",
      "weighted avg       0.96      0.96      0.96        49\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  1\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.8s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.39145676 0.5        0.49433301 0.49239619 0.49128813 0.48570463\n",
      " 0.49146115 0.48571133 0.49266293 0.49296598 0.49227526 0.48570463\n",
      " 0.49191511 0.49131497 0.48834346 0.48839412 0.49248352 0.4919077\n",
      " 0.49140031 0.49314282 0.49000255 0.49057523 0.48942202 0.48820464\n",
      " 0.49415633 0.49217611 0.49217611 0.49128813 0.49484939 0.49217611\n",
      " 0.49033862 0.49436498 0.49313328 0.5098059  0.4923315  0.49217611\n",
      " 0.4930437  0.4906721  0.48848226 0.49136101 0.5        0.49109098\n",
      " 0.49205838 0.49186931 0.5        0.49217611 0.5        0.48880568\n",
      " 0.48905142]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 0]\n",
      "\n",
      " auc\n",
      "0.74\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 8 12]\n",
      " [ 5 24]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6530612244897959\n",
      "recall:  0.8275862068965517\n",
      "specificity:  0.4\n",
      "precision:  0.6666666666666666\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.40      0.48        20\n",
      "           1       0.67      0.83      0.74        29\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.64      0.61      0.61        49\n",
      "weighted avg       0.65      0.65      0.63        49\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  1\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:59:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:59:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.40560046 0.55403256 0.40257263 0.5315843  0.5656633  0.39149654\n",
      " 0.51320493 0.4317971  0.537516   0.47923505 0.62357634 0.39149654\n",
      " 0.57355267 0.47217113 0.41258067 0.521136   0.470327   0.39993727\n",
      " 0.4965575  0.569329   0.3803316  0.49900135 0.5192319  0.5691615\n",
      " 0.616108   0.6033783  0.6033783  0.5656633  0.5147372  0.6033783\n",
      " 0.47132376 0.58461404 0.66600555 0.46665257 0.61097276 0.6033783\n",
      " 0.62240535 0.53617424 0.5216284  0.5244949  0.40202704 0.47687733\n",
      " 0.5990107  0.42430806 0.40202704 0.6033783  0.61298925 0.3539678\n",
      " 0.54840523]\n",
      "\n",
      " yhat\n",
      "[0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 1 0 0 1 0 0 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.88\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[15  5]\n",
      " [ 5 24]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7959183673469388\n",
      "recall:  0.8275862068965517\n",
      "specificity:  0.75\n",
      "precision:  0.8275862068965517\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        20\n",
      "           1       0.83      0.83      0.83        29\n",
      "\n",
      "    accuracy                           0.80        49\n",
      "   macro avg       0.79      0.79      0.79        49\n",
      "weighted avg       0.80      0.80      0.80        49\n",
      "\n",
      "\n",
      "KFold:  2\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[-4.62167103e-01 -1.08122407e+00 -1.87189822e-01 -2.03298242e-01\n",
      "   5.86896373e-01  6.02052595e-03 -7.90854983e-01 -6.29439472e-02\n",
      "  -4.38541538e-01 -2.99918260e-01]\n",
      " [-3.40393443e-01 -7.27786632e-01 -4.12440769e-01 -9.01238805e-01\n",
      "  -6.27169653e-01  4.97177901e-01 -2.70453876e-01  1.23317148e-02\n",
      "  -3.96744629e-01 -1.84674198e-01]\n",
      " [-1.43777264e-01 -1.63636948e+00  3.58669993e-01  1.23266328e+00\n",
      "  -1.20901460e-02 -2.87779846e+00 -6.99069299e-01  3.22122867e+00\n",
      "  -2.03528862e+00 -4.46478179e+00]\n",
      " [-5.21660389e-01 -3.13900906e-01 -5.35466483e-01 -1.84888920e-01\n",
      "  -1.52605688e-02 -7.54506336e-01 -5.29202795e-01  4.64989626e-01\n",
      "  -3.38628353e-01 -5.47485513e-01]\n",
      " [-5.38762623e-01 -7.81938769e-01 -2.58790381e-01 -4.70966197e-01\n",
      "   1.60010866e-02 -7.63184278e-01 -4.07889932e-01  3.04475068e-01\n",
      "  -2.61516679e-01 -2.14249220e-01]\n",
      " [ 1.48858368e-02  1.56866353e-01 -1.99042767e+00  3.83015314e+00\n",
      "  -6.03786887e-01 -9.99335883e-01  2.32138588e-01 -7.77973408e-01\n",
      "  -9.30952865e-01 -9.19938396e-01]\n",
      " [-5.30981076e-01 -9.03059310e-01 -3.77517671e-01 -1.19616731e-01\n",
      "  -1.43378185e-01 -1.04040439e-01 -3.22054704e-01 -1.02650266e-01\n",
      "  -2.55671282e-01 -4.03426626e-01]\n",
      " [-2.94111850e-01  2.08066264e+00  8.12617401e-01 -6.24172902e-01\n",
      "  -9.81351994e-02 -9.42660894e-01 -1.35084283e+00 -4.18780085e-01\n",
      "  -2.80982348e+00 -1.35214677e+00]\n",
      " [-5.34439250e-01 -1.10317723e+00  6.57632903e-02 -5.86005498e-01\n",
      "  -1.08267366e-02 -8.14205373e-01 -4.64720971e-01  2.84674570e-01\n",
      "  -5.36019752e-01 -4.48765978e-01]\n",
      " [-5.08059272e-01 -8.17157196e-01 -3.06576790e-01  1.70489354e-02\n",
      "  -4.39394794e-02 -5.59230050e-01 -5.49531060e-01 -2.43399832e-02\n",
      "  -3.03735764e-01 -3.45874172e-01]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-5.22839401e-01 -9.66971872e-01 -4.43772077e-01 -5.14491274e-01\n",
      "  -4.37665942e-03 -6.60722055e-01 -4.38366122e-01  1.44617086e-01\n",
      "  -3.26050044e-01 -2.49890836e-01]\n",
      " [-4.07789395e-01 -1.23754979e+00  7.02721017e-01 -1.56332007e-01\n",
      "   1.68192280e+00 -2.80864534e-01 -3.32144650e-01  1.87884480e-01\n",
      "   2.06050257e-01  2.62863168e-02]\n",
      " [-2.22990594e-01 -5.08706215e-01 -2.77341663e-01 -4.32516851e-01\n",
      "  -1.13478139e-01  2.18784385e-01 -5.06719617e-01 -1.04240955e-02\n",
      "  -5.49644917e-01 -4.59230400e-01]\n",
      " [-5.19691127e-01 -1.47071107e+00  1.71026165e+00 -3.59880689e-01\n",
      "  -6.77622950e-01 -8.64176364e-01 -5.07163828e-01  2.46700775e-01\n",
      "  -7.55696989e-01 -2.55333971e-01]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-5.38940230e-01 -9.73384033e-01 -1.74230050e-01 -5.89624024e-01\n",
      "   1.34429405e-01 -6.05469668e-01 -7.19162219e-01  3.26332971e-01\n",
      "  -7.90056387e-01 -4.50591071e-01]\n",
      " [-4.24104726e-01 -5.45820995e-01 -7.28168460e-01 -1.17890770e+00\n",
      "  -4.61110137e-01 -4.36531164e-01 -5.39287934e-01  2.74675355e-01\n",
      "  -8.04995845e-01 -6.93271126e-01]\n",
      " [-4.33643945e-01  6.51823497e-01  4.42721791e-01 -7.36444494e-01\n",
      "   4.98651923e-01 -1.17479278e-02 -5.84500165e-01  1.49406712e+00\n",
      "  -8.72447309e-01 -2.75935354e-01]\n",
      " [-5.70128172e-01 -8.27093889e-01  5.37380941e-01 -5.01445649e-01\n",
      "  -1.94635202e-01 -7.56704031e-01 -4.82234628e-01  4.14563161e-01\n",
      "  -5.99431137e-01 -5.14222369e-01]\n",
      " [-5.31221519e-01 -1.27494337e+00  9.58743405e-02 -3.17163851e-01\n",
      "   1.07403492e-02 -8.27313785e-01 -1.23691255e-01  1.27746087e-01\n",
      "  -6.16745385e-01 -4.48461080e-01]\n",
      " [-5.29258836e-01 -9.77276694e-01 -4.00797663e-01 -5.00615299e-01\n",
      "   4.77366575e-02 -6.46151786e-01 -5.28983990e-01  1.87865377e-01\n",
      "  -4.68060781e-01 -3.37941464e-01]\n",
      " [-3.36074929e-01 -1.24633914e+00 -4.36828570e-01 -9.01817011e-01\n",
      "  -3.91307819e-01 -4.13197182e-01 -5.44081112e-01  1.07128160e-01\n",
      "  -2.59152427e-01 -6.79942828e-01]\n",
      " [-5.38913858e-01 -1.13627763e+00  1.11162406e-01 -4.46882762e-01\n",
      "   6.18886138e-02 -7.39150711e-01 -5.89030004e-01  1.60625299e-01\n",
      "  -6.95346636e-01 -1.53739479e-01]\n",
      " [-4.77950771e-01 -7.75419090e-01  4.51209653e-02 -1.01766610e-01\n",
      "   2.73576420e-01 -5.16990896e-01 -3.64210480e-01  7.40611066e-01\n",
      "  -4.95422236e-01 -4.61211470e-01]\n",
      " [-8.32317829e-02 -5.00568669e-01 -3.48741778e-01 -7.09698132e-01\n",
      "   9.41593635e-02 -8.79136385e-01 -7.50661425e-01  6.90540969e-02\n",
      "  -8.04676683e-01 -6.07074881e-01]\n",
      " [-5.07394878e-01 -1.19115843e+00 -4.50555636e-01 -6.02956377e-01\n",
      "  -4.12877429e-02 -7.62557580e-01 -5.55399975e-01  5.93729233e-01\n",
      "  -5.69587243e-01  2.39967452e-01]\n",
      " [-4.73012293e-01 -1.22228710e+00 -5.15636917e-01  2.33008091e+00\n",
      "  -4.14185967e-01  2.71825603e-01 -6.49145802e-01  4.45695759e-01\n",
      "  -6.31677426e-01  3.58848622e-02]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-6.05499161e-01 -3.54963517e-01 -3.66185613e-01 -2.01272163e+00\n",
      "  -3.50962108e-01 -3.92599039e-01  9.88928820e-01 -9.25233795e-02\n",
      "   1.44934399e+00  2.46461664e+00]\n",
      " [ 1.65168011e+00 -1.87126683e-02 -5.72672258e-01  4.59546507e+00\n",
      "   1.17902143e+00  8.67700779e-01 -5.70875006e+00 -3.33783092e+00\n",
      "   6.15956015e+00  6.36130734e+00]\n",
      " [-4.86110847e-01 -4.37814814e-01  7.08645751e-01 -1.37915441e+00\n",
      "  -1.56638707e+00  8.88864103e-01 -1.95182033e-01 -1.57047451e-02\n",
      "  -5.60297786e-01 -7.81400510e-02]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-4.77187690e-01 -1.47849563e+00 -4.78531225e-02 -2.69162749e-01\n",
      "  -4.20534531e-01 -4.21134946e-01 -6.32893918e-01 -5.83552005e-01\n",
      "  -8.62705127e-02 -4.41792224e-01]\n",
      " [ 7.24796023e-02  1.30806155e+00  2.93913841e+00  1.78478654e+00\n",
      "  -1.79534247e+00  1.48337847e+00  7.28454373e-01  1.03958966e+01\n",
      "  -6.69373407e+00  5.40153909e+00]\n",
      " [-5.32651201e-01 -1.01463847e+00 -4.20912881e-01 -5.07381203e-01\n",
      "  -1.32623291e-02 -7.00606827e-01 -4.32458253e-01  3.51546435e-01\n",
      "  -5.50761879e-01  2.47573847e-01]\n",
      " [-4.72185945e-01 -9.76668714e-01 -6.64707410e-01 -9.80846555e-01\n",
      "  -3.74621810e-01 -2.57444624e-01 -1.55846059e-01 -4.23744944e-01\n",
      "  -5.52984853e-02 -1.72609392e-02]\n",
      " [-3.15744024e-01 -1.27408327e+00  7.25445262e-01 -1.31752031e-01\n",
      "  -8.80754817e-02 -7.43239268e-01 -5.83247965e-01  1.12235932e-01\n",
      "  -5.38015554e-01 -3.15200241e-01]\n",
      " [ 6.73874926e-01 -1.87427308e+00  1.66792320e+00 -1.20217761e+00\n",
      "   1.23715061e+00  5.22419212e-01 -9.29372762e-01  1.62624409e+00\n",
      "  -1.43401870e+00 -5.76263286e-01]\n",
      " [-3.49200839e-02 -6.41644850e-01 -5.01131816e-01 -6.32992831e-02\n",
      "  -1.09011486e+00  5.36218908e-01 -8.87075641e-01  5.94692360e-01\n",
      "  -2.08894014e-01 -5.27654773e-01]\n",
      " [-4.62167103e-01 -1.08122407e+00 -1.87189822e-01 -2.03298242e-01\n",
      "   5.86896373e-01  6.02052595e-03 -7.90854983e-01 -6.29439472e-02\n",
      "  -4.38541538e-01 -2.99918260e-01]\n",
      " [-6.05499161e-01 -3.54963517e-01 -3.66185613e-01 -2.01272163e+00\n",
      "  -3.50962108e-01 -3.92599039e-01  9.88928820e-01 -9.25233795e-02\n",
      "   1.44934399e+00  2.46461664e+00]\n",
      " [-5.51459362e-01 -1.07591854e+00 -3.93615647e-01 -6.21000935e-01\n",
      "  -1.91599809e-02 -8.25749038e-01 -4.43282388e-01  2.51139814e-01\n",
      "  -2.82804078e-01 -7.28746631e-02]\n",
      " [-5.29709128e-01 -1.07424409e+00 -4.55626021e-01 -3.40860777e-01\n",
      "   4.09448211e-03 -6.24947568e-01 -5.39898762e-01  2.45454570e-01\n",
      "  -3.72116247e-01 -3.23105648e-01]\n",
      " [-4.92997038e-01 -1.01321897e+00 -2.23594223e-01 -3.53318926e-01\n",
      "   9.85110438e-02 -6.78686185e-01 -4.64501467e-01  9.35378604e-02\n",
      "  -4.41549628e-01 -2.97150407e-01]\n",
      " [-4.90846646e-01  3.80439201e-01 -5.15885135e-01 -1.45750359e-01\n",
      "  -1.36441214e-01 -6.09163464e-01 -4.26942219e-01  1.71099390e-01\n",
      "  -3.50453723e-01 -5.16655549e-01]\n",
      " [ 1.36803266e+00  1.34446364e+00  1.23132828e+00  3.48856011e+00\n",
      "   6.47752552e+00  4.10978430e+00  2.06494184e+00  3.19410363e+00\n",
      "  -6.32655483e+00  1.76534990e+00]\n",
      " [-5.76413160e-01 -1.48204754e+00  2.87038295e-02 -7.16711151e-03\n",
      "   9.57640131e-02 -7.63828494e-01  9.95159297e-01  1.91140525e-01\n",
      "  -1.43957115e+00 -3.32826855e-01]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1\n",
      " 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  2\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.07520416883405764\n",
      "\n",
      " Coefficients \n",
      "[ 0.01987348 -0.37077903  0.29568794 -0.00225233  0.37607863  0.20062514\n",
      "  0.19123306  0.54804704  0.27054134  0.08376642]\n",
      "\n",
      " pop_polarity\n",
      "[5.75529783e-01 4.78632550e-01 7.12492811e-01 4.70623727e-01\n",
      " 5.32960514e-01 1.52091184e-01 4.98131669e-01 1.14282677e-01\n",
      " 5.52678659e-01 4.79788162e-01 3.14477845e-06 5.11340093e-01\n",
      " 8.03400076e-01 4.72475479e-01 6.22662746e-01 3.14477845e-06\n",
      " 5.23514828e-01 3.93423172e-01 6.43489363e-01 5.58553296e-01\n",
      " 5.61297027e-01 5.11207253e-01 5.00261190e-01 5.42162306e-01\n",
      " 6.29372312e-01 4.11542465e-01 5.72383046e-01 5.52874131e-01\n",
      " 4.89738662e-01 6.49593798e-01 4.57865449e-01 4.56535649e-01\n",
      " 3.14477845e-06 4.64195644e-01 9.89619428e-01 5.38339667e-01\n",
      " 4.40935333e-01 5.87081790e-01 8.93481314e-01 4.79401577e-01\n",
      " 5.75529783e-01 6.49593798e-01 5.36326867e-01 5.27154352e-01\n",
      " 5.23667668e-01 3.71143581e-01 9.78169950e-01 5.94416684e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0\n",
      " 1 1 0 1 1 1 1 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.6\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[11 10]\n",
      " [ 8 19]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.625\n",
      "recall:  0.7037037037037037\n",
      "specificity:  0.5238095238095238\n",
      "precision:  0.6551724137931034\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55        21\n",
      "           1       0.66      0.70      0.68        27\n",
      "\n",
      "    accuracy                           0.62        48\n",
      "   macro avg       0.62      0.61      0.61        48\n",
      "weighted avg       0.62      0.62      0.62        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  2\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[1.13103853e-02 8.05300916e-03 4.61233799e-01 1.07880627e-02\n",
      " 1.20729265e-02 7.48191637e-04 1.13186821e-02 1.43817023e-04\n",
      " 1.22849517e-02 1.15117230e-02 0.00000000e+00 1.10629608e-02\n",
      " 1.65156259e-02 9.44407938e-03 4.27506755e-02 0.00000000e+00\n",
      " 1.27681059e-02 8.61397333e-03 4.16827292e-03 1.86393353e-02\n",
      " 1.13120795e-02 1.14871693e-02 7.80743273e-03 1.27696224e-02\n",
      " 1.30730451e-02 1.15286562e-02 1.09111922e-02 2.98130825e-03\n",
      " 1.11151370e-02 4.29396336e-02 1.00000000e+00 1.10914204e-02\n",
      " 0.00000000e+00 8.12582651e-03 9.98124540e-01 1.20501708e-02\n",
      " 8.48066191e-03 1.41087307e-02 4.79227228e-01 1.35233330e-02\n",
      " 1.13103853e-02 4.29396336e-02 1.12222493e-02 1.13204608e-02\n",
      " 1.10288608e-02 4.71772734e-03 9.86809586e-01 1.30766076e-02]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.58\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[19  2]\n",
      " [26  1]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.4166666666666667\n",
      "recall:  0.037037037037037035\n",
      "specificity:  0.9047619047619048\n",
      "precision:  0.3333333333333333\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.90      0.58        21\n",
      "           1       0.33      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.42        48\n",
      "   macro avg       0.38      0.47      0.32        48\n",
      "weighted avg       0.37      0.42      0.29        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  2\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.11373842 0.31070382 0.17995695 0.62676337 0.75857124 0.01675939\n",
      " 0.50880398 0.19205755 0.66371305 0.45344554 0.02754723 0.42735325\n",
      " 0.80401497 0.35962963 0.2707376  0.02754723 0.90949973 0.0091483\n",
      " 0.93958164 0.59731815 0.23545293 0.91883522 0.30777918 0.86500729\n",
      " 0.93628925 0.17842117 0.4831092  0.61416465 0.07839393 0.08880099\n",
      " 0.29749291 0.4627373  0.02754723 0.05555033 0.22930056 0.73534149\n",
      " 0.03336258 0.5906876  0.82735599 0.65347838 0.11373842 0.08880099\n",
      " 0.63905011 0.90409366 0.63553398 0.59447247 0.61452768 0.73016577]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[21  0]\n",
      " [ 5 22]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8958333333333334\n",
      "recall:  0.8148148148148148\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        21\n",
      "           1       1.00      0.81      0.90        27\n",
      "\n",
      "    accuracy                           0.90        48\n",
      "   macro avg       0.90      0.91      0.90        48\n",
      "weighted avg       0.92      0.90      0.90        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  2\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.2s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.49356444 0.49244579 0.5        0.49172003 0.49339758 0.4818589\n",
      " 0.49239139 0.47981402 0.49408074 0.49198478 0.40643291 0.49286646\n",
      " 0.5        0.49162781 0.5        0.40643291 0.49317869 0.49038808\n",
      " 0.5        0.4944463  0.49426232 0.49284282 0.49294718 0.49382178\n",
      " 0.5        0.49021371 0.49487318 0.49438626 0.492542   0.5\n",
      " 0.48806102 0.49308857 0.40643291 0.49200248 0.52821966 0.493838\n",
      " 0.49126525 0.5        0.5        0.49300574 0.49356444 0.5\n",
      " 0.49365493 0.49329298 0.49307887 0.48902783 0.5087759  0.5       ]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.64\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[10 11]\n",
      " [ 4 23]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6875\n",
      "recall:  0.8518518518518519\n",
      "specificity:  0.47619047619047616\n",
      "precision:  0.6764705882352942\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.48      0.57        21\n",
      "           1       0.68      0.85      0.75        27\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.70      0.66      0.66        48\n",
      "weighted avg       0.69      0.69      0.67        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  2\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[04:59:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:59:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.4927801  0.41096693 0.48340565 0.556568   0.61192983 0.36410072\n",
      " 0.46765444 0.443661   0.5975886  0.49695617 0.3987205  0.5852917\n",
      " 0.5678766  0.5036495  0.47965243 0.3987205  0.609154   0.40528035\n",
      " 0.5648981  0.5006373  0.4516636  0.6296202  0.3954781  0.6296202\n",
      " 0.5991314  0.44549996 0.57266146 0.47064784 0.43153083 0.38814256\n",
      " 0.4849086  0.4091193  0.3987205  0.42408964 0.438744   0.6201221\n",
      " 0.35995847 0.4819657  0.5299679  0.4845991  0.4927801  0.38814256\n",
      " 0.578381   0.6488542  0.57368445 0.451136   0.5        0.52628046]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.83\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[19  2]\n",
      " [10 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.75\n",
      "recall:  0.6296296296296297\n",
      "specificity:  0.9047619047619048\n",
      "precision:  0.8947368421052632\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76        21\n",
      "           1       0.89      0.63      0.74        27\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.77      0.77      0.75        48\n",
      "weighted avg       0.79      0.75      0.75        48\n",
      "\n",
      "\n",
      "KFold:  3\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[-5.18903429e-01 -1.11620414e+00 -4.15113894e-01 -3.46284685e-01\n",
      "  -7.98039289e-03 -7.79108112e-01 -1.65817532e-01  1.76889114e-01\n",
      "  -3.80483290e-01 -1.38568656e-01]\n",
      " [-4.88949117e-01 -1.12273660e+00 -5.10399757e-01 -7.90966878e-01\n",
      "   6.93696477e-02 -7.92717560e-01 -4.98503917e-01  1.79220646e-01\n",
      "  -4.71066924e-01 -3.77982772e-01]\n",
      " [-5.72646283e-01 -1.06008517e+00 -6.34552475e-01 -7.18833384e-01\n",
      "   1.21522922e-01 -1.10696779e+00 -5.81807053e-01  2.34727061e-01\n",
      "  -2.59744584e-01 -5.49266272e-01]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-4.54598176e-01  1.06727171e+00 -6.89935466e-01 -2.49176001e-01\n",
      "   2.92438347e-01 -1.25841696e+00 -8.83602716e-01 -1.78942398e-01\n",
      "   3.93698469e-02  8.61375263e-02]\n",
      " [-2.58864548e-01 -8.50964484e-01 -4.58064729e-01 -5.85918432e-01\n",
      "   9.37523264e-02 -7.23802844e-01 -5.65503085e-01  2.19363748e-01\n",
      "  -4.87174809e-01 -3.24552548e-01]\n",
      " [-3.62661315e-01 -1.27195558e+00 -7.95451597e-01  6.01980572e-01\n",
      "  -7.86710526e-03 -4.05097104e-01 -4.78759326e-01 -4.98257715e-01\n",
      "   1.37431238e-01 -2.01107993e-01]\n",
      " [-5.79080652e-01 -3.37294805e-01 -4.28950140e-01 -9.30142973e-01\n",
      "  -5.64821329e-01 -1.14363977e-01 -4.90320498e-01  2.82461571e-01\n",
      "  -5.81064976e-01 -6.99095867e-02]\n",
      " [-6.49270705e-02  1.48508603e+00 -3.19104035e+00  2.38923331e-01\n",
      "   3.32287549e+00 -4.71205573e+00  2.90252802e+00 -2.24477353e+01\n",
      "   2.48385802e+01  2.32861645e+00]\n",
      " [-5.45464224e-01 -1.18405692e+00 -2.59893090e-01 -5.44467505e-01\n",
      "   2.91560345e-02 -9.61099041e-01 -5.73039275e-01  6.00873869e-01\n",
      "  -7.47406019e-01 -1.95449439e-01]\n",
      " [-5.76854919e-01 -1.62850915e+00  1.97214936e+00  6.63662239e+00\n",
      "  -2.66053412e+00  1.47858385e+00 -2.13317076e+00  1.04966864e-02\n",
      "  -1.91018548e+00 -2.46316519e-01]\n",
      " [-5.85004842e-01 -1.43299896e+00  1.21464860e+00 -2.35960342e-01\n",
      "  -2.76815532e-01 -1.24319410e+00  1.26088817e+00  4.89139542e-02\n",
      "  -1.24801649e+00 -4.34475834e-01]\n",
      " [ 4.81036433e-02 -4.96174757e-01 -3.55339737e-01  2.13323651e-01\n",
      "  -1.22449322e-01 -1.10491609e+00  2.88178491e-01  6.60615894e-02\n",
      "  -5.87434383e-01 -5.11938129e-01]\n",
      " [-4.94942875e-01 -7.54735285e-01  3.65885178e-01 -7.88132066e-01\n",
      "  -8.11626201e-02  3.92777768e-02 -4.91027426e-01  6.18007039e-01\n",
      "  -1.13671929e+00  1.32264112e+00]\n",
      " [-5.35720930e-01 -1.00060779e+00 -4.68855221e-01 -5.17616190e-01\n",
      "  -3.54861954e-03 -6.79004965e-01 -5.19897783e-01  1.52551806e-01\n",
      "  -3.85013194e-01 -2.94405305e-01]\n",
      " [ 2.48006154e-01 -2.65989078e-01 -4.63217068e-01  1.05903924e-01\n",
      "   1.50800003e-01 -5.47233111e-01  3.73671014e-01  4.75732750e-01\n",
      "  -9.08395266e-01 -5.81383824e-01]\n",
      " [-5.27830223e-01 -1.02753438e+00 -4.54006395e-01 -4.37118313e-01\n",
      "   1.67474743e-03 -6.50643852e-01 -5.05367879e-01  1.96180419e-01\n",
      "  -3.75967400e-01 -2.96282748e-01]\n",
      " [-3.37901077e-01 -4.66789345e-01 -8.60774417e-01  4.46392714e-01\n",
      "  -7.35094376e-02 -1.08970896e+00 -6.68349501e-01 -2.10412965e-01\n",
      "  -1.02908668e-01 -9.65289271e-01]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-3.91088852e-01 -1.13020089e+00 -4.93675739e-01 -7.89604025e-02\n",
      "  -6.62500486e-03 -7.63543754e-01 -5.07468931e-01 -1.76432961e-01\n",
      "  -5.36219852e-02 -4.26148196e-01]\n",
      " [-5.29709128e-01 -1.07424409e+00 -4.55626021e-01 -3.40860777e-01\n",
      "   4.09448211e-03 -6.24947568e-01 -5.39898762e-01  2.45454570e-01\n",
      "  -3.72116247e-01 -3.23105648e-01]\n",
      " [-4.24104726e-01 -5.45820995e-01 -7.28168460e-01 -1.17890770e+00\n",
      "  -4.61110137e-01 -4.36531164e-01 -5.39287934e-01  2.74675355e-01\n",
      "  -8.04995845e-01 -6.93271126e-01]\n",
      " [-7.26431409e-01  1.65355661e+00 -2.05094632e+00 -1.68067701e+01\n",
      "  -1.99736868e+01  2.70030734e+01  5.32303718e+00 -3.40877951e+00\n",
      "   2.85885781e+00  1.01894711e+00]\n",
      " [-5.37562915e-01 -4.59151233e-01 -4.37246164e-01 -1.26021538e+00\n",
      "  -8.37778748e-01  3.93500567e-01 -5.08564278e-01  1.35425619e-01\n",
      "  -6.17370554e-01 -7.09791426e-01]\n",
      " [-3.50644002e-01  1.29021798e+00  9.52377417e-01 -1.55109364e+00\n",
      "   3.40091656e+00  1.85927608e+00 -4.01629191e+00  3.33054670e+00\n",
      "  -6.84483882e+00 -2.96322291e+00]\n",
      " [-2.78121759e-01 -1.43200908e+00 -1.54140531e+00  9.71628625e-01\n",
      "   5.99106340e+00 -2.04158556e+00  2.57382166e+00 -1.80371798e+01\n",
      "   1.84640913e+01 -4.99685687e+00]\n",
      " [-8.32317829e-02 -5.00568669e-01 -3.48741778e-01 -7.09698132e-01\n",
      "   9.41593635e-02 -8.79136385e-01 -7.50661425e-01  6.90540969e-02\n",
      "  -8.04676683e-01 -6.07074881e-01]\n",
      " [-4.63108913e-01 -1.33729655e-01 -2.64518123e-01 -3.05493243e-01\n",
      "   4.75915728e-01  8.35845588e-02 -8.17123383e-02 -1.44986231e-01\n",
      "  -7.02533591e-01 -2.05322427e-01]\n",
      " [-5.06538529e-01  8.94240102e-01 -3.50189382e-01 -8.01711519e-02\n",
      "   2.00466812e-02 -7.57850391e-01 -2.59969105e-01  1.55531686e-01\n",
      "  -5.52185904e-01 -3.50940849e-01]\n",
      " [-4.04154792e-01 -3.65259721e-01 -8.93776528e-01 -1.61027304e+00\n",
      "   5.04581993e-02 -1.56267206e+00  3.57652336e-02 -2.59477054e-01\n",
      "   2.92671129e-01 -4.22085951e-01]\n",
      " [-5.19691127e-01 -1.47071107e+00  1.71026165e+00 -3.59880689e-01\n",
      "  -6.77622950e-01 -8.64176364e-01 -5.07163828e-01  2.46700775e-01\n",
      "  -7.55696989e-01 -2.55333971e-01]\n",
      " [-5.07394878e-01 -1.19115843e+00 -4.50555636e-01 -6.02956377e-01\n",
      "  -4.12877429e-02 -7.62557580e-01 -5.55399975e-01  5.93729233e-01\n",
      "  -5.69587243e-01  2.39967452e-01]\n",
      " [-1.84402761e-01 -2.13931016e+00  1.96936353e+00 -5.50012607e-01\n",
      "   5.20601298e-01 -2.05039427e+00  5.86884417e-01  5.15009689e-01\n",
      "   9.12659291e-02 -4.92863661e-01]\n",
      " [-5.39548467e-01 -1.07388101e+00 -7.22590503e-02 -4.45007478e-01\n",
      "  -7.41431849e-02 -7.85761820e-01 -4.39493993e-01  2.42591164e-01\n",
      "  -3.35983024e-01 -3.22112156e-01]\n",
      " [-4.10435522e-01 -9.47517539e-01 -4.09025337e-01 -4.75684434e-01\n",
      "   5.94733821e-02 -7.02789967e-01 -3.42427350e-01  1.42913014e-01\n",
      "  -7.28665711e-02 -3.46273094e-01]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-2.18474837e-01 -1.30306408e+00 -5.42762106e-01  4.91792762e-01\n",
      "  -2.45228210e-01 -5.06211020e-01 -5.81802036e-01  2.73602409e-01\n",
      "  -3.46355303e-01 -3.58066208e-01]\n",
      " [-4.44962288e-01  4.04152317e-01  1.34591826e-01 -3.29797680e-01\n",
      "   3.31559745e-01 -8.57972586e-01 -4.87972416e-01 -5.12028344e-02\n",
      "  -2.44782783e-01 -3.75784853e-01]\n",
      " [-3.53709540e-01 -1.28170916e+00 -2.97170406e-01  2.66692175e-01\n",
      "  -1.15909360e-01 -1.35698318e+00  1.74016211e-01 -3.45961630e-02\n",
      "  -6.19434533e-01 -3.62533376e-01]\n",
      " [-4.03973396e-01 -9.10379006e-01 -2.33716833e-01 -9.74386351e-01\n",
      "   5.58467735e-01  4.70391215e-01 -2.83162413e-01  8.13149276e-01\n",
      "  -8.80700417e-02  1.81608602e-02]\n",
      " [-4.92730094e-01 -1.43973604e+00 -7.23914205e-01  1.10974590e+00\n",
      "  -5.21827433e-01 -4.90780977e-01  3.91139272e-01 -3.77493253e-02\n",
      "  -1.00180505e+00  3.00195489e-01]\n",
      " [-5.16091527e-01 -7.04972222e-01 -5.84668004e-01 -3.02782737e-02\n",
      "  -2.98573281e-01 -3.70371846e-01 -7.08107493e-01  4.14753287e-01\n",
      "  -4.48687525e-01 -5.05226763e-01]\n",
      " [-4.52265927e-01 -1.19964925e+00 -4.59339000e-01 -3.35528079e-01\n",
      "   9.15996812e-02 -6.74005167e-01 -3.29903831e-01  4.56982784e-01\n",
      "  -4.08138099e-01 -3.32009333e-01]\n",
      " [-5.33554037e-01 -9.24297231e-01 -5.70603977e-01 -2.48564854e-01\n",
      "  -1.00819603e-01 -2.10848716e-01 -4.00381784e-01 -4.07239101e-01\n",
      "   1.37872026e-01 -4.05468205e-01]\n",
      " [-5.38033668e-01 -1.10886776e+00 -5.75109366e-02 -4.58954727e-01\n",
      "   9.89826262e-02 -6.76464253e-01 -5.98143710e-01  2.25637912e-01\n",
      "  -4.66966634e-01 -3.32017858e-01]\n",
      " [-5.22433748e-01 -1.46639941e+00 -1.79472010e-01 -8.17040377e-02\n",
      "   4.13397636e-01 -9.39394248e-01  1.10466029e+00  2.21162408e-01\n",
      "  -1.66933537e+00 -5.25064714e-01]\n",
      " [-5.39288975e-01 -1.35563610e+00  2.80330128e-01 -6.00633762e-01\n",
      "   6.75091937e-01 -5.15661544e-01 -4.57260166e-01  7.78768996e-01\n",
      "  -6.30357422e-01 -3.51204586e-01]\n",
      " [-3.58308486e-01  1.24782501e-01 -2.78095198e-02 -4.02474804e-01\n",
      "  -2.84649900e-02 -4.07181612e-01 -5.19626215e-01  1.73316245e-01\n",
      "  -5.58690164e-01 -4.20667601e-01]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1\n",
      " 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 1 0 0 1 1 1 1 1 1] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  3\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "-0.007587203297397978\n",
      "\n",
      " Coefficients \n",
      "[ 0.01814921 -0.39804061  0.22901631 -0.03783794  0.39870169  0.21014917\n",
      "  0.16019282  0.44367613  0.21443167  0.04820015]\n",
      "\n",
      " pop_polarity\n",
      "[0.53545684 0.52122967 0.50761074 0.49922042 0.27980313 0.50389969\n",
      " 0.48024068 0.43111501 0.00629759 0.55716307 0.33673459 0.5993597\n",
      " 0.43662994 0.59601632 0.50918037 0.49648499 0.51986899 0.36140657\n",
      " 0.51904073 0.49260016 0.52904001 0.40943101 0.05737128 0.41913037\n",
      " 0.67253904 0.14871432 0.4251919  0.48939479 0.32979333 0.40406602\n",
      " 0.59285051 0.56565187 0.80336002 0.54123786 0.53461912 0.49922042\n",
      " 0.52416105 0.41269696 0.48721818 0.72105719 0.47081675 0.4710433\n",
      " 0.57700145 0.47752963 0.55321754 0.59576094 0.70891482 0.42598831]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 0 1 0 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.67\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[16  8]\n",
      " [ 9 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6458333333333334\n",
      "recall:  0.625\n",
      "specificity:  0.6666666666666666\n",
      "precision:  0.6521739130434783\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65        24\n",
      "           1       0.65      0.62      0.64        24\n",
      "\n",
      "    accuracy                           0.65        48\n",
      "   macro avg       0.65      0.65      0.65        48\n",
      "weighted avg       0.65      0.65      0.65        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  3\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[1.20438029e-02 1.10778078e-02 1.37291851e-02 1.26477991e-02\n",
      " 1.52151730e-03 1.10280411e-02 8.33474316e-03 1.13851189e-02\n",
      " 9.97580966e-01 1.29806662e-02 6.34263696e-06 4.13677422e-02\n",
      " 1.44196962e-02 2.50634233e-02 1.29686669e-02 2.28303923e-02\n",
      " 1.28645761e-02 1.18102282e-02 1.28434869e-02 1.05248847e-02\n",
      " 1.29276846e-02 1.01211508e-02 8.11152327e-28 1.02220368e-02\n",
      " 2.05030905e-01 9.99419373e-01 1.22808252e-02 9.69724310e-03\n",
      " 2.20377205e-03 6.88426088e-03 4.53387397e-02 1.21613621e-02\n",
      " 2.71279848e-02 1.34843392e-02 1.12444180e-02 1.26477991e-02\n",
      " 8.63988415e-03 5.77722398e-03 9.24537671e-03 1.09764356e-02\n",
      " 7.33278069e-03 1.41945799e-02 1.10607653e-02 1.27314307e-02\n",
      " 1.37450175e-02 1.47644498e-02 1.43134692e-02 7.41186071e-03]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.46\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[22  2]\n",
      " [24  0]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.4583333333333333\n",
      "recall:  0.0\n",
      "specificity:  0.9166666666666666\n",
      "precision:  0.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63        24\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.46        48\n",
      "   macro avg       0.24      0.46      0.31        48\n",
      "weighted avg       0.24      0.46      0.31        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  3\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.42568809 0.72916472 0.39330167 0.05965112 0.37919086 0.81984504\n",
      " 0.40758347 0.27494707 0.06257845 0.84476508 0.61638742 0.58745299\n",
      " 0.12154038 0.89703458 0.74786815 0.81566958 0.77694935 0.28371544\n",
      " 0.7379434  0.49541311 0.91246273 0.01520844 0.03589299 0.2917504\n",
      " 0.04518416 0.08190162 0.22723899 0.34566123 0.88489719 0.08216033\n",
      " 0.3079341  0.47649971 0.13553057 0.64301432 0.80613303 0.05965112\n",
      " 0.62215379 0.30859142 0.06642834 0.88409299 0.23172869 0.19989811\n",
      " 0.92987383 0.54454163 0.92376879 0.65209496 0.95614839 0.86748758]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 1 1 1 1 1 1]\n",
      "\n",
      " auc\n",
      "0.95\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[22  2]\n",
      " [ 4 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.875\n",
      "recall:  0.8333333333333334\n",
      "specificity:  0.9166666666666666\n",
      "precision:  0.9090909090909091\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        24\n",
      "           1       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.88      0.88      0.87        48\n",
      "weighted avg       0.88      0.88      0.87        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  3\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.7s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.51158239 0.51089354 0.50881521 0.50915661 0.47749712 0.50848065\n",
      " 0.5062059  0.5        0.29470261 0.51488117 0.5        0.51482833\n",
      " 0.5        0.51836833 0.50927538 0.50722683 0.51045721 0.49211829\n",
      " 0.51020955 0.50660497 0.51164104 0.5        0.47889516 0.5\n",
      " 0.54369633 0.3988423  0.5        0.50599997 0.48562696 0.49392528\n",
      " 0.51395322 0.51603831 0.53584885 0.51141863 0.5106126  0.50915661\n",
      " 0.51210047 0.49339586 0.50576232 0.53336416 0.50791944 0.50638899\n",
      " 0.516918   0.50514459 0.51324248 0.51994381 0.5311598  0.5       ]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.66\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 8 16]\n",
      " [ 4 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5833333333333334\n",
      "recall:  0.8333333333333334\n",
      "specificity:  0.3333333333333333\n",
      "precision:  0.5555555555555556\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44        24\n",
      "           1       0.56      0.83      0.67        24\n",
      "\n",
      "    accuracy                           0.58        48\n",
      "   macro avg       0.61      0.58      0.56        48\n",
      "weighted avg       0.61      0.58      0.56        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  3\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:00:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:00:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.50886285 0.6147514  0.51564735 0.48952842 0.4195863  0.5718242\n",
      " 0.4749165  0.50337994 0.4271623  0.61365795 0.51282984 0.45313376\n",
      " 0.40916607 0.59049207 0.63273644 0.464417   0.6678195  0.40989262\n",
      " 0.6678195  0.49670556 0.6587769  0.4464251  0.3630389  0.47482738\n",
      " 0.489109   0.4271623  0.4890814  0.4250284  0.6349106  0.3799519\n",
      " 0.5085899  0.5785749  0.45406553 0.60197914 0.56347203 0.48952842\n",
      " 0.5179579  0.49948698 0.3753085  0.6111277  0.38675967 0.4690482\n",
      " 0.59522843 0.4965001  0.6254659  0.48599136 0.6455087  0.59985465]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1\n",
      " 0 0 1 0 0 1 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.77\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[17  7]\n",
      " [ 8 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6875\n",
      "recall:  0.6666666666666666\n",
      "specificity:  0.7083333333333334\n",
      "precision:  0.6956521739130435\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        24\n",
      "           1       0.70      0.67      0.68        24\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.69      0.69      0.69        48\n",
      "weighted avg       0.69      0.69      0.69        48\n",
      "\n",
      "\n",
      "KFold:  4\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[-4.62167103e-01 -1.08122407e+00 -1.87189822e-01 -2.03298242e-01\n",
      "   5.86896373e-01  6.02052595e-03 -7.90854983e-01 -6.29439472e-02\n",
      "  -4.38541538e-01 -2.99918260e-01]\n",
      " [ 4.38792858e-02  6.13110377e-02 -8.54702138e-01  4.43303980e-01\n",
      "  -1.28530696e+00  2.06580468e+00  4.24917642e-01 -4.41774520e-01\n",
      "   1.77399137e+00  7.90062783e-01]\n",
      " [-4.95542998e-01 -9.17953925e-01 -6.67438067e-02 -1.38000649e+00\n",
      "  -3.14132914e-01  5.32482593e-01 -6.01004497e-01  7.36843993e-01\n",
      "  -4.02648542e-01 -2.77537431e-01]\n",
      " [-2.71682130e-01 -6.36999735e-01  8.97990524e-01 -5.72673724e-01\n",
      "   6.39311405e-01 -5.81594490e-01 -6.07603211e-01  1.02435000e+00\n",
      "  -5.22812433e-01 -4.32012290e-01]\n",
      " [-5.19022689e-01 -1.18637590e+00  3.15384021e-01 -5.04569688e-01\n",
      "  -8.00412178e-01 -2.72245138e-01 -6.65487600e-01 -9.20701323e-02\n",
      "  -8.24364142e-02 -4.02732413e-01]\n",
      " [-3.83578220e-01 -1.31037259e+00 -4.39976877e-01 -2.89725353e-01\n",
      "   3.11026901e-01 -9.28500667e-01 -3.78167096e-01 -8.21467424e-02\n",
      "   3.82216249e-01 -1.75917498e-01]\n",
      " [-3.02993433e-01  1.15594609e+00 -7.82271277e-01 -2.23098595e-01\n",
      "  -6.90721517e-01 -5.25233224e-01 -6.21184529e-01  4.44692847e-01\n",
      "  -7.60067436e-01 -8.43495206e-01]\n",
      " [-5.15361345e-01 -1.20444994e+00 -3.30901377e-01 -3.78428931e-01\n",
      "   2.28375766e-02 -6.67918510e-01 -4.18331167e-01  4.07046229e-01\n",
      "  -4.80789542e-01 -3.67763000e-01]\n",
      " [-3.15015711e-01 -6.13440347e-01  3.96247943e-01 -2.38510002e-01\n",
      "   6.98345884e-01 -2.30372930e+00  8.25243927e-01 -1.46077359e+00\n",
      "   1.08102573e+00  1.83489831e-01]\n",
      " [-1.43777264e-01 -1.63636948e+00  3.58669993e-01  1.23266328e+00\n",
      "  -1.20901460e-02 -2.87779846e+00 -6.99069299e-01  3.22122867e+00\n",
      "  -2.03528862e+00 -4.46478179e+00]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [ 5.29263522e-01 -6.60689048e-01  8.29729664e-01 -2.35189044e+00\n",
      "  -7.12273315e-01  1.01713985e+00  2.41132584e+00  6.85059870e+00\n",
      "   4.20045230e+00  4.79045869e-01]\n",
      " [-5.46403124e-01 -1.06739321e+00  1.41540725e-01 -4.87901099e-01\n",
      "   1.29227037e-01 -7.64141439e-01 -4.74606727e-01  3.34040550e-01\n",
      "  -2.92749902e-01 -4.98440913e-01]\n",
      " [-4.03889396e-01 -1.23054498e+00 -4.76638386e-01  7.77511123e-01\n",
      "  -4.42396931e-01 -2.89500024e-01 -7.61954666e-01 -3.93833127e-01\n",
      "   3.57763291e-01 -3.54129795e-01]\n",
      " [-5.31221519e-01 -1.27494337e+00  9.58743405e-02 -3.17163851e-01\n",
      "   1.07403492e-02 -8.27313785e-01 -1.23691255e-01  1.27746087e-01\n",
      "  -6.16745385e-01 -4.48461080e-01]\n",
      " [-5.34103906e-01 -1.06196367e+00 -4.49325083e-01 -4.35074001e-01\n",
      "   2.08338875e-03 -6.73472839e-01 -5.06558190e-01  2.03274210e-01\n",
      "  -3.90956192e-01 -3.23939123e-01]\n",
      " [-5.31221519e-01 -1.27494337e+00  9.58743405e-02 -3.17163851e-01\n",
      "   1.07403492e-02 -8.27313785e-01 -1.23691255e-01  1.27746087e-01\n",
      "  -6.16745385e-01 -4.48461080e-01]\n",
      " [-4.50421360e-01 -1.30532666e+00 -2.39335531e-01 -4.60462404e-01\n",
      "   3.87729313e-02 -9.74103525e-01 -6.03500627e-01  4.26982785e-02\n",
      "  -5.85266944e-01  3.57077183e-01]\n",
      " [-2.94111850e-01  2.08066264e+00  8.12617401e-01 -6.24172902e-01\n",
      "  -9.81351994e-02 -9.42660894e-01 -1.35084283e+00 -4.18780085e-01\n",
      "  -2.80982348e+00 -1.35214677e+00]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-4.44962288e-01  4.04152317e-01  1.34591826e-01 -3.29797680e-01\n",
      "   3.31559745e-01 -8.57972586e-01 -4.87972416e-01 -5.12028344e-02\n",
      "  -2.44782783e-01 -3.75784853e-01]\n",
      " [-5.44887497e-01  1.12555495e+00 -6.49219412e-01  6.19516779e-01\n",
      "  -1.66305945e-01 -9.24994010e-01 -8.41404435e-01  9.06675538e-01\n",
      "  -6.47729777e-01 -8.13536042e-01]\n",
      " [-5.10013497e-01 -1.18467999e+00  2.77624822e-02  4.06670194e-01\n",
      "  -1.47762620e-01 -5.50924427e-01 -3.21993869e-01  2.65097911e-01\n",
      "  -5.55312300e-01  1.16644333e-01]\n",
      " [-4.86039496e-01 -1.17356539e+00 -2.22207557e-01 -4.51701218e-01\n",
      "   1.66052015e-01 -7.10821568e-01 -3.96813712e-01  6.22102095e-01\n",
      "  -4.06916099e-01 -3.00777410e-01]\n",
      " [-6.05499161e-01 -3.54963517e-01 -3.66185613e-01 -2.01272163e+00\n",
      "  -3.50962108e-01 -3.92599039e-01  9.88928820e-01 -9.25233795e-02\n",
      "   1.44934399e+00  2.46461664e+00]\n",
      " [ 1.52654881e+02 -2.72761626e+00 -1.88781799e-01 -1.49910691e+00\n",
      "  -1.45097542e+00 -2.10217628e-01 -2.01180476e+00  2.96249235e-01\n",
      "   8.91332194e-02 -1.91874909e-01]\n",
      " [-5.31434259e-01 -9.78786392e-01 -4.96828505e-01 -5.88473119e-01\n",
      "  -3.59261823e-01 -1.64984790e-01 -4.09299905e-01  9.53164916e-02\n",
      "  -3.20729999e-01 -2.67154372e-01]\n",
      " [-5.37666242e-01 -1.97320944e-01 -6.97822949e-01  8.72009215e-01\n",
      "  -3.39338101e-01  1.77259673e-02 -5.32453617e-01 -4.50315796e-01\n",
      "   2.34853227e-01 -5.06343902e-01]\n",
      " [-3.50644002e-01  1.29021798e+00  9.52377417e-01 -1.55109364e+00\n",
      "   3.40091656e+00  1.85927608e+00 -4.01629191e+00  3.33054670e+00\n",
      "  -6.84483882e+00 -2.96322291e+00]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-2.68606043e-01  9.53628175e-01 -5.72598579e-01 -1.13874593e+00\n",
      "   5.22937987e-01 -4.86062010e-01 -5.80086339e-01 -4.09719434e-01\n",
      "   1.48477184e-01 -4.13527152e-01]\n",
      " [-2.84390717e-01 -7.33180278e-01  9.40482562e-01 -2.49917224e-01\n",
      "  -3.50172490e-01 -8.41738355e-01 -2.73018514e-01 -6.33978557e-02\n",
      "  -6.75753251e-01 -4.27653972e-01]\n",
      " [-4.24104726e-01 -5.45820995e-01 -7.28168460e-01 -1.17890770e+00\n",
      "  -4.61110137e-01 -4.36531164e-01 -5.39287934e-01  2.74675355e-01\n",
      "  -8.04995845e-01 -6.93271126e-01]\n",
      " [-7.26431409e-01  1.65355661e+00 -2.05094632e+00 -1.68067701e+01\n",
      "  -1.99736868e+01  2.70030734e+01  5.32303718e+00 -3.40877951e+00\n",
      "   2.85885781e+00  1.01894711e+00]\n",
      " [-4.77588851e-01 -9.99238344e-01 -2.71118847e-01 -3.73245291e-01\n",
      "   1.98642106e-01 -9.43828633e-01 -6.70183032e-01 -3.76460547e-01\n",
      "  -3.45399921e-02  6.75883465e-02]\n",
      " [-2.42347592e-01  2.18815455e-01  6.63630620e-01 -1.25332627e+00\n",
      "   2.05636314e+00  1.72288761e+00 -8.32148792e-01  7.94950736e-01\n",
      "  -1.26469856e+00 -3.97716835e-02]\n",
      " [-4.06442641e-01 -1.19385306e+00 -2.07122611e-01 -4.83456855e-01\n",
      "   9.62002115e-02 -9.31697518e-01 -3.02196627e-01  1.62177111e-01\n",
      "  -2.05159286e-01 -8.67383307e-02]\n",
      " [-4.62167103e-01 -1.08122407e+00 -1.87189822e-01 -2.03298242e-01\n",
      "   5.86896373e-01  6.02052595e-03 -7.90854983e-01 -6.29439472e-02\n",
      "  -4.38541538e-01 -2.99918260e-01]\n",
      " [-4.48392546e-01 -1.17159775e+00 -4.71833365e-02 -4.88779562e-01\n",
      "  -3.35180306e-02 -6.79416922e-01 -5.37424873e-01  1.18104156e-01\n",
      "  -4.59891086e-01 -2.07940951e-01]\n",
      " [ 6.57217391e-02  6.83179447e-01 -2.86231642e-01 -7.33692323e-02\n",
      "   6.32873765e-01 -9.96981825e-01  1.52947637e+00 -9.93644890e-01\n",
      "   5.47929509e-01 -6.77409704e-01]\n",
      " [-5.16427954e-01 -6.40963437e-01  1.33117416e+00 -7.82079652e-01\n",
      "   2.20472981e+00  3.61094195e-01 -1.08408881e+00  3.19064580e+00\n",
      "  -4.73257447e-01 -3.81850461e-01]\n",
      " [-7.26431409e-01  1.65355661e+00 -2.05094632e+00 -1.68067701e+01\n",
      "  -1.99736868e+01  2.70030734e+01  5.32303718e+00 -3.40877951e+00\n",
      "   2.85885781e+00  1.01894711e+00]\n",
      " [-1.46174275e-01 -6.35852102e-01 -6.47049357e-02 -4.88773805e-01\n",
      "   1.24762916e+00  4.09149953e-01 -5.41067696e-01  6.34704893e-01\n",
      "  -7.15613475e-01 -1.36279480e-01]\n",
      " [-3.53709540e-01 -1.28170916e+00 -2.97170406e-01  2.66692175e-01\n",
      "  -1.15909360e-01 -1.35698318e+00  1.74016211e-01 -3.45961630e-02\n",
      "  -6.19434533e-01 -3.62533376e-01]\n",
      " [-4.28532914e-01 -1.60440462e+00 -7.13067607e-02  6.35286797e-01\n",
      "   1.42641810e+00 -3.74287914e-01  4.62691165e+00  2.18662195e-01\n",
      "  -2.13955509e+00 -1.09781217e+00]\n",
      " [ 1.59863454e+00  1.90030312e-01  1.92504517e-01 -2.33237950e-01\n",
      "   2.43665166e+00  9.13726549e-01 -8.71598525e-01  1.54140360e+00\n",
      "  -9.06599349e-01 -5.51704109e-01]\n",
      " [-5.05777692e-01 -1.06200200e+00 -4.32914922e-01 -4.92816562e-01\n",
      "   6.82997417e-02 -6.82451476e-01 -3.47276798e-01  2.41476432e-01\n",
      "  -4.48598452e-01 -2.97264425e-01]\n",
      " [-3.01210978e-01 -1.09835864e+00  4.28623588e-01  3.60554555e+00\n",
      "  -1.91471277e+00  5.50975174e-01 -7.52485727e-02 -5.98095403e-01\n",
      "  -2.67816019e+00 -5.58537845e-01]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1\n",
      " 0 1 0 1 0 1 0 1 1 1 0] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  4\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "-0.32631111973942056\n",
      "\n",
      " Coefficients \n",
      "[-1.090991   -0.33976206  0.33909776  0.02483606  0.40647423  0.20625566\n",
      "  0.18246746  0.38968378  0.18696481  0.05172652]\n",
      "\n",
      " pop_polarity\n",
      "[6.10687756e-01 3.79359039e-01 6.31644209e-01 6.86739687e-01\n",
      " 5.40507580e-01 5.68873415e-01 2.36098799e-01 5.91086284e-01\n",
      " 4.88972524e-01 6.12187149e-01 5.48820401e-01 9.67189120e-01\n",
      " 6.28624496e-01 4.76676772e-01 6.06706571e-01 5.53026344e-01\n",
      " 6.06706571e-01 5.36537817e-01 1.55567062e-01 5.48820401e-01\n",
      " 4.60801851e-01 3.67999710e-01 6.04726972e-01 6.26067586e-01\n",
      " 6.45644263e-01 3.20510079e-73 5.27861117e-01 4.31226872e-01\n",
      " 6.90009688e-01 5.48820401e-01 3.25952193e-01 5.01709336e-01\n",
      " 3.99016210e-01 2.85374054e-02 5.11786726e-01 7.62836256e-01\n",
      " 5.62827580e-01 6.10687756e-01 5.57314434e-01 3.27806112e-01\n",
      " 9.42394061e-01 2.85374054e-02 6.48944610e-01 4.89406278e-01\n",
      " 8.39322254e-01 3.42312037e-01 5.61133217e-01 3.03503363e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1\n",
      " 1 1 0 1 0 1 0 1 0 1 0]\n",
      "\n",
      " auc\n",
      "0.64\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[11 13]\n",
      " [ 6 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6041666666666666\n",
      "recall:  0.75\n",
      "specificity:  0.4583333333333333\n",
      "precision:  0.5806451612903226\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.46      0.54        24\n",
      "           1       0.58      0.75      0.65        24\n",
      "\n",
      "    accuracy                           0.60        48\n",
      "   macro avg       0.61      0.60      0.60        48\n",
      "weighted avg       0.61      0.60      0.60        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  4\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[2.57700851e-01 1.36875949e-01 2.10211144e-01 3.81948720e-01\n",
      " 2.65345775e-01 2.00192009e-01 2.60918251e-02 2.34709189e-01\n",
      " 2.96545127e-01 9.17551183e-01 2.45214704e-01 4.87771522e-01\n",
      " 2.75461090e-01 1.87525042e-01 2.44953675e-01 2.44358584e-01\n",
      " 2.44953675e-01 2.25410185e-01 3.17690095e-03 2.45214704e-01\n",
      " 1.25274654e-01 3.13015692e-02 2.40169559e-01 2.39044507e-01\n",
      " 4.41213037e-01 1.00000000e+00 2.36343956e-01 1.78216816e-01\n",
      " 8.22923909e-01 2.45214704e-01 2.99571728e-02 3.62536042e-01\n",
      " 2.12560464e-01 9.79955293e-23 2.45282893e-01 1.95221998e-01\n",
      " 2.18898445e-01 2.57700851e-01 2.35352353e-01 9.35276542e-02\n",
      " 6.42578503e-01 9.79955293e-23 2.48861520e-01 2.04004691e-01\n",
      " 9.63609817e-01 1.60588079e-01 2.38134170e-01 2.26472157e-02]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.53\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[22  2]\n",
      " [21  3]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5208333333333334\n",
      "recall:  0.125\n",
      "specificity:  0.9166666666666666\n",
      "precision:  0.6\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.92      0.66        24\n",
      "           1       0.60      0.12      0.21        24\n",
      "\n",
      "    accuracy                           0.52        48\n",
      "   macro avg       0.56      0.52      0.43        48\n",
      "weighted avg       0.56      0.52      0.43        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  4\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.11486858 0.15355138 0.81445241 0.93209877 0.21543164 0.64148996\n",
      " 0.01151104 0.96340446 0.05177726 0.14631834 0.76982664 0.63307799\n",
      " 0.56525337 0.09728338 0.45633424 0.84675539 0.45633424 0.5475224\n",
      " 0.17219889 0.76982664 0.42810923 0.49829804 0.77185842 0.95603347\n",
      " 0.06789635 0.51681899 0.13700189 0.4798331  0.07836508 0.76982664\n",
      " 0.23557093 0.59999845 0.01211189 0.02787226 0.15825343 0.820019\n",
      " 0.83309538 0.11486858 0.59993321 0.13991273 0.88863089 0.02787226\n",
      " 0.90897988 0.08718347 0.70507955 0.94516972 0.9019865  0.1390849 ]\n",
      "\n",
      " yhat\n",
      "[0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1\n",
      " 0 1 0 1 0 1 0 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.93\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[21  3]\n",
      " [ 4 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8541666666666666\n",
      "recall:  0.8333333333333334\n",
      "specificity:  0.875\n",
      "precision:  0.8695652173913043\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86        24\n",
      "           1       0.87      0.83      0.85        24\n",
      "\n",
      "    accuracy                           0.85        48\n",
      "   macro avg       0.85      0.85      0.85        48\n",
      "weighted avg       0.85      0.85      0.85        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  4\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n",
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   25.3s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[5.24286756e-01 4.81999160e-01 5.26129674e-01 5.32676597e-01\n",
      " 5.12862782e-01 5.15535347e-01 4.59566710e-01 5.20598430e-01\n",
      " 5.00000000e-01 5.21047169e-01 5.14165195e-01 6.11326573e-01\n",
      " 5.26636323e-01 5.00000000e-01 5.23326400e-01 5.14962335e-01\n",
      " 5.23326400e-01 5.11151284e-01 4.41254654e-01 5.14165195e-01\n",
      " 5.00000000e-01 4.86388066e-01 5.23111981e-01 5.25446860e-01\n",
      " 5.25425942e-01 1.00000010e-07 5.11155233e-01 5.00000000e-01\n",
      " 5.39563910e-01 5.14165195e-01 4.75546757e-01 5.00000000e-01\n",
      " 4.89796515e-01 3.75102667e-01 5.07994790e-01 5.48368779e-01\n",
      " 5.14517084e-01 5.24286756e-01 5.14566538e-01 4.72456910e-01\n",
      " 6.10145452e-01 3.75102667e-01 5.26315390e-01 5.00000000e-01\n",
      " 5.69332235e-01 4.59236603e-01 5.15764690e-01 4.78556663e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 0]\n",
      "\n",
      " auc\n",
      "0.63\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 7 17]\n",
      " [ 5 19]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5416666666666666\n",
      "recall:  0.7916666666666666\n",
      "specificity:  0.2916666666666667\n",
      "precision:  0.5277777777777778\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.29      0.39        24\n",
      "           1       0.53      0.79      0.63        24\n",
      "\n",
      "    accuracy                           0.54        48\n",
      "   macro avg       0.56      0.54      0.51        48\n",
      "weighted avg       0.56      0.54      0.51        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  4\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:01:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:01:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.4756718  0.36418086 0.47815698 0.58828616 0.4399444  0.51850283\n",
      " 0.42755955 0.66980225 0.40688854 0.4820066  0.66980225 0.44482216\n",
      " 0.61656815 0.4080469  0.5427091  0.66980225 0.5427091  0.54212797\n",
      " 0.4545066  0.66980225 0.53811574 0.44124973 0.5099904  0.66980225\n",
      " 0.37410414 0.5044205  0.48276106 0.39822698 0.48584747 0.66980225\n",
      " 0.45537826 0.37603033 0.4226389  0.35002834 0.50195503 0.50378215\n",
      " 0.57666916 0.4756718  0.5880697  0.40688854 0.57947654 0.35002834\n",
      " 0.56389123 0.37026328 0.51384026 0.50820684 0.66980225 0.38825667]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1\n",
      " 0 1 0 1 0 1 0 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.7\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[17  7]\n",
      " [ 7 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7083333333333334\n",
      "recall:  0.7083333333333334\n",
      "specificity:  0.7083333333333334\n",
      "precision:  0.7083333333333334\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        24\n",
      "           1       0.71      0.71      0.71        24\n",
      "\n",
      "    accuracy                           0.71        48\n",
      "   macro avg       0.71      0.71      0.71        48\n",
      "weighted avg       0.71      0.71      0.71        48\n",
      "\n",
      "\n",
      "KFold:  5\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[-3.73176240e-01 -1.77610380e-01 -7.40763200e-01 -9.75121574e-01\n",
      "  -1.58317232e-01 -7.95803787e-01  5.93285580e-02 -1.02061261e-01\n",
      "  -6.22775711e-01  1.27222632e+00]\n",
      " [-5.25607803e-01 -1.44534730e+00  9.31138812e-01 -9.67402626e-01\n",
      "   1.34320226e-01 -9.73318001e-01 -4.85990301e-01  9.99576141e-01\n",
      "  -8.13824612e-01  3.60401874e+00]\n",
      " [-4.04154792e-01 -3.65259721e-01 -8.93776528e-01 -1.61027304e+00\n",
      "   5.04581993e-02 -1.56267206e+00  3.57652336e-02 -2.59477054e-01\n",
      "   2.92671129e-01 -4.22085951e-01]\n",
      " [-5.38385283e-01 -7.54885128e-01 -5.63628079e-01 -1.32390371e+00\n",
      "   1.50964041e-01 -8.25541030e-01 -9.62651637e-01  3.38113372e-01\n",
      "  -8.94265953e-01 -5.98617741e-01]\n",
      " [-5.05859772e-01 -1.16119530e+00 -6.10367335e-01  9.31632239e-01\n",
      "  -3.68798254e-01 -1.43853287e-01 -7.25614432e-01  1.44949950e-01\n",
      "  -3.01129186e-01 -2.41151252e-01]\n",
      " [-3.76562697e-01  1.93059380e+00 -3.72485112e-01 -1.98278692e-02\n",
      "   3.27172983e-02 -1.40342685e+00 -6.15313340e-01  8.76819642e-01\n",
      "   5.71375175e-01 -8.79919546e-01]\n",
      " [-4.62167103e-01 -1.08122407e+00 -1.87189822e-01 -2.03298242e-01\n",
      "   5.86896373e-01  6.02052595e-03 -7.90854983e-01 -6.29439472e-02\n",
      "  -4.38541538e-01 -2.99918260e-01]\n",
      " [-3.50644002e-01  1.29021798e+00  9.52377417e-01 -1.55109364e+00\n",
      "   3.40091656e+00  1.85927608e+00 -4.01629191e+00  3.33054670e+00\n",
      "  -6.84483882e+00 -2.96322291e+00]\n",
      " [-5.33019826e-01 -9.93147108e-01 -4.74376476e-01 -5.53259390e-01\n",
      "  -5.00251013e-02 -6.36417940e-01 -4.87157601e-01  1.49284487e-01\n",
      "  -3.79033182e-01 -3.10356304e-01]\n",
      " [-2.33899037e-01 -1.01729567e+00  5.14616156e-01 -4.78847038e-01\n",
      "   2.00839501e-01 -8.26797943e-01 -1.39161098e-01  9.52279299e-02\n",
      "  -4.01772599e-01 -4.58115542e-03]\n",
      " [-4.24104726e-01 -5.45820995e-01 -7.28168460e-01 -1.17890770e+00\n",
      "  -4.61110137e-01 -4.36531164e-01 -5.39287934e-01  2.74675355e-01\n",
      "  -8.04995845e-01 -6.93271126e-01]\n",
      " [-5.22839401e-01 -9.66971872e-01 -4.43772077e-01 -5.14491274e-01\n",
      "  -4.37665942e-03 -6.60722055e-01 -4.38366122e-01  1.44617086e-01\n",
      "  -3.26050044e-01 -2.49890836e-01]\n",
      " [-4.72054490e-01 -1.28456003e+00  1.06813035e-01 -3.56752190e-01\n",
      "   2.10574450e-01 -1.27345498e+00 -1.91294135e-01  7.94253433e-01\n",
      "  -3.28910162e-01 -3.24982914e-01]\n",
      " [-2.45576015e-01 -6.77427304e-01 -1.05885628e+00 -9.89528982e-01\n",
      "   4.12688136e-01 -1.65014585e+00  5.00551375e-01 -1.85407508e+00\n",
      "  -7.27716476e-01  5.86457957e-01]\n",
      " [-5.39548467e-01 -1.07388101e+00 -7.22590503e-02 -4.45007478e-01\n",
      "  -7.41431849e-02 -7.85761820e-01 -4.39493993e-01  2.42591164e-01\n",
      "  -3.35983024e-01 -3.22112156e-01]\n",
      " [-4.77187690e-01 -1.47849563e+00 -4.78531225e-02 -2.69162749e-01\n",
      "  -4.20534531e-01 -4.21134946e-01 -6.32893918e-01 -5.83552005e-01\n",
      "  -8.62705127e-02 -4.41792224e-01]\n",
      " [-4.71176023e-01 -8.47788122e-01 -3.55145799e-01 -4.27245456e-01\n",
      "   7.68549771e-02 -6.27612085e-01 -4.15699571e-01 -6.25061270e-02\n",
      "  -4.42810951e-01 -1.60835889e-01]\n",
      " [-6.49270705e-02  1.48508603e+00 -3.19104035e+00  2.38923331e-01\n",
      "   3.32287549e+00 -4.71205573e+00  2.90252802e+00 -2.24477353e+01\n",
      "   2.48385802e+01  2.32861645e+00]\n",
      " [-2.45576015e-01 -6.77427304e-01 -1.05885628e+00 -9.89528982e-01\n",
      "   4.12688136e-01 -1.65014585e+00  5.00551375e-01 -1.85407508e+00\n",
      "  -7.27716476e-01  5.86457957e-01]\n",
      " [-5.48482212e-01 -8.30911435e-01  9.90631098e-02 -3.86669700e-01\n",
      "   1.50152200e-01 -8.74943690e-01 -3.93201111e-01 -8.35311134e-02\n",
      "  -6.38729657e-01 -5.38647316e-01]\n",
      " [-4.39745026e-01 -1.04487347e+00 -6.26033879e-02 -3.80095643e-01\n",
      "   5.28247777e-01 -9.38437147e-01 -1.75904061e-01 -2.18160963e-01\n",
      "  -2.63530223e-01 -1.43414713e-01]\n",
      " [-4.64617583e-01 -1.02337851e+00 -4.46638126e-01 -1.37699154e-01\n",
      "   1.31035899e-01 -6.34045069e-01 -3.99215779e-01 -2.33363219e-01\n",
      "   4.06089046e-01 -2.46121142e-01]\n",
      " [-6.02623905e-01 -1.14088688e+00 -5.05266690e-01 -1.03133763e+00\n",
      "   8.94503940e-02 -1.15792018e-01 -5.69265902e-01  5.30147448e-01\n",
      "  -4.64454731e-01 -5.17383779e-01]\n",
      " [-4.03889396e-01 -1.23054498e+00 -4.76638386e-01  7.77511123e-01\n",
      "  -4.42396931e-01 -2.89500024e-01 -7.61954666e-01 -3.93833127e-01\n",
      "   3.57763291e-01 -3.54129795e-01]\n",
      " [-4.37409855e-01 -1.75050615e+00 -3.24220192e-01 -9.04919708e-01\n",
      "  -3.83658314e-02 -2.88911806e+00  8.15836210e-01  6.29697589e-01\n",
      "   2.21579311e+00  5.54847063e+00]\n",
      " [-5.07394878e-01 -1.19115843e+00 -4.50555636e-01 -6.02956377e-01\n",
      "  -4.12877429e-02 -7.62557580e-01 -5.55399975e-01  5.93729233e-01\n",
      "  -5.69587243e-01  2.39967452e-01]\n",
      " [-4.89408520e-01 -8.78465896e-01 -4.74409978e-02 -2.09848107e-01\n",
      "  -2.33475108e-01 -4.50106096e-01  1.57534183e-01  1.88763603e-02\n",
      "  -7.41604570e-01 -2.67777499e-01]\n",
      " [-5.15971501e-01 -1.10142275e+00 -4.04786987e-01 -5.01259137e-01\n",
      "   2.37563566e-01 -7.68268396e-01 -4.55581854e-01  2.36312893e-01\n",
      "   4.74278051e-03 -4.71582468e-01]\n",
      " [-3.15015711e-01 -6.13440347e-01  3.96247943e-01 -2.38510002e-01\n",
      "   6.98345884e-01 -2.30372930e+00  8.25243927e-01 -1.46077359e+00\n",
      "   1.08102573e+00  1.83489831e-01]\n",
      " [-4.86289526e-01 -2.07311590e-01 -2.29801375e-01 -5.03825797e-01\n",
      "  -4.55803361e-01  4.09780998e-02 -2.73835190e-01  5.95452446e-01\n",
      "  -5.38894709e-01  6.36721834e-02]\n",
      " [ 9.64971636e-02 -1.63296730e-02 -1.66836553e-01 -2.90504077e-01\n",
      "   1.83592305e+00 -1.96334128e-01 -6.47356777e-01 -1.75750933e+00\n",
      "   1.99353691e+00 -9.35861586e-03]\n",
      " [-4.72185945e-01 -9.76668714e-01 -6.64707410e-01 -9.80846555e-01\n",
      "  -3.74621810e-01 -2.57444624e-01 -1.55846059e-01 -4.23744944e-01\n",
      "  -5.52984853e-02 -1.72609392e-02]\n",
      " [-5.16332408e-01 -1.61720368e+00 -9.37397983e-01  3.85490615e+00\n",
      "  -3.04484039e-02  1.74293550e+00 -8.38482706e-01  1.44316943e-03\n",
      "  -1.88149641e-01 -3.90942942e-01]\n",
      " [-2.89900135e-01  2.31186436e-02 -4.44435322e-01 -5.34052934e-01\n",
      "  -1.94013670e-01 -6.46482583e-01 -6.87093712e-01  2.03407527e-01\n",
      "  -6.26216077e-01  5.54657055e-01]\n",
      " [-3.04698547e-01  2.56184513e+00  5.40628240e-01 -4.84743055e-03\n",
      "   1.33632041e+00  7.52100429e-01 -3.92218092e-01  2.10212563e-01\n",
      "  -1.90323153e-01 -3.83091292e-01]\n",
      " [-5.07210006e-01 -7.92944309e-01 -2.79731182e-01 -3.78585468e-01\n",
      "   4.51250124e-02 -8.28968051e-01 -6.18155340e-01  1.41726676e-01\n",
      "  -3.57052987e-01 -4.06828024e-01]\n",
      " [-4.24104726e-01 -5.45820995e-01 -7.28168460e-01 -1.17890770e+00\n",
      "  -4.61110137e-01 -4.36531164e-01 -5.39287934e-01  2.74675355e-01\n",
      "  -8.04995845e-01 -6.93271126e-01]\n",
      " [-5.01478494e-01 -1.07824974e+00 -4.23096906e-01 -4.50328773e-01\n",
      "   1.56814374e-01 -8.04255021e-01 -5.42872199e-01 -1.32666412e-01\n",
      "  -9.39367235e-02 -3.75665596e-01]\n",
      " [-3.02993433e-01  1.15594609e+00 -7.82271277e-01 -2.23098595e-01\n",
      "  -6.90721517e-01 -5.25233224e-01 -6.21184529e-01  4.44692847e-01\n",
      "  -7.60067436e-01 -8.43495206e-01]\n",
      " [-5.57907414e-01 -1.25656884e+00 -3.55814669e-01 -6.08331892e-01\n",
      "   1.43912639e-01 -7.29647701e-01 -7.29167626e-01  5.15172380e-01\n",
      "  -8.67330989e-01 -6.36644885e-01]\n",
      " [-1.43777264e-01 -1.63636948e+00  3.58669993e-01  1.23266328e+00\n",
      "  -1.20901460e-02 -2.87779846e+00 -6.99069299e-01  3.22122867e+00\n",
      "  -2.03528862e+00 -4.46478179e+00]\n",
      " [-4.82658893e-01 -8.60937136e-01 -6.10357111e-01 -9.31001532e-01\n",
      "  -6.07774963e-01  3.21487446e-02 -4.36223480e-01  4.62847166e-01\n",
      "  -6.19809907e-01  6.01032765e-02]\n",
      " [-4.66555556e-01 -1.68374203e+00 -2.32198785e-01 -3.00515426e-01\n",
      "   3.97346693e-01 -1.40719317e+00  9.57337397e-01  6.12029374e-01\n",
      "  -1.36555879e+00 -1.28037446e+00]\n",
      " [-2.71112597e-01 -8.53244129e-01 -2.45455996e-01 -2.64949570e-01\n",
      "   2.13630418e-01 -7.49266373e-01 -4.98900937e-01  1.03768286e-02\n",
      "  -4.77224947e-01 -4.83061962e-01]\n",
      " [-2.38930181e-02 -1.90546506e+00  4.82914181e-02  5.98970609e-01\n",
      "   6.94932432e-01 -5.04715774e-01  3.74720463e+00  3.12430526e+00\n",
      "   1.14219410e+00 -6.63028983e-01]\n",
      " [-1.01886612e-02 -5.59642058e+00 -7.73617564e+00  4.76476551e+01\n",
      "  -1.41209605e+01  1.82085571e+01 -5.72862712e+00 -7.05213012e-01\n",
      "   2.75722648e+00  1.30739869e+00]\n",
      " [-5.31434259e-01 -9.78786392e-01 -4.96828505e-01 -5.88473119e-01\n",
      "  -3.59261823e-01 -1.64984790e-01 -4.09299905e-01  9.53164916e-02\n",
      "  -3.20729999e-01 -2.67154372e-01]\n",
      " [-4.03889396e-01 -1.23054498e+00 -4.76638386e-01  7.77511123e-01\n",
      "  -4.42396931e-01 -2.89500024e-01 -7.61954666e-01 -3.93833127e-01\n",
      "   3.57763291e-01 -3.54129795e-01]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  5\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "-0.004220350310673378\n",
      "\n",
      " Coefficients \n",
      "[ 0.0184532  -0.34693594  0.16358901 -0.02372366  0.36330713  0.18054631\n",
      "  0.13702532  0.41278398  0.16912556  0.03866546]\n",
      "\n",
      " pop_polarity\n",
      "[0.4160846  0.70756703 0.41926312 0.48151218 0.50188688 0.34463929\n",
      " 0.58194516 0.70219997 0.51292521 0.57828799 0.42956207 0.51878118\n",
      " 0.6315103  0.29554374 0.53965714 0.47761022 0.49599698 0.00512073\n",
      " 0.29554374 0.49467081 0.55160518 0.52839904 0.59294507 0.47144954\n",
      " 0.72886926 0.56697464 0.50406223 0.56938516 0.45290865 0.49862082\n",
      " 0.53419694 0.46295924 0.60942626 0.41108516 0.44947999 0.49728779\n",
      " 0.42956207 0.51356745 0.28049271 0.55962582 0.68639822 0.50539428\n",
      " 0.63044319 0.50794889 0.9417017  0.05413107 0.50415286 0.47144954]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0\n",
      " 1 0 1 1 1 1 1 1 0 1 0]\n",
      "\n",
      " auc\n",
      "0.81\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[19 11]\n",
      " [ 3 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7083333333333334\n",
      "recall:  0.8333333333333334\n",
      "specificity:  0.6333333333333333\n",
      "precision:  0.5769230769230769\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73        30\n",
      "           1       0.58      0.83      0.68        18\n",
      "\n",
      "    accuracy                           0.71        48\n",
      "   macro avg       0.72      0.73      0.71        48\n",
      "weighted avg       0.76      0.71      0.71        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  5\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[1.62166779e-002 3.31411644e-001 9.19715740e-003 1.65191363e-002\n",
      " 1.27536404e-002 1.53391842e-004 1.70582073e-002 2.00139960e-001\n",
      " 1.67560460e-002 1.92277991e-002 1.36107565e-002 1.65998796e-002\n",
      " 1.58936305e-002 1.56922337e-002 1.75053074e-002 1.19803536e-002\n",
      " 1.59926941e-002 6.07935571e-001 1.56922337e-002 2.04527790e-002\n",
      " 1.55002630e-002 1.49431961e-002 1.67225137e-002 1.11169403e-002\n",
      " 8.75217822e-001 1.59271046e-002 1.72718916e-002 1.62092269e-002\n",
      " 1.94828676e-002 1.37676060e-002 1.56442852e-002 1.29095287e-002\n",
      " 4.52121787e-004 1.12472502e-002 1.59039958e-005 1.79301741e-002\n",
      " 1.36107565e-002 1.57372577e-002 1.58879158e-003 1.74785870e-002\n",
      " 3.54830196e-001 1.48477821e-002 1.57674201e-002 1.53738821e-002\n",
      " 1.35229746e-001 4.49199300e-202 1.60784534e-002 1.11169403e-002]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.68\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[29  1]\n",
      " [17  1]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.625\n",
      "recall:  0.05555555555555555\n",
      "specificity:  0.9666666666666667\n",
      "precision:  0.5\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.76        30\n",
      "           1       0.50      0.06      0.10        18\n",
      "\n",
      "    accuracy                           0.62        48\n",
      "   macro avg       0.57      0.51      0.43        48\n",
      "weighted avg       0.58      0.62      0.51        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  5\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.02717451 0.77979078 0.09365504 0.32110979 0.47109004 0.28069024\n",
      " 0.08687257 0.14771686 0.70177334 0.4601139  0.05382548 0.46401925\n",
      " 0.73089114 0.10418753 0.57327916 0.12544744 0.19773689 0.06768479\n",
      " 0.10418753 0.50860224 0.40540519 0.62952919 0.72142557 0.16258501\n",
      " 0.40205913 0.57151413 0.47542576 0.72458823 0.04588743 0.76450603\n",
      " 0.41134454 0.05022192 0.44566093 0.45420836 0.40074148 0.59948635\n",
      " 0.05382548 0.44154147 0.02659579 0.83305247 0.20961078 0.13693219\n",
      " 0.51314938 0.23515333 0.86926761 0.24545007 0.13430337 0.16258501]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.93\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[27  3]\n",
      " [ 7 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7916666666666666\n",
      "recall:  0.6111111111111112\n",
      "specificity:  0.9\n",
      "precision:  0.7857142857142857\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        30\n",
      "           1       0.79      0.61      0.69        18\n",
      "\n",
      "    accuracy                           0.79        48\n",
      "   macro avg       0.79      0.76      0.77        48\n",
      "weighted avg       0.79      0.79      0.79        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  5\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.2s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.51396221 0.51451195 0.51394117 0.51412689 0.51417326 0.51371433\n",
      " 0.5143001  0.51468962 0.51417217 0.51424872 0.51404221 0.51417698\n",
      " 0.51436579 0.51370128 0.51420808 0.5141115  0.51412855 0.51061458\n",
      " 0.51370128 0.51411355 0.5142029  0.51416824 0.51434679 0.51409188\n",
      " 0.51444146 0.51427999 0.51414966 0.51425876 0.51389505 0.51414158\n",
      " 0.51405678 0.51408396 0.51442446 0.51395468 0.51391108 0.51412525\n",
      " 0.51404221 0.51415644 0.513686   0.51427899 0.51453383 0.51419329\n",
      " 0.51440139 0.51414382 0.515351   0.51368582 0.51417139 0.51409188]\n",
      "\n",
      " yhat\n",
      "[0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.77\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[11 19]\n",
      " [ 0 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6041666666666666\n",
      "recall:  1.0\n",
      "specificity:  0.36666666666666664\n",
      "precision:  0.4864864864864865\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54        30\n",
      "           1       0.49      1.00      0.65        18\n",
      "\n",
      "    accuracy                           0.60        48\n",
      "   macro avg       0.74      0.68      0.60        48\n",
      "weighted avg       0.81      0.60      0.58        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  5\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.3581683  0.5217373  0.39868814 0.48545554 0.44246414 0.49333674\n",
      " 0.48472062 0.4879458  0.6672965  0.45763588 0.44429806 0.6255432\n",
      " 0.59561837 0.39173427 0.6209576  0.42835844 0.589082   0.38932288\n",
      " 0.39173427 0.5476899  0.5493825  0.5755661  0.5294328  0.4117512\n",
      " 0.46593547 0.6318468  0.43137518 0.62442875 0.41286713 0.55154085\n",
      " 0.46520612 0.36328012 0.4875389  0.5045032  0.55462885 0.53999215\n",
      " 0.44429806 0.5501325  0.43465304 0.56022495 0.48545554 0.49290878\n",
      " 0.46593547 0.53108275 0.48233542 0.44775695 0.46225324 0.4117512 ]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0\n",
      " 1 0 1 0 0 0 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.7\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[22  8]\n",
      " [ 7 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6875\n",
      "recall:  0.6111111111111112\n",
      "specificity:  0.7333333333333333\n",
      "precision:  0.5789473684210527\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75        30\n",
      "           1       0.58      0.61      0.59        18\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.67      0.67      0.67        48\n",
      "weighted avg       0.69      0.69      0.69        48\n",
      "\n",
      "\n",
      "KFold:  6\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-5.45087209e-01 -1.09865931e+00 -5.00455747e-01 -3.75635012e-01\n",
      "   1.04674209e-01 -8.55371701e-01 -5.33335177e-01 -1.29397999e-01\n",
      "  -8.33213509e-02 -3.61777338e-01]\n",
      " [-4.28433683e-01  7.55270600e-02 -5.15000861e-01 -7.23203910e-01\n",
      "  -5.28349206e-02  1.76938169e-01 -4.25586302e-01 -4.29727655e-01\n",
      "  -2.94728510e-01 -3.58973320e-01]\n",
      " [-5.29709128e-01 -1.07424409e+00 -4.55626021e-01 -3.40860777e-01\n",
      "   4.09448211e-03 -6.24947568e-01 -5.39898762e-01  2.45454570e-01\n",
      "  -3.72116247e-01 -3.23105648e-01]\n",
      " [-3.18887243e-01 -1.35014789e+00  3.98537187e-01 -5.20535918e-01\n",
      "   3.24093915e-01 -2.59470990e-01 -5.58671892e-01  1.38588189e-01\n",
      "  -2.27713267e-01 -1.17765630e-01]\n",
      " [-4.66149433e-01 -1.22695425e+00 -4.68562682e-01 -2.67234213e-01\n",
      "   7.83659501e-02 -6.53479320e-01 -3.93034712e-01  4.66684841e-01\n",
      "  -4.12125344e-01 -3.50071689e-01]\n",
      " [-5.56287985e-01 -6.89339217e-01 -5.27371529e-02 -1.56006441e+00\n",
      "  -2.45602222e-01  2.08477733e+00 -2.43597766e-01  4.02877442e-01\n",
      "  -2.88090019e-01 -3.63874261e-01]\n",
      " [-1.87211336e-01 -5.02810681e-01 -7.71397040e-02 -5.43142883e-03\n",
      "   1.10263834e+00 -4.31469685e-01  1.31253982e-01  2.80431912e+00\n",
      "   3.98576185e-01  7.98447771e-01]\n",
      " [-5.00782166e-01 -1.15511686e+00 -2.53264573e-01 -4.30358209e-01\n",
      "   1.35984878e-01 -7.30293312e-01 -3.89900236e-01  8.30074459e-01\n",
      "  -5.69731396e-01 -2.30598968e-01]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-3.50644002e-01  1.29021798e+00  9.52377417e-01 -1.55109364e+00\n",
      "   3.40091656e+00  1.85927608e+00 -4.01629191e+00  3.33054670e+00\n",
      "  -6.84483882e+00 -2.96322291e+00]\n",
      " [-3.18887243e-01 -1.35014789e+00  3.98537187e-01 -5.20535918e-01\n",
      "   3.24093915e-01 -2.59470990e-01 -5.58671892e-01  1.38588189e-01\n",
      "  -2.27713267e-01 -1.17765630e-01]\n",
      " [-5.41865711e-01 -1.01730511e+00 -3.90384946e-01 -5.19691045e-01\n",
      "   6.06819777e-01 -2.88283335e-01 -5.24076552e-01  4.09383079e-01\n",
      "  -5.06521953e-01 -3.43158746e-01]\n",
      " [-1.36208886e-01 -1.76606582e+00 -8.68787782e-01 -1.76624975e-01\n",
      "   1.47690437e+00 -1.51263141e+00  2.39064592e+00 -3.74209240e+00\n",
      "  -3.61679069e+00  2.32042094e+00]\n",
      " [-3.01210978e-01 -1.09835864e+00  4.28623588e-01  3.60554555e+00\n",
      "  -1.91471277e+00  5.50975174e-01 -7.52485727e-02 -5.98095403e-01\n",
      "  -2.67816019e+00 -5.58537845e-01]\n",
      " [-3.15015711e-01 -6.13440347e-01  3.96247943e-01 -2.38510002e-01\n",
      "   6.98345884e-01 -2.30372930e+00  8.25243927e-01 -1.46077359e+00\n",
      "   1.08102573e+00  1.83489831e-01]\n",
      " [ 1.48858368e-02  1.56866353e-01 -1.99042767e+00  3.83015314e+00\n",
      "  -6.03786887e-01 -9.99335883e-01  2.32138588e-01 -7.77973408e-01\n",
      "  -9.30952865e-01 -9.19938396e-01]\n",
      " [ 3.94769544e-01 -5.94605590e-01 -9.59946749e-01 -7.72610328e-01\n",
      "  -1.26632000e-01 -6.03058888e-01 -7.74465480e-01 -6.94679087e-01\n",
      "   1.16353593e+00  1.63831062e-01]\n",
      " [-4.66555556e-01 -1.68374203e+00 -2.32198785e-01 -3.00515426e-01\n",
      "   3.97346693e-01 -1.40719317e+00  9.57337397e-01  6.12029374e-01\n",
      "  -1.36555879e+00 -1.28037446e+00]\n",
      " [-5.06559716e-01 -1.05477399e+00 -4.39758803e-01 -5.05643227e-01\n",
      "   8.37889087e-02 -6.66760038e-01 -3.35733959e-01  2.49999825e-01\n",
      "  -4.63831008e-01 -2.96524104e-01]\n",
      " [ 1.54990529e+00 -1.14187085e+00  1.54080148e+00  5.22956986e-03\n",
      "   2.41345228e-01 -1.24179369e+00 -1.83316678e-01  4.78102702e-01\n",
      "  -1.78928801e+00 -1.76129784e+00]\n",
      " [-5.01221917e-01 -1.05349839e+00 -4.40753864e-01 -4.92349146e-01\n",
      "   1.02754773e-01 -6.92484371e-01 -3.63412745e-01  2.95390951e-01\n",
      "  -4.61893376e-01 -2.88044585e-01]\n",
      " [-4.72185945e-01 -9.76668714e-01 -6.64707410e-01 -9.80846555e-01\n",
      "  -3.74621810e-01 -2.57444624e-01 -1.55846059e-01 -4.23744944e-01\n",
      "  -5.52984853e-02 -1.72609392e-02]\n",
      " [-3.73176240e-01 -1.77610380e-01 -7.40763200e-01 -9.75121574e-01\n",
      "  -1.58317232e-01 -7.95803787e-01  5.93285580e-02 -1.02061261e-01\n",
      "  -6.22775711e-01  1.27222632e+00]\n",
      " [-2.94111850e-01  2.08066264e+00  8.12617401e-01 -6.24172902e-01\n",
      "  -9.81351994e-02 -9.42660894e-01 -1.35084283e+00 -4.18780085e-01\n",
      "  -2.80982348e+00 -1.35214677e+00]\n",
      " [-4.74177786e-01 -1.36046691e+00 -1.38678452e-01  1.20898126e+00\n",
      "  -2.62942693e-01 -3.69232592e-01  5.16022938e-01  1.27272778e+00\n",
      "   1.81460770e-01 -3.72544236e-01]\n",
      " [-4.62167103e-01 -1.08122407e+00 -1.87189822e-01 -2.03298242e-01\n",
      "   5.86896373e-01  6.02052595e-03 -7.90854983e-01 -6.29439472e-02\n",
      "  -4.38541538e-01 -2.99918260e-01]\n",
      " [-3.70972234e-01 -1.07738669e+00 -4.42128304e-01 -5.42160721e-01\n",
      "   8.16188914e-02 -7.37047659e-01 -5.19723604e-01  3.10654037e-01\n",
      "  -4.22001087e-01 -3.64119263e-01]\n",
      " [-5.29453066e-01 -9.96939575e-01 -4.56101671e-01 -5.25844247e-01\n",
      "   1.48712715e-04 -6.83076462e-01 -4.79837859e-01  1.53393016e-01\n",
      "  -3.74133910e-01 -2.88026986e-01]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-5.46403124e-01 -1.06739321e+00  1.41540725e-01 -4.87901099e-01\n",
      "   1.29227037e-01 -7.64141439e-01 -4.74606727e-01  3.34040550e-01\n",
      "  -2.92749902e-01 -4.98440913e-01]\n",
      " [-5.36673579e-01 -1.06958463e+00 -3.95944744e-01 -2.78171021e-01\n",
      "   3.18353445e-02 -6.51105166e-01 -1.99074253e-01  9.52757864e-02\n",
      "  -5.60954084e-01 -3.25982115e-01]\n",
      " [-4.77588851e-01 -9.99238344e-01 -2.71118847e-01 -3.73245291e-01\n",
      "   1.98642106e-01 -9.43828633e-01 -6.70183032e-01 -3.76460547e-01\n",
      "  -3.45399921e-02  6.75883465e-02]\n",
      " [-3.09725753e-01 -1.48282286e+00  9.47098207e+01  8.71909183e+00\n",
      "  -1.59827610e+01 -1.81206348e+00  3.54289389e-01 -1.05196479e+01\n",
      "   3.00954976e+00  1.66132911e+00]\n",
      " [-4.81154664e-01 -1.17459706e+00 -3.89255600e-01 -3.85121832e-01\n",
      "   5.87691401e-02 -7.08281717e-01 -4.18084053e-01  3.94479854e-01\n",
      "  -3.92074340e-01 -3.32253646e-01]\n",
      " [-7.26431409e-01  1.65355661e+00 -2.05094632e+00 -1.68067701e+01\n",
      "  -1.99736868e+01  2.70030734e+01  5.32303718e+00 -3.40877951e+00\n",
      "   2.85885781e+00  1.01894711e+00]\n",
      " [-4.62167103e-01 -1.08122407e+00 -1.87189822e-01 -2.03298242e-01\n",
      "   5.86896373e-01  6.02052595e-03 -7.90854983e-01 -6.29439472e-02\n",
      "  -4.38541538e-01 -2.99918260e-01]\n",
      " [ 7.10612072e-01 -6.29768620e-01 -1.00514230e+00  1.12777337e+00\n",
      "   9.06637152e-01 -1.29740196e+00  1.72688847e-01 -1.01520823e+00\n",
      "   1.94873751e+00 -1.39759063e+00]\n",
      " [-4.88108813e-01 -1.83568655e-01 -5.56813700e-01 -6.00274216e-01\n",
      "  -4.73877463e-02 -1.83105075e-01 -3.51721985e-01  7.92883103e-01\n",
      "  -7.51523898e-02 -4.68525944e-01]\n",
      " [-4.28433414e-01  2.93945196e-01 -6.84168417e-01  3.77959782e+00\n",
      "   1.17148935e+00  2.28415996e+00 -2.66072076e+00  1.61120364e-01\n",
      "  -2.63680228e-01  4.15578420e-01]\n",
      " [-2.89900135e-01  2.31186436e-02 -4.44435322e-01 -5.34052934e-01\n",
      "  -1.94013670e-01 -6.46482583e-01 -6.87093712e-01  2.03407527e-01\n",
      "  -6.26216077e-01  5.54657055e-01]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-1.75862497e-01  2.38371310e+00  4.01663063e-02 -6.84569461e-01\n",
      "   4.60280432e-01  1.11815837e+00 -8.30594450e-01  8.51059961e-01\n",
      "  -7.93837212e-01 -4.15224221e-02]\n",
      " [-6.49270705e-02  1.48508603e+00 -3.19104035e+00  2.38923331e-01\n",
      "   3.32287549e+00 -4.71205573e+00  2.90252802e+00 -2.24477353e+01\n",
      "   2.48385802e+01  2.32861645e+00]\n",
      " [-5.31952201e-01 -1.18776138e+00 -3.46667101e-01 -4.71221320e-01\n",
      "   1.35512235e-01 -7.45125878e-01 -4.86776732e-01  3.76465646e-01\n",
      "  -5.23399547e-01 -4.44506521e-01]\n",
      " [-1.84402761e-01 -2.13931016e+00  1.96936353e+00 -5.50012607e-01\n",
      "   5.20601298e-01 -2.05039427e+00  5.86884417e-01  5.15009689e-01\n",
      "   9.12659291e-02 -4.92863661e-01]\n",
      " [-5.19691127e-01 -1.47071107e+00  1.71026165e+00 -3.59880689e-01\n",
      "  -6.77622950e-01 -8.64176364e-01 -5.07163828e-01  2.46700775e-01\n",
      "  -7.55696989e-01 -2.55333971e-01]\n",
      " [ 4.81036433e-02 -4.96174757e-01 -3.55339737e-01  2.13323651e-01\n",
      "  -1.22449322e-01 -1.10491609e+00  2.88178491e-01  6.60615894e-02\n",
      "  -5.87434383e-01 -5.11938129e-01]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0\n",
      " 0 1 1 0 0 1 0 1 0 0 0] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  6\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "-0.006828378830909512\n",
      "\n",
      " Coefficients \n",
      "[ 0.01785562 -0.42610009  0.32025212 -0.02114494  0.36095053  0.19545899\n",
      "  0.13757325  0.37405163  0.1709461   0.05011599]\n",
      "\n",
      " pop_polarity\n",
      "[0.52002424 0.50392292 0.38498372 0.5299142  0.66770715 0.57353816\n",
      " 0.65962048 0.8413514  0.61269597 0.50512652 0.67712288 0.66770715\n",
      " 0.60894207 0.29595456 0.31292618 0.48594862 0.15850295 0.41087085\n",
      " 0.63776581 0.53904972 0.64670809 0.54269931 0.45833792 0.391781\n",
      " 0.14989037 0.70821931 0.59403099 0.5387234  0.51326643 0.52002424\n",
      " 0.59285829 0.52464661 0.49579345 1.         0.56406989 0.04925117\n",
      " 0.59403099 0.47732198 0.51400049 0.52511147 0.39007966 0.50512652\n",
      " 0.36647961 0.00653559 0.56318376 0.83134454 0.65315    0.44158248]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 1 0 1 0 0 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.71\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[15 12]\n",
      " [ 1 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7291666666666666\n",
      "recall:  0.9523809523809523\n",
      "specificity:  0.5555555555555556\n",
      "precision:  0.625\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.56      0.70        27\n",
      "           1       0.62      0.95      0.75        21\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.78      0.75      0.73        48\n",
      "weighted avg       0.80      0.73      0.72        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  6\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[7.30422178e-02 7.11981937e-02 3.74275670e-02 7.32090843e-02\n",
      " 6.96906966e-02 6.36288703e-02 5.20979852e-02 1.15483004e-01\n",
      " 7.42933365e-02 7.11060476e-02 4.47862546e-01 6.96906966e-02\n",
      " 7.99153479e-02 3.15503641e-01 2.49135129e-03 9.18426975e-02\n",
      " 8.47637270e-04 1.73948640e-01 7.44378434e-02 6.96740186e-02\n",
      " 9.99835360e-01 6.97850209e-02 5.28205084e-02 6.30925495e-02\n",
      " 6.93681563e-04 4.59764603e-02 7.72867822e-02 6.25093344e-02\n",
      " 7.24047447e-02 7.30422178e-02 9.04655358e-02 7.34138311e-02\n",
      " 7.31875008e-02 1.00000000e+00 6.69664881e-02 7.17636037e-32\n",
      " 7.72867822e-02 4.85257709e-01 5.67822505e-02 2.28761274e-03\n",
      " 4.80588581e-02 7.11060476e-02 9.34973181e-05 4.95668191e-01\n",
      " 7.25302737e-02 7.25760627e-02 1.43684886e-01 8.52797236e-02]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.44\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[27  0]\n",
      " [19  2]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6041666666666666\n",
      "recall:  0.09523809523809523\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        27\n",
      "           1       1.00      0.10      0.17        21\n",
      "\n",
      "    accuracy                           0.60        48\n",
      "   macro avg       0.79      0.55      0.46        48\n",
      "weighted avg       0.77      0.60      0.49        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  6\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.71304227 0.43410095 0.27710791 0.89839811 0.80748809 0.92766504\n",
      " 0.74898013 0.81747464 0.94823083 0.1074259  0.05489051 0.80748809\n",
      " 0.94966114 0.0364694  0.11283518 0.03871604 0.04742153 0.10353152\n",
      " 0.42819329 0.90868222 0.78123052 0.90863549 0.05076124 0.01487901\n",
      " 0.19578809 0.7192032  0.14435461 0.86145941 0.79559534 0.71304227\n",
      " 0.56183797 0.63503776 0.1975949  0.45913577 0.89802438 0.01580121\n",
      " 0.14435461 0.06261334 0.70162798 0.60238846 0.40687443 0.1074259\n",
      " 0.60113521 0.06588068 0.90161937 0.15661152 0.29169748 0.1105618 ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 1 0 0 1 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.95\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[23  4]\n",
      " [ 2 19]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.875\n",
      "recall:  0.9047619047619048\n",
      "specificity:  0.8518518518518519\n",
      "precision:  0.8260869565217391\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        27\n",
      "           1       0.83      0.90      0.86        21\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.87      0.88      0.87        48\n",
      "weighted avg       0.88      0.88      0.88        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  6\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.50790548 0.50778553 0.50705232 0.50797    0.50864187 0.50821026\n",
      " 0.50862786 0.50974998 0.50842932 0.5078767  0.50861393 0.50864187\n",
      " 0.50828471 0.50633879 0.50720817 0.50734785 0.50564157 0.50715231\n",
      " 0.50861438 0.50800139 0.50862592 0.50802    0.50757815 0.50713187\n",
      " 0.50544271 0.50902597 0.5081788  0.50800707 0.5078706  0.50790548\n",
      " 0.50827554 0.50793236 0.50768818 0.53617949 0.50815395 0.50633854\n",
      " 0.5081788  0.50727333 0.5078179  0.50757869 0.50715755 0.5078767\n",
      " 0.50671691 0.5        0.50815001 0.50982862 0.50879105 0.50746128]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 0 1 0 0 1 1 1 1]\n",
      "\n",
      " auc\n",
      "0.7\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12 15]\n",
      " [ 1 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6666666666666666\n",
      "recall:  0.9523809523809523\n",
      "specificity:  0.4444444444444444\n",
      "precision:  0.5714285714285714\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.44      0.60        27\n",
      "           1       0.57      0.95      0.71        21\n",
      "\n",
      "    accuracy                           0.67        48\n",
      "   macro avg       0.75      0.70      0.66        48\n",
      "weighted avg       0.77      0.67      0.65        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  6\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.6497156  0.5508736  0.5503152  0.6497156  0.6143521  0.6318506\n",
      " 0.5201527  0.47817376 0.6497156  0.46406955 0.48141593 0.6143521\n",
      " 0.6368644  0.3928373  0.39125586 0.40692937 0.36215818 0.4215185\n",
      " 0.49353567 0.6497156  0.5229353  0.6497156  0.35627472 0.3735476\n",
      " 0.44218948 0.4804817  0.491359   0.6497156  0.6497156  0.6497156\n",
      " 0.6234797  0.5795686  0.51206255 0.3673737  0.6497156  0.35800683\n",
      " 0.491359   0.40692937 0.6174887  0.53014797 0.52742326 0.46406955\n",
      " 0.5453761  0.40692937 0.6497156  0.45018983 0.47435802 0.39954424]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0\n",
      " 0 1 1 1 0 1 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.85\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[20  7]\n",
      " [ 3 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7916666666666666\n",
      "recall:  0.8571428571428571\n",
      "specificity:  0.7407407407407407\n",
      "precision:  0.72\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80        27\n",
      "           1       0.72      0.86      0.78        21\n",
      "\n",
      "    accuracy                           0.79        48\n",
      "   macro avg       0.79      0.80      0.79        48\n",
      "weighted avg       0.80      0.79      0.79        48\n",
      "\n",
      "\n",
      "KFold:  7\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[-4.65441984e-01 -8.01009840e-01 -4.45936863e-01 -4.95234904e-01\n",
      "  -2.43313387e-02 -5.46660812e-01 -4.71998556e-01  1.65166482e-01\n",
      "  -2.60497487e-01 -3.54176812e-01]\n",
      " [-4.89286794e-01 -9.73522403e-01 -3.11601803e-01 -6.63092970e-01\n",
      "  -3.10725210e-01 -2.26021205e-01 -4.43744482e-01  2.91869965e-01\n",
      "  -5.73028185e-01 -3.42168381e-01]\n",
      " [-5.37562915e-01 -4.59151233e-01 -4.37246164e-01 -1.26021538e+00\n",
      "  -8.37778748e-01  3.93500567e-01 -5.08564278e-01  1.35425619e-01\n",
      "  -6.17370554e-01 -7.09791426e-01]\n",
      " [-1.36208886e-01 -1.76606582e+00 -8.68787782e-01 -1.76624975e-01\n",
      "   1.47690437e+00 -1.51263141e+00  2.39064592e+00 -3.74209240e+00\n",
      "  -3.61679069e+00  2.32042094e+00]\n",
      " [-1.36208886e-01 -1.76606582e+00 -8.68787782e-01 -1.76624975e-01\n",
      "   1.47690437e+00 -1.51263141e+00  2.39064592e+00 -3.74209240e+00\n",
      "  -3.61679069e+00  2.32042094e+00]\n",
      " [-1.84402761e-01 -2.13931016e+00  1.96936353e+00 -5.50012607e-01\n",
      "   5.20601298e-01 -2.05039427e+00  5.86884417e-01  5.15009689e-01\n",
      "   9.12659291e-02 -4.92863661e-01]\n",
      " [-4.92730094e-01 -1.43973604e+00 -7.23914205e-01  1.10974590e+00\n",
      "  -5.21827433e-01 -4.90780977e-01  3.91139272e-01 -3.77493253e-02\n",
      "  -1.00180505e+00  3.00195489e-01]\n",
      " [-5.58996113e-01 -1.16458722e+00 -3.36207930e-01 -4.49323474e-01\n",
      "   9.85627929e-02 -8.03334359e-01 -3.83261057e-01  2.04434916e-01\n",
      "  -5.70118052e-01 -3.05241645e-01]\n",
      " [ 1.25108656e-01  5.20316708e-01 -1.07748580e+00  1.80496085e+00\n",
      "   3.70409571e+00  2.45391778e+00  1.03999882e+00 -1.96509502e+00\n",
      "   4.14944221e+00  1.00504246e+01]\n",
      " [-3.02993433e-01  1.15594609e+00 -7.82271277e-01 -2.23098595e-01\n",
      "  -6.90721517e-01 -5.25233224e-01 -6.21184529e-01  4.44692847e-01\n",
      "  -7.60067436e-01 -8.43495206e-01]\n",
      " [-5.24259958e-01 -9.78151404e-01 -4.44039608e-01 -5.13454101e-01\n",
      "   2.31933799e-03 -6.65709238e-01 -4.67893706e-01  1.52701283e-01\n",
      "  -3.67035083e-01 -2.74446966e-01]\n",
      " [-4.82658893e-01 -8.60937136e-01 -6.10357111e-01 -9.31001532e-01\n",
      "  -6.07774963e-01  3.21487446e-02 -4.36223480e-01  4.62847166e-01\n",
      "  -6.19809907e-01  6.01032765e-02]\n",
      " [-3.01210978e-01 -1.09835864e+00  4.28623588e-01  3.60554555e+00\n",
      "  -1.91471277e+00  5.50975174e-01 -7.52485727e-02 -5.98095403e-01\n",
      "  -2.67816019e+00 -5.58537845e-01]\n",
      " [-5.26833150e-01 -3.49293611e-01 -2.80268039e-01 -4.73406353e-01\n",
      "  -5.53926754e-02 -6.79260225e-01 -4.80464024e-01  1.84461880e-01\n",
      "  -3.93021221e-01 -2.91071934e-01]\n",
      " [-4.23985456e-01 -5.24127076e-01 -4.89183223e-01 -4.33978045e-01\n",
      "  -6.15929696e-03 -7.65053590e-01 -3.69923754e-01  2.30098472e-01\n",
      "  -4.93202727e-01 -4.10491830e-01]\n",
      " [-5.23654818e-01 -1.13823418e+00 -3.71272341e-01 -5.14569638e-01\n",
      "   2.07040027e-01 -6.23491949e-01 -1.37573912e-01  1.00867249e+00\n",
      "  -1.19150655e-02 -3.26421472e-01]\n",
      " [-5.16091527e-01 -7.04972222e-01 -5.84668004e-01 -3.02782737e-02\n",
      "  -2.98573281e-01 -3.70371846e-01 -7.08107493e-01  4.14753287e-01\n",
      "  -4.48687525e-01 -5.05226763e-01]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-3.02993433e-01  1.15594609e+00 -7.82271277e-01 -2.23098595e-01\n",
      "  -6.90721517e-01 -5.25233224e-01 -6.21184529e-01  4.44692847e-01\n",
      "  -7.60067436e-01 -8.43495206e-01]\n",
      " [-2.71112597e-01 -8.53244129e-01 -2.45455996e-01 -2.64949570e-01\n",
      "   2.13630418e-01 -7.49266373e-01 -4.98900937e-01  1.03768286e-02\n",
      "  -4.77224947e-01 -4.83061962e-01]\n",
      " [-4.54284862e-01  3.00560635e-01 -1.50996808e-01 -3.48702720e-01\n",
      "   3.53948978e-01 -5.42534877e-02 -7.08080035e-01  4.57271058e-01\n",
      "  -6.93107478e-01 -6.43029600e-01]\n",
      " [-5.93466966e-01  1.24206925e+00  9.33745382e-01 -4.14980276e-01\n",
      "   4.49720585e-01 -1.26582913e+00 -1.17592270e+00  7.35283982e-01\n",
      "  -1.17787451e+00 -9.26975458e-01]\n",
      " [-1.36208886e-01 -1.76606582e+00 -8.68787782e-01 -1.76624975e-01\n",
      "   1.47690437e+00 -1.51263141e+00  2.39064592e+00 -3.74209240e+00\n",
      "  -3.61679069e+00  2.32042094e+00]\n",
      " [-3.53709540e-01 -1.28170916e+00 -2.97170406e-01  2.66692175e-01\n",
      "  -1.15909360e-01 -1.35698318e+00  1.74016211e-01 -3.45961630e-02\n",
      "  -6.19434533e-01 -3.62533376e-01]\n",
      " [-5.38385283e-01 -7.54885128e-01 -5.63628079e-01 -1.32390371e+00\n",
      "   1.50964041e-01 -8.25541030e-01 -9.62651637e-01  3.38113372e-01\n",
      "  -8.94265953e-01 -5.98617741e-01]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-5.10624302e-01 -7.15689341e-01 -3.17119078e-01 -4.09252310e-01\n",
      "  -4.06125155e-02 -4.51467262e-01 -3.97190091e-01  1.52676407e-01\n",
      "  -6.39490369e-01 -3.96944318e-01]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-3.73176240e-01 -1.77610380e-01 -7.40763200e-01 -9.75121574e-01\n",
      "  -1.58317232e-01 -7.95803787e-01  5.93285580e-02 -1.02061261e-01\n",
      "  -6.22775711e-01  1.27222632e+00]\n",
      " [-5.55469726e-01 -8.82873533e-01 -4.83055485e-01 -6.97690955e-01\n",
      "  -9.97176911e-02 -4.48414415e-01 -5.48497547e-01  2.14767648e-01\n",
      "  -4.82750997e-01 -3.64372881e-01]\n",
      " [-4.71821230e-01 -1.41493724e+00 -5.49652304e-01 -1.09239051e-01\n",
      "  -4.84658845e-02 -9.50065514e-01 -5.18768899e-01  4.97897189e-01\n",
      "  -7.96576791e-01  2.83603337e+00]\n",
      " [-5.35525838e-01 -1.02052768e+00 -4.64716717e-01 -5.52276366e-01\n",
      "   1.54299110e-02 -6.95471348e-01 -5.38376483e-01  1.74973454e-01\n",
      "  -3.70816167e-01 -3.09424328e-01]\n",
      " [-3.02993433e-01  1.15594609e+00 -7.82271277e-01 -2.23098595e-01\n",
      "  -6.90721517e-01 -5.25233224e-01 -6.21184529e-01  4.44692847e-01\n",
      "  -7.60067436e-01 -8.43495206e-01]\n",
      " [-4.76084676e-01 -1.00240705e+00 -2.92977124e-01 -5.79147490e-01\n",
      "   9.61413339e-02 -6.67115322e-01 -6.65896908e-01  2.79057279e-01\n",
      "  -6.33495970e-01 -4.22480236e-01]\n",
      " [-4.14666009e-01 -7.38340593e-01 -4.61124795e-01 -7.11731373e-01\n",
      "  -1.06483429e-01 -4.93717617e-01 -4.75328391e-01  2.37918386e-01\n",
      "  -5.21149125e-01 -3.64510570e-01]\n",
      " [-2.55061245e-01  1.00459750e-01 -1.37039725e-01  4.92923864e-02\n",
      "   2.46460796e-01 -1.42932699e-01 -6.44332012e-01  8.76587009e-01\n",
      "  -8.20197961e-01 -4.12532457e-01]\n",
      " [-3.53709540e-01 -1.28170916e+00 -2.97170406e-01  2.66692175e-01\n",
      "  -1.15909360e-01 -1.35698318e+00  1.74016211e-01 -3.45961630e-02\n",
      "  -6.19434533e-01 -3.62533376e-01]\n",
      " [-4.03889396e-01 -1.23054498e+00 -4.76638386e-01  7.77511123e-01\n",
      "  -4.42396931e-01 -2.89500024e-01 -7.61954666e-01 -3.93833127e-01\n",
      "   3.57763291e-01 -3.54129795e-01]\n",
      " [-5.26550413e-01 -1.00604093e+00 -4.41375391e-01 -4.65900391e-01\n",
      "   7.65852770e-03 -6.56157542e-01 -4.87063973e-01  1.82076048e-01\n",
      "  -3.61356438e-01 -2.92180472e-01]\n",
      " [-2.45576015e-01 -6.77427304e-01 -1.05885628e+00 -9.89528982e-01\n",
      "   4.12688136e-01 -1.65014585e+00  5.00551375e-01 -1.85407508e+00\n",
      "  -7.27716476e-01  5.86457957e-01]\n",
      " [-4.09859815e-01 -4.29789940e-01  1.94629517e-02 -1.90020573e-01\n",
      "   3.34285455e-01 -1.43356949e+00  1.29302514e-01  5.13317989e-01\n",
      "  -1.68498310e+00 -1.66244043e-01]\n",
      " [-3.56493927e-01  1.04249093e+00 -4.36975730e-02 -4.05694027e-01\n",
      "   9.40501184e-01  1.13701933e-01 -9.71192162e-01  6.17472765e-01\n",
      "  -1.30302558e+00 -5.45650558e-01]\n",
      " [-4.66929221e-01 -9.93165009e-01 -3.30343476e-01 -3.81795040e-01\n",
      "   1.09024207e-01 -7.15685264e-01 -7.03336798e-01  2.78217559e-01\n",
      "  -7.52734182e-01 -4.68323936e-01]\n",
      " [-5.07321456e-01 -1.21870778e+00 -2.66617963e-01 -3.87455906e-01\n",
      "   4.07519878e-01 -5.09254947e-01 -4.20544246e-01  9.54750825e-01\n",
      "  -2.36523578e-01 -2.98836671e-01]\n",
      " [-5.31221519e-01 -1.27494337e+00  9.58743405e-02 -3.17163851e-01\n",
      "   1.07403492e-02 -8.27313785e-01 -1.23691255e-01  1.27746087e-01\n",
      "  -6.16745385e-01 -4.48461080e-01]\n",
      " [ 3.94769544e-01 -5.94605590e-01 -9.59946749e-01 -7.72610328e-01\n",
      "  -1.26632000e-01 -6.03058888e-01 -7.74465480e-01 -6.94679087e-01\n",
      "   1.16353593e+00  1.63831062e-01]\n",
      " [ 1.51001589e+00 -1.67233470e+00  1.39683981e+00  2.23931846e-01\n",
      "   6.60711992e-01 -4.06183965e+00  3.71489152e+00 -3.06037690e+00\n",
      "   1.05123199e+00 -4.57313154e+00]\n",
      " [-6.49270705e-02  1.48508603e+00 -3.19104035e+00  2.38923331e-01\n",
      "   3.32287549e+00 -4.71205573e+00  2.90252802e+00 -2.24477353e+01\n",
      "   2.48385802e+01  2.32861645e+00]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 0 0] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  7\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "-0.08172256970475632\n",
      "\n",
      " Coefficients \n",
      "[ 0.01926807 -0.44496723  0.25044459 -0.02370873  0.32104769  0.16177051\n",
      "  0.13690585  0.36451054  0.16896564  0.04642245]\n",
      "\n",
      " pop_polarity\n",
      "[5.01168714e-01 5.19072843e-01 4.18182931e-01 3.05217087e-01\n",
      " 3.05217087e-01 8.12899798e-01 4.94834379e-01 5.41255083e-01\n",
      " 8.25842754e-01 2.33295105e-01 5.13568371e-01 4.94602515e-01\n",
      " 3.08045745e-01 4.49783737e-01 4.59141537e-01 6.52752176e-01\n",
      " 4.68918513e-01 1.75583481e-07 2.33295105e-01 5.04331040e-01\n",
      " 4.43707399e-01 3.54901138e-01 3.05217087e-01 5.08504450e-01\n",
      " 4.65434121e-01 5.19407963e-01 4.86478778e-01 5.07066994e-01\n",
      " 3.94819950e-01 4.99035475e-01 5.84675014e-01 5.16061614e-01\n",
      " 2.33295105e-01 5.25564608e-01 4.85711032e-01 4.90689023e-01\n",
      " 5.08504450e-01 4.81887134e-01 5.19407963e-01 2.96455528e-01\n",
      " 4.74722786e-01 4.04479357e-01 5.13233452e-01 6.63349336e-01\n",
      " 5.69815168e-01 4.19485042e-01 4.87362580e-01 8.79970927e-03]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1\n",
      " 0 1 0 0 0 1 1 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.75\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[20  7]\n",
      " [ 9 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6666666666666666\n",
      "recall:  0.5714285714285714\n",
      "specificity:  0.7407407407407407\n",
      "precision:  0.631578947368421\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71        27\n",
      "           1       0.63      0.57      0.60        21\n",
      "\n",
      "    accuracy                           0.67        48\n",
      "   macro avg       0.66      0.66      0.66        48\n",
      "weighted avg       0.66      0.67      0.66        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  7\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[0.01588665 0.01559588 0.01295761 0.11621179 0.11621179 0.03445972\n",
      " 0.01049718 0.01694291 0.99999998 0.00127081 0.01673397 0.01469709\n",
      " 0.00109367 0.01529264 0.01476571 0.01689428 0.01829969 0.\n",
      " 0.00127081 0.01541635 0.00826009 0.00318867 0.11621179 0.0126111\n",
      " 0.01591183 0.01686473 0.01714481 0.01665704 0.01614162 0.01749437\n",
      " 0.0899801  0.01690925 0.00127081 0.01650254 0.01461843 0.00997455\n",
      " 0.0126111  0.01118818 0.01686473 0.01625698 0.01669452 0.00200517\n",
      " 0.01702293 0.01660305 0.01697625 0.06219667 0.99999888 0.72938034]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.55\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[25  2]\n",
      " [20  1]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5416666666666666\n",
      "recall:  0.047619047619047616\n",
      "specificity:  0.9259259259259259\n",
      "precision:  0.3333333333333333\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.69        27\n",
      "           1       0.33      0.05      0.08        21\n",
      "\n",
      "    accuracy                           0.54        48\n",
      "   macro avg       0.44      0.49      0.39        48\n",
      "weighted avg       0.46      0.54      0.43        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  7\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.70105714 0.81529249 0.27865861 0.03295775 0.03295775 0.16743385\n",
      " 0.26227697 0.82897587 0.27185715 0.05068629 0.68085006 0.18108101\n",
      " 0.14070193 0.70185845 0.69783556 0.88104397 0.22187547 0.01781314\n",
      " 0.05068629 0.24767971 0.83814117 0.72481403 0.03295775 0.13419831\n",
      " 0.28734923 0.68257745 0.77542061 0.08484589 0.01149245 0.56115635\n",
      " 0.6098855  0.84417787 0.05068629 0.85043083 0.59902954 0.89259747\n",
      " 0.13419831 0.08168697 0.68257745 0.01686989 0.57546921 0.87476608\n",
      " 0.8455093  0.94440122 0.33661348 0.12832031 0.51526376 0.05047465]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 0 0 1 0]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[24  3]\n",
      " [ 1 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9166666666666666\n",
      "recall:  0.9523809523809523\n",
      "specificity:  0.8888888888888888\n",
      "precision:  0.8695652173913043\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92        27\n",
      "           1       0.87      0.95      0.91        21\n",
      "\n",
      "    accuracy                           0.92        48\n",
      "   macro avg       0.91      0.92      0.92        48\n",
      "weighted avg       0.92      0.92      0.92        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  7\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.6s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.50832098 0.50866234 0.5075567  0.5        0.5        0.51221877\n",
      " 0.50850967 0.5088402  0.50981482 0.5        0.50850936 0.5085378\n",
      " 0.50611639 0.50757862 0.50778563 0.51028067 0.50808881 0.45349106\n",
      " 0.5        0.50820584 0.50718503 0.50569715 0.5        0.50848933\n",
      " 0.50799195 0.50858635 0.5080976  0.50853507 0.50689916 0.50838091\n",
      " 0.50938078 0.50856291 0.5        0.50862398 0.50818116 0.50785987\n",
      " 0.50848933 0.50818233 0.50858635 0.5053999  0.50775867 0.50630442\n",
      " 0.50848147 0.51032449 0.5091066  0.5072326  0.50726416 0.48879288]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.72\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[13 14]\n",
      " [ 3 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6458333333333334\n",
      "recall:  0.8571428571428571\n",
      "specificity:  0.48148148148148145\n",
      "precision:  0.5625\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.48      0.60        27\n",
      "           1       0.56      0.86      0.68        21\n",
      "\n",
      "    accuracy                           0.65        48\n",
      "   macro avg       0.69      0.67      0.64        48\n",
      "weighted avg       0.70      0.65      0.64        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  7\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:02:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:02:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.57405597 0.59641224 0.4549684  0.40116125 0.40116125 0.4572135\n",
      " 0.3893319  0.6370362  0.4155383  0.44636995 0.6333046  0.475561\n",
      " 0.39838237 0.58507615 0.55980223 0.5783191  0.5253432  0.40945333\n",
      " 0.44636995 0.533578   0.52556455 0.5109116  0.40116125 0.4170196\n",
      " 0.5151528  0.6333046  0.61390287 0.48691747 0.3828741  0.5607857\n",
      " 0.54538333 0.6333046  0.44636995 0.56733185 0.59554356 0.5481988\n",
      " 0.4170196  0.42282563 0.6333046  0.40116125 0.46879795 0.53465545\n",
      " 0.5539137  0.6335926  0.49647424 0.42736924 0.4457422  0.39390302]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.9\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[22  5]\n",
      " [ 2 19]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8541666666666666\n",
      "recall:  0.9047619047619048\n",
      "specificity:  0.8148148148148148\n",
      "precision:  0.7916666666666666\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86        27\n",
      "           1       0.79      0.90      0.84        21\n",
      "\n",
      "    accuracy                           0.85        48\n",
      "   macro avg       0.85      0.86      0.85        48\n",
      "weighted avg       0.86      0.85      0.85        48\n",
      "\n",
      "\n",
      "KFold:  8\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.49968104 -1.12401472 -0.44342229 ...  0.34992547 -0.4235201\n",
      "  -0.37135307]\n",
      " [-0.54630149 -1.1053007  -0.50378943 ...  0.15647683 -0.26394636\n",
      "  -0.29676943]\n",
      " [-0.47117602 -0.84778812 -0.3551458  ... -0.06250613 -0.44281095\n",
      "  -0.16083589]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[ 8.99616270e-02 -1.02025053e+00 -5.82086316e-01  5.54163719e-02\n",
      "  -1.78414681e-01 -6.19923132e-01 -3.76623821e-01  2.21003452e-01\n",
      "  -6.48027879e-02 -1.05225674e+00]\n",
      " [-4.04154792e-01 -3.65259721e-01 -8.93776528e-01 -1.61027304e+00\n",
      "   5.04581993e-02 -1.56267206e+00  3.57652336e-02 -2.59477054e-01\n",
      "   2.92671129e-01 -4.22085951e-01]\n",
      " [-4.82045010e-01 -1.24936270e+00 -6.00142568e-01 -7.59949749e-01\n",
      "  -2.75209393e-01 -4.10344946e-01 -5.93201207e-01  7.27487764e-02\n",
      "  -5.64286879e-01 -3.53117867e-01]\n",
      " [-1.94171253e-01  2.77968137e+00  9.92211627e-02 -2.28703720e-01\n",
      "   7.78132474e-01 -1.19466671e+00  7.60163780e-01  3.11462643e+00\n",
      "   1.97614244e-02 -6.18086461e-01]\n",
      " [-5.18903429e-01 -1.11620414e+00 -4.15113894e-01 -3.46284685e-01\n",
      "  -7.98039289e-03 -7.79108112e-01 -1.65817532e-01  1.76889114e-01\n",
      "  -3.80483290e-01 -1.38568656e-01]\n",
      " [-5.79080652e-01 -3.37294805e-01 -4.28950140e-01 -9.30142973e-01\n",
      "  -5.64821329e-01 -1.14363977e-01 -4.90320498e-01  2.82461571e-01\n",
      "  -5.81064976e-01 -6.99095867e-02]\n",
      " [ 7.10612072e-01 -6.29768620e-01 -1.00514230e+00  1.12777337e+00\n",
      "   9.06637152e-01 -1.29740196e+00  1.72688847e-01 -1.01520823e+00\n",
      "   1.94873751e+00 -1.39759063e+00]\n",
      " [-5.52257440e-01 -1.22059878e+00 -5.68354689e-01 -5.47571746e-01\n",
      "   1.37370744e-01 -6.86630113e-01 -2.63854707e-01  4.77537089e-01\n",
      "  -1.98995584e-01 -7.44848567e-01]\n",
      " [-4.77588851e-01 -9.99238344e-01 -2.71118847e-01 -3.73245291e-01\n",
      "   1.98642106e-01 -9.43828633e-01 -6.70183032e-01 -3.76460547e-01\n",
      "  -3.45399921e-02  6.75883465e-02]\n",
      " [-5.01478494e-01 -1.07824974e+00 -4.23096906e-01 -4.50328773e-01\n",
      "   1.56814374e-01 -8.04255021e-01 -5.42872199e-01 -1.32666412e-01\n",
      "  -9.39367235e-02 -3.75665596e-01]\n",
      " [-5.56330377e-01 -1.18312763e+00  1.04700459e-01 -4.26961056e-01\n",
      "   5.47930595e-02 -7.62729670e-01 -6.40435693e-01  1.97032219e-01\n",
      "  -6.39210622e-01 -4.03746143e-02]\n",
      " [-5.46403124e-01 -1.06739321e+00  1.41540725e-01 -4.87901099e-01\n",
      "   1.29227037e-01 -7.64141439e-01 -4.74606727e-01  3.34040550e-01\n",
      "  -2.92749902e-01 -4.98440913e-01]\n",
      " [-3.50644002e-01  1.29021798e+00  9.52377417e-01 -1.55109364e+00\n",
      "   3.40091656e+00  1.85927608e+00 -4.01629191e+00  3.33054670e+00\n",
      "  -6.84483882e+00 -2.96322291e+00]\n",
      " [-5.11600766e-01 -1.03182405e+00 -4.56192094e-01 -4.75251631e-01\n",
      "   5.80268245e-02 -6.84712497e-01 -3.93720092e-01  2.56829889e-01\n",
      "  -4.37010458e-01 -3.05325259e-01]\n",
      " [-1.37580783e-01 -2.39445169e-01 -2.89553971e-01 -2.60357341e-01\n",
      "   1.29254135e-01 -1.43743877e+00  7.87537525e-02  2.37700281e-01\n",
      "   1.08051406e-01 -4.14564171e-01]\n",
      " [-2.80887643e-01  8.30768644e-01  3.08639236e+00 -7.49215408e-01\n",
      "  -5.93827702e-01  6.54521964e-02 -3.41265849e+00 -9.80730506e-01\n",
      "  -2.74192153e+00 -8.55817308e-01]\n",
      " [-3.04698547e-01  2.56184513e+00  5.40628240e-01 -4.84743055e-03\n",
      "   1.33632041e+00  7.52100429e-01 -3.92218092e-01  2.10212563e-01\n",
      "  -1.90323153e-01 -3.83091292e-01]\n",
      " [-1.36208886e-01 -1.76606582e+00 -8.68787782e-01 -1.76624975e-01\n",
      "   1.47690437e+00 -1.51263141e+00  2.39064592e+00 -3.74209240e+00\n",
      "  -3.61679069e+00  2.32042094e+00]\n",
      " [ 1.65168011e+00 -1.87126683e-02 -5.72672258e-01  4.59546507e+00\n",
      "   1.17902143e+00  8.67700779e-01 -5.70875006e+00 -3.33783092e+00\n",
      "   6.15956015e+00  6.36130734e+00]\n",
      " [-4.83709139e-01 -1.12286485e+00 -4.37216657e-01 -4.44849593e-01\n",
      "   1.39901514e-01 -6.61239957e-01 -2.66540640e-01  3.52002166e-01\n",
      "  -5.02801758e-01 -2.85205927e-01]\n",
      " [ 3.06339085e+00 -1.65415439e+00 -2.29961864e+00  1.51284686e+01\n",
      "   1.54429367e+00 -5.86754401e+00  8.31047270e+01 -1.25763181e+01\n",
      "  -2.43576021e+01 -3.26744808e+00]\n",
      " [-5.07698032e-01 -4.21120500e-01 -5.18164164e-01  2.79814334e-01\n",
      "  -5.21513842e-01 -8.86718038e-02 -7.69064195e-01  2.46641893e-01\n",
      "  -5.19937340e-01 -3.77074998e-01]\n",
      " [-2.22309578e-01 -6.16399507e-01 -1.98248010e+00 -1.47101223e+00\n",
      "   1.17307804e+00 -5.90075284e+00  1.41879759e+00 -9.22686082e-01\n",
      "  -3.74338705e+00  8.32601319e+01]\n",
      " [-1.36208886e-01 -1.76606582e+00 -8.68787782e-01 -1.76624975e-01\n",
      "   1.47690437e+00 -1.51263141e+00  2.39064592e+00 -3.74209240e+00\n",
      "  -3.61679069e+00  2.32042094e+00]\n",
      " [-4.00525389e-01 -1.70544909e+00  1.65391879e+00 -2.79250619e-02\n",
      "  -1.93771965e-01 -1.27997579e+00 -3.86883925e-01  5.48391167e-02\n",
      "  -1.91442147e-01 -1.53935082e+00]\n",
      " [-1.80164925e-01 -1.35244755e+00 -1.00362716e-01 -4.10446665e-01\n",
      "   1.37418518e+00  1.28093938e-01 -5.28478059e-01  3.83467055e-01\n",
      "  -5.32858404e-01 -3.60793660e-01]\n",
      " [-4.99401652e-01 -1.08624734e+00 -3.48809569e-01 -4.68226190e-01\n",
      "   7.95489599e-02 -6.92166012e-01 -3.68973295e-01  2.96134514e-01\n",
      "  -4.34363428e-01 -2.91050064e-01]\n",
      " [-1.01886612e-02 -5.59642058e+00 -7.73617564e+00  4.76476551e+01\n",
      "  -1.41209605e+01  1.82085571e+01 -5.72862712e+00 -7.05213012e-01\n",
      "   2.75722648e+00  1.30739869e+00]\n",
      " [ 9.61089701e-01  3.46517289e+01  1.12487693e-03  3.03516206e+00\n",
      "  -5.18896492e-01 -9.08198988e-01  1.85542587e-01  7.12103669e-01\n",
      "   1.98652370e-01 -1.38106660e-01]\n",
      " [-3.67878072e-01 -7.66977850e-01  1.59097978e-02 -2.83826201e-01\n",
      "   2.04716139e-02 -5.54282730e-01 -5.32600282e-01  3.68645138e-01\n",
      "  -6.12888899e-01 -3.28501420e-01]\n",
      " [-5.94878917e-01 -9.12570521e-01 -6.04661593e-02 -6.18762076e-01\n",
      "   1.97695317e-01 -8.40412351e-01 -7.68362527e-01  5.72436256e-01\n",
      "  -1.29276589e+00 -2.98987742e-01]\n",
      " [-3.63342576e-01 -5.07478711e-01  8.89510046e-01 -1.47887972e-01\n",
      "   2.64497292e+00 -3.71699331e-01  1.02591802e+00  6.37660023e-01\n",
      "   1.17050936e+00 -7.93828379e-02]\n",
      " [ 1.48003352e+00  1.66762855e+00  1.18553962e+01  1.57735875e+00\n",
      "   7.29631936e+01  5.43959552e+01  2.77341001e-01 -5.47063332e+00\n",
      "  -4.94187638e+00  2.44965935e+00]\n",
      " [-4.70584598e-01 -7.16539424e-01 -4.57731997e-01 -4.37396830e-01\n",
      "   2.13310967e-01 -6.78730012e-01 -4.74434404e-01  3.63782937e-01\n",
      "  -3.91096700e-01 -3.53128250e-01]\n",
      " [-3.32730262e-01 -1.38327495e+00 -4.39366240e-01 -2.85761300e-01\n",
      "   3.48658317e-02 -9.25525894e-01 -3.23631118e-01  2.71277307e-01\n",
      "  -1.70423726e-01 -4.33985038e-01]\n",
      " [-8.32317829e-02 -5.00568669e-01 -3.48741778e-01 -7.09698132e-01\n",
      "   9.41593635e-02 -8.79136385e-01 -7.50661425e-01  6.90540969e-02\n",
      "  -8.04676683e-01 -6.07074881e-01]\n",
      " [-5.69764896e-01 -2.57235809e+00  1.16240201e+01  5.78112886e+00\n",
      "   7.33648323e+00  8.81320658e+00 -7.84498611e-01  6.80945440e+00\n",
      "   1.61836019e+00 -6.05714121e-01]\n",
      " [-5.07979813e-01 -4.60847916e-01 -2.73686294e-01 -3.56150458e-01\n",
      "   7.58714954e-02 -7.25723011e-01 -6.14128448e-01  3.42222476e-01\n",
      "  -6.16874054e-01 -4.74231238e-01]\n",
      " [ 1.48858368e-02  1.56866353e-01 -1.99042767e+00  3.83015314e+00\n",
      "  -6.03786887e-01 -9.99335883e-01  2.32138588e-01 -7.77973408e-01\n",
      "  -9.30952865e-01 -9.19938396e-01]\n",
      " [-4.94124395e-01 -3.70698249e-01 -2.71681889e-01 -3.39656017e-01\n",
      "  -3.67718835e-01 -2.06566979e-01 -7.64877996e-01  3.39622657e-01\n",
      "  -5.70388272e-01 -4.56303747e-01]\n",
      " [-2.71112597e-01 -8.53244129e-01 -2.45455996e-01 -2.64949570e-01\n",
      "   2.13630418e-01 -7.49266373e-01 -4.98900937e-01  1.03768286e-02\n",
      "  -4.77224947e-01 -4.83061962e-01]\n",
      " [-4.46932158e-01 -4.07902826e-01 -5.56944690e-01 -3.48607934e-02\n",
      "  -8.85892629e-02 -6.09277324e-01 -5.73566925e-01  3.16251126e-01\n",
      "  -3.25020218e-01 -4.15070115e-01]\n",
      " [-5.18903429e-01 -1.11620414e+00 -4.15113894e-01 -3.46284685e-01\n",
      "  -7.98039289e-03 -7.79108112e-01 -1.65817532e-01  1.76889114e-01\n",
      "  -3.80483290e-01 -1.38568656e-01]\n",
      " [-4.87641319e-01 -1.16697519e+00  2.35628399e-01 -3.01871764e-01\n",
      "   8.88156110e-02 -8.29581956e-01 -6.74631088e-01  1.48161205e-01\n",
      "  -5.48017066e-01 -4.23867023e-01]\n",
      " [-4.82045010e-01 -1.24936270e+00 -6.00142568e-01 -7.59949749e-01\n",
      "  -2.75209393e-01 -4.10344946e-01 -5.93201207e-01  7.27487764e-02\n",
      "  -5.64286879e-01 -3.53117867e-01]\n",
      " [-4.49853093e-01 -1.33788879e+00 -1.62287481e-01 -7.02860136e-03\n",
      "   7.58048130e-01 -3.00285094e-01 -1.00369733e+00  9.27568688e-01\n",
      "  -8.60428839e-01 -7.83978313e-01]\n",
      " [-3.02993433e-01  1.15594609e+00 -7.82271277e-01 -2.23098595e-01\n",
      "  -6.90721517e-01 -5.25233224e-01 -6.21184529e-01  4.44692847e-01\n",
      "  -7.60067436e-01 -8.43495206e-01]\n",
      " [-3.00208711e-01 -1.21018247e+00 -1.03799801e-01 -4.36736875e-01\n",
      "   3.01597018e-01 -8.64453553e-01 -3.67075745e-01 -1.28634165e-01\n",
      "   1.37535638e-01  2.05999303e-02]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1\n",
      " 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 1 0 1 0 0 0 1 0 1 0 1] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  8\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "-0.12811645792695472\n",
      "\n",
      " Coefficients \n",
      "[ 0.01509387 -0.42466836  0.16054705 -0.0685251   0.38006682  0.22068687\n",
      " -0.16677942  0.4339225   0.27103662  0.03193391]\n",
      "\n",
      " pop_polarity\n",
      "[5.28017211e-01 4.03561475e-01 5.30468075e-01 4.90639017e-01\n",
      " 5.29226871e-01 4.51642581e-01 4.95972087e-01 5.99252305e-01\n",
      " 5.19862194e-01 5.40603473e-01 5.70100239e-01 5.94451801e-01\n",
      " 8.09376598e-01 5.45258416e-01 4.45419178e-01 3.15086280e-01\n",
      " 4.09304760e-01 9.89697164e-02 8.19632826e-01 5.64826023e-01\n",
      " 1.12111990e-12 4.51462864e-01 5.15911750e-01 9.89697164e-02\n",
      " 6.19797409e-01 7.51131892e-01 5.60260957e-01 1.02589474e-01\n",
      " 2.74843191e-07 5.42816810e-01 5.47211973e-01 8.28977501e-01\n",
      " 1.00000000e+00 5.44021767e-01 5.80292851e-01 4.58916454e-01\n",
      " 9.99976628e-01 4.94412886e-01 1.31868021e-01 4.80492445e-01\n",
      " 5.16909521e-01 4.78699187e-01 5.29226871e-01 5.70534073e-01\n",
      " 5.30468075e-01 7.19334952e-01 2.59475084e-01 5.89459890e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 0 1 1 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.75\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[13 10]\n",
      " [ 6 19]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6666666666666666\n",
      "recall:  0.76\n",
      "specificity:  0.5652173913043478\n",
      "precision:  0.6551724137931034\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62        23\n",
      "           1       0.66      0.76      0.70        25\n",
      "\n",
      "    accuracy                           0.67        48\n",
      "   macro avg       0.67      0.66      0.66        48\n",
      "weighted avg       0.67      0.67      0.66        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  8\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[8.49016536e-01 3.82485658e-01 7.85720221e-01 3.05457287e-04\n",
      " 8.09093650e-01 7.79147195e-01 9.61365528e-01 8.05418610e-01\n",
      " 7.91537584e-01 8.03425661e-01 8.36827331e-01 8.37932618e-01\n",
      " 7.87750539e-04 8.20768084e-01 6.20106155e-01 9.91693967e-01\n",
      " 4.59269730e-04 2.51536942e-01 1.90942102e-01 8.12162078e-01\n",
      " 1.00000000e+00 7.90991997e-01 0.00000000e+00 2.51536942e-01\n",
      " 8.20875198e-01 7.23119307e-01 8.15428373e-01 0.00000000e+00\n",
      " 0.00000000e+00 8.31925090e-01 8.47575507e-01 7.77448954e-01\n",
      " 0.00000000e+00 8.24041990e-01 7.28700257e-01 7.88975598e-01\n",
      " 1.17539269e-15 8.20265261e-01 5.06451679e-03 8.12408588e-01\n",
      " 8.02215727e-01 8.07609925e-01 8.09093650e-01 8.25722579e-01\n",
      " 7.85720221e-01 8.04212075e-01 1.87875149e-01 7.66099982e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.68\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[10 13]\n",
      " [ 4 21]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6458333333333334\n",
      "recall:  0.84\n",
      "specificity:  0.43478260869565216\n",
      "precision:  0.6176470588235294\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.43      0.54        23\n",
      "           1       0.62      0.84      0.71        25\n",
      "\n",
      "    accuracy                           0.65        48\n",
      "   macro avg       0.67      0.64      0.63        48\n",
      "weighted avg       0.66      0.65      0.63        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  8\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.58147889 0.05369172 0.14140093 0.40503379 0.53333253 0.31154874\n",
      " 0.04381626 0.78351853 0.16444101 0.42210976 0.81137405 0.6095816\n",
      " 0.04983649 0.89157192 0.40881442 0.50448645 0.21514467 0.00531449\n",
      " 0.36350542 0.95987025 0.17819525 0.57327199 0.21270403 0.00531449\n",
      " 0.60507817 0.91843192 0.94327522 0.13195423 0.01374177 0.93891591\n",
      " 0.86521574 0.90699808 0.65387256 0.87448766 0.8411669  0.15492195\n",
      " 0.73486856 0.92725391 0.03842144 0.76952228 0.18892103 0.72110694\n",
      " 0.53333253 0.79351321 0.14140093 0.8446554  0.01943924 0.61476273]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 1 0 1 0 1 1 1 0 1 0 1]\n",
      "\n",
      " auc\n",
      "0.93\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[18  5]\n",
      " [ 4 21]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8125\n",
      "recall:  0.84\n",
      "specificity:  0.782608695652174\n",
      "precision:  0.8076923076923077\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80        23\n",
      "           1       0.81      0.84      0.82        25\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.81      0.81      0.81        48\n",
      "weighted avg       0.81      0.81      0.81        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  8\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.8s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.50657151 0.5        0.5        0.5        0.5        0.49337338\n",
      " 0.5        0.5        0.40284576 0.5        0.4742407  0.49337338\n",
      " 0.5        0.5        0.5        0.5        0.43636734 0.5\n",
      " 0.5        0.5        0.63220601 0.5        0.5        0.5\n",
      " 0.53221573 0.5        0.49332501 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5       ]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1]\n",
      "\n",
      " auc\n",
      "0.56\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 8 15]\n",
      " [ 5 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5833333333333334\n",
      "recall:  0.8\n",
      "specificity:  0.34782608695652173\n",
      "precision:  0.5714285714285714\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.35      0.44        23\n",
      "           1       0.57      0.80      0.67        25\n",
      "\n",
      "    accuracy                           0.58        48\n",
      "   macro avg       0.59      0.57      0.56        48\n",
      "weighted avg       0.59      0.58      0.56        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  8\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:03:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.47564656 0.3830697  0.43932328 0.42438284 0.5608895  0.4717934\n",
      " 0.39995214 0.5920856  0.46939453 0.5708301  0.6101365  0.6093583\n",
      " 0.48497367 0.66100585 0.46279317 0.40858608 0.5222183  0.37956685\n",
      " 0.48313224 0.66100585 0.46147174 0.48561376 0.3893435  0.37956685\n",
      " 0.48986518 0.5705285  0.66100585 0.4497858  0.38793778 0.6122397\n",
      " 0.568463   0.48577034 0.46147174 0.6263373  0.5526241  0.46293673\n",
      " 0.51789546 0.6393929  0.3635071  0.5211237  0.523385   0.5894888\n",
      " 0.5608895  0.5763858  0.43932328 0.5146591  0.42385954 0.5108806 ]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1\n",
      " 1 0 1 1 1 1 1 0 1 0 1]\n",
      "\n",
      " auc\n",
      "0.73\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[16  7]\n",
      " [ 9 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6666666666666666\n",
      "recall:  0.64\n",
      "specificity:  0.6956521739130435\n",
      "precision:  0.6956521739130435\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67        23\n",
      "           1       0.70      0.64      0.67        25\n",
      "\n",
      "    accuracy                           0.67        48\n",
      "   macro avg       0.67      0.67      0.67        48\n",
      "weighted avg       0.67      0.67      0.67        48\n",
      "\n",
      "\n",
      "KFold:  9\n",
      "\n",
      "X_train:\n",
      " [[-0.53143426 -0.97878639 -0.49682851 ...  0.09531649 -0.32073\n",
      "  -0.26715437]\n",
      " [-0.55466384 -1.06422276 -0.00270784 ...  0.5064787  -0.56582164\n",
      "  -0.50917104]\n",
      " [-0.53246859 -1.03230548 -0.4168956  ...  0.23243473 -0.46531519\n",
      "  -0.35479587]\n",
      " ...\n",
      " [-0.44985309 -1.33788879 -0.16228748 ...  0.92756869 -0.86042884\n",
      "  -0.78397831]\n",
      " [-0.30299343  1.15594609 -0.78227128 ...  0.44469285 -0.76006744\n",
      "  -0.84349521]\n",
      " [-0.30020871 -1.21018247 -0.1037998  ... -0.12863416  0.13753564\n",
      "   0.02059993]] \n",
      "Shape:  (434, 10)\n",
      "\n",
      "X_test:\n",
      " [[-4.86981341e-01 -1.17373538e+00 -2.46398906e-01 -5.16918357e-01\n",
      "   4.44827799e-01 -3.35508484e-01 -3.47919071e-01  3.82014152e-01\n",
      "  -2.73929200e-01 -5.48289570e-01]\n",
      " [-3.73176240e-01 -1.77610380e-01 -7.40763200e-01 -9.75121574e-01\n",
      "  -1.58317232e-01 -7.95803787e-01  5.93285580e-02 -1.02061261e-01\n",
      "  -6.22775711e-01  1.27222632e+00]\n",
      " [-2.49172794e-01  1.75433905e+00  1.44340899e-01 -6.82963806e-01\n",
      "  -2.77237326e-01 -1.22005151e+00 -4.74877858e-01  5.78256537e-02\n",
      "  -6.54595743e-01 -7.06553310e-01]\n",
      " [-5.19022689e-01 -1.18637590e+00  3.15384021e-01 -5.04569688e-01\n",
      "  -8.00412178e-01 -2.72245138e-01 -6.65487600e-01 -9.20701323e-02\n",
      "  -8.24364142e-02 -4.02732413e-01]\n",
      " [-5.00220308e-01 -1.16217599e+00 -2.99829725e-01 -5.89296096e-01\n",
      "   1.47674361e-01 -9.13192980e-01 -3.85426095e-01  1.26693710e-01\n",
      "  -2.95214674e-01 -5.54680366e-01]\n",
      " [-3.04698547e-01  2.56184513e+00  5.40628240e-01 -4.84743055e-03\n",
      "   1.33632041e+00  7.52100429e-01 -3.92218092e-01  2.10212563e-01\n",
      "  -1.90323153e-01 -3.83091292e-01]\n",
      " [-5.59547601e-02  1.21022782e+00  5.37132623e-01 -4.10830628e-01\n",
      "   3.15514811e+00  1.15802258e+00 -1.32684552e+00  1.70615308e+00\n",
      "  -1.28482566e+00 -6.96984393e-01]\n",
      " [-4.69493750e-01 -2.03310189e-01  8.57816514e-01 -3.71213786e-01\n",
      "  -9.02592327e-02 -3.51320979e-01 -4.46385960e-01  1.40187924e-01\n",
      "  -2.86740754e-01 -5.21922775e-01]\n",
      " [-4.82658893e-01 -8.60937136e-01 -6.10357111e-01 -9.31001532e-01\n",
      "  -6.07774963e-01  3.21487446e-02 -4.36223480e-01  4.62847166e-01\n",
      "  -6.19809907e-01  6.01032765e-02]\n",
      " [ 7.24796023e-02  1.30806155e+00  2.93913841e+00  1.78478654e+00\n",
      "  -1.79534247e+00  1.48337847e+00  7.28454373e-01  1.03958966e+01\n",
      "  -6.69373407e+00  5.40153909e+00]\n",
      " [-5.72646283e-01 -1.06008517e+00 -6.34552475e-01 -7.18833384e-01\n",
      "   1.21522922e-01 -1.10696779e+00 -5.81807053e-01  2.34727061e-01\n",
      "  -2.59744584e-01 -5.49266272e-01]\n",
      " [-5.05692442e-01 -7.90888941e-01  3.68837134e-01 -8.26378423e-01\n",
      "  -8.69451068e-02  2.49414375e-02 -5.19419065e-01  6.48234133e-01\n",
      "  -1.19396231e+00  1.38128388e+00]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-5.16091527e-01 -7.04972222e-01 -5.84668004e-01 -3.02782737e-02\n",
      "  -2.98573281e-01 -3.70371846e-01 -7.08107493e-01  4.14753287e-01\n",
      "  -4.48687525e-01 -5.05226763e-01]\n",
      " [-4.77187690e-01 -1.47849563e+00 -4.78531225e-02 -2.69162749e-01\n",
      "  -4.20534531e-01 -4.21134946e-01 -6.32893918e-01 -5.83552005e-01\n",
      "  -8.62705127e-02 -4.41792224e-01]\n",
      " [-2.78121759e-01 -1.43200908e+00 -1.54140531e+00  9.71628625e-01\n",
      "   5.99106340e+00 -2.04158556e+00  2.57382166e+00 -1.80371798e+01\n",
      "   1.84640913e+01 -4.99685687e+00]\n",
      " [-5.29709128e-01 -1.07424409e+00 -4.55626021e-01 -3.40860777e-01\n",
      "   4.09448211e-03 -6.24947568e-01 -5.39898762e-01  2.45454570e-01\n",
      "  -3.72116247e-01 -3.23105648e-01]\n",
      " [-5.29709128e-01 -1.07424409e+00 -4.55626021e-01 -3.40860777e-01\n",
      "   4.09448211e-03 -6.24947568e-01 -5.39898762e-01  2.45454570e-01\n",
      "  -3.72116247e-01 -3.23105648e-01]\n",
      " [ 7.10612072e-01 -6.29768620e-01 -1.00514230e+00  1.12777337e+00\n",
      "   9.06637152e-01 -1.29740196e+00  1.72688847e-01 -1.01520823e+00\n",
      "   1.94873751e+00 -1.39759063e+00]\n",
      " [ 1.48858368e-02  1.56866353e-01 -1.99042767e+00  3.83015314e+00\n",
      "  -6.03786887e-01 -9.99335883e-01  2.32138588e-01 -7.77973408e-01\n",
      "  -9.30952865e-01 -9.19938396e-01]\n",
      " [-4.84888229e-01 -8.64971909e-01 -4.83481411e-01 -5.42605498e-01\n",
      "  -3.65554492e-01 -2.01619280e-02 -3.98068725e-01  1.43757380e-01\n",
      "  -4.47450582e-01 -2.27077859e-01]\n",
      " [-5.47949760e-01 -1.15897427e+00 -4.79491304e-01 -4.22923318e-01\n",
      "  -1.32630343e-01 -5.88492767e-01 -5.94202616e-01  9.54562797e-02\n",
      "  -4.89581380e-01 -3.88547182e-01]\n",
      " [-4.99221376e-01 -1.07624776e+00 -6.39208069e-01  2.95979985e-03\n",
      "  -1.12660046e-01  7.94349020e-02 -3.64268404e-01 -1.03840357e+00\n",
      "   1.60674497e+00 -6.67229942e-01]\n",
      " [-4.96816461e-01 -1.07677232e+00 -4.57555853e-01 -3.79425128e-01\n",
      "  -8.58433242e-03 -7.50949256e-01 -4.90903593e-01  3.68126475e-01\n",
      "  -3.67842907e-01 -4.77400322e-01]\n",
      " [-1.84402761e-01 -2.13931016e+00  1.96936353e+00 -5.50012607e-01\n",
      "   5.20601298e-01 -2.05039427e+00  5.86884417e-01  5.15009689e-01\n",
      "   9.12659291e-02 -4.92863661e-01]\n",
      " [ 4.81036433e-02 -4.96174757e-01 -3.55339737e-01  2.13323651e-01\n",
      "  -1.22449322e-01 -1.10491609e+00  2.88178491e-01  6.60615894e-02\n",
      "  -5.87434383e-01 -5.11938129e-01]\n",
      " [-4.84530847e-01 -3.78823429e-01  3.60304359e-02 -7.14242607e-01\n",
      "  -2.55779960e-01 -3.49241721e-01 -4.60313111e-01  5.26414543e-01\n",
      "  -6.13823518e-01  1.52507928e-01]\n",
      " [-5.07096357e-01 -8.83499307e-01 -4.75926727e-01 -5.25500660e-01\n",
      "   1.31185071e-01 -1.00123260e+00 -7.98246119e-01  7.70866460e-01\n",
      "  -7.29151566e-01 -5.86912802e-01]\n",
      " [-5.41162513e-01 -1.04851436e+00 -4.83927312e-01 -4.61517409e-01\n",
      "   2.57825790e-02 -6.87725923e-01 -5.38177603e-01  1.63559733e-01\n",
      "  -3.84635799e-01  1.80712388e-01]\n",
      " [-3.63538632e-01 -9.27638521e-01 -2.36575140e-01 -7.33920139e-01\n",
      "  -2.27343297e-02 -9.35425876e-01 -6.28992690e-01  4.21902693e-01\n",
      "  -5.43017740e-01 -2.09510958e-01]\n",
      " [-5.49395022e-01 -1.09496569e+00 -1.84248377e-01 -4.47480767e-01\n",
      "   4.82314649e-02 -7.33856370e-01 -4.79259929e-01  3.44387602e-01\n",
      "  -4.95248314e-01 -1.47280284e-01]\n",
      " [-3.79050933e-01  3.14909786e-02 -4.35100127e-01 -4.99077450e-01\n",
      "   2.75902927e-02 -6.64646577e-01 -4.87515185e-01  3.25714934e-01\n",
      "  -2.56784068e-01 -5.01477475e-01]\n",
      " [-5.38833592e-01 -1.07700992e+00 -3.84934254e-01 -5.65568162e-01\n",
      "   5.54539895e-02 -6.93572349e-01 -3.73375802e-01  8.46965910e-01\n",
      "  -1.55604133e-02 -2.75926683e-01]\n",
      " [-2.32469964e-01 -1.10390149e+00 -4.71790662e-01 -3.81809432e-01\n",
      "   2.66532837e-01 -7.70175996e-01 -4.17629619e-01  4.75486757e-02\n",
      "   4.99774053e-01  1.91645727e-01]\n",
      " [-5.07024303e-01 -1.12660839e+00 -4.51242015e-01 -3.77616175e-01\n",
      "   8.15165233e-02 -6.46473003e-01 -4.04367870e-01  3.23938435e-01\n",
      "  -4.53249311e-01 -3.11310653e-01]\n",
      " [-4.75849536e-01 -6.10539849e-01 -4.79351966e-01 -6.83012905e-01\n",
      "  -6.35298156e-01  3.03419635e-01 -4.08778713e-01 -6.23518376e-02\n",
      "  -3.66297002e-01 -1.57093009e-01]\n",
      " [-8.32317829e-02 -5.00568669e-01 -3.48741778e-01 -7.09698132e-01\n",
      "   9.41593635e-02 -8.79136385e-01 -7.50661425e-01  6.90540969e-02\n",
      "  -8.04676683e-01 -6.07074881e-01]\n",
      " [-5.33034174e-01 -3.96043073e-01 -7.54392528e-01 -2.59751385e-02\n",
      "   1.76654904e-02 -9.85850469e-01 -6.45754100e-01  3.38606615e-01\n",
      "  -6.32051218e-01 -5.67139006e-01]\n",
      " [-4.81085607e-01 -4.50656604e-01  8.67798597e-01 -8.94906062e-01\n",
      "  -9.29694368e-01  3.72898958e-01 -4.30452444e-01  3.84846225e-01\n",
      "  -9.02194627e-01 -1.96900749e-01]\n",
      " [ 5.26914378e-01 -2.50219009e+00  3.61693470e-01  1.15887945e+00\n",
      "   2.52085221e+00  3.53690438e-01  2.35133244e+00  4.32330923e+00\n",
      "   3.44991242e+00 -5.77893940e+00]\n",
      " [-3.76562697e-01  1.93059380e+00 -3.72485112e-01 -1.98278692e-02\n",
      "   3.27172983e-02 -1.40342685e+00 -6.15313340e-01  8.76819642e-01\n",
      "   5.71375175e-01 -8.79919546e-01]\n",
      " [-2.89900135e-01  2.31186436e-02 -4.44435322e-01 -5.34052934e-01\n",
      "  -1.94013670e-01 -6.46482583e-01 -6.87093712e-01  2.03407527e-01\n",
      "  -6.26216077e-01  5.54657055e-01]\n",
      " [-2.30426951e-01  1.63840971e+00 -2.00025149e-01 -1.07201719e-01\n",
      "   2.87424252e-01 -8.59975361e-01 -3.24697979e-01  1.00131739e+00\n",
      "  -9.65110326e-02 -8.09416031e-02]\n",
      " [-4.84945308e-01 -1.00705098e+00 -4.67672198e-01 -4.57906306e-01\n",
      "   7.20048181e-02 -6.91278090e-01 -4.37727989e-01 -3.91546290e-02\n",
      "  -6.21314601e-02 -3.89854129e-01]\n",
      " [-5.48426211e-01 -7.34957041e-01 -6.16066914e-01 -3.73540675e-01\n",
      "  -1.08614012e-01 -6.59445484e-01 -5.55954565e-01  2.93355057e-01\n",
      "  -4.38400938e-01 -5.02146738e-01]\n",
      " [-4.99681039e-01 -1.12401472e+00 -4.43422291e-01 -2.41142437e-01\n",
      "  -7.72409763e-02 -5.94960904e-01 -4.84144557e-01  3.49925466e-01\n",
      "  -4.23520096e-01 -3.71353075e-01]\n",
      " [-5.46301493e-01 -1.10530070e+00 -5.03789434e-01 -4.32729591e-01\n",
      "   2.22429306e-02 -7.03524818e-01 -5.29694686e-01  1.56476830e-01\n",
      "  -2.63946361e-01 -2.96769427e-01]\n",
      " [-4.71176023e-01 -8.47788122e-01 -3.55145799e-01 -4.27245456e-01\n",
      "   7.68549771e-02 -6.27612085e-01 -4.15699571e-01 -6.25061270e-02\n",
      "  -4.42810951e-01 -1.60835889e-01]] \n",
      "Shape:  (48, 10)\n",
      "\n",
      "y_train:\n",
      " [0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1\n",
      " 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1] \n",
      "Shape:  (434,)\n",
      "\n",
      "y_test:\n",
      " [1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 0 0 1 1 1 1 1 0] \n",
      "Shape:  (48,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  9\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.06597821659973309\n",
      "\n",
      " Coefficients \n",
      "[ 1.98690207e-02 -3.72917081e-01  3.16997834e-01 -4.17327610e-04\n",
      "  3.68156102e-01  2.04799803e-01  1.81175181e-01  5.07952234e-01\n",
      "  2.45379956e-01  6.47963774e-02]\n",
      "\n",
      " pop_polarity\n",
      "[0.63168141 0.39117968 0.2382754  0.5085439  0.53696352 0.47156726\n",
      " 0.80977722 0.54624847 0.49376482 0.98625844 0.49540002 0.61607573\n",
      " 0.49041162 0.47179702 0.47273924 0.06940934 0.52495486 0.52495486\n",
      " 0.49179038 0.15539525 0.49088922 0.49041162 0.49678665 0.53311876\n",
      " 0.83406893 0.44431164 0.52171307 0.52696445 0.51613765 0.52088342\n",
      " 0.55716702 0.44143067 0.63514817 0.58602584 0.54752051 0.43905304\n",
      " 0.41523788 0.40895438 0.5293151  0.99461295 0.34574201 0.39370226\n",
      " 0.43477577 0.50726541 0.46683762 0.53656243 0.51784624 0.4835024 ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 0 0 1 0 1 1 0]\n",
      "\n",
      " auc\n",
      "0.81\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[18  3]\n",
      " [ 6 21]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8125\n",
      "recall:  0.7777777777777778\n",
      "specificity:  0.8571428571428571\n",
      "precision:  0.875\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        21\n",
      "           1       0.88      0.78      0.82        27\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.81      0.82      0.81        48\n",
      "weighted avg       0.82      0.81      0.81        48\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  9\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[1.42271361e-02 1.44129812e-02 1.59868143e-04 1.64330707e-02\n",
      " 1.37662719e-02 7.68796427e-06 2.84875113e-03 2.13540299e-02\n",
      " 1.31273645e-02 9.96018813e-01 1.59442671e-02 3.24102536e-02\n",
      " 1.47730343e-02 1.65706815e-02 1.07878541e-02 9.89577709e-01\n",
      " 1.51381988e-02 1.51381988e-02 2.13158526e-01 1.04785971e-03\n",
      " 1.39048833e-02 1.47730343e-02 1.29947257e-02 1.46775376e-02\n",
      " 3.13370702e-02 1.76308883e-02 1.42652085e-02 1.73635071e-02\n",
      " 1.56261558e-02 1.32381245e-02 1.58131485e-02 8.63256931e-03\n",
      " 1.53281685e-02 1.23972551e-02 1.42504476e-02 1.26890216e-02\n",
      " 1.45826207e-02 1.58897139e-02 2.20153314e-02 9.88391744e-01\n",
      " 8.94957056e-05 9.45363729e-03 2.37959872e-04 1.39520536e-02\n",
      " 1.68268207e-02 1.43487249e-02 1.49833264e-02 1.42665567e-02]\n",
      "\n",
      " yhat\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.46\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[19  2]\n",
      " [26  1]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.4166666666666667\n",
      "recall:  0.037037037037037035\n",
      "specificity:  0.9047619047619048\n",
      "precision:  0.3333333333333333\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.90      0.58        21\n",
      "           1       0.33      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.42        48\n",
      "   macro avg       0.38      0.47      0.32        48\n",
      "weighted avg       0.37      0.42      0.29        48\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  9\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.86424284 0.02811034 0.35530365 0.22262244 0.52262921 0.39296122\n",
      " 0.85480002 0.67360862 0.14898979 0.21503732 0.40508051 0.91674773\n",
      " 0.08923007 0.25278569 0.10179381 0.08800535 0.88950085 0.88950085\n",
      " 0.08099608 0.0195555  0.40969382 0.08923007 0.54150423 0.75536618\n",
      " 0.11307423 0.08590442 0.82172252 0.70614267 0.82558294 0.748338\n",
      " 0.93406139 0.71401927 0.94572496 0.55848545 0.93155856 0.27845208\n",
      " 0.13761915 0.44045456 0.69476238 0.71263244 0.17808164 0.38415481\n",
      " 0.68562656 0.41661243 0.38140574 0.77831453 0.81989713 0.24656812]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 0 0 1 0 0 1 1 0]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[21  0]\n",
      " [ 4 23]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9166666666666666\n",
      "recall:  0.8518518518518519\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        21\n",
      "           1       1.00      0.85      0.92        27\n",
      "\n",
      "    accuracy                           0.92        48\n",
      "   macro avg       0.92      0.93      0.92        48\n",
      "weighted avg       0.93      0.92      0.92        48\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  9\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   25.5s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n",
      "100%|██████████| 219/219 [00:00<00:00, 19962.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.5        0.49039915 0.4839677  0.5        0.5        0.49317521\n",
      " 0.50802119 0.5        0.5        0.54520594 0.49383955 0.5\n",
      " 0.49438462 0.49386349 0.49378821 0.44377275 0.5        0.5\n",
      " 0.49008961 0.47835656 0.4947216  0.49438462 0.49261366 0.5\n",
      " 0.5088918  0.49214873 0.5        0.5        0.5        0.5\n",
      " 0.5        0.49209574 0.5        0.5        0.5        0.49302797\n",
      " 0.49153642 0.49102051 0.5        0.53717653 0.48724729 0.49093341\n",
      " 0.49149876 0.49432917 0.49331864 0.5        0.5        0.49389275]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 0 0 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.76\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[14  7]\n",
      " [ 5 22]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.75\n",
      "recall:  0.8148148148148148\n",
      "specificity:  0.6666666666666666\n",
      "precision:  0.7586206896551724\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70        21\n",
      "           1       0.76      0.81      0.79        27\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.75      0.74      0.74        48\n",
      "weighted avg       0.75      0.75      0.75        48\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "nKFold round:  9\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:04:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:04:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.6038755  0.35808122 0.4242828  0.43151903 0.5713266  0.59104884\n",
      " 0.52862614 0.47753388 0.436038   0.44803163 0.5094487  0.5934374\n",
      " 0.4670572  0.4798122  0.41690093 0.41692728 0.63042355 0.63042355\n",
      " 0.41692728 0.3623919  0.46165192 0.4670572  0.45697638 0.6276727\n",
      " 0.4557838  0.42302483 0.516668   0.5408256  0.6081389  0.56471163\n",
      " 0.6230822  0.58138597 0.6558865  0.49035272 0.6558865  0.41928083\n",
      " 0.44770238 0.5196397  0.4661598  0.5049774  0.5062209  0.52047676\n",
      " 0.5704577  0.5560852  0.4641801  0.6139014  0.60902905 0.54975784]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0\n",
      " 1 0 1 1 1 1 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[15  6]\n",
      " [ 7 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7291666666666666\n",
      "recall:  0.7407407407407407\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.7692307692307693\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70        21\n",
      "           1       0.77      0.74      0.75        27\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.73      0.73      0.73        48\n",
      "weighted avg       0.73      0.73      0.73        48\n",
      "\n",
      "\n",
      " compare_final_result() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      "=====  Logistic baseline  =====\n",
      "accuracy =  0.8125\n",
      "recall =  0.7777777777777778\n",
      "specificity =  0.8571428571428571\n",
      "precision =  0.875\n",
      "auc =  0.81\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      "=====  GaussianNB  =====\n",
      "accuracy =  0.4166666666666667\n",
      "recall =  0.037037037037037035\n",
      "specificity =  0.9047619047619048\n",
      "precision =  0.3333333333333333\n",
      "auc =  0.46\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      "=====  Random forest  =====\n",
      "accuracy =  0.9166666666666666\n",
      "recall =  0.8518518518518519\n",
      "specificity =  1.0\n",
      "precision =  1.0\n",
      "auc =  0.98\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      "=====  SVM  =====\n",
      "accuracy =  0.75\n",
      "recall =  0.8148148148148148\n",
      "specificity =  0.6666666666666666\n",
      "precision =  0.7586206896551724\n",
      "auc =  0.76\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: chula\n",
      "\n",
      "=====  XGBoost  =====\n",
      "accuracy =  0.7291666666666666\n",
      "recall =  0.7407407407407407\n",
      "specificity =  0.7142857142857143\n",
      "precision =  0.7692307692307693\n",
      "auc =  0.86\n",
      "\n",
      "\n",
      "====================================================\n",
      "\n",
      "Hospital name: bangkok-hospital\n",
      "\n",
      "====================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      ">>>>> Step: Read data for NLP process <<<<<\n",
      "\n",
      " load_dataset() is activated...\n",
      "\n",
      "\n",
      ">> Positive and negative dataset:\n",
      "     score                                                 en  polarity\n",
      "0        4  The doctor at the Internal Medicine Department...         1\n",
      "1        5  Used to heal himself at the Conservation Depar...         1\n",
      "3        4  With good service The doctor is very knowledge...         1\n",
      "4        5  The service is very good, clear, good, the nur...         1\n",
      "5        5  Has antenatal clinic with Bangkok Hospital Sin...         1\n",
      "..     ...                                                ...       ...\n",
      "235      5                           Very good service staff.         1\n",
      "236      5  Clean hospital / Medical care and attentivenes...         1\n",
      "237      5  Born in this hospital until now, over 30 years...         1\n",
      "238      5  Convenient, attentive to every detail, excelle...         1\n",
      "239      5  Today, go to the doctor at this hospital. Is a...         1\n",
      "\n",
      "[219 rows x 3 columns]\n",
      "\n",
      ">> Positive dataset:\n",
      "     score                                                 en  polarity\n",
      "0        4  The doctor at the Internal Medicine Department...         1\n",
      "1        5  Used to heal himself at the Conservation Depar...         1\n",
      "3        4  With good service The doctor is very knowledge...         1\n",
      "4        5  The service is very good, clear, good, the nur...         1\n",
      "5        5  Has antenatal clinic with Bangkok Hospital Sin...         1\n",
      "..     ...                                                ...       ...\n",
      "235      5                           Very good service staff.         1\n",
      "236      5  Clean hospital / Medical care and attentivenes...         1\n",
      "237      5  Born in this hospital until now, over 30 years...         1\n",
      "238      5  Convenient, attentive to every detail, excelle...         1\n",
      "239      5  Today, go to the doctor at this hospital. Is a...         1\n",
      "\n",
      "[177 rows x 3 columns]\n",
      "\n",
      ">> Negative dataset:\n",
      "     score                                                 en  polarity\n",
      "23       1  Go to use the physical examination service pac...         0\n",
      "31       1  Service is very slow. If many patients can und...         0\n",
      "34       2  When will the time and payment system be updat...         0\n",
      "36       2  Bangkok Hospital ... Normally, we are regular ...         0\n",
      "40       2  Would like to take better care of the subcontr...         0\n",
      "47       2  On 28 January, she took her daughter to underg...         0\n",
      "54       2  Waiting very long. The lift is scary. In addit...         0\n",
      "61       1  Meaning difficult contact The doctor who heals...         0\n",
      "62       2  Use this hospital for over 10 years, but met t...         0\n",
      "63       1  We trust us, so how much money have you paid t...         0\n",
      "67       1  Waiting for a very long queue, even if already...         0\n",
      "72       1  Medical expenses get higher every time you com...         0\n",
      "73       1  But before, often, people who do not like to p...         0\n",
      "82       2  Go to check the appointment eye at 9.45 am, ch...         0\n",
      "83       1  I took the blood and didn't send the test beca...         0\n",
      "86       1  The phone receptionist of the hospital was ter...         0\n",
      "92       2  What is a shouting at the patient? Sitting, wa...         0\n",
      "94       2  Not rest Because there is construction for ren...         0\n",
      "96       2  I've come to inspect since 8 PM. So far, it's ...         0\n",
      "98       2  I brought my child to the admin team at Bangko...         0\n",
      "102      2  Room and food Not suitable for the price of 17...         0\n",
      "109      2  Going to check the atmosphere, like the Olympi...         0\n",
      "115      2  To wait for 3 hours, have to walk 2 rounds or ...         0\n",
      "119      2  Confused ... ?? !!! With many queue management...         0\n",
      "134      1  The hospital looks really good, but the parkin...         0\n",
      "138      2  Business type hospital Medicine is much cheape...         0\n",
      "149      1     Good service. Polite staff. Cute. Clean place.         0\n",
      "152      2  This is like a very discriminating practice. S...         0\n",
      "158      1  Mother almost went to the teeth to die. The do...         0\n",
      "166      2  The doctor said because the service is very go...         0\n",
      "169      2  Come and go, the cheeks of the bruise Half pas...         0\n",
      "172      1  Just take the baby to check, but at the hospit...         0\n",
      "173      1  See the doctor, talk bad Don't know where the ...         0\n",
      "180      1  Our grandmother has undergone heart valve repl...         0\n",
      "181      2  I have always been impressed. But today is ver...         0\n",
      "185      1  Please create a private bathroom of the nurse ...         0\n",
      "199      1  This hospital makes you know that nose surgery...         0\n",
      "202      1  If people have money, it is good but people do...         0\n",
      "203      1                           The service is not free.         0\n",
      "213      1  With a fever of up to 40, given Parama only Pa...         0\n",
      "217      1  The doctor treated thyroid errors and did not ...         0\n",
      "229      2  Went to see a doctor on December 31, internal ...         0\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 219\n",
      "Positive = 177\n",
      "Nagative = 42\n",
      "\n",
      "Dataframe size\n",
      "(219, 3)\n",
      "\n",
      " up_sample() is activated...\n",
      "\n",
      "\n",
      "Dataset after up sample\n",
      "\n",
      "     score                                                 en  polarity\n",
      "0        2  Would like to take better care of the subcontr...         0\n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0\n",
      "2        2  Confused ... ?? !!! With many queue management...         0\n",
      "3        1                           The service is not free.         0\n",
      "4        5  Every time he gets sick, he goes here. Both do...         1\n",
      "..     ...                                                ...       ...\n",
      "349      4  Like. Have had the opportunity to visit friend...         1\n",
      "350      5                       Very much love this hospital         1\n",
      "351      5  Every doctor here Acne is very good. The treat...         1\n",
      "352      5  Very good service, convenient, clean, personne...         1\n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0\n",
      "\n",
      "[354 rows x 3 columns]\n",
      "\n",
      "Dataset after up sample group by class\n",
      "\n",
      "1    177\n",
      "0    177\n",
      "Name: polarity, dtype: int64\n",
      "\n",
      " plot_data() is activated...\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/354 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total = 354\n",
      "Positive = 177\n",
      "Nagative = 177\n",
      "\n",
      "Dataframe size\n",
      "(354, 3)\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert sentense to token <<<<<\n",
      "\n",
      " gen_token() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/354 [00:00<00:00, 1606.10it/s]\n",
      "100%|██████████| 354/354 [00:00<00:00, 25350.58it/s]\n",
      "  0%|          | 0/354 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Would like to take better care of the subcontr...         0   \n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0   \n",
      "2        2  Confused ... ?? !!! With many queue management...         0   \n",
      "3        1                           The service is not free.         0   \n",
      "4        5  Every time he gets sick, he goes here. Both do...         1   \n",
      "..     ...                                                ...       ...   \n",
      "349      4  Like. Have had the opportunity to visit friend...         1   \n",
      "350      5                       Very much love this hospital         1   \n",
      "351      5  Every doctor here Acne is very good. The treat...         1   \n",
      "352      5  Very good service, convenient, clean, personne...         1   \n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0   \n",
      "\n",
      "                                                 token  \n",
      "0    [Would, like, to, take, better, care, of, the,...  \n",
      "1    [With, a, fever, of, up, to, 40, ,, given, Par...  \n",
      "2    [Confused, ..., ?, ?, !, !, !, With, many, que...  \n",
      "3                     [The, service, is, not, free, .]  \n",
      "4    [Every, time, he, gets, sick, ,, he, goes, her...  \n",
      "..                                                 ...  \n",
      "349  [Like, ., Have, had, the, opportunity, to, vis...  \n",
      "350                 [Very, much, love, this, hospital]  \n",
      "351  [Every, doctor, here, Acne, is, very, good, .,...  \n",
      "352  [Very, good, service, ,, convenient, ,, clean,...  \n",
      "353  [To, wait, for, 3, hours, ,, have, to, walk, 2...  \n",
      "\n",
      "[354 rows x 4 columns]\n",
      "(354, 4)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Convert text to lowercase <<<<<\n",
      "\n",
      " lowercase_text() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Would like to take better care of the subcontr...         0   \n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0   \n",
      "2        2  Confused ... ?? !!! With many queue management...         0   \n",
      "3        1                           The service is not free.         0   \n",
      "4        5  Every time he gets sick, he goes here. Both do...         1   \n",
      "..     ...                                                ...       ...   \n",
      "349      4  Like. Have had the opportunity to visit friend...         1   \n",
      "350      5                       Very much love this hospital         1   \n",
      "351      5  Every doctor here Acne is very good. The treat...         1   \n",
      "352      5  Very good service, convenient, clean, personne...         1   \n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Would, like, to, take, better, care, of, the,...   \n",
      "1    [With, a, fever, of, up, to, 40, ,, given, Par...   \n",
      "2    [Confused, ..., ?, ?, !, !, !, With, many, que...   \n",
      "3                     [The, service, is, not, free, .]   \n",
      "4    [Every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [Like, ., Have, had, the, opportunity, to, vis...   \n",
      "350                 [Very, much, love, this, hospital]   \n",
      "351  [Every, doctor, here, Acne, is, very, good, .,...   \n",
      "352  [Very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [To, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                             lowercase  \n",
      "0    [would, like, to, take, better, care, of, the,...  \n",
      "1    [with, a, fever, of, up, to, 40, ,, given, par...  \n",
      "2    [confused, ..., ?, ?, !, !, !, with, many, que...  \n",
      "3                     [the, service, is, not, free, .]  \n",
      "4    [every, time, he, gets, sick, ,, he, goes, her...  \n",
      "..                                                 ...  \n",
      "349  [like, ., have, had, the, opportunity, to, vis...  \n",
      "350                 [very, much, love, this, hospital]  \n",
      "351  [every, doctor, here, acne, is, very, good, .,...  \n",
      "352  [very, good, service, ,, convenient, ,, clean,...  \n",
      "353  [to, wait, for, 3, hours, ,, have, to, walk, 2...  \n",
      "\n",
      "[354 rows x 5 columns]\n",
      "(354, 5)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove special character <<<<<\n",
      "\n",
      " remove_spec_char() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Would like to take better care of the subcontr...         0   \n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0   \n",
      "2        2  Confused ... ?? !!! With many queue management...         0   \n",
      "3        1                           The service is not free.         0   \n",
      "4        5  Every time he gets sick, he goes here. Both do...         1   \n",
      "..     ...                                                ...       ...   \n",
      "349      4  Like. Have had the opportunity to visit friend...         1   \n",
      "350      5                       Very much love this hospital         1   \n",
      "351      5  Every doctor here Acne is very good. The treat...         1   \n",
      "352      5  Very good service, convenient, clean, personne...         1   \n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Would, like, to, take, better, care, of, the,...   \n",
      "1    [With, a, fever, of, up, to, 40, ,, given, Par...   \n",
      "2    [Confused, ..., ?, ?, !, !, !, With, many, que...   \n",
      "3                     [The, service, is, not, free, .]   \n",
      "4    [Every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [Like, ., Have, had, the, opportunity, to, vis...   \n",
      "350                 [Very, much, love, this, hospital]   \n",
      "351  [Every, doctor, here, Acne, is, very, good, .,...   \n",
      "352  [Very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [To, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, ,, given, par...   \n",
      "2    [confused, ..., ?, ?, !, !, !, with, many, que...   \n",
      "3                     [the, service, is, not, free, .]   \n",
      "4    [every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [like, ., have, had, the, opportunity, to, vis...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, .,...   \n",
      "352  [very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [to, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                         rem_spec_char  \n",
      "0    [would, like, to, take, better, care, of, the,...  \n",
      "1    [with, a, fever, of, up, to, 40, , given, para...  \n",
      "2    [confused, , , , , , , with, many, queue, mana...  \n",
      "3                      [the, service, is, not, free, ]  \n",
      "4    [every, time, he, gets, sick, , he, goes, here...  \n",
      "..                                                 ...  \n",
      "349  [like, , have, had, the, opportunity, to, visi...  \n",
      "350                 [very, much, love, this, hospital]  \n",
      "351  [every, doctor, here, acne, is, very, good, , ...  \n",
      "352  [very, good, service, , convenient, , clean, ,...  \n",
      "353  [to, wait, for, 3, hours, , have, to, walk, 2,...  \n",
      "\n",
      "[354 rows x 6 columns]\n",
      "(354, 6)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word <<<<<\n",
      "\n",
      " remove_stop_word() is activated...\n",
      "\n",
      "\n",
      "stop_words:\n",
      "\n",
      "{'before', 'how', 'on', 'yourself', 'should', 'ours', 'more', 'aren', \"mustn't\", \"shouldn't\", 'no', 'being', \"needn't\", 'myself', 'are', 'too', \"mightn't\", 'o', 'ourselves', 'whom', 'who', 'down', \"should've\", 'from', 'during', 'shan', 'at', 'theirs', 'couldn', 'through', \"you've\", 'again', 'all', 'nor', \"you're\", 'into', 'this', 'weren', \"it's\", 'the', 'yourselves', 'while', 'haven', 'isn', 'themselves', 'why', 'until', 'under', 's', 'hasn', 'because', 'wasn', 'can', 'now', 'doing', 'with', \"don't\", 'my', \"aren't\", 'their', 'both', 'wouldn', 'we', 'in', 'or', 'hadn', 'up', 'by', 'yours', 'few', 'those', 'below', 'll', 'itself', 'and', 'than', 'own', \"that'll\", 'did', 'about', 'mustn', 'once', \"wasn't\", \"won't\", 'ma', 'don', 'some', \"shan't\", 'our', 'won', 'here', \"she's\", 'was', 'has', 'each', 'y', 'they', 'ain', 'is', 've', 'hers', 'such', 'against', 'only', 'above', 'shouldn', \"couldn't\", 'them', 'mightn', 'you', 'had', 't', 'there', 'its', 'any', 'will', 'that', 'a', 'needn', 'me', 'she', 'having', \"haven't\", 'so', 'which', 'for', 'be', 'after', 'further', 'i', 'am', 'most', 'these', 'himself', \"you'd\", 'over', 'just', 'very', \"wouldn't\", \"you'll\", 'were', 'been', 'd', 're', 'does', 'didn', 'as', \"isn't\", 'his', \"hasn't\", 'her', 'not', 'him', 'then', 'doesn', 'he', 'it', \"hadn't\", 'have', 'm', 'where', \"didn't\", 'out', 'other', 'when', 'but', 'your', 'herself', 'an', \"doesn't\", 'if', 'of', 'what', 'do', 'same', 'between', \"weren't\", 'to', 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/354 [01:45<00:00,  3.35it/s]\n",
      "100%|██████████| 354/354 [00:00<00:00, 32154.18it/s]\n",
      "100%|██████████| 354/354 [00:00<00:00, 7394.86it/s]\n",
      "  0%|          | 0/354 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Would like to take better care of the subcontr...         0   \n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0   \n",
      "2        2  Confused ... ?? !!! With many queue management...         0   \n",
      "3        1                           The service is not free.         0   \n",
      "4        5  Every time he gets sick, he goes here. Both do...         1   \n",
      "..     ...                                                ...       ...   \n",
      "349      4  Like. Have had the opportunity to visit friend...         1   \n",
      "350      5                       Very much love this hospital         1   \n",
      "351      5  Every doctor here Acne is very good. The treat...         1   \n",
      "352      5  Very good service, convenient, clean, personne...         1   \n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Would, like, to, take, better, care, of, the,...   \n",
      "1    [With, a, fever, of, up, to, 40, ,, given, Par...   \n",
      "2    [Confused, ..., ?, ?, !, !, !, With, many, que...   \n",
      "3                     [The, service, is, not, free, .]   \n",
      "4    [Every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [Like, ., Have, had, the, opportunity, to, vis...   \n",
      "350                 [Very, much, love, this, hospital]   \n",
      "351  [Every, doctor, here, Acne, is, very, good, .,...   \n",
      "352  [Very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [To, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, ,, given, par...   \n",
      "2    [confused, ..., ?, ?, !, !, !, with, many, que...   \n",
      "3                     [the, service, is, not, free, .]   \n",
      "4    [every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [like, ., have, had, the, opportunity, to, vis...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, .,...   \n",
      "352  [very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [to, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, , given, para...   \n",
      "2    [confused, , , , , , , with, many, queue, mana...   \n",
      "3                      [the, service, is, not, free, ]   \n",
      "4    [every, time, he, gets, sick, , he, goes, here...   \n",
      "..                                                 ...   \n",
      "349  [like, , have, had, the, opportunity, to, visi...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, , ...   \n",
      "352  [very, good, service, , convenient, , clean, ,...   \n",
      "353  [to, wait, for, 3, hours, , have, to, walk, 2,...   \n",
      "\n",
      "                                             stop_word  \n",
      "0    [would, like, better, subcontractor, least, ab...  \n",
      "1    [fever, 40, , given, parama, paid, nearly, tho...  \n",
      "2    [confused, , , , , , , many, queue, management...  \n",
      "3                                    [service, free, ]  \n",
      "4    [every, time, gets, sick, , goes, , doctors, n...  \n",
      "..                                                 ...  \n",
      "349  [like, , opportunity, visit, friends, , good, ...  \n",
      "350                             [much, love, hospital]  \n",
      "351  [every, doctor, acne, good, , treatment, impro...  \n",
      "352  [good, service, , convenient, , clean, , perso...  \n",
      "353  [wait, 3, hours, , walk, 2, rounds, else, chec...  \n",
      "\n",
      "[354 rows x 7 columns]\n",
      "(354, 7)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove stop word (Special) <<<<<\n",
      "\n",
      ">>>>> 've, ``, 's, n't, '', ' ' <<<<<\n",
      "\n",
      " remove_stop_word_spec() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Would like to take better care of the subcontr...         0   \n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0   \n",
      "2        2  Confused ... ?? !!! With many queue management...         0   \n",
      "3        1                           The service is not free.         0   \n",
      "4        5  Every time he gets sick, he goes here. Both do...         1   \n",
      "..     ...                                                ...       ...   \n",
      "349      4  Like. Have had the opportunity to visit friend...         1   \n",
      "350      5                       Very much love this hospital         1   \n",
      "351      5  Every doctor here Acne is very good. The treat...         1   \n",
      "352      5  Very good service, convenient, clean, personne...         1   \n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Would, like, to, take, better, care, of, the,...   \n",
      "1    [With, a, fever, of, up, to, 40, ,, given, Par...   \n",
      "2    [Confused, ..., ?, ?, !, !, !, With, many, que...   \n",
      "3                     [The, service, is, not, free, .]   \n",
      "4    [Every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [Like, ., Have, had, the, opportunity, to, vis...   \n",
      "350                 [Very, much, love, this, hospital]   \n",
      "351  [Every, doctor, here, Acne, is, very, good, .,...   \n",
      "352  [Very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [To, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, ,, given, par...   \n",
      "2    [confused, ..., ?, ?, !, !, !, with, many, que...   \n",
      "3                     [the, service, is, not, free, .]   \n",
      "4    [every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [like, ., have, had, the, opportunity, to, vis...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, .,...   \n",
      "352  [very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [to, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, , given, para...   \n",
      "2    [confused, , , , , , , with, many, queue, mana...   \n",
      "3                      [the, service, is, not, free, ]   \n",
      "4    [every, time, he, gets, sick, , he, goes, here...   \n",
      "..                                                 ...   \n",
      "349  [like, , have, had, the, opportunity, to, visi...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, , ...   \n",
      "352  [very, good, service, , convenient, , clean, ,...   \n",
      "353  [to, wait, for, 3, hours, , have, to, walk, 2,...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [would, like, better, subcontractor, least, ab...   \n",
      "1    [fever, 40, , given, parama, paid, nearly, tho...   \n",
      "2    [confused, , , , , , , many, queue, management...   \n",
      "3                                    [service, free, ]   \n",
      "4    [every, time, gets, sick, , goes, , doctors, n...   \n",
      "..                                                 ...   \n",
      "349  [like, , opportunity, visit, friends, , good, ...   \n",
      "350                             [much, love, hospital]   \n",
      "351  [every, doctor, acne, good, , treatment, impro...   \n",
      "352  [good, service, , convenient, , clean, , perso...   \n",
      "353  [wait, 3, hours, , walk, 2, rounds, else, chec...   \n",
      "\n",
      "                                          stop_word_02  \n",
      "0    [would, like, better, subcontractor, least, ab...  \n",
      "1    [fever, 40, , given, parama, paid, nearly, tho...  \n",
      "2    [confused, , , , , , , many, queue, management...  \n",
      "3                                    [service, free, ]  \n",
      "4    [every, time, gets, sick, , goes, , doctors, n...  \n",
      "..                                                 ...  \n",
      "349  [like, , opportunity, visit, friends, , good, ...  \n",
      "350                             [much, love, hospital]  \n",
      "351  [every, doctor, acne, good, , treatment, impro...  \n",
      "352  [good, service, , convenient, , clean, , perso...  \n",
      "353  [wait, 3, hours, , walk, 2, rounds, else, chec...  \n",
      "\n",
      "[354 rows x 8 columns]\n",
      "(354, 8)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Remove single and space token <<<<<\n",
      "\n",
      " remove_single_token() is activated...\n",
      "\n",
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Would like to take better care of the subcontr...         0   \n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0   \n",
      "2        2  Confused ... ?? !!! With many queue management...         0   \n",
      "3        1                           The service is not free.         0   \n",
      "4        5  Every time he gets sick, he goes here. Both do...         1   \n",
      "..     ...                                                ...       ...   \n",
      "349      4  Like. Have had the opportunity to visit friend...         1   \n",
      "350      5                       Very much love this hospital         1   \n",
      "351      5  Every doctor here Acne is very good. The treat...         1   \n",
      "352      5  Very good service, convenient, clean, personne...         1   \n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Would, like, to, take, better, care, of, the,...   \n",
      "1    [With, a, fever, of, up, to, 40, ,, given, Par...   \n",
      "2    [Confused, ..., ?, ?, !, !, !, With, many, que...   \n",
      "3                     [The, service, is, not, free, .]   \n",
      "4    [Every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [Like, ., Have, had, the, opportunity, to, vis...   \n",
      "350                 [Very, much, love, this, hospital]   \n",
      "351  [Every, doctor, here, Acne, is, very, good, .,...   \n",
      "352  [Very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [To, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, ,, given, par...   \n",
      "2    [confused, ..., ?, ?, !, !, !, with, many, que...   \n",
      "3                     [the, service, is, not, free, .]   \n",
      "4    [every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [like, ., have, had, the, opportunity, to, vis...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, .,...   \n",
      "352  [very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [to, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, , given, para...   \n",
      "2    [confused, , , , , , , with, many, queue, mana...   \n",
      "3                      [the, service, is, not, free, ]   \n",
      "4    [every, time, he, gets, sick, , he, goes, here...   \n",
      "..                                                 ...   \n",
      "349  [like, , have, had, the, opportunity, to, visi...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, , ...   \n",
      "352  [very, good, service, , convenient, , clean, ,...   \n",
      "353  [to, wait, for, 3, hours, , have, to, walk, 2,...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [would, like, better, subcontractor, least, ab...   \n",
      "1    [fever, 40, , given, parama, paid, nearly, tho...   \n",
      "2    [confused, , , , , , , many, queue, management...   \n",
      "3                                    [service, free, ]   \n",
      "4    [every, time, gets, sick, , goes, , doctors, n...   \n",
      "..                                                 ...   \n",
      "349  [like, , opportunity, visit, friends, , good, ...   \n",
      "350                             [much, love, hospital]   \n",
      "351  [every, doctor, acne, good, , treatment, impro...   \n",
      "352  [good, service, , convenient, , clean, , perso...   \n",
      "353  [wait, 3, hours, , walk, 2, rounds, else, chec...   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0    [would, like, better, subcontractor, least, ab...   \n",
      "1    [fever, 40, , given, parama, paid, nearly, tho...   \n",
      "2    [confused, , , , , , , many, queue, management...   \n",
      "3                                    [service, free, ]   \n",
      "4    [every, time, gets, sick, , goes, , doctors, n...   \n",
      "..                                                 ...   \n",
      "349  [like, , opportunity, visit, friends, , good, ...   \n",
      "350                             [much, love, hospital]   \n",
      "351  [every, doctor, acne, good, , treatment, impro...   \n",
      "352  [good, service, , convenient, , clean, , perso...   \n",
      "353  [wait, 3, hours, , walk, 2, rounds, else, chec...   \n",
      "\n",
      "                                       rem_single_char  \n",
      "0    [would, like, better, subcontractor, least, ab...  \n",
      "1    [fever, 40, given, parama, paid, nearly, thous...  \n",
      "2    [confused, many, queue, management, took, chil...  \n",
      "3                                      [service, free]  \n",
      "4    [every, time, gets, sick, goes, doctors, nurse...  \n",
      "..                                                 ...  \n",
      "349  [like, opportunity, visit, friends, good, serv...  \n",
      "350                             [much, love, hospital]  \n",
      "351  [every, doctor, acne, good, treatment, improve...  \n",
      "352  [good, service, convenient, clean, personnel, ...  \n",
      "353  [wait, hours, walk, rounds, else, checked, imp...  \n",
      "\n",
      "[354 rows x 9 columns]\n",
      "(354, 9)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Normalization (Lemmatization: root word) <<<<<\n",
      "\n",
      " lemmatize_token() is activated...\n",
      "\n",
      "\n",
      "Test POS:\n",
      "\n",
      "This is a book\n",
      "\n",
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('book', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/354 [00:03<00:00, 95.18it/s] \n",
      "100%|██████████| 354/354 [00:00<00:00, 7672.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview some records:\n",
      "\n",
      "     score                                                 en  polarity  \\\n",
      "0        2  Would like to take better care of the subcontr...         0   \n",
      "1        1  With a fever of up to 40, given Parama only Pa...         0   \n",
      "2        2  Confused ... ?? !!! With many queue management...         0   \n",
      "3        1                           The service is not free.         0   \n",
      "4        5  Every time he gets sick, he goes here. Both do...         1   \n",
      "..     ...                                                ...       ...   \n",
      "349      4  Like. Have had the opportunity to visit friend...         1   \n",
      "350      5                       Very much love this hospital         1   \n",
      "351      5  Every doctor here Acne is very good. The treat...         1   \n",
      "352      5  Very good service, convenient, clean, personne...         1   \n",
      "353      2  To wait for 3 hours, have to walk 2 rounds or ...         0   \n",
      "\n",
      "                                                 token  \\\n",
      "0    [Would, like, to, take, better, care, of, the,...   \n",
      "1    [With, a, fever, of, up, to, 40, ,, given, Par...   \n",
      "2    [Confused, ..., ?, ?, !, !, !, With, many, que...   \n",
      "3                     [The, service, is, not, free, .]   \n",
      "4    [Every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [Like, ., Have, had, the, opportunity, to, vis...   \n",
      "350                 [Very, much, love, this, hospital]   \n",
      "351  [Every, doctor, here, Acne, is, very, good, .,...   \n",
      "352  [Very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [To, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                             lowercase  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, ,, given, par...   \n",
      "2    [confused, ..., ?, ?, !, !, !, with, many, que...   \n",
      "3                     [the, service, is, not, free, .]   \n",
      "4    [every, time, he, gets, sick, ,, he, goes, her...   \n",
      "..                                                 ...   \n",
      "349  [like, ., have, had, the, opportunity, to, vis...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, .,...   \n",
      "352  [very, good, service, ,, convenient, ,, clean,...   \n",
      "353  [to, wait, for, 3, hours, ,, have, to, walk, 2...   \n",
      "\n",
      "                                         rem_spec_char  \\\n",
      "0    [would, like, to, take, better, care, of, the,...   \n",
      "1    [with, a, fever, of, up, to, 40, , given, para...   \n",
      "2    [confused, , , , , , , with, many, queue, mana...   \n",
      "3                      [the, service, is, not, free, ]   \n",
      "4    [every, time, he, gets, sick, , he, goes, here...   \n",
      "..                                                 ...   \n",
      "349  [like, , have, had, the, opportunity, to, visi...   \n",
      "350                 [very, much, love, this, hospital]   \n",
      "351  [every, doctor, here, acne, is, very, good, , ...   \n",
      "352  [very, good, service, , convenient, , clean, ,...   \n",
      "353  [to, wait, for, 3, hours, , have, to, walk, 2,...   \n",
      "\n",
      "                                             stop_word  \\\n",
      "0    [would, like, better, subcontractor, least, ab...   \n",
      "1    [fever, 40, , given, parama, paid, nearly, tho...   \n",
      "2    [confused, , , , , , , many, queue, management...   \n",
      "3                                    [service, free, ]   \n",
      "4    [every, time, gets, sick, , goes, , doctors, n...   \n",
      "..                                                 ...   \n",
      "349  [like, , opportunity, visit, friends, , good, ...   \n",
      "350                             [much, love, hospital]   \n",
      "351  [every, doctor, acne, good, , treatment, impro...   \n",
      "352  [good, service, , convenient, , clean, , perso...   \n",
      "353  [wait, 3, hours, , walk, 2, rounds, else, chec...   \n",
      "\n",
      "                                          stop_word_02  \\\n",
      "0    [would, like, better, subcontractor, least, ab...   \n",
      "1    [fever, 40, , given, parama, paid, nearly, tho...   \n",
      "2    [confused, , , , , , , many, queue, management...   \n",
      "3                                    [service, free, ]   \n",
      "4    [every, time, gets, sick, , goes, , doctors, n...   \n",
      "..                                                 ...   \n",
      "349  [like, , opportunity, visit, friends, , good, ...   \n",
      "350                             [much, love, hospital]   \n",
      "351  [every, doctor, acne, good, , treatment, impro...   \n",
      "352  [good, service, , convenient, , clean, , perso...   \n",
      "353  [wait, 3, hours, , walk, 2, rounds, else, chec...   \n",
      "\n",
      "                                       rem_single_char  \\\n",
      "0    [would, like, better, subcontractor, least, ab...   \n",
      "1    [fever, 40, given, parama, paid, nearly, thous...   \n",
      "2    [confused, many, queue, management, took, chil...   \n",
      "3                                      [service, free]   \n",
      "4    [every, time, gets, sick, goes, doctors, nurse...   \n",
      "..                                                 ...   \n",
      "349  [like, opportunity, visit, friends, good, serv...   \n",
      "350                             [much, love, hospital]   \n",
      "351  [every, doctor, acne, good, treatment, improve...   \n",
      "352  [good, service, convenient, clean, personnel, ...   \n",
      "353  [wait, hours, walk, rounds, else, checked, imp...   \n",
      "\n",
      "                                            norm_lemma  \n",
      "0    [would, like, well, subcontractor, least, able...  \n",
      "1    [fever, 40, give, parama, paid, nearly, thousa...  \n",
      "2    [confuse, many, queue, management, take, child...  \n",
      "3                                      [service, free]  \n",
      "4    [every, time, get, sick, go, doctor, nurse, sk...  \n",
      "..                                                 ...  \n",
      "349  [like, opportunity, visit, friend, good, servi...  \n",
      "350                             [much, love, hospital]  \n",
      "351  [every, doctor, acne, good, treatment, improve...  \n",
      "352  [good, service, convenient, clean, personnel, ...  \n",
      "353  [wait, hour, walk, round, else, checked, impro...  \n",
      "\n",
      "[354 rows x 10 columns]\n",
      "(354, 10)\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF) <<<<<\n",
      "\n",
      " vec_tf_idf() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 1076\n",
      "\n",
      "\n",
      "\n",
      "['09', '093', '10', '10250', '1030', '11', '1100', '1108', '11pm', '11th', '13', '130', '14', '15', '15000', '16', '1600', '17', '17000', '1820', '1920', '20', '20000', '2016', '2017', '21st', '230', '232', '28', '2nd', '30', '30900', '31', '40', '40000', '45', '50', '5264', '555', '5r', '5th', '60000', '730', '78', '802', '82', '820', '8297', '8th', '930', '945', 'ability', 'able', 'accept', 'accident', 'accord', 'accurate', 'ache', 'acne', 'act', 'activity', 'actual', 'add', 'addition', 'adjust', 'admin', 'admit', 'adult', 'advance', 'advice', 'advise', 'afraid', 'age', 'aggravation', 'airforce', 'airy', 'allergic', 'almost', 'along', 'already', 'alright', 'although', 'always', 'analysis', 'analyze', 'aneurysm', 'annual', 'another', 'answer', 'antenatal', 'anxiety', 'anymore', 'anyone', 'anything', 'anywhere', 'apparatus', 'appointment', 'appreciate', 'approximately', 'april', 'area', 'around', 'arrange', 'arrhythmia', 'arrive', 'artery', 'aside', 'ask', 'aspect', 'assistant', 'astray', 'atmosphere', 'attention', 'attentive', 'attentiveness', 'aunt', 'authority', 'available', 'await', 'away', 'baby', 'back', 'bad', 'badly', 'bag', 'baht', 'ball', 'bang', 'bangkok', 'banquet', 'basket', 'bathroom', 'beam', 'beautiful', 'become', 'bed', 'begin', 'believe', 'benefit', 'best', 'big', 'bill', 'birth', 'bit', 'bite', 'bleeding', 'blogging', 'blood', 'body', 'bon', 'book', 'bore', 'born', 'brain', 'branch', 'breast', 'breastfeed', 'breathing', 'bring', 'brought', 'bruise', 'building', 'business', 'busy', 'buy', 'bypass', 'caesarean', 'calculate', 'call', 'calm', 'cancer', 'car', 'card', 'cardiac', 'care', 'careful', 'carefully', 'carry', 'cart', 'case', 'cash', 'catering', 'cause', 'centennial', 'center', 'certificate', 'cesarean', 'chaloem', 'change', 'charge', 'charm', 'charnpong', 'chat', 'cheap', 'cheaper', 'check', 'checked', 'cheek', 'cheerful', 'child', 'childbirth', 'choose', 'chose', 'chronic', 'circumcise', 'class', 'clean', 'cleanliness', 'clear', 'clearly', 'clinic', 'clock', 'cold', 'collect', 'collection', 'collide', 'color', 'colorblind', 'come', 'comfort', 'comfortable', 'comfortably', 'comment', 'commercial', 'commercially', 'compare', 'complain', 'complete', 'completely', 'comply', 'comprehensive', 'conclude', 'conclusion', 'condition', 'confident', 'confuse', 'congratulation', 'conservation', 'consider', 'construction', 'consult', 'consultation', 'contact', 'continue', 'continuous', 'control', 'convenience', 'convenient', 'cooking', 'coordination', 'coronary', 'correctly', 'cost', 'could', 'counter', 'course', 'courteous', 'cover', 'crazy', 'create', 'credit', 'culture', 'cup', 'customer', 'cute', 'date', 'daughter', 'day', 'dealer', 'december', 'decide', 'decision', 'dee', 'definitely', 'delicious', 'delivery', 'dental', 'dentist', 'department', 'depend', 'deposit', 'desk', 'despite', 'detail', 'detailed', 'detector', 'diagnose', 'diagnosis', 'diarrhea', 'different', 'difficult', 'digestive', 'diligent', 'diligently', 'direction', 'directly', 'disadvantage', 'disappear', 'disappears', 'disappointed', 'discount', 'discriminate', 'discuss', 'disease', 'dish', 'dispense', 'displeasure', 'dissatisfied', 'dissect', 'district', 'disturbed', 'dizzy', 'do', 'docile', 'doctor', 'dr', 'draw', 'dream', 'drink', 'drive', 'drove', 'duangsit', 'duct', 'due', 'duty', 'ease', 'easily', 'easy', 'eat', 'edid', 'elderly', 'eldest', 'electric', 'elevator', 'else', 'email', 'emergency', 'encourage', 'endoscopy', 'enough', 'ensure', 'enter', 'equal', 'equip', 'equipment', 'error', 'especially', 'even', 'event', 'ever', 'every', 'everyone', 'everything', 'examination', 'examine', 'excellent', 'except', 'exercise', 'exists', 'expect', 'expense', 'expensive', 'expert', 'explain', 'explanation', 'expression', 'extra', 'eye', 'eyelid', 'face', 'facial', 'facility', 'fact', 'fade', 'fair', 'fall', 'family', 'famous', 'far', 'fast', 'fat', 'father', 'fear', 'fee', 'feed', 'feel', 'feeling', 'felt', 'female', 'festival', 'fever', 'field', 'finally', 'financial', 'find', 'finger', 'finish', 'first', 'fix', 'floor', 'flow', 'flu', 'follow', 'food', 'foreigner', 'forget', 'forgot', 'found', 'frankly', 'free', 'friend', 'friendly', 'front', 'frustrate', 'fully', 'future', 'gastroenterologist', 'general', 'genitals', 'gentle', 'get', 'give', 'go', 'good', 'goodness', 'government', 'grace', 'gradually', 'grandma', 'grandmother', 'grant', 'great', 'greatly', 'group', 'grown', 'guard', 'guest', 'gynecology', 'hahaha', 'half', 'hand', 'haphazard', 'happen', 'happens', 'happy', 'hardly', 'hassle', 'head', 'headache', 'heal', 'heals', 'health', 'healthy', 'heart', 'heartbeat', 'heavy', 'heir', 'help', 'helpful', 'heng', 'hesitate', 'high', 'highly', 'history', 'hit', 'hmm', 'home', 'hospitable', 'hospital', 'hospitality', 'hospitalize', 'hot', 'hotel', 'hour', 'house', 'housekeeper', 'housewife', 'however', 'hr', 'hundred', 'hurry', 'husband', 'id', 'illness', 'immediately', 'implant', 'importance', 'important', 'importantly', 'impress', 'impressed', 'impression', 'impressive', 'imprint', 'improve', 'improvement', 'incision', 'include', 'inclusive', 'infect', 'infection', 'inform', 'information', 'inhale', 'inhaler', 'injection', 'inquire', 'inquiry', 'inspect', 'inspection', 'inspector', 'instruction', 'insurance', 'intelligence', 'intend', 'intention', 'interested', 'internal', 'international', 'intestine', 'item', 'jaidee', 'january', 'japanese', 'july', 'kaen', 'keep', 'keng', 'kengen', 'key', 'khon', 'kidney', 'kieri', 'kilometer', 'kind', 'kiss', 'know', 'knowledgeable', 'lab', 'language', 'large', 'last', 'late', 'later', 'lay', 'least', 'leave', 'left', 'leg', 'less', 'let', 'level', 'life', 'lift', 'light', 'lightlove', 'like', 'limb', 'limp', 'line', 'listen', 'little', 'livable', 'liver', 'living', 'll', 'locate', 'location', 'loei', 'lonely', 'long', 'look', 'lose', 'lot', 'lottery', 'loud', 'loudly', 'love', 'lovely', 'low', 'loyal', 'luang', 'luggage', 'lump', 'lunch', 'luxurious', 'maid', 'maintain', 'maintenance', 'make', 'male', 'mall', 'management', 'manager', 'manner', 'many', 'massage', 'matt', 'matter', 'may', 'meaning', 'measure', 'medical', 'medication', 'medicine', 'meet', 'member', 'mental', 'middle', 'midweek', 'miko', 'milk', 'mind', 'minute', 'mischievous', 'modern', 'moment', 'money', 'month', 'mop', 'morality', 'moret', 'mother', 'move', 'much', 'mushroom', 'must', 'narrow', 'nature', 'near', 'nearly', 'neat', 'need', 'neurosis', 'never', 'new', 'newborn', 'next', 'ni', 'nice', 'night', 'noisy', 'nong', 'nonsense', 'nonthaburi', 'noon', 'normal', 'normally', 'nose', 'nothing', 'notify', 'nowadays', 'number', 'nurse', 'nursery', 'nursing', 'nutritionist', 'obstetrics', 'oct', 'offer', 'office', 'officer', 'often', 'ok', 'okay', 'old', 'olympics', 'on', 'open', 'operating', 'opportunity', 'option', 'order', 'organization', 'organize', 'original', 'others', 'outside', 'overall', 'own', 'owner', 'package', 'packge', 'page', 'paid', 'pain', 'painkiller', 'pait', 'parama', 'paramaporn', 'park', 'parking', 'partum', 'past', 'patience', 'patient', 'patty', 'pay', 'payment', 'peace', 'pediatric', 'penetration', 'people', 'person', 'personnel', 'pharmacist', 'pharmacy', 'phaya', 'phone', 'phrakiat', 'physical', 'pichit', 'pick', 'pierce', 'pin', 'pipe', 'pity', 'place', 'planning', 'please', 'pleased', 'plus', 'pm', 'point', 'policy', 'polite', 'politely', 'poor', 'pornthep', 'post', 'powder', 'practice', 'pravej', 'pregnancy', 'preliminary', 'prepare', 'pretend', 'pretty', 'previous', 'price', 'private', 'probably', 'problem', 'proceed', 'process', 'product', 'professional', 'professor', 'promotion', 'provide', 'province', 'psychiatrist', 'psychologist', 'pudja', 'put', 'quality', 'question', 'queue', 'quick', 'quickly', 'quite', 'rama', 'rapid', 'rate', 'ray', 're', 'reach', 'ready', 'real', 'realize', 'really', 'rear', 'reason', 'receive', 'reception', 'receptionist', 'recommend', 'recommends', 'recover', 'recovery', 'red', 'reduce', 'referral', 'refuse', 'regardless', 'registration', 'regular', 'regularly', 'rehabilitation', 'related', 'relative', 'relatively', 'relax', 'relaxed', 'relief', 'relieve', 'remember', 'remembers', 'removable', 'renovate', 'repeatedly', 'replace', 'replacement', 'request', 'require', 'research', 'reservation', 'responsible', 'rest', 'restaurant', 'result', 'return', 'review', 'revive', 'rice', 'right', 'rise', 'road', 'robotic', 'rom', 'room', 'rotten', 'round', 'rush', 'sachet', 'safe', 'safely', 'salt', 'samitivej', 'samjak', 'saw', 'say', 'scar', 'scary', 'schedule', 'seat', 'section', 'see', 'seem', 'seep', 'selective', 'sell', 'seminar', 'send', 'seng', 'sent', 'separately', 'seriously', 'serve', 'service', 'set', 'shine', 'shop', 'shorten', 'shout', 'show', 'shuttle', 'sick', 'sign', 'since', 'sincerity', 'sinus', 'sister', 'sit', 'size', 'skill', 'skilled', 'sleep', 'slept', 'slow', 'slowly', 'small', 'smell', 'smile', 'smoke', 'smythejetch', 'sofa', 'soi', 'soil', 'solution', 'solve', 'somchai', 'something', 'sometimes', 'soonvijai', 'sound', 'soup', 'spacious', 'speak', 'speaks', 'special', 'specialized', 'specific', 'spent', 'spite', 'spoil', 'spoke', 'sprain', 'stack', 'staff', 'stamp', 'standard', 'star', 'start', 'state', 'stay', 'step', 'stick', 'still', 'stomach', 'stomachache', 'story', 'straight', 'stress', 'stroke', 'strong', 'stuck', 'suan', 'subcontractor', 'subdistrict', 'subject', 'submit', 'successfully', 'suck', 'sudarat', 'suffer', 'sufficient', 'suggestion', 'suitable', 'summary', 'super', 'superiority', 'supervise', 'surachai', 'surgery', 'surname', 'survive', 'suspect', 'swagger', 'swollen', 'symptom', 'system', 'take', 'talented', 'talk', 'taste', 'taught', 'taxi', 'teach', 'teacher', 'team', 'teeth', 'tell', 'ten', 'tense', 'term', 'terrible', 'test', 'thai', 'thank', 'thanks', 'therefore', 'thing', 'think', 'thorough', 'thoroughly', 'though', 'thought', 'thousand', 'three', 'throughout', 'thyroid', 'tichai', 'ticket', 'tie', 'time', 'today', 'told', 'tool', 'touch', 'tour', 'toy', 'treat', 'treatment', 'trick', 'tricked', 'troyo', 'true', 'trust', 'try', 'tumor', 'twenty', 'two', 'type', 'ugly', 'ultimate', 'ultrasound', 'unable', 'unacceptable', 'unclean', 'uncomfortable', 'undergo', 'undergone', 'understand', 'understands', 'understood', 'up', 'upbut', 'update', 'upper', 'upset', 'use', 'user', 'usually', 'valais', 'value', 'valve', 'vanicha', 'various', 'vegan', 'vegetarian', 'vinichai', 'vip', 'visa', 'visit', 'vomit', 'wait', 'waiter', 'wake', 'walk', 'want', 'ward', 'wash', 'waste', 'watch', 'water', 'waterview', 'way', 'weak', 'wedding', 'week', 'weekday', 'welcome', 'well', 'whatever', 'wheelchair', 'whether', 'white', 'whole', 'wide', 'willing', 'win', 'wipe', 'wisdom', 'withdrawal', 'within', 'without', 'wittaya', 'word', 'work', 'worried', 'worry', 'worth', 'would', 'wound', 'wrist', 'wrong', 'yai', 'year', 'yellow', 'yes', 'yesterday', 'yet', 'yoga', 'yothin', 'young']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.18409596 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (0, 451)\t0.3094173714589229\n",
      "  (0, 587)\t0.3775607320421052\n",
      "  (0, 52)\t0.40022394738452344\n",
      "  (0, 545)\t0.4321659553816761\n",
      "  (0, 918)\t0.45482917072409434\n",
      "  (0, 1043)\t0.26357435738257523\n",
      "  (0, 556)\t0.21252366259735603\n",
      "  (0, 1063)\t0.30537655318192736\n",
      "  (1, 695)\t0.13209568902712865\n",
      "  (1, 617)\t0.20414991258177287\n",
      "  (1, 565)\t0.2731851280891162\n",
      "  (1, 677)\t0.22280903993368786\n",
      "  (1, 706)\t0.2731851280891162\n",
      "  (1, 479)\t0.22755533263123578\n",
      "  (1, 549)\t0.26207294038490747\n",
      "  (1, 164)\t0.26207294038490747\n",
      "  (1, 328)\t0.25299362193861646\n",
      "  (1, 604)\t0.14740792941968364\n",
      "  (1, 536)\t0.19060805366736425\n",
      "  (1, 968)\t0.17284621872706435\n",
      "  (1, 630)\t0.207363826480736\n",
      "  (1, 684)\t0.19828450803444503\n",
      "  (1, 688)\t0.2731851280891162\n",
      "  (1, 421)\t0.3303395287199671\n",
      "  (1, 33)\t0.2731851280891162\n",
      "  :\t:\n",
      "  (351, 491)\t0.26904796000058845\n",
      "  (351, 832)\t0.2831571043674707\n",
      "  (351, 208)\t0.25810405740283904\n",
      "  (351, 494)\t0.1877214486659684\n",
      "  (351, 982)\t0.17361230429908614\n",
      "  (351, 983)\t0.15994302140319244\n",
      "  (351, 423)\t0.09610034005522848\n",
      "  (351, 350)\t0.175395927232268\n",
      "  (351, 314)\t0.0837347661691036\n",
      "  (352, 467)\t0.49867175362094135\n",
      "  (352, 247)\t0.3915297791086547\n",
      "  (352, 411)\t0.3726549670577417\n",
      "  (352, 704)\t0.5248225996021144\n",
      "  (352, 423)\t0.1781188941139147\n",
      "  (352, 206)\t0.35237079504668256\n",
      "  (352, 849)\t0.16681999593460034\n",
      "  (353, 822)\t0.39238330996896414\n",
      "  (353, 1029)\t0.3315031664293326\n",
      "  (353, 494)\t0.35479874374198866\n",
      "  (353, 196)\t0.3640759745101567\n",
      "  (353, 573)\t0.3504865734132827\n",
      "  (353, 334)\t0.444256865110259\n",
      "  (353, 849)\t0.1701105375808655\n",
      "  (353, 1026)\t0.23081886467497903\n",
      "  (353, 473)\t0.27438582562194364\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "bangkok-hospital\n",
      "\n",
      "Up-sample dataset\n",
      "\n",
      ">>>>> Step: Create vectors of Term Frequency–Inverse Document Frequency (TF-IDF), bigrams <<<<<\n",
      "\n",
      " vec_tf_idf_bigram() is activated...\n",
      "\n",
      "\n",
      "Preview features name:\n",
      "\n",
      "Number of features = 3217\n",
      "\n",
      "\n",
      "\n",
      "['09 2016', '093 232', '10 2016', '10 doctor', '10 hour', '10 year', '1030 say', '11 clock', '1100 must', '1108 doctor', '11pm therefore', '11th january', '13 hour', '130 hour', '14 april', '15 go', '15 january', '15 minute', '15000 baht', '16 room', '1600 hr', '17 09', '17000 baht', '1820 see', '1920 hr', '20 minute', '20 year', '20000 crazy', '2016 1920', '2016 nurse', '2016 suspect', '2017 go', '21st july', '230 see', '232 8297', '28 2016', '28 january', '2nd floor', '2nd pregnancy', '30 minute', '30 understand', '30 year', '30900 baht', '31 internal', '40 give', '40000 medical', '45 nong', '50 discount', '5264 baht', '5r cute', '5th floor', '730 pm', '78 go', '802 10', '82 year', '820 born', '8297 patty', '8th floor', '930 wait', '945 check', 'ability hospital', 'able analyze', 'able maintain', 'able quickly', 'able solve', 'accident due', 'accident hit', 'accord goodness', 'accord symptom', 'accurate doctor', 'ache well', 'acne good', 'act correctly', 'activity yoga', 'actual surgery', 'add 30900', 'addition parking', 'adjust room', 'admin team', 'admin week', 'admit bangkok', 'adult pity', 'advance staff', 'advice every', 'advice good', 'advice healthy', 'advice help', 'advice inquire', 'advice recommends', 'advice room', 'advice thank', 'advice throughout', 'advise contact', 'advise question', 'afraid hospital', 'afraid medical', 'afraid mother', 'afraid surgery', 'age 78', 'age 82', 'aggravation everyone', 'airforce give', 'airy good', 'allergic sinus', 'almost 60000', 'almost always', 'almost every', 'almost go', 'almost half', 'almost hour', 'almost like', 'almost noon', 'almost patient', 'along could', 'already afraid', 'already book', 'already checked', 'already cover', 'already go', 'already impressed', 'already mother', 'already paid', 'already small', 'already time', 'alright re', 'although price', 'although treatment', 'always admit', 'always ask', 'always impressed', 'always long', 'always new', 'always provide', 'always sell', 'always treat', 'analysis cause', 'analyze treat', 'aneurysm successfully', 'annual health', 'another 20', 'another half', 'another province', 'another robotic', 'another three', 'answer cause', 'answer question', 'antenatal cesarean', 'antenatal clinic', 'antenatal package', 'antenatal speak', 'anxiety specialized', 'anyone come', 'anyone look', 'anything inform', 'anywhere else', 'apparatus wake', 'appointment cardiac', 'appointment comfort', 'appointment date', 'appointment every', 'appointment eye', 'appointment see', 'appointment sometimes', 'appointment wait', 'appreciate service', 'approximately 130', 'april thanks', 'area expect', 'area hospital', 'around 11pm', 'around next', 'around word', 'arrange queue', 'arrhythmia department', 'arrive 1820', 'arrive hospital', 'arrive late', 'arrive overall', 'artery aneurysm', 'aside say', 'ask always', 'ask antenatal', 'ask check', 'ask conclude', 'ask condition', 'ask doctor', 'ask forget', 'ask free', 'ask housekeeper', 'ask many', 'ask meet', 'ask nurse', 'ask patient', 'ask queue', 'ask symptom', 'ask tell', 'ask time', 'ask way', 'ask wheelchair', 'assistant doctor', 'assistant manager', 'astray ever', 'atmosphere hospital', 'atmosphere light', 'atmosphere like', 'attention cost', 'attention detail', 'attention examination', 'attention good', 'attention patient', 'attention service', 'attention teacher', 'attentive bangkok', 'attentive care', 'attentive detailed', 'attentive every', 'attentive friendly', 'attentive give', 'attentive good', 'attentive treatment', 'attentiveness friendly', 'aunt many', 'authority arrange', 'available receive', 'await examination', 'away home', 'away walk', 'baby bangkok', 'baby polite', 'baby stomach', 'back arrive', 'back home', 'back importantly', 'back meaning', 'back minute', 'bad condition', 'bad doctor', 'bad first', 'bad know', 'bad like', 'bad notify', 'bad step', 'bad stomach', 'badly upset', 'bag heavy', 'baht december', 'baht dental', 'baht expensive', 'baht hardly', 'baht night', 'ball strong', 'bang yai', 'bangkok 10250', 'bangkok branch', 'bangkok hospital', 'bangkok know', 'banquet seminar', 'basket see', 'bathroom cause', 'bathroom clean', 'bathroom make', 'bathroom nurse', 'beam heart', 'beautiful anywhere', 'beautiful atmosphere', 'beautiful care', 'beautiful day', 'beautiful nurse', 'become tumor', 'bed already', 'bed doctor', 'bed food', 'bed give', 'bed night', 'bed small', 'bed walk', 'begin recover', 'believe superiority', 'benefit well', 'best customer', 'best every', 'best medical', 'best patient', 'best service', 'best since', 'big doctor', 'big service', 'big spacious', 'bill night', 'birth 14', 'birth baby', 'birth decide', 'birth hospital', 'bit difficult', 'bit high', 'bit noisy', 'bit strong', 'bite taste', 'bleeding seep', 'blogging 820', 'blood checked', 'blood collection', 'blood result', 'blood room', 'blood send', 'blood test', 'body medicine', 'bon subdistrict', 'book advance', 'bore time', 'born hospital', 'born stay', 'brain center', 'branch hospital', 'branch nonthaburi', 'branch pay', 'breast implant', 'breast surgery', 'breastfeed recommends', 'breathing apparatus', 'bring blood', 'bring cart', 'bring husband', 'bring mother', 'bring people', 'brought child', 'brought get', 'brought mother', 'bruise half', 'building 8th', 'building area', 'building finish', 'building found', 'building state', 'building still', 'business type', 'busy home', 'buy less', 'buy toy', 'bypass surgery', 'caesarean section', 'calculate true', 'call appointment', 'call ask', 'call check', 'call class', 'call hospital', 'call nurse', 'call taxi', 'calm talk', 'cancer age', 'car back', 'car get', 'car go', 'car kiss', 'car nurse', 'car staff', 'car straight', 'car well', 'car wheelchair', 'card cash', 'card need', 'card require', 'card twenty', 'cardiac arrhythmia', 'care afraid', 'care attentive', 'care patient', 'care treatment', 'care well', 'carefully like', 'carry bed', 'carry would', 'cart pick', 'cart walk', 'case cute', 'case pay', 'case see', 'case would', 'cash desk', 'cash drive', 'catering planning', 'cause aside', 'cause disease', 'cause slow', 'cause ultrasound', 'cause understand', 'centennial building', 'center doctor', 'center improve', 'certificate blood', 'cesarean section', 'cesarean treatment', 'chaloem phrakiat', 'change original', 'change park', 'change think', 'change year', 'charge dr', 'charge expensive', 'charge still', 'charnpong brain', 'chat comfortably', 'cheap place', 'cheap service', 'cheaper poor', 'check 11', 'check 17', 'check 230', 'check annual', 'check appointment', 'check ask', 'check atmosphere', 'check bangkok', 'check first', 'check good', 'check health', 'check nursing', 'check pregnancy', 'check probably', 'check sit', 'check start', 'check up', 'check visa', 'check wound', 'check wrong', 'check year', 'checked almost', 'checked fast', 'checked health', 'checked improve', 'checked less', 'checked yet', 'cheek bruise', 'cheerful cute', 'child admin', 'child adult', 'child baby', 'child bed', 'child child', 'child doctor', 'child eat', 'child even', 'child fever', 'child grown', 'child long', 'child mischievous', 'child relax', 'child shine', 'child soil', 'child use', 'childbirth day', 'choose best', 'choose stuck', 'chose want', 'circumcise doctor', 'class activity', 'class group', 'class nurse', 'class talk', 'clean airy', 'clean bathroom', 'clean best', 'clean big', 'clean complete', 'clean everyone', 'clean friendly', 'clean good', 'clean hospital', 'clean luxurious', 'clean need', 'clean personnel', 'clean place', 'clean see', 'clean spacious', 'cleanliness hospital', 'cleanliness impressed', 'clear fade', 'clear good', 'clear instruction', 'clear therefore', 'clearly arrange', 'clearly place', 'clinic bangkok', 'clinic outside', 'clock blogging', 'clock go', 'cold easily', 'cold hundred', 'collect deposit', 'collection walk', 'collide next', 'color walk', 'colorblind problem', 'come ask', 'come check', 'come convenient', 'come could', 'come elevator', 'come even', 'come frustrate', 'come get', 'come heal', 'come medical', 'come put', 'come star', 'come treat', 'comfort page', 'comfortable atmosphere', 'comfortably plus', 'comment dish', 'comment give', 'commercial even', 'commercially diligent', 'compare place', 'compare previous', 'compare standard', 'compare well', 'complain look', 'complete equipment', 'complete month', 'complete tell', 'complete tool', 'completely doctor', 'comply doctor', 'comprehensive information', 'conclude nurse', 'conclude relieve', 'conclude wait', 'conclusion spoil', 'condition good', 'condition improve', 'condition talk', 'condition well', 'confident doctor', 'confident father', 'confuse arrive', 'confuse confuse', 'confuse home', 'confuse many', 'confuse please', 'confuse service', 'confuse walk', 'congratulation place', 'conservation department', 'consider ok', 'consider okay', 'construction renovate', 'consult problem', 'consult psychologist', 'consultation solution', 'contact 093', 'contact doctor', 'contact matt', 'continue treat', 'continue use', 'continuous symptom', 'control food', 'control medical', 'convenience saw', 'convenient attentive', 'convenient clean', 'convenient convenient', 'convenient every', 'convenient fast', 'convenient lovely', 'convenient people', 'convenient worth', 'cooking class', 'coordination patient', 'coordination problem', 'coronary artery', 'cost 5264', 'cost treatment', 'could heal', 'could inform', 'could rise', 'could tell', 'counter bring', 'counter outside', 'counter probably', 'counter staff', 'courteous docile', 'courteous make', 'cover everything', 'crazy impression', 'create private', 'credit card', 'culture doctor', 'cup subject', 'customer admin', 'customer nurse', 'customer service', 'customer use', 'customer wait', 'cute clean', 'cute commercially', 'cute doctor', 'cute everyone', 'cute friendly', 'cute good', 'cute help', 'cute nurse', 'cute please', 'cute really', 'cute service', 'cute still', 'date doctor', 'daughter post', 'daughter undergo', 'daughter well', 'day 16', 'day almost', 'day bring', 'day class', 'day doctor', 'day father', 'day improve', 'day leave', 'day lottery', 'day many', 'day next', 'day night', 'day order', 'day take', 'day talk', 'day team', 'day wound', 'dealer medical', 'december 28', 'december 30', 'december 31', 'december great', 'decide go', 'decide hesitate', 'decide replace', 'decide whether', 'decision many', 'dee touch', 'definitely convenient', 'definitely usually', 'delicious food', 'delicious leave', 'delicious vegan', 'delivery certificate', 'delivery room', 'delivery service', 'dental payment', 'dental work', 'dentist nurse', 'department beam', 'department careful', 'department change', 'department control', 'department department', 'department friendly', 'department good', 'department helpful', 'department impressed', 'department mental', 'department nurse', 'department offer', 'department patient', 'department point', 'department room', 'department smoke', 'department staff', 'department super', 'department think', 'depend doctor', 'deposit 20000', 'desk first', 'desk good', 'despite yellow', 'detail easy', 'detail excellent', 'detail well', 'detailed diagnosis', 'detailed doctor', 'detailed first', 'detailed information', 'detector international', 'diagnose disease', 'diagnosis doctor', 'diagnosis impressed', 'diarrhea hospital', 'different service', 'difficult contact', 'difficult long', 'difficult plus', 'digestive department', 'diligent sell', 'diligently exercise', 'direction walk', 'directly lab', 'disadvantage child', 'disadvantage food', 'disappear hospital', 'disappears impression', 'disappointed trust', 'disappointed worth', 'discount check', 'discriminate practice', 'discuss good', 'discuss patient', 'disease already', 'disease doctor', 'disease make', 'disease many', 'disease much', 'disease therefore', 'dish delicious', 'dispense medication', 'dispense price', 'dissatisfied since', 'dissect wound', 'district bangkok', 'disturbed hospital', 'dizzy like', 'dizzy sleep', 'do chose', 'do month', 'docile doctor', 'doctor 730', 'doctor acne', 'doctor advice', 'doctor advise', 'doctor already', 'doctor alright', 'doctor another', 'doctor answer', 'doctor anyone', 'doctor appointment', 'doctor ask', 'doctor back', 'doctor care', 'doctor charge', 'doctor check', 'doctor checked', 'doctor come', 'doctor continuous', 'doctor cute', 'doctor december', 'doctor decision', 'doctor dissect', 'doctor doctor', 'doctor dr', 'doctor duty', 'doctor especially', 'doctor even', 'doctor examination', 'doctor explain', 'doctor fee', 'doctor feel', 'doctor field', 'doctor forget', 'doctor forgot', 'doctor found', 'doctor give', 'doctor good', 'doctor heals', 'doctor help', 'doctor hospital', 'doctor however', 'doctor inspector', 'doctor intend', 'doctor internal', 'doctor jaidee', 'doctor japanese', 'doctor keng', 'doctor kind', 'doctor knowledgeable', 'doctor lay', 'doctor listen', 'doctor little', 'doctor long', 'doctor look', 'doctor lovely', 'doctor loyal', 'doctor make', 'doctor many', 'doctor medication', 'doctor mother', 'doctor move', 'doctor much', 'doctor nurse', 'doctor nutritionist', 'doctor order', 'doctor own', 'doctor provide', 'doctor ready', 'doctor really', 'doctor receive', 'doctor rush', 'doctor say', 'doctor service', 'doctor sometimes', 'doctor speak', 'doctor staff', 'doctor still', 'doctor take', 'doctor talk', 'doctor taught', 'doctor time', 'doctor told', 'doctor treat', 'doctor try', 'doctor ultrasound', 'doctor vinichai', 'doctor wait', 'doctor walk', 'doctor yesterday', 'doctor yothin', 'dr airforce', 'dr charnpong', 'dr heir', 'dr jaidee', 'dr kieri', 'dr paramaporn', 'dr pichit', 'dr pornthep', 'dr rom', 'dr samjak', 'dr somchai', 'dr surachai', 'dr vanicha', 'dr wittaya', 'draw 1030', 'draw facial', 'dream doctor', 'drink comfortable', 'drive another', 'drive back', 'drive parking', 'drove front', 'drove parking', 'duangsit impressed', 'duct help', 'due accident', 'due fall', 'duty decide', 'ease nurse', 'easily fat', 'easily understood', 'easy understand', 'eat buy', 'eat think', 'edid nurse', 'elderly hospital', 'eldest child', 'electric shuttle', 'elevator think', 'else checked', 'else discuss', 'email probably', 'emergency bed', 'emergency room', 'encourage operating', 'endoscopy department', 'enough ask', 'enough get', 'enough tell', 'ensure intelligence', 'enter queue', 'equal importance', 'equip modern', 'equipment able', 'equipment modern', 'equipment nurse', 'equipment ready', 'error disappear', 'especially professor', 'even already', 'even doctor', 'even go', 'even look', 'even patient', 'even staff', 'even though', 'event delicious', 'ever find', 'ever treat', 'every 30', 'every card', 'every department', 'every detail', 'every doctor', 'every month', 'every nurse', 'every service', 'every time', 'every way', 'everyone already', 'everyone case', 'everyone dr', 'everyone family', 'everyone give', 'everyone good', 'everyone nurse', 'everyone polite', 'everyone set', 'everyone smile', 'everything already', 'everything best', 'everything doctor', 'everything every', 'everything good', 'everything great', 'everything like', 'everything ok', 'everything wait', 'examination bangkok', 'examination department', 'examination detector', 'examination overall', 'examination prepare', 'examination price', 'examination provide', 'examination schedule', 'examination service', 'examine provide', 'examine thoroughly', 'excellent health', 'excellent please', 'excellent pleased', 'excellent room', 'excellent service', 'excellent treatment', 'except last', 'exercise control', 'exists nurse', 'expect people', 'expense expensive', 'expense get', 'expense medicine', 'expensive accord', 'expensive beautiful', 'expensive clinic', 'expensive doctor', 'expensive everything', 'expensive good', 'expensive medicine', 'expensive overall', 'expensive see', 'expensive service', 'expensive thought', 'expensive would', 'expert examination', 'explain cause', 'explain detail', 'explain disease', 'explain easy', 'explain thoroughly', 'explain understood', 'explanation examine', 'expression case', 'extra advice', 'eye 945', 'eye examination', 'eyelid long', 'face customer', 'facial expression', 'facility always', 'facility facility', 'fact commercial', 'fade gradually', 'fade scar', 'fair cost', 'fall doctor', 'family health', 'family heng', 'family like', 'family patient', 'family would', 'famous private', 'far yet', 'fast cheerful', 'fast complete', 'fast convenient', 'fast doctor', 'fast every', 'fast friendly', 'fast good', 'fast incision', 'fast patient', 'fast please', 'fast service', 'fast slow', 'fast tool', 'fat doctor', 'father coronary', 'father go', 'father husband', 'father survive', 'fear become', 'fee another', 'fee expensive', 'fee immediately', 'fee impressive', 'fee improve', 'fee little', 'fee medicine', 'fee paid', 'fee plus', 'fee return', 'feed use', 'feel afraid', 'feel bad', 'feel ease', 'feel little', 'feel relaxed', 'feel safe', 'feel see', 'feel vip', 'feeling word', 'felt service', 'female staff', 'festival delicious', 'fever 40', 'fever go', 'fever overall', 'fever throughout', 'fever treat', 'field stomach', 'finally encourage', 'financial matter', 'financial service', 'find 5th', 'find car', 'find course', 'find doctor', 'find history', 'find right', 'find solution', 'finger area', 'finish cart', 'finish explain', 'finish saw', 'finish teeth', 'finish within', 'first bite', 'first intend', 'first pregnancy', 'first require', 'first round', 'first step', 'first symptom', 'first thought', 'first time', 'fix colorblind', 'floor found', 'floor obstetrics', 'floor parking', 'floor room', 'floor sound', 'flow doctor', 'flu medical', 'follow upbut', 'follow year', 'food change', 'food compare', 'food department', 'food good', 'food little', 'food matter', 'food service', 'food suitable', 'food waiter', 'food well', 'foreigner good', 'foreigner service', 'foreigner use', 'forget appointment', 'forget delivery', 'forget everything', 'forgot key', 'forgot therefore', 'found car', 'found flu', 'found important', 'found sudarat', 'frankly every', 'free doctor', 'free electric', 'free good', 'free medicine', 'free request', 'free service', 'free treatment', 'friend good', 'friend relative', 'friend would', 'friendly beautiful', 'friendly cold', 'friendly doctor', 'friendly explain', 'friendly friendly', 'friendly get', 'friendly give', 'friendly hospitable', 'friendly knowledgeable', 'friendly near', 'friendly quality', 'friendly rapid', 'friendly recommend', 'friendly say', 'friendly service', 'friendly staff', 'front attention', 'front back', 'front desk', 'front hospital', 'fully equip', 'future know', 'general ok', 'genitals circumcise', 'gentle knowledgeable', 'get bed', 'get blood', 'get car', 'get doctor', 'get expensive', 'get good', 'get high', 'get service', 'get sick', 'get taxi', 'get treatment', 'give advice', 'give birth', 'give clear', 'give comment', 'give detailed', 'give equal', 'give every', 'give extra', 'give good', 'give medication', 'give medicine', 'give milk', 'give pain', 'give parama', 'give reception', 'give salt', 'give time', 'go anymore', 'go ask', 'go basket', 'go bed', 'go check', 'go cheek', 'go department', 'go doctor', 'go health', 'go heart', 'go home', 'go hospital', 'go impressive', 'go light', 'go many', 'go mother', 'go nurse', 'go open', 'go operating', 'go see', 'go teeth', 'go treat', 'go use', 'go well', 'good able', 'good advice', 'good another', 'good aspect', 'good benefit', 'good bore', 'good brought', 'good checked', 'good child', 'good clear', 'good courteous', 'good daughter', 'good disadvantage', 'good doctor', 'good dr', 'good emergency', 'good endoscopy', 'good enough', 'good every', 'good everything', 'good excellent', 'good explanation', 'good fast', 'good follow', 'good future', 'good give', 'good heart', 'good hospital', 'good impressed', 'good inform', 'good information', 'good inspection', 'good kind', 'good last', 'good may', 'good medical', 'good medicine', 'good mother', 'good nurse', 'good overall', 'good parking', 'good past', 'good patient', 'good people', 'good polite', 'good quality', 'good really', 'good rest', 'good service', 'good sick', 'good since', 'good speak', 'good spoke', 'good staff', 'good standard', 'good surgery', 'good take', 'good taste', 'good thai', 'good thank', 'good treatment', 'good user', 'good valais', 'good visit', 'good white', 'government hospital', 'government overall', 'gradually disappears', 'grandma left', 'grandmother building', 'grandmother kind', 'grandmother undergone', 'grant half', 'great except', 'great grace', 'great love', 'great nurse', 'great promotion', 'great service', 'great welcome', 'greatly bad', 'group cooking', 'grown time', 'guard look', 'guest compare', 'gynecology big', 'gynecology obstetrics', 'hahaha impressed', 'half hour', 'half kilometer', 'half past', 'hand help', 'haphazard understand', 'happen smell', 'happens remember', 'happy whole', 'hardly see', 'hassle doctor', 'head office', 'headache vomit', 'heal conservation', 'heal doctor', 'heal fast', 'heal still', 'heal welcome', 'heal wisdom', 'heal yet', 'heals always', 'health bangkok', 'health check', 'health examination', 'health history', 'health nurse', 'health throughout', 'health time', 'health well', 'heart building', 'heart dr', 'heart good', 'heart like', 'heart problem', 'heart service', 'heart valve', 'heartbeat dentist', 'heavy think', 'heir dr', 'help breastfeed', 'help case', 'help every', 'help matter', 'help relax', 'help shorten', 'help watch', 'help without', 'helpful even', 'helpful wait', 'heng heng', 'heng seng', 'hesitate contact', 'high every', 'high maintenance', 'high quality', 'high treatment', 'high would', 'highly talented', 'history check', 'history child', 'history heart', 'history hospital', 'history treatment', 'hit house', 'hmm expensive', 'home 1100', 'home almost', 'home father', 'home feel', 'home include', 'home next', 'home service', 'hospitable friendly', 'hospitable good', 'hospital 10', 'hospital 20', 'hospital 30', 'hospital already', 'hospital always', 'hospital around', 'hospital ask', 'hospital best', 'hospital bring', 'hospital busy', 'hospital cesarean', 'hospital collect', 'hospital complete', 'hospital conclusion', 'hospital congratulation', 'hospital consultation', 'hospital convenient', 'hospital doctor', 'hospital drove', 'hospital family', 'hospital famous', 'hospital find', 'hospital first', 'hospital go', 'hospital good', 'hospital head', 'hospital hospitable', 'hospital hospital', 'hospital importantly', 'hospital impressed', 'hospital khon', 'hospital let', 'hospital level', 'hospital locate', 'hospital long', 'hospital look', 'hospital make', 'hospital medical', 'hospital medicine', 'hospital move', 'hospital much', 'hospital near', 'hospital normally', 'hospital often', 'hospital package', 'hospital place', 'hospital private', 'hospital reason', 'hospital receive', 'hospital regardless', 'hospital regularly', 'hospital relatively', 'hospital responsible', 'hospital service', 'hospital since', 'hospital small', 'hospital smythejetch', 'hospital soi', 'hospital staff', 'hospital suitable', 'hospital swollen', 'hospital take', 'hospital tense', 'hospital terrible', 'hospital throughout', 'hospital treatment', 'hospital whole', 'hospital wide', 'hospital yet', 'hospitality doctor', 'hospitalize headache', 'hot water', 'hour almost', 'hour go', 'hour noon', 'hour order', 'hour repeatedly', 'hour send', 'hour still', 'hour summary', 'hour surgery', 'hour wait', 'hour walk', 'house pay', 'house right', 'housekeeper mop', 'housewife staff', 'however say', 'hr accident', 'hr room', 'hundred pharmacy', 'hundred thousand', 'hurry compare', 'hurry drive', 'hurry everything', 'hurry go', 'hurry rush', 'hurry time', 'husband go', 'husband japanese', 'husband scar', 'husband surgery', 'husband weak', 'id card', 'illness dental', 'illness every', 'implant well', 'importance patient', 'important convenient', 'important department', 'important people', 'importantly guard', 'importantly thank', 'impress every', 'impress staff', 'impressed cesarean', 'impressed doctor', 'impressed every', 'impressed everything', 'impressed health', 'impressed hospitality', 'impressed nurse', 'impressed service', 'impressed since', 'impressed sincerity', 'impressed team', 'impressed today', 'impressed ward', 'impression important', 'impression maintain', 'impression treat', 'impressive good', 'impressive hospital', 'impressive modern', 'impressive service', 'impressive since', 'imprint everyone', 'improve clear', 'improve good', 'improve lot', 'improve organization', 'improve point', 'improve service', 'improve think', 'improve wait', 'improvement building', 'incision heal', 'incision small', 'include doctor', 'include health', 'include maid', 'inclusive although', 'infect doctor', 'infect infect', 'infection blood', 'inform food', 'inform pay', 'inform queue', 'inform sent', 'inform spite', 'inform walk', 'information discuss', 'information inspection', 'information provide', 'information relief', 'information teach', 'inhale inhaler', 'inhaler please', 'injection overall', 'injection relieve', 'inquire need', 'inquire patient', 'inquire preliminary', 'inquiry hassle', 'inspect counter', 'inspect provide', 'inspect since', 'inspection department', 'inspection late', 'inspector service', 'instruction eye', 'insurance card', 'insurance customer', 'insurance submit', 'intelligence pay', 'intend breastfeed', 'intend leave', 'intend maintain', 'intention hurry', 'interested contact', 'interested patient', 'internal coordination', 'internal medicine', 'international standard', 'intestine come', 'item problem', 'jaidee lovely', 'jaidee quality', 'january 2017', 'january doctor', 'january take', 'japanese patient', 'japanese talk', 'july go', 'kaen get', 'keep calm', 'keng good', 'kengen nong', 'key order', 'khon kaen', 'kidney disease', 'kieri tichai', 'kilometer away', 'kind care', 'kind condition', 'kind cute', 'kind feel', 'kind speak', 'kind speaks', 'kiss front', 'know cesarean', 'know disappointed', 'know doctor', 'know fix', 'know forgot', 'know give', 'know hurry', 'know nose', 'know opportunity', 'know peace', 'know think', 'know upset', 'knowledgeable highly', 'knowledgeable look', 'knowledgeable love', 'lab long', 'lab wait', 'language friendly', 'large check', 'last day', 'last month', 'late hurry', 'late wait', 'later call', 'later check', 'lay wait', 'least able', 'least attentive', 'leave food', 'leave health', 'leave hospital', 'leave important', 'leave stomach', 'leave story', 'left available', 'left counter', 'left operating', 'leg staff', 'less hundred', 'less minute', 'level call', 'life depend', 'life insurance', 'lift scary', 'light child', 'light price', 'lightlove tell', 'like add', 'like check', 'like come', 'like comment', 'like department', 'like diarrhea', 'like discriminate', 'like doctor', 'like excellent', 'like fact', 'like family', 'like feel', 'like government', 'like health', 'like housewife', 'like lottery', 'like near', 'like olympics', 'like opportunity', 'like park', 'like place', 'like professional', 'like really', 'like receive', 'like recommend', 'like relative', 'like service', 'like staff', 'like stay', 'like take', 'like thank', 'like treatment', 'like water', 'like well', 'like whatever', 'limb consult', 'limp counter', 'line pay', 'listen answer', 'listen blood', 'little hahaha', 'little high', 'little little', 'little overall', 'little unclean', 'liver cancer', 'living still', 'living wound', 'll money', 'locate 8th', 'location excellent', 'loei call', 'lonely nurse', 'long lift', 'long pierce', 'long queue', 'long time', 'long wait', 'look area', 'look ask', 'look charm', 'look child', 'look doctor', 'look expensive', 'look face', 'look give', 'look like', 'look patient', 'look private', 'look professional', 'look really', 'look wound', 'lose feeling', 'lot change', 'lot confuse', 'lot dizzy', 'lot doctor', 'lot drove', 'lot many', 'lot patient', 'lot restaurant', 'lot terrible', 'lot well', 'lottery cheap', 'lottery like', 'lottery result', 'lottery ticket', 'loud doctor', 'loudly win', 'love doctor', 'love everyone', 'love hospital', 'love lightlove', 'love mind', 'love team', 'love thank', 'lovely attentive', 'lovely care', 'lovely disadvantage', 'lovely doctor', 'lovely friendly', 'lovely good', 'lovely grandmother', 'lovely nurse', 'lovely pharmacist', 'low state', 'loyal doctor', 'luang rama', 'lump upper', 'lunch leave', 'luxurious complete', 'luxurious place', 'maid food', 'maintain 30', 'maintain health', 'maintain quality', 'maintain think', 'maintain work', 'maintenance fee', 'make appointment', 'make feel', 'make impressed', 'make know', 'make lose', 'make nurse', 'make patient', 'make reservation', 'make unacceptable', 'make understand', 'male nurse', 'mall many', 'management review', 'management system', 'management take', 'manager catering', 'manner time', 'many branch', 'many hospital', 'many hotel', 'many inquiry', 'many language', 'many patient', 'many people', 'many queue', 'many restaurant', 'many round', 'many stamp', 'many stress', 'many time', 'many treatment', 'many user', 'many wait', 'many year', 'massage open', 'matt ask', 'matter financial', 'matter intend', 'matter many', 'matter place', 'matter slow', 'may give', 'may wheelchair', 'meaning come', 'meaning difficult', 'meaning understand', 'measure well', 'medical assistant', 'medical attentiveness', 'medical bill', 'medical cost', 'medical department', 'medical equipment', 'medical expense', 'medical expert', 'medical facility', 'medical fee', 'medical location', 'medical service', 'medical team', 'medication accord', 'medication bangkok', 'medication could', 'medication day', 'medication doctor', 'medication injection', 'medication place', 'medication psychiatrist', 'medication queue', 'medication say', 'medication separately', 'medicine 15', 'medicine cheap', 'medicine cost', 'medicine department', 'medicine dispense', 'medicine doctor', 'medicine eat', 'medicine expensive', 'medicine fair', 'medicine heal', 'medicine meaning', 'medicine much', 'medicine must', 'medicine order', 'medicine pay', 'medicine recover', 'medicine reduce', 'medicine say', 'medicine seat', 'medicine slowly', 'medicine stick', 'medicine wait', 'meet 10', 'meet feel', 'member cleanliness', 'member enter', 'mental illness', 'middle finger', 'midweek nurse', 'miko kengen', 'milk duct', 'milk flow', 'milk powder', 'milk selective', 'milk three', 'mind come', 'mind much', 'minute always', 'minute blood', 'minute later', 'minute take', 'minute wait', 'mischievous ask', 'modern bangkok', 'modern doctor', 'modern equipment', 'modern medical', 'modern tool', 'moment doctor', 'moment need', 'money good', 'money money', 'money notify', 'money paid', 'money patient', 'money spent', 'month 30900', 'month already', 'month bad', 'month december', 'mop floor', 'morality doctor', 'moret next', 'mother almost', 'mother check', 'mother child', 'mother condition', 'mother could', 'mother credit', 'mother daughter', 'mother doctor', 'mother eye', 'mother get', 'mother give', 'mother go', 'mother patient', 'mother treat', 'move child', 'move hospital', 'move make', 'move try', 'much 13', 'much aggravation', 'much antenatal', 'much cheaper', 'much disturbed', 'much dream', 'much love', 'much money', 'much nurse', 'much well', 'mushroom soup', 'must make', 'must wait', 'narrow today', 'nature disease', 'near bangkok', 'near friend', 'near suan', 'nearly ten', 'nearly thousand', 'neat teacher', 'need improve', 'need patient', 'need pay', 'need time', 'need use', 'never complain', 'never mushroom', 'new clean', 'new doctor', 'new policy', 'newborn baby', 'next day', 'next doctor', 'next size', 'next time', 'next week', 'ni on', 'nice clean', 'night doctor', 'night free', 'night quality', 'night small', 'noisy information', 'nong bon', 'nong care', 'nonsense related', 'nonthaburi bang', 'noon check', 'noon go', 'normal fear', 'normally regular', 'nose surgery', 'nothing confuse', 'nothing doctor', 'notify go', 'notify medical', 'nowadays good', 'number patient', 'nurse 5r', 'nurse always', 'nurse ask', 'nurse attentive', 'nurse cute', 'nurse delivery', 'nurse doctor', 'nurse everyone', 'nurse feel', 'nurse first', 'nurse friendly', 'nurse good', 'nurse hand', 'nurse hurry', 'nurse include', 'nurse inform', 'nurse large', 'nurse left', 'nurse look', 'nurse lovely', 'nurse male', 'nurse medicine', 'nurse move', 'nurse much', 'nurse nurse', 'nurse nursery', 'nurse offer', 'nurse ok', 'nurse others', 'nurse patient', 'nurse place', 'nurse policy', 'nurse pretty', 'nurse professional', 'nurse provide', 'nurse pudja', 'nurse say', 'nurse section', 'nurse sent', 'nurse service', 'nurse shop', 'nurse skilled', 'nurse smile', 'nurse speak', 'nurse staff', 'nurse still', 'nurse supervise', 'nurse take', 'nurse understands', 'nurse wait', 'nurse well', 'nursery cute', 'nursery nurse', 'nursery take', 'nursing staff', 'nursing team', 'nutritionist lovely', 'obstetrics gynecology', 'obstetrics right', 'oct 15', 'offer good', 'office impressed', 'officer arrange', 'officer say', 'often half', 'often people', 'often visit', 'ok accept', 'ok convenient', 'ok definitely', 'ok doctor', 'ok service', 'ok whether', 'okay like', 'old child', 'old grandmother', 'old narrow', 'olympics know', 'on use', 'open branch', 'open milk', 'operating room', 'opportunity use', 'opportunity visit', 'option know', 'order lunch', 'order medicine', 'order work', 'order wrong', 'organization livable', 'organize banquet', 'original delicious', 'others well', 'outside cold', 'outside great', 'outside ll', 'overall consider', 'overall excellent', 'overall good', 'overall look', 'overall ok', 'overall service', 'overall try', 'own fever', 'owner good', 'package 15000', 'package give', 'package product', 'package send', 'packge examination', 'paid hospital', 'paid nearly', 'paid penetration', 'paid receive', 'pain bleeding', 'pain doctor', 'pain medication', 'painkiller price', 'pait age', 'parama paid', 'paramaporn cute', 'park car', 'park parking', 'park rear', 'park taxi', 'park tell', 'parking bit', 'parking building', 'parking lot', 'parking pay', 'parking stack', 'parking terrible', 'partum recovery', 'past call', 'patience child', 'patient 20', 'patient always', 'patient attentive', 'patient await', 'patient bangkok', 'patient bathroom', 'patient card', 'patient care', 'patient decide', 'patient department', 'patient difficult', 'patient elderly', 'patient explain', 'patient feel', 'patient food', 'patient good', 'patient heart', 'patient history', 'patient hospital', 'patient information', 'patient lot', 'patient management', 'patient patient', 'patient relative', 'patient room', 'patient sit', 'patient something', 'patient speak', 'patient sprain', 'patient thoroughly', 'patient try', 'patient understand', 'patient wait', 'patient well', 'patty assistant', 'pay 40000', 'pay attention', 'pay bad', 'pay confuse', 'pay doctor', 'pay half', 'pay long', 'pay management', 'pay many', 'pay medicine', 'pay receive', 'pay room', 'pay round', 'pay summary', 'payment mother', 'payment queue', 'payment system', 'peace mind', 'pediatric surgery', 'penetration fee', 'people get', 'people know', 'people later', 'people like', 'people may', 'people money', 'people recommend', 'people sit', 'people time', 'people use', 'person nurse', 'personnel doctor', 'personnel friendly', 'pharmacist speak', 'pharmacy outside', 'phaya thai', 'phone receptionist', 'phrakiat rama', 'physical examination', 'pichit good', 'pick take', 'pierce finish', 'pierce lump', 'pin kind', 'pipe digestive', 'pity child', 'place afraid', 'place bad', 'place clean', 'place doctor', 'place excellent', 'place go', 'place good', 'place nice', 'place spacious', 'place taxi', 'planning department', 'please adjust', 'please clearly', 'please create', 'please give', 'please improve', 'please smile', 'please staff', 'please talk', 'please tell', 'pleased provide', 'plus confuse', 'plus drive', 'plus kidney', 'plus swagger', 'plus tricked', 'pm far', 'pm queue', 'point give', 'point quality', 'point term', 'policy hospital', 'policy package', 'polite gentle', 'polite kind', 'polite long', 'polite make', 'polite manner', 'polite staff', 'politely thank', 'poor people', 'pornthep treat', 'post partum', 'powder teach', 'practice service', 'pravej district', 'pregnancy 2nd', 'pregnancy check', 'pregnancy doctor', 'pregnancy genitals', 'preliminary information', 'prepare thing', 'pretend child', 'previous packge', 'price 17000', 'price almost', 'price bag', 'price bit', 'price expensive', 'price friendly', 'price hmm', 'price nearly', 'price samitivej', 'price seem', 'price time', 'private bathroom', 'private expensive', 'private hospital', 'probably 21st', 'probably carry', 'probably go', 'probably move', 'probably wait', 'problem contact', 'problem finish', 'problem hour', 'problem red', 'problem referral', 'problem refuse', 'problem use', 'proceed quickly', 'process queue', 'professional include', 'professional medical', 'professional service', 'professional skill', 'professor doctor', 'promotion 50', 'provide ask', 'provide comprehensive', 'provide convenience', 'provide detailed', 'provide excellent', 'provide fast', 'provide good', 'provide medication', 'provide service', 'provide suggestion', 'province realize', 'psychiatrist examine', 'psychologist first', 'psychologist many', 'pudja good', 'put eldest', 'quality low', 'quality medicine', 'quality nurse', 'quality pay', 'quality personnel', 'quality reduce', 'quality service', 'quality since', 'question clearly', 'question well', 'queue always', 'queue arrive', 'queue call', 'queue cash', 'queue even', 'queue long', 'queue management', 'queue medication', 'queue officer', 'queue pay', 'queue quite', 'queue size', 'queue spoke', 'queue still', 'queue system', 'queue walk', 'quick doctor', 'quick result', 'quickly diagnose', 'quickly safely', 'quite long', 'rama interested', 'rama road', 'rapid diagnosis', 'rate calculate', 'rate great', 'ray 15', 'ray ray', 're dizzy', 'reach place', 'ready modern', 'ready provide', 'real 1600', 'realize bangkok', 'really good', 'really like', 'really suitable', 'really talk', 'really wait', 'rear parking', 'reason child', 'receive car', 'receive color', 'receive good', 'receive guest', 'receive injection', 'receive medication', 'receive medicine', 'receive treatment', 'reception advise', 'reception great', 'reception well', 'receptionist hospital', 'recommend anyone', 'recommend bangkok', 'recommend living', 'recommend send', 'recommend wound', 'recommends breast', 'recommends edid', 'recommends treatment', 'recover chronic', 'recover completely', 'recover nowadays', 'recovery lovely', 'red item', 'reduce fever', 'referral coordination', 'refuse go', 'refuse stay', 'regardless illness', 'registration complete', 'registration staff', 'regular customer', 'regular doctor', 'regularly doctor', 'regularly dr', 'regularly meet', 'regularly trust', 'rehabilitation patient', 'related work', 'relative cardiac', 'relative like', 'relative patient', 'relative seem', 'relatively high', 'relax day', 'relax lot', 'relaxed surgery', 'relief anxiety', 'relieve pain', 'relieve stomach', 'remember others', 'remembers mother', 'removable breathing', 'renovate building', 'repeatedly ask', 'replace doctor', 'replacement surgery', 'request free', 'require id', 'require medication', 'research attentive', 'research center', 'reservation help', 'responsible bangkok', 'rest construction', 'rest improvement', 'rest like', 'restaurant choose', 'restaurant good', 'restaurant many', 'restaurant pretend', 'result approximately', 'result like', 'result sit', 'result term', 'result trick', 'return nursing', 'return real', 'revive doctor', 'right left', 'right middle', 'right way', 'rise nurse', 'road soi', 'robotic doctor', 'rom nurse', 'room 1108', 'room 802', 'room bathroom', 'room draw', 'room fast', 'room fee', 'room felt', 'room finally', 'room food', 'room hospital', 'room insurance', 'room moret', 'room must', 'room patient', 'room price', 'room queue', 'room rate', 'room recommends', 'room registration', 'room say', 'room time', 'room ward', 'rotten milk', 'round doctor', 'round else', 'round sent', 'rush hurry', 'sachet painkiller', 'safe every', 'safe thank', 'safe trust', 'safely husband', 'salt water', 'samitivej hospital', 'samjak due', 'saw come', 'saw sit', 'say badly', 'say go', 'say hospital', 'say hot', 'say impressed', 'say infect', 'say least', 'say nurse', 'say officer', 'say quickly', 'say ray', 'say scary', 'say service', 'say slept', 'say wait', 'say well', 'say wound', 'scar fade', 'scar say', 'scary addition', 'scary think', 'schedule number', 'seat wait', 'section bangkok', 'section go', 'section take', 'section therefore', 'section worried', 'see bad', 'see day', 'see doctor', 'see dr', 'see long', 'see people', 'see result', 'see symptom', 'see whether', 'see wound', 'seem bit', 'seem like', 'seep see', 'selective milk', 'sell choose', 'sell hospital', 'sell rice', 'seminar wedding', 'send along', 'send email', 'send financial', 'send matter', 'send test', 'seng receive', 'sent culture', 'sent emergency', 'sent worry', 'separately love', 'seriously trust', 'serve surname', 'service 20', 'service accurate', 'service attention', 'service bangkok', 'service believe', 'service best', 'service carry', 'service charge', 'service clean', 'service convenient', 'service counter', 'service department', 'service doctor', 'service drink', 'service emergency', 'service everyone', 'service everything', 'service excellent', 'service fast', 'service fee', 'service feel', 'service female', 'service first', 'service foreigner', 'service free', 'service get', 'service good', 'service great', 'service greatly', 'service heart', 'service hospital', 'service impress', 'service impressed', 'service impression', 'service impressive', 'service leave', 'service life', 'service like', 'service long', 'service lot', 'service love', 'service maintain', 'service modern', 'service nurse', 'service organize', 'service overall', 'service owner', 'service package', 'service pay', 'service please', 'service polite', 'service price', 'service problem', 'service provide', 'service quality', 'service quick', 'service regularly', 'service relatively', 'service since', 'service slow', 'service slowly', 'service speak', 'service staff', 'service standard', 'service star', 'service still', 'service take', 'service user', 'service wait', 'set dee', 'shine despite', 'shop various', 'shorten time', 'shout patient', 'show sign', 'shuttle service', 'sick go', 'sick life', 'sign displeasure', 'since 930', 'since antenatal', 'since ever', 'since first', 'since know', 'since old', 'since parking', 'since pm', 'since step', 'since walk', 'sincerity doctor', 'sinus professional', 'sister mother', 'sister stomachache', 'sit chat', 'sit queue', 'sit wait', 'size understand', 'size weekday', 'skill maintain', 'skilled medical', 'sleep house', 'sleep treat', 'slept long', 'slow doctor', 'slow heartbeat', 'slow many', 'slow patience', 'slow sit', 'slowly government', 'slowly throughout', 'small incision', 'small mall', 'small old', 'small sofa', 'smell like', 'smile cheerful', 'smile doctor', 'smile friendly', 'smile really', 'smile registration', 'smile rest', 'smile say', 'smile time', 'smoke inhale', 'smythejetch much', 'sofa uncomfortable', 'soi 45', 'soi research', 'soi soonvijai', 'soil move', 'solution loei', 'solution make', 'solve many', 'somchai gynecology', 'something happens', 'sometimes confuse', 'sometimes forget', 'sometimes morality', 'sometimes wait', 'soonvijai go', 'soonvijai impressed', 'sound loud', 'soup taste', 'soup thought', 'spacious big', 'spacious look', 'spacious walk', 'speak everyone', 'speak many', 'speak politely', 'speak reception', 'speak smile', 'speak time', 'speak well', 'speaks well', 'special room', 'specialized examination', 'specific disease', 'spent treatment', 'spite everything', 'spoil mushroom', 'spoke show', 'spoke well', 'sprain leg', 'stack found', 'staff bring', 'staff call', 'staff courteous', 'staff cute', 'staff dealer', 'staff department', 'staff direction', 'staff doctor', 'staff follow', 'staff friendly', 'staff front', 'staff good', 'staff haphazard', 'staff helpful', 'staff hospitable', 'staff hospital', 'staff interested', 'staff lovely', 'staff make', 'staff member', 'staff nurse', 'staff park', 'staff pick', 'staff price', 'staff provide', 'staff smile', 'staff speaks', 'staff talk', 'staff told', 'staff welcome', 'staff willing', 'stamp service', 'standard cleanliness', 'standard measure', 'standard never', 'standard really', 'standard room', 'star 555', 'star doctor', 'start sachet', 'start work', 'state hospital', 'stay clock', 'stay hospital', 'stay special', 'step car', 'step ensure', 'step front', 'step slow', 'step smile', 'stick directly', 'stick history', 'still come', 'still confuse', 'still exists', 'still expensive', 'still living', 'still pain', 'still patient', 'still pay', 'still remembers', 'still suck', 'stomach ache', 'stomach around', 'stomach call', 'stomach intestine', 'stomach luggage', 'stomachache doctor', 'story food', 'straight away', 'stress worried', 'stroke infection', 'strong day', 'strong safe', 'stuck long', 'suan luang', 'subcontractor least', 'subdistrict pravej', 'subject hospital', 'submit insurance', 'successfully change', 'suck different', 'sudarat friendly', 'suffer recover', 'suggestion good', 'suitable medical', 'suitable newborn', 'suitable price', 'summary almost', 'summary send', 'super cute', 'superiority general', 'supervise comply', 'surachai surgery', 'surgery actual', 'surgery bypass', 'surgery day', 'surgery doctor', 'surgery dr', 'surgery expensive', 'surgery fast', 'surgery good', 'surgery grandma', 'surgery hospital', 'surgery proceed', 'surgery trust', 'surname tie', 'survive doctor', 'survive stroke', 'suspect day', 'swagger park', 'swollen ugly', 'symptom attentive', 'symptom dispense', 'symptom even', 'symptom examine', 'symptom hour', 'symptom medical', 'symptom start', 'system fast', 'system good', 'system update', 'take blood', 'take case', 'take child', 'take daughter', 'take good', 'take medication', 'take mother', 'take pait', 'take people', 'take wheelchair', 'talented patient', 'talk bad', 'talk child', 'talk like', 'talk lottery', 'talk nonsense', 'talk patient', 'talk price', 'talk psychologist', 'talk relative', 'talk removable', 'talk try', 'taste bad', 'taste clear', 'taste like', 'taste patient', 'taught diligently', 'taxi new', 'taxi patient', 'taxi please', 'taxi plus', 'teach feed', 'teach massage', 'teach work', 'teacher doctor', 'teacher dr', 'teacher duangsit', 'team bangkok', 'team doctor', 'team fast', 'team fully', 'team pediatric', 'team staff', 'team well', 'teeth doctor', 'teeth mother', 'tell call', 'tell do', 'tell find', 'tell get', 'tell love', 'tell place', 'tell symptom', 'tell tell', 'tell walk', 'ten thousand', 'tense like', 'term rehabilitation', 'term service', 'terrible old', 'terrible tell', 'test refuse', 'test room', 'test wait', 'thai compare', 'thai foreigner', 'thai lot', 'thai people', 'thank dr', 'thank excellent', 'thank look', 'thank much', 'thank pin', 'thank teacher', 'thanks doctor', 'therefore call', 'therefore decide', 'therefore find', 'therefore recommend', 'therefore treatment', 'therefore would', 'thing able', 'think carefully', 'think centennial', 'think eat', 'think patient', 'think return', 'think say', 'think troyo', 'think wait', 'think walk', 'thorough treatment', 'thoroughly doctor', 'thoroughly easily', 'thoroughly research', 'thoroughly staff', 'thoroughly wash', 'though many', 'though patient', 'though regular', 'thought come', 'thought government', 'thought taste', 'thought would', 'thousand baht', 'thousand continue', 'thousand know', 'thousand nothing', 'thousand plus', 'three month', 'three thousand', 'throughout ball', 'throughout day', 'throughout father', 'throughout treatment', 'thyroid error', 'tichai inspect', 'ticket loudly', 'tie wrist', 'time advise', 'time already', 'time ask', 'time attentive', 'time come', 'time conclude', 'time day', 'time department', 'time doctor', 'time fast', 'time feel', 'time find', 'time gastroenterologist', 'time get', 'time go', 'time hospital', 'time intention', 'time like', 'time lonely', 'time many', 'time milk', 'time money', 'time mother', 'time must', 'time nurse', 'time often', 'time park', 'time pay', 'time payment', 'time polite', 'time queue', 'time receive', 'time service', 'time speak', 'time stick', 'time use', 'time wait', 'time well', 'time whether', 'time would', 'time yet', 'time young', 'today dissatisfied', 'today go', 'today parking', 'told authority', 'told child', 'tool equipment', 'tool quick', 'touch treat', 'tour event', 'toy back', 'treat arrive', 'treat bangkok', 'treat caesarean', 'treat free', 'treat impressed', 'treat liver', 'treat neurosis', 'treat regular', 'treat regularly', 'treat specific', 'treat thyroid', 'treat vegetarian', 'treat week', 'treat well', 'treatment advice', 'treatment confident', 'treatment disease', 'treatment doctor', 'treatment fee', 'treatment free', 'treatment give', 'treatment good', 'treatment great', 'treatment hospital', 'treatment improve', 'treatment inquire', 'treatment keep', 'treatment long', 'treatment never', 'treatment nurse', 'treatment option', 'treatment slow', 'treatment therefore', 'treatment unable', 'trick doctor', 'tricked listen', 'troyo waterview', 'true ask', 'trust ability', 'trust bangkok', 'trust doctor', 'trust excellent', 'trust leave', 'trust long', 'trust much', 'try consult', 'try help', 'try look', 'try sell', 'try smile', 'try walk', 'tumor rotten', 'twenty thousand', 'two time', 'type hospital', 'ugly say', 'ultimate analysis', 'ultrasound doctor', 'ultrasound regularly', 'unable diagnose', 'unacceptable relative', 'unclean nurse', 'uncomfortable bed', 'undergo breast', 'undergone heart', 'understand act', 'understand day', 'understand foreigner', 'understand husband', 'understand internal', 'understand language', 'understand many', 'understand need', 'understand pay', 'understand well', 'understands nature', 'understood best', 'understood finish', 'up first', 'up hospital', 'upbut step', 'update everything', 'upper eyelid', 'upset come', 'upset nurse', 'use bangkok', 'use cup', 'use dr', 'use heal', 'use hospital', 'use physical', 'use service', 'use use', 'user attentive', 'user cause', 'user thai', 'usually home', 'usually phaya', 'valais receive', 'value child', 'valve replacement', 'vanicha good', 'various restaurant', 'vegan food', 'vegetarian festival', 'vinichai point', 'vip customer', 'visa grant', 'visit aunt', 'visit fever', 'visit friend', 'vomit day', 'wait advice', 'wait almost', 'wait another', 'wait anything', 'wait blood', 'wait come', 'wait confuse', 'wait definitely', 'wait doctor', 'wait hour', 'wait lab', 'wait line', 'wait long', 'wait matter', 'wait moment', 'wait money', 'wait paid', 'wait pay', 'wait payment', 'wait problem', 'wait process', 'wait result', 'wait see', 'wait sometimes', 'wait wait', 'wait watch', 'wait wipe', 'wait withdrawal', 'waiter everyone', 'wake revive', 'walk 2nd', 'walk around', 'walk ask', 'walk astray', 'walk bathroom', 'walk car', 'walk inspect', 'walk limp', 'walk nurse', 'walk reach', 'walk room', 'walk round', 'walk talk', 'want seem', 'want waste', 'ward nurse', 'wash wound', 'waste time', 'watch nothing', 'watch teach', 'water enough', 'water hospital', 'water pipe', 'waterview chaloem', 'way appointment', 'way back', 'way nurse', 'weak limb', 'wedding tour', 'week medicine', 'week midweek', 'week pay', 'welcome good', 'welcome inquire', 'welcome since', 'well although', 'well ask', 'well bathroom', 'well begin', 'well check', 'well disappointed', 'well doctor', 'well even', 'well frankly', 'well get', 'well high', 'well hospital', 'well inclusive', 'well like', 'well look', 'well matter', 'well mother', 'well pay', 'well phaya', 'well please', 'well recommend', 'well service', 'well staff', 'well standard', 'well subcontractor', 'well suitable', 'well thank', 'well wound', 'well yes', 'whatever find', 'wheelchair collide', 'wheelchair delivery', 'wheelchair emergency', 'wheelchair wait', 'whether do', 'whether room', 'whether seriously', 'whether sufficient', 'white beautiful', 'whole family', 'whole reception', 'wide even', 'willing serve', 'win lottery', 'wipe body', 'wisdom charge', 'withdrawal medicine', 'within day', 'without anything', 'wittaya heart', 'word draw', 'word wait', 'work bit', 'work childbirth', 'work conclude', 'work people', 'work staff', 'work team', 'worried everyone', 'worried try', 'worry history', 'worth price', 'worth treatment', 'would continue', 'would finish', 'would like', 'would probably', 'would use', 'wound beautiful', 'wound heal', 'wound neat', 'wound normal', 'wound polite', 'wound thoroughly', 'wound time', 'wound use', 'wound well', 'wound wound', 'wrist check', 'wrong medicine', 'wrong person', 'year allergic', 'year doctor', 'year family', 'year friend', 'year good', 'year impressed', 'year payment', 'year service', 'year since', 'year suffer', 'year year', 'yellow value', 'yes thorough', 'yesterday 10', 'yesterday go', 'yesterday take', 'yet problem', 'yet wait', 'yoga class', 'yothin nurse', 'young sister']\n",
      "\n",
      "Preview in matrix:\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Preview tf-idf score:\n",
      "\n",
      "  (0, 1711)\t0.388472765559297\n",
      "  (0, 62)\t0.388472765559297\n",
      "  (0, 1576)\t0.388472765559297\n",
      "  (0, 2721)\t0.388472765559297\n",
      "  (0, 3139)\t0.388472765559297\n",
      "  (0, 1630)\t0.388472765559297\n",
      "  (0, 3180)\t0.3074629449417746\n",
      "  (1, 1841)\t0.23675285720086955\n",
      "  (1, 1645)\t0.23675285720086955\n",
      "  (1, 2022)\t0.23675285720086955\n",
      "  (1, 2131)\t0.23675285720086955\n",
      "  (1, 1420)\t0.23675285720086955\n",
      "  (1, 1588)\t0.23675285720086955\n",
      "  (1, 337)\t0.23675285720086955\n",
      "  (1, 845)\t0.22712260314155786\n",
      "  (1, 1793)\t0.23675285720086955\n",
      "  (1, 1138)\t0.22712260314155786\n",
      "  (1, 1555)\t0.23675285720086955\n",
      "  (1, 2873)\t0.23675285720086955\n",
      "  (1, 1887)\t0.23675285720086955\n",
      "  (1, 2038)\t0.23675285720086955\n",
      "  (1, 2046)\t0.23675285720086955\n",
      "  (1, 1141)\t0.23675285720086955\n",
      "  (1, 44)\t0.23675285720086955\n",
      "  (1, 1018)\t0.23675285720086955\n",
      "  :\t:\n",
      "  (351, 1236)\t0.28103536460843304\n",
      "  (351, 965)\t0.28103536460843304\n",
      "  (351, 2439)\t0.28103536460843304\n",
      "  (351, 966)\t0.28103536460843304\n",
      "  (351, 477)\t0.28103536460843304\n",
      "  (351, 1467)\t0.28103536460843304\n",
      "  (351, 2962)\t0.28103536460843304\n",
      "  (351, 71)\t0.28103536460843304\n",
      "  (351, 724)\t0.28103536460843304\n",
      "  (351, 1229)\t0.2495092605135371\n",
      "  (351, 886)\t0.2625937759190872\n",
      "  (352, 1099)\t0.4549632965132615\n",
      "  (352, 2129)\t0.4549632965132615\n",
      "  (352, 471)\t0.4549632965132615\n",
      "  (352, 561)\t0.42510852718650227\n",
      "  (352, 2489)\t0.38749596605913833\n",
      "  (352, 1217)\t0.21944204902109404\n",
      "  (353, 1472)\t0.3702691256923929\n",
      "  (353, 852)\t0.3702691256923929\n",
      "  (353, 2409)\t0.3702691256923929\n",
      "  (353, 3091)\t0.3702691256923929\n",
      "  (353, 1412)\t0.3702691256923929\n",
      "  (353, 2519)\t0.34659577223287324\n",
      "  (353, 430)\t0.31479521804670496\n",
      "  (353, 3059)\t0.3086733130028903\n",
      "\n",
      " reduce_feature() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      "Before reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.18409596 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "explained_variance_ratio_:\n",
      "[0.02928798 0.02247081 0.02058795 0.01991021 0.0189123  0.01803869\n",
      " 0.01721243 0.01685074 0.01642078 0.01619265]\n",
      "\n",
      "singular_values_:\n",
      "[105.62152657  92.51606213  88.5552446   87.08547298  84.87501901\n",
      "  82.89155511  80.97088211  80.11562509  79.0869252   78.53563695]\n",
      "\n",
      "Afte reduce feature\n",
      "\n",
      "\n",
      "self.X_array_pca, shape:  (354, 10)\n",
      "[[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]]\n",
      "\n",
      " kfold_train_test() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\\X_array_pca:\n",
      "\n",
      "[[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]]\n",
      "\n",
      "y_array:\n",
      "[0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1\n",
      " 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0]\n",
      "\n",
      "KFold:  0\n",
      "\n",
      "X_train:\n",
      " [[-0.22477155 -0.30579822 -0.07553105 ... -0.78748711 -0.25649051\n",
      "  -1.1793068 ]\n",
      " [ 0.18573107 -0.96472066  0.44005145 ... -1.27494871  1.72358265\n",
      "   0.61410984]\n",
      " [-0.23272081 -0.67098982 -0.03682995 ... -1.26748339 -0.4540629\n",
      "  -0.62463836]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (318, 10)\n",
      "\n",
      "X_test:\n",
      " [[-2.49789706e-01 -6.83404951e-01  4.34946333e-01 -9.98083331e-01\n",
      "  -1.49756532e-01 -8.80562049e-01 -6.08125338e-01 -1.40799622e+00\n",
      "   8.87391698e-02 -6.98227542e-01]\n",
      " [ 1.65713058e-01 -1.29377149e+00 -6.78647776e-01  2.33484336e+00\n",
      "  -4.34143597e-01 -9.15431794e-01 -5.12853993e-01 -1.67779518e+00\n",
      "  -1.34066723e+00 -9.13625174e-01]\n",
      " [-4.52520769e-01 -1.15084724e+00 -8.18409649e-01 -5.14685255e-01\n",
      "  -4.08759769e-01  7.42957994e-01 -5.28073983e-01 -1.46176927e+00\n",
      "  -6.80696611e-01 -1.09940355e+00]\n",
      " [-1.57445588e-01 -6.76840022e-01 -1.32457106e-01 -7.39433729e-01\n",
      "  -4.43769324e-02 -6.47252651e-01 -7.43986695e-01 -1.06993216e+00\n",
      "  -3.71365558e-01 -7.70599765e-01]\n",
      " [-2.09214618e-01 -9.91618611e-01 -1.80632117e-01 -4.98192978e-01\n",
      "  -2.05914724e-01 -9.62643297e-01 -5.10099376e-01 -4.80842818e-01\n",
      "  -8.75999349e-01 -8.18463344e-01]\n",
      " [-3.85251944e-01 -1.32346218e+00 -2.49638089e-01 -2.37985219e-01\n",
      "  -3.98311688e-01 -6.99379400e-01 -6.41087880e-01  3.36370475e-01\n",
      "  -3.27362100e-01 -8.34912314e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-3.41853752e-01 -9.53907648e-01 -2.61142689e-01 -4.86390211e-01\n",
      "   1.38351203e-01  1.20605815e+00 -4.98790897e-01 -6.33624583e-01\n",
      "  -2.91281648e-01 -5.82395550e-01]\n",
      " [-1.77844074e-01  4.42698149e-01 -3.10883395e-01  2.58616830e-02\n",
      "   4.89176905e-01  1.52303849e-01 -8.64650687e-01 -1.50904510e+00\n",
      "  -1.25745532e-01 -1.82359326e-01]\n",
      " [-4.27903348e-01 -2.92420036e-01 -2.58225954e-01 -4.16117454e-01\n",
      "  -2.18541380e-01 -2.48684131e+00 -1.18577993e+00 -2.84355037e+00\n",
      "  -1.24503395e+00  1.76749674e-01]\n",
      " [-2.03966141e-01 -7.50502500e-01  5.84826783e-02 -9.05054286e-01\n",
      "  -1.11143347e-01 -1.10531749e+00 -8.67677310e-01 -1.36295472e+00\n",
      "  -3.12885404e-01 -9.03240639e-01]\n",
      " [-5.12479702e-01 -4.29541619e-01 -6.59578081e-01 -1.93389612e+00\n",
      "  -5.24606588e-01  2.53029381e+00 -1.79492356e-01  3.61208787e-01\n",
      "  -1.07852723e+00 -1.57117874e+00]\n",
      " [-3.35639558e-01 -3.22318296e-01  5.35302046e-01 -1.15396180e+00\n",
      "   2.36155994e-01 -1.57566672e+00 -2.06845923e+00 -2.25956677e+00\n",
      "  -3.82468231e-01 -1.24832699e+00]\n",
      " [-3.90326516e-01 -9.42464261e-01 -4.71785179e-01  1.59010826e-01\n",
      "  -4.63861845e-01 -9.02084396e-01 -1.04080293e+00 -1.14125016e+00\n",
      "   1.08870289e+00 -1.57565535e+00]\n",
      " [-2.32178720e-01 -7.96243112e-01  2.94148116e-01 -8.89831474e-01\n",
      "  -1.65137119e-01 -1.24186056e+00 -1.17236480e+00 -1.22478660e+00\n",
      "  -2.38715929e-02 -9.70109926e-01]\n",
      " [-4.52520769e-01 -1.15084724e+00 -8.18409649e-01 -5.14685255e-01\n",
      "  -4.08759769e-01  7.42957994e-01 -5.28073983e-01 -1.46176927e+00\n",
      "  -6.80696611e-01 -1.09940355e+00]\n",
      " [-2.43308040e-01 -6.55530203e-01 -7.41637405e-02 -5.54468482e-01\n",
      "   3.21988624e-02 -6.86704604e-01 -1.18759962e+00 -1.15870581e+00\n",
      "  -3.25530625e-01 -9.63558700e-01]\n",
      " [-9.35899846e-02 -7.85823208e-01  3.71983953e-01 -1.84840019e+00\n",
      "   2.18035855e-01 -1.79142329e+00 -1.03146735e+00 -2.31386284e+00\n",
      "  -1.58044554e-01 -1.07484774e+00]\n",
      " [-1.31203656e-01 -8.15276427e-01  1.25553011e-01 -4.81988008e-01\n",
      "  -5.73516839e-01 -1.33811214e+00 -1.17942429e+00  8.36093553e-01\n",
      "  -1.85118281e+00 -5.18978551e-01]\n",
      " [-4.00613390e-01  7.78766213e-02  1.05251952e-02 -1.28969302e+00\n",
      "  -7.63889648e-01 -5.29738530e-01  1.58544622e+00 -1.85169021e-01\n",
      "  -1.23749157e+00 -2.27983952e-01]\n",
      " [-4.40736349e-01 -4.69078761e-02  2.44287480e+00 -1.16549871e+00\n",
      "  -6.31194264e-01  3.30868797e+00 -1.41069984e+00 -1.67450533e+00\n",
      "   3.36625979e-02 -1.58188935e+00]\n",
      " [-2.51740925e-01 -7.93377924e-01 -1.63517430e-01 -9.90998813e-01\n",
      "  -1.16375895e-01 -5.84103482e-01  1.86303436e-01 -9.28149820e-01\n",
      "   3.87207320e-02 -5.13145279e-01]\n",
      " [-3.18662163e-01 -1.00241292e+00 -6.56201055e-02 -1.63235140e+00\n",
      "  -1.25525990e-01  4.74015571e-01  3.16902859e-01 -2.48305527e-01\n",
      "  -2.40721168e-01  1.44874754e-01]\n",
      " [-7.26855967e-01  2.60627385e+00  1.78588152e+01  7.99204996e+00\n",
      "   8.09081447e+01 -4.67654738e+00  4.38315395e+00  9.34200247e+00\n",
      "  -1.00389889e+00  7.49053120e-01]\n",
      " [-2.05333445e-01 -7.76598185e-01 -1.54695647e-01 -6.62597872e-01\n",
      "  -8.82253911e-02 -1.29680015e+00 -1.25647855e+00 -8.85707468e-01\n",
      "  -8.92432291e-02 -9.82562604e-01]\n",
      " [-2.43308040e-01 -6.55530203e-01 -7.41637405e-02 -5.54468482e-01\n",
      "   3.21988624e-02 -6.86704604e-01 -1.18759962e+00 -1.15870581e+00\n",
      "  -3.25530625e-01 -9.63558700e-01]\n",
      " [-4.25427769e-01 -1.58475788e+00  3.96741136e-01  4.17089912e+00\n",
      "  -1.09707492e+00  1.10344829e+00  4.52589891e+00  5.26426688e+00\n",
      "  -2.03717491e+00  3.36012265e+00]\n",
      " [-4.01823688e-01 -1.18026843e+00 -2.00187071e-01  4.69010887e-01\n",
      "   1.05874478e+00 -3.74989899e-01 -5.07762330e-01  1.15940745e-01\n",
      "   8.75301388e-01 -2.67989278e-01]\n",
      " [-7.92196402e-01 -2.10967526e+00  1.96304059e+00 -3.77768764e+00\n",
      "  -3.07625874e+00  1.89803259e+00  3.46936401e+00  2.28845369e+01\n",
      "  -1.85655935e+01  1.54670811e-01]\n",
      " [-9.40895950e-01  9.51217327e-02 -7.70331571e-01 -1.00574444e+01\n",
      "  -5.11123018e-01  1.56022872e+00  2.66258777e+01 -3.00563562e-01\n",
      "   1.11690328e+01  5.94936961e+00]\n",
      " [-5.33633073e-01 -2.08979543e+00 -2.66000324e-01 -4.58726293e-01\n",
      "  -1.17345254e+00 -1.26925439e+00 -6.66816305e-01 -2.35970044e+00\n",
      "   1.99805899e+00 -1.92692221e+00]\n",
      " [-4.35344949e-01 -1.30922765e+00 -5.69647741e-01  1.71268898e+00\n",
      "   2.42807678e-02 -1.26841368e+00 -2.07101153e-01 -5.08008805e-01\n",
      "  -6.94939571e-01 -3.78938638e-01]\n",
      " [-5.12479702e-01 -4.29541619e-01 -6.59578081e-01 -1.93389612e+00\n",
      "  -5.24606588e-01  2.53029381e+00 -1.79492356e-01  3.61208787e-01\n",
      "  -1.07852723e+00 -1.57117874e+00]\n",
      " [-1.23857933e-01 -2.86779682e-01 -5.70135300e-01  1.96939136e-01\n",
      "   2.27578571e-02 -4.96470317e-01 -8.00391021e-01 -1.23638629e+00\n",
      "  -9.15155904e-01 -6.70782751e-01]\n",
      " [-2.11576984e-01 -6.44251376e-01 -3.14737545e-02 -8.24692214e-01\n",
      "  -1.58939599e-02 -1.08033595e+00 -1.18520073e+00 -1.41082272e+00\n",
      "  -4.89620681e-01 -7.55865622e-01]\n",
      " [-5.06047609e-02 -5.47660847e-01  4.25172458e-01 -6.73291832e-01\n",
      "   1.23638874e+00 -1.09927082e+00 -5.05942603e-01 -1.11663083e+00\n",
      "  -2.92679108e-01 -8.68980003e-01]] \n",
      "Shape:  (36, 10)\n",
      "\n",
      "y_train:\n",
      " [1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1\n",
      " 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0\n",
      " 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (318,)\n",
      "\n",
      "y_test:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1] \n",
      "Shape:  (36,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  0\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.3170898627154977\n",
      "\n",
      " Coefficients \n",
      "[ 2.33965833  0.12071488  1.47324982 -0.22560234  1.12592562 -0.10015763\n",
      " -0.48443516 -0.05830883 -0.05062459 -0.21038497]\n",
      "\n",
      " pop_polarity\n",
      "[7.22080493e-01 3.16758891e-01 1.30332445e-01 6.12367935e-01\n",
      " 4.77622868e-01 2.78209135e-01 1.70311121e-09 3.96025988e-01\n",
      " 6.40538956e-01 4.41071332e-01 6.74994932e-01 1.34438161e-01\n",
      " 9.15394607e-01 2.63930512e-01 7.49314506e-01 1.30332445e-01\n",
      " 6.57378980e-01 9.05675211e-01 6.03291601e-01 1.47040214e-01\n",
      " 9.61291688e-01 4.04279835e-01 3.48864962e-01 1.00000000e+00\n",
      " 6.37983252e-01 6.57378980e-01 3.41885489e-03 5.78022527e-01\n",
      " 2.17064105e-02 9.50809427e-08 1.29958766e-01 1.56315824e-01\n",
      " 1.34438161e-01 4.57834168e-01 6.93071743e-01 9.48869384e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.73\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[15  6]\n",
      " [ 5 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6944444444444444\n",
      "recall:  0.6666666666666666\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.625\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73        21\n",
      "           1       0.62      0.67      0.65        15\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.69      0.69      0.69        36\n",
      "weighted avg       0.70      0.69      0.70        36\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  0\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.79915924e-001 9.24645418e-001 9.48724877e-001 9.84070619e-001\n",
      " 9.70677696e-001 9.28061057e-001 1.70763759e-064 9.47088306e-001\n",
      " 9.80298780e-001 6.81729100e-001 9.80708232e-001 3.75329031e-001\n",
      " 9.48325619e-001 9.63296282e-001 9.81029163e-001 9.48724877e-001\n",
      " 9.82591082e-001 9.56875482e-001 7.93863800e-001 7.31764290e-001\n",
      " 7.11541073e-001 9.69512164e-001 9.18743215e-001 1.00000000e+000\n",
      " 9.80749519e-001 9.82591082e-001 3.06837166e-014 9.64259728e-001\n",
      " 3.53763452e-169 7.97118763e-107 8.15442009e-001 8.63605898e-001\n",
      " 3.75329031e-001 9.79089846e-001 9.80136784e-001 9.96233224e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.63\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 5 16]\n",
      " [ 1 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.5277777777777778\n",
      "recall:  0.9333333333333333\n",
      "specificity:  0.23809523809523808\n",
      "precision:  0.4666666666666667\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.24      0.37        21\n",
      "           1       0.47      0.93      0.62        15\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.65      0.59      0.50        36\n",
      "weighted avg       0.68      0.53      0.48        36\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  0\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[6.91972589e-01 1.14707341e-01 0.00000000e+00 3.60634896e-01\n",
      " 5.64197305e-01 2.96180017e-02 3.70898716e-04 1.32047109e-01\n",
      " 8.71706385e-01 6.57676403e-02 9.93033974e-01 6.43564356e-04\n",
      " 4.34380066e-02 1.11030428e-02 6.02465736e-01 0.00000000e+00\n",
      " 2.56811307e-01 5.31949288e-01 7.62147378e-01 1.42685734e-02\n",
      " 5.30731655e-01 6.42599484e-01 2.56848609e-02 6.08939171e-01\n",
      " 1.87423574e-01 2.56811307e-01 2.88076887e-01 6.05104377e-01\n",
      " 7.17451527e-03 1.57125022e-02 3.67586185e-01 1.78908633e-01\n",
      " 6.43564356e-04 6.13673893e-02 9.22546348e-01 9.26365487e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.95\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[20  1]\n",
      " [ 3 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8888888888888888\n",
      "recall:  0.8\n",
      "specificity:  0.9523809523809523\n",
      "precision:  0.9230769230769231\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.90      0.88      0.88        36\n",
      "weighted avg       0.89      0.89      0.89        36\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  0\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   11.9s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[6.87860884e-01 2.79883435e-01 2.05533823e-01 6.02838112e-01\n",
      " 4.86020390e-01 3.20404054e-01 1.00000010e-07 4.09367653e-01\n",
      " 5.91593064e-01 4.49857022e-01 6.53656337e-01 3.05453263e-01\n",
      " 8.75296865e-01 3.05624552e-01 7.17737571e-01 2.05533823e-01\n",
      " 6.33773657e-01 8.61630871e-01 6.45640498e-01 2.50373144e-01\n",
      " 9.55645182e-01 4.21049042e-01 4.04924571e-01 1.00000000e+00\n",
      " 6.23556311e-01 6.33773657e-01 4.59440819e-03 3.88701533e-01\n",
      " 3.05219870e-01 7.69216725e-07 1.90499270e-01 1.30588577e-01\n",
      " 3.05453263e-01 4.62167705e-01 6.69123150e-01 8.61125289e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.7\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[15  6]\n",
      " [ 5 10]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6944444444444444\n",
      "recall:  0.6666666666666666\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.625\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73        21\n",
      "           1       0.62      0.67      0.65        15\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.69      0.69      0.69        36\n",
      "weighted avg       0.70      0.69      0.70        36\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  0\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.63151807 0.4307297  0.35830978 0.66592574 0.48330146 0.3612625\n",
      " 0.31700674 0.4048468  0.6004678  0.4555826  0.70779663 0.33205754\n",
      " 0.4267253  0.387717   0.5998368  0.35830978 0.59673834 0.5385604\n",
      " 0.55804014 0.31243077 0.44262555 0.5213323  0.3941692  0.4295285\n",
      " 0.57591295 0.59673834 0.32830656 0.38771883 0.35355633 0.33258948\n",
      " 0.4142657  0.36971715 0.33205754 0.513381   0.6888232  0.6449804 ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.71\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[15  6]\n",
      " [ 7  8]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6388888888888888\n",
      "recall:  0.5333333333333333\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.5714285714285714\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70        21\n",
      "           1       0.57      0.53      0.55        15\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.63      0.62      0.62        36\n",
      "weighted avg       0.64      0.64      0.64        36\n",
      "\n",
      "\n",
      "KFold:  1\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (318, 10)\n",
      "\n",
      "X_test:\n",
      " [[-2.24771549e-01 -3.05798217e-01 -7.55310478e-02 -8.54728015e-01\n",
      "  -1.48499256e-02 -1.29475268e+00 -1.42563329e+00 -7.87487113e-01\n",
      "  -2.56490510e-01 -1.17930680e+00]\n",
      " [ 1.85731067e-01 -9.64720661e-01  4.40051451e-01 -3.14892297e+00\n",
      "  -2.27057898e-01 -1.60216762e+00  3.01834675e+00 -1.27494871e+00\n",
      "   1.72358265e+00  6.14109842e-01]\n",
      " [-2.32720806e-01 -6.70989824e-01 -3.68299472e-02 -9.00638897e-01\n",
      "  -9.98969761e-02 -9.84055014e-01 -7.36268223e-01 -1.26748339e+00\n",
      "  -4.54062898e-01 -6.24638357e-01]\n",
      " [ 1.05233957e+02  2.38378400e+00 -2.24272672e-01  6.88544716e-01\n",
      "  -2.67538378e-02 -4.65747786e-02  2.05971465e+00  1.58083428e+00\n",
      "   4.63368096e-01 -2.20056179e+00]\n",
      " [-1.51426693e+00  3.94948541e+01 -9.41247525e+00  7.81505331e-01\n",
      "   2.05601033e-01  3.33182923e-01 -5.96224843e-01  1.76165877e+00\n",
      "  -8.27582703e-01 -1.08238314e+00]\n",
      " [-3.90326516e-01 -9.42464261e-01 -4.71785179e-01  1.59010826e-01\n",
      "  -4.63861845e-01 -9.02084396e-01 -1.04080293e+00 -1.14125016e+00\n",
      "   1.08870289e+00 -1.57565535e+00]\n",
      " [-1.83934250e-01 -7.23608859e-01 -1.17271038e-01 -8.30508225e-01\n",
      "  -7.35864081e-02 -1.00645157e+00 -8.76938629e-01 -1.19475310e+00\n",
      "  -4.50113079e-01 -7.43981044e-01]\n",
      " [-3.68001431e-01 -1.09846418e+00 -5.53019511e-01  3.47456322e-01\n",
      "   3.63845828e-02 -9.01266845e-01 -1.04879650e+00 -1.50055638e+00\n",
      "  -8.30116072e-01 -1.44074638e+00]\n",
      " [-2.45148478e-01 -5.62096921e-01  2.43408428e-03 -7.91035518e-01\n",
      "   1.47999584e-03 -8.78090918e-01 -7.55465048e-01 -1.13047790e+00\n",
      "  -3.07652526e-01 -5.79982687e-01]\n",
      " [-1.12480605e-01 -1.52319511e-01 -2.26259270e-01 -9.77827766e-01\n",
      "  -9.11296705e-02 -1.06503140e+00 -6.09067061e-01 -1.15866883e+00\n",
      "  -1.39094452e-01 -8.63514270e-01]\n",
      " [-2.44078945e-01 -6.37732326e-01 -3.34369358e-02 -8.44260926e-01\n",
      "   6.91683074e-01 -6.87359961e-01 -4.53786523e-01 -1.10260056e+00\n",
      "  -1.16624909e-01 -8.39749747e-01]\n",
      " [-2.98472550e-01 -3.57028743e-01  1.92865695e-01 -1.03290841e+00\n",
      "  -1.80450148e-01 -8.98505879e-01 -1.11481121e+00 -3.54621241e-01\n",
      "  -1.79403415e-01 -9.19102162e-01]\n",
      " [-5.12479702e-01 -4.29541619e-01 -6.59578081e-01 -1.93389612e+00\n",
      "  -5.24606588e-01  2.53029381e+00 -1.79492356e-01  3.61208787e-01\n",
      "  -1.07852723e+00 -1.57117874e+00]\n",
      " [-3.49264390e-01 -4.40297096e-01 -5.26757834e-01 -6.50004237e-01\n",
      "  -8.98122552e-02 -9.48019624e-01 -6.34547992e-01 -8.27163115e-01\n",
      "   8.85733282e-01 -1.17886374e+00]\n",
      " [-2.09676605e-01 -7.75724866e-01 -5.18742214e-02 -8.82544521e-01\n",
      "  -1.66201844e-01 -1.04045926e+00 -8.76660707e-01 -6.49558089e-01\n",
      "  -6.79720350e-01 -9.27630592e-01]\n",
      " [-6.14699560e-01 -9.71813957e-01 -2.13965498e-01 -1.77170260e+00\n",
      "  -3.81254121e-01  3.02921426e-01  3.49360179e+00  2.46875953e+00\n",
      "  -2.46709088e+00  1.38141684e+00]\n",
      " [-4.76471297e-01 -3.55086787e-01  1.93565953e+00 -3.55795949e-01\n",
      "   3.96255315e+00  9.75272450e+00  4.06308185e-01  1.49129611e+00\n",
      "   1.56968529e+00 -8.34436570e-01]\n",
      " [-4.52520769e-01 -1.15084724e+00 -8.18409649e-01 -5.14685255e-01\n",
      "  -4.08759769e-01  7.42957994e-01 -5.28073983e-01 -1.46176927e+00\n",
      "  -6.80696611e-01 -1.09940355e+00]\n",
      " [-9.23454201e-01  2.05689476e+01  8.08905935e+01  1.52494948e+01\n",
      "  -1.86206403e+01  2.98670890e+00  4.46306785e+00 -2.09047775e+00\n",
      "   3.69809225e+00 -9.03013166e-01]\n",
      " [-1.57445588e-01 -6.76840022e-01 -1.32457106e-01 -7.39433729e-01\n",
      "  -4.43769324e-02 -6.47252651e-01 -7.43986695e-01 -1.06993216e+00\n",
      "  -3.71365558e-01 -7.70599765e-01]\n",
      " [ 1.00901566e+00  1.64924368e-01 -4.10147830e-01 -1.10417813e+00\n",
      "   8.15593759e-01  5.84835390e+00 -4.22654643e+00 -1.75250133e+00\n",
      "   9.26109291e-01  4.00879489e+00]\n",
      " [-3.45748944e-01 -9.03024365e-01 -3.00817498e-01 -1.53527827e+00\n",
      "   9.33315060e-02  2.56579684e+00 -3.24821020e-01 -1.31363083e+00\n",
      "   2.99901149e-01 -9.86341231e-01]\n",
      " [-1.98570668e-01 -1.01895391e+00  1.36983694e-01 -3.81820688e-01\n",
      "  -4.72629034e-01 -6.97792228e-01 -4.72025932e-01  1.34585211e+00\n",
      "  -1.53992153e+00 -8.63397308e-01]\n",
      " [-8.53166914e-01  5.57322003e-01  4.39487252e-01 -4.27456407e+00\n",
      "  -1.93569591e+00  4.37470421e-01  6.82172775e+00  7.52433891e+00\n",
      "  -1.15913405e+00 -4.26600927e-01]\n",
      " [-1.96993224e-01 -6.99295696e-01  2.15666106e-01 -8.08624672e-01\n",
      "   7.39721428e-02 -1.11661291e+00 -9.56320566e-01 -1.27707648e+00\n",
      "  -4.21715399e-01 -8.68107287e-01]\n",
      " [-3.90326516e-01 -9.42464261e-01 -4.71785179e-01  1.59010826e-01\n",
      "  -4.63861845e-01 -9.02084396e-01 -1.04080293e+00 -1.14125016e+00\n",
      "   1.08870289e+00 -1.57565535e+00]\n",
      " [-9.96181706e-02 -8.14928019e-01  9.51551324e-02 -2.63174306e-01\n",
      "  -6.32960463e-02 -5.22775477e-01 -6.20157729e-01 -1.28704608e+00\n",
      "   7.94242591e-02 -7.28049396e-01]\n",
      " [-1.23857933e-01 -2.86779682e-01 -5.70135300e-01  1.96939136e-01\n",
      "   2.27578571e-02 -4.96470317e-01 -8.00391021e-01 -1.23638629e+00\n",
      "  -9.15155904e-01 -6.70782751e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-3.90326516e-01 -9.42464261e-01 -4.71785179e-01  1.59010826e-01\n",
      "  -4.63861845e-01 -9.02084396e-01 -1.04080293e+00 -1.14125016e+00\n",
      "   1.08870289e+00 -1.57565535e+00]\n",
      " [-2.61867318e-01 -8.41871670e-01 -1.16801978e-01 -7.14996708e-01\n",
      "   5.57977772e-01 -8.82798855e-01  1.26057727e+00 -1.40891508e+00\n",
      "   5.05044916e-01  5.00530776e-01]\n",
      " [-3.42461633e-01 -1.36441580e+00  1.82474539e-01  1.81428718e+00\n",
      "   7.03643523e-02 -2.43805249e+00 -1.71348633e+00 -3.50556139e-03\n",
      "   7.09357093e-02 -8.02498982e-01]\n",
      " [-2.73073841e-01 -7.94691287e-01  4.03171074e-01  9.01888069e-01\n",
      "  -1.91696026e-01 -8.92326784e-01 -8.85671274e-01 -9.67049207e-01\n",
      "   1.29813852e-01 -8.80107171e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-3.25035341e-01 -4.84581766e-01  2.95706844e-02 -1.26278060e+00\n",
      "   3.21227921e-01 -9.30448387e-01 -7.90359370e-01 -2.82005501e-01\n",
      "   6.56476421e-01  1.82237768e-01]] \n",
      "Shape:  (36, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0\n",
      " 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1\n",
      " 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0\n",
      " 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (318,)\n",
      "\n",
      "y_test:\n",
      " [1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1] \n",
      "Shape:  (36,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  1\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.6727065139391898\n",
      "\n",
      " Coefficients \n",
      "[ 2.11575994 -0.17983945  1.79382951  0.19244169  0.99134378 -0.10596935\n",
      " -0.13497243 -0.05406984  0.04934876 -0.10919784]\n",
      "\n",
      " pop_polarity\n",
      "[6.04862370e-01 7.40157060e-01 5.69685019e-01 1.00000000e+00\n",
      " 4.45611382e-12 3.23962157e-01 5.79125714e-01 4.10263624e-01\n",
      " 6.01811008e-01 5.30680940e-01 7.33778160e-01 6.05895473e-01\n",
      " 7.21033701e-02 3.22384413e-01 5.67678883e-01 7.83108383e-02\n",
      " 9.97671287e-01 1.31009362e-01 1.00000000e+00 5.81782477e-01\n",
      " 9.08180556e-01 3.37718240e-01 5.55448270e-01 1.02481314e-02\n",
      " 7.45869612e-01 3.23962157e-01 7.22702451e-01 4.39187690e-01\n",
      " 3.43044283e-04 3.23962157e-01 6.09674065e-01 8.20641124e-01\n",
      " 7.88099859e-01 3.43044283e-04 3.43044283e-04 6.06746628e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[13  3]\n",
      " [ 2 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8611111111111112\n",
      "recall:  0.9\n",
      "specificity:  0.8125\n",
      "precision:  0.8571428571428571\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84        16\n",
      "           1       0.86      0.90      0.88        20\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.86      0.86      0.86        36\n",
      "weighted avg       0.86      0.86      0.86        36\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  1\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.99473514e-001 6.96886999e-001 9.99482681e-001 1.00000000e+000\n",
      " 0.00000000e+000 9.98574972e-001 9.99548912e-001 9.98537353e-001\n",
      " 9.99540544e-001 9.99528445e-001 9.99723681e-001 9.99392894e-001\n",
      " 7.01468754e-001 9.99131896e-001 9.99456048e-001 1.89682524e-002\n",
      " 9.96937974e-015 9.96013240e-001 5.19880725e-241 9.99611249e-001\n",
      " 1.06761311e-003 8.95649749e-001 9.95755853e-001 2.43864638e-015\n",
      " 9.99600408e-001 9.98574972e-001 9.99639038e-001 9.99360356e-001\n",
      " 4.71390257e-112 9.98574972e-001 9.98450239e-001 9.43971028e-001\n",
      " 9.98826329e-001 4.71390257e-112 4.71390257e-112 9.99268419e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.78\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 6 10]\n",
      " [ 3 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6388888888888888\n",
      "recall:  0.85\n",
      "specificity:  0.375\n",
      "precision:  0.6296296296296297\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.48        16\n",
      "           1       0.63      0.85      0.72        20\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.65      0.61      0.60        36\n",
      "weighted avg       0.65      0.64      0.62        36\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  1\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.47474991 0.09619132 0.90122756 0.45478564 0.00530944 0.08516673\n",
      " 0.98912969 0.01130392 0.91762933 0.86866508 0.76715443 0.84659636\n",
      " 0.00167772 0.34364739 0.94772127 0.00457118 0.66405317 0.00688795\n",
      " 0.63505727 0.3007008  0.79782461 0.60237501 0.56479852 0.06039203\n",
      " 0.99404534 0.08516673 0.82150271 0.07400414 0.01148714 0.08516673\n",
      " 0.60057219 0.09441713 0.91446042 0.01148714 0.01148714 0.80328471]\n",
      "\n",
      " yhat\n",
      "[0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[16  0]\n",
      " [ 3 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9166666666666666\n",
      "recall:  0.85\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        16\n",
      "           1       1.00      0.85      0.92        20\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.92      0.93      0.92        36\n",
      "weighted avg       0.93      0.92      0.92        36\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  1\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.4s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[6.14978589e-01 5.00000000e-01 5.47289764e-01 1.00000000e+00\n",
      " 3.73608757e-04 3.77069755e-01 5.57639356e-01 4.49209611e-01\n",
      " 5.69726464e-01 5.44893614e-01 6.52560824e-01 6.02766571e-01\n",
      " 2.35052116e-01 4.02955810e-01 5.59793839e-01 1.51813774e-01\n",
      " 9.76396543e-01 2.46565691e-01 1.00000000e+00 5.57902120e-01\n",
      " 8.52432802e-01 4.11986727e-01 5.51331121e-01 5.97878855e-02\n",
      " 6.62054816e-01 3.77069755e-01 6.17486096e-01 4.88855924e-01\n",
      " 6.32127840e-04 3.77069755e-01 4.77334310e-01 6.78692045e-01\n",
      " 6.51919524e-01 6.32127840e-04 6.32127840e-04 5.74793370e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.9\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[12  4]\n",
      " [ 2 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8333333333333334\n",
      "recall:  0.9\n",
      "specificity:  0.75\n",
      "precision:  0.8181818181818182\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80        16\n",
      "           1       0.82      0.90      0.86        20\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.84      0.82      0.83        36\n",
      "weighted avg       0.84      0.83      0.83        36\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  1\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:07:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:07:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.53554195 0.44093838 0.6672055  0.46833542 0.39342886 0.41089407\n",
      " 0.6883829  0.40742132 0.6672055  0.5839389  0.59888595 0.5964236\n",
      " 0.32374954 0.4520721  0.65615225 0.33969456 0.42651498 0.35459965\n",
      " 0.42106003 0.6411654  0.5473826  0.45467952 0.44357544 0.32374954\n",
      " 0.7122705  0.41089407 0.62459916 0.50426173 0.35655227 0.41089407\n",
      " 0.6001273  0.44192982 0.64689827 0.35655227 0.35655227 0.4741459 ]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.92\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[14  2]\n",
      " [ 7 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.75\n",
      "recall:  0.65\n",
      "specificity:  0.875\n",
      "precision:  0.8666666666666667\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76        16\n",
      "           1       0.87      0.65      0.74        20\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.77      0.76      0.75        36\n",
      "weighted avg       0.78      0.75      0.75        36\n",
      "\n",
      "\n",
      "KFold:  2\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (318, 10)\n",
      "\n",
      "X_test:\n",
      " [[-3.68001431e-01 -1.09846418e+00 -5.53019511e-01  3.47456322e-01\n",
      "   3.63845828e-02 -9.01266845e-01 -1.04879650e+00 -1.50055638e+00\n",
      "  -8.30116072e-01 -1.44074638e+00]\n",
      " [-5.89325549e-01 -9.13954913e-01  1.50501516e+00 -1.94848932e+00\n",
      "  -7.30678371e-01 -1.98429675e+00 -2.93736578e+00  1.20423648e+00\n",
      "  -1.78837172e+00 -1.29054164e+00]\n",
      " [-1.23857933e-01 -2.86779682e-01 -5.70135300e-01  1.96939136e-01\n",
      "   2.27578571e-02 -4.96470317e-01 -8.00391021e-01 -1.23638629e+00\n",
      "  -9.15155904e-01 -6.70782751e-01]\n",
      " [-1.39469328e-01 -5.35745691e-01  2.48265990e-01  2.48386113e-01\n",
      "   3.16754314e-02 -8.80838494e-01 -1.07386757e+00 -1.23578119e+00\n",
      "  -2.23291613e-01 -6.92054364e-01]\n",
      " [-8.53166914e-01  5.57322003e-01  4.39487252e-01 -4.27456407e+00\n",
      "  -1.93569591e+00  4.37470421e-01  6.82172775e+00  7.52433891e+00\n",
      "  -1.15913405e+00 -4.26600927e-01]\n",
      " [-6.16525317e-01  1.34561686e+00  2.73893820e-01  7.11308496e-01\n",
      "   1.66147585e-01 -1.64218284e+00 -4.77629926e+00 -9.01458079e+00\n",
      "  -4.37165640e+00  1.61050026e+01]\n",
      " [-2.37425223e-01 -1.45779345e-01 -5.32003747e-02 -1.08735815e+00\n",
      "  -1.99717022e-01 -1.11522007e+00 -1.01242912e+00 -1.00868095e+00\n",
      "   3.05957439e-01 -4.99580225e-01]\n",
      " [-2.06021508e-01 -7.92700881e-01 -3.06171072e-01 -7.40495815e-01\n",
      "  -4.28268888e-02 -9.58052679e-01 -1.04170051e+00 -1.16446671e+00\n",
      "  -6.46768027e-01 -9.29176272e-01]\n",
      " [-3.58550337e-01 -6.77576969e-02  4.18069461e+00  7.87913036e-01\n",
      "  -1.24257993e+00  1.05869328e+00 -1.99009896e+00 -2.01537826e+00\n",
      "   1.25544112e+00 -7.63354947e-01]\n",
      " [-2.97065159e-01 -7.90950429e-01  3.67684764e-01 -1.14552766e+00\n",
      "   5.09482129e-01 -1.16824626e+00 -1.18498636e+00 -1.66839215e+00\n",
      "  -7.47431018e-01  4.31280154e-02]\n",
      " [-2.89630691e-01 -5.79678359e-02 -7.03604103e-02 -1.03998795e+00\n",
      "   3.79831421e-01 -5.38161258e-01 -1.52150654e-01 -3.55567838e-01\n",
      "  -6.59379579e-01 -3.15757523e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-2.71406578e-01 -8.82895261e-01 -1.65302661e-01 -5.72677016e-01\n",
      "  -2.59765543e-01 -7.51351701e-01 -4.57938828e-01 -5.54345179e-01\n",
      "  -3.53200255e-01 -8.58531107e-01]\n",
      " [-2.22752348e-01 -8.57643671e-01  1.61782945e-01 -4.87235854e-01\n",
      "  -7.43981427e-02 -8.75419872e-01 -8.21513249e-01 -1.55895141e+00\n",
      "  -1.29615873e-01 -8.98457428e-01]\n",
      " [ 1.19171879e-01 -4.02088994e-01 -1.43516664e-01 -1.89699004e+00\n",
      "   6.50494131e-01  8.09796757e-02  3.33175380e-01 -1.30691446e+00\n",
      "  -1.04573729e-01 -5.87825297e-01]\n",
      " [-4.00613390e-01  7.78766213e-02  1.05251952e-02 -1.28969302e+00\n",
      "  -7.63889648e-01 -5.29738530e-01  1.58544622e+00 -1.85169021e-01\n",
      "  -1.23749157e+00 -2.27983952e-01]\n",
      " [-2.17848942e-01 -7.12439671e-01 -1.26253764e-01 -9.71026269e-01\n",
      "  -1.60277544e-01 -9.60405452e-01 -9.21351024e-02 -4.35723221e-01\n",
      "  -3.15628553e-01 -6.89988696e-01]\n",
      " [-4.00613390e-01  7.78766213e-02  1.05251952e-02 -1.28969302e+00\n",
      "  -7.63889648e-01 -5.29738530e-01  1.58544622e+00 -1.85169021e-01\n",
      "  -1.23749157e+00 -2.27983952e-01]\n",
      " [-4.18172429e-03  2.44060512e-01  4.18924467e+00  8.41306043e-01\n",
      "   6.18143720e+00  1.15222460e+00 -4.91823015e+00 -6.03158640e+00\n",
      "   6.66626716e+00  1.47167805e+00]\n",
      " [-2.66890076e-01 -1.96025327e-01 -3.96448427e-01 -6.71031484e-01\n",
      "  -8.57950474e-02 -4.88202684e-01 -7.26827352e-01 -8.87338695e-01\n",
      "   1.53274089e-03 -7.95910898e-01]\n",
      " [-4.06727859e-01 -6.04675010e-02  1.83903036e-01 -4.80432363e-01\n",
      "   5.32141022e-02  2.66805036e+00 -2.85616610e+00 -2.90572342e+00\n",
      "  -6.61581771e-01  5.92034270e-01]\n",
      " [-1.23857933e-01 -2.86779682e-01 -5.70135300e-01  1.96939136e-01\n",
      "   2.27578571e-02 -4.96470317e-01 -8.00391021e-01 -1.23638629e+00\n",
      "  -9.15155904e-01 -6.70782751e-01]\n",
      " [-2.18898973e-01 -6.77329376e-01 -3.17946528e-02 -1.02083202e+00\n",
      "  -1.26311816e-01 -1.14745253e+00 -2.67582805e-01 -1.01592884e+00\n",
      "  -8.88691063e-02 -6.90927524e-01]\n",
      " [-2.55777585e-01 -7.24253971e-01  1.03384992e-01 -6.70647023e-01\n",
      "   7.18497853e-01  9.78391207e-01 -1.85475062e+00 -2.55285086e-01\n",
      "   9.26479928e-01 -8.19863143e-01]\n",
      " [-2.63207998e-01 -3.66939477e-01 -1.06865104e-01 -1.22574428e+00\n",
      "  -1.71830501e-01 -8.28041449e-01  4.26908071e-01 -1.10406518e+00\n",
      "  -6.99577247e-02 -4.51076822e-01]\n",
      " [-1.85271989e-01 -7.51219528e-01 -1.21576093e-01 -8.77350749e-01\n",
      "  -6.36701840e-02 -1.01194194e+00 -8.76476670e-01 -1.27908685e+00\n",
      "  -4.10324605e-01 -7.43424561e-01]\n",
      " [-2.48745917e-01 -7.58026675e-01 -5.51948034e-01  1.17922469e+00\n",
      "  -1.76809544e-01 -9.40577771e-01 -3.67447290e-01 -1.09801075e+00\n",
      "  -4.73859630e-01 -7.86967769e-01]\n",
      " [-8.50559656e-02 -6.83151300e-01  7.94238131e-02 -1.76160284e-01\n",
      "  -6.91715738e-01 -1.86869143e+00 -2.75158654e+00  1.72312891e+00\n",
      "   2.67785460e+00  1.04953638e+00]\n",
      " [-4.00613390e-01  7.78766213e-02  1.05251952e-02 -1.28969302e+00\n",
      "  -7.63889648e-01 -5.29738530e-01  1.58544622e+00 -1.85169021e-01\n",
      "  -1.23749157e+00 -2.27983952e-01]\n",
      " [-1.73689784e-01 -5.63035946e-01  7.95270397e-01 -6.51704068e-01\n",
      "   8.83340556e-04 -1.18900135e+00 -1.19038286e+00 -8.56756080e-01\n",
      "   1.22546110e-01 -9.52027067e-01]\n",
      " [-8.40473654e-01 -1.90963959e+00 -7.58620401e-01  1.85092008e+00\n",
      "  -3.16903313e+00 -5.24486593e+00 -1.49258442e+01  2.63995468e+01\n",
      "   3.09257258e+01  6.59261254e-01]\n",
      " [-2.66147628e-01 -1.00231936e+00  6.66430228e-02 -1.12571620e+00\n",
      "  -5.09286845e-01 -1.94042473e+00 -2.13429466e+00  4.82888758e-01\n",
      "   1.62517622e+00 -1.25889435e+00]\n",
      " [-2.71406578e-01 -8.82895261e-01 -1.65302661e-01 -5.72677016e-01\n",
      "  -2.59765543e-01 -7.51351701e-01 -4.57938828e-01 -5.54345179e-01\n",
      "  -3.53200255e-01 -8.58531107e-01]\n",
      " [-6.14699560e-01 -9.71813957e-01 -2.13965498e-01 -1.77170260e+00\n",
      "  -3.81254121e-01  3.02921426e-01  3.49360179e+00  2.46875953e+00\n",
      "  -2.46709088e+00  1.38141684e+00]\n",
      " [-1.74764403e-01 -6.33005305e-01 -1.11958332e-01 -6.35962963e-01\n",
      "  -3.27279205e-02 -9.57421273e-01 -8.55472278e-01 -1.08812365e+00\n",
      "  -4.25205899e-01 -8.00489288e-01]\n",
      " [-8.68144920e-02 -8.07458463e-01 -6.97707152e-02 -8.70188714e-01\n",
      "  -1.38835330e-01 -1.21465188e+00 -1.06516581e+00 -9.79020528e-01\n",
      "  -7.35924222e-01 -1.08540231e+00]] \n",
      "Shape:  (36, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0\n",
      " 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (318,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1] \n",
      "Shape:  (36,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  2\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.8036421112148479\n",
      "\n",
      " Coefficients \n",
      "[ 2.06278383  0.01832114  1.56837374  0.12832109  1.0753365  -0.10602073\n",
      " -0.12844554 -0.01582322  0.03737849 -0.09404134]\n",
      "\n",
      " pop_polarity\n",
      "[4.01132404e-01 8.20397941e-01 4.75603135e-01 7.80580155e-01\n",
      " 1.92335872e-02 3.79503232e-01 5.48878090e-01 5.14966148e-01\n",
      " 9.96593216e-01 8.06023596e-01 6.12314251e-01 1.66926299e-04\n",
      " 4.57681733e-01 6.77497919e-01 7.84782917e-01 2.38467169e-01\n",
      " 5.04971613e-01 2.38467169e-01 9.99999641e-01 4.21512511e-01\n",
      " 5.73736179e-01 4.75603135e-01 5.63838753e-01 7.96043937e-01\n",
      " 4.58728918e-01 5.81919362e-01 3.99574365e-01 6.22338495e-01\n",
      " 2.38467169e-01 8.79348087e-01 1.01956765e-01 5.74453887e-01\n",
      " 4.57681733e-01 1.00011233e-01 6.05190830e-01 6.44519453e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[14  5]\n",
      " [ 2 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8055555555555556\n",
      "recall:  0.8823529411764706\n",
      "specificity:  0.7368421052631579\n",
      "precision:  0.75\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80        19\n",
      "           1       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.81      0.81      0.81        36\n",
      "weighted avg       0.82      0.81      0.81        36\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  2\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[7.97094466e-001 1.96196594e-001 8.60563558e-001 8.91789306e-001\n",
      " 3.92213437e-015 1.47936023e-004 8.44660702e-001 8.60686120e-001\n",
      " 9.35604667e-001 8.64047762e-001 8.40881831e-001 2.75679291e-049\n",
      " 8.39619626e-001 8.66246421e-001 9.47096183e-001 3.88289007e-001\n",
      " 8.30241716e-001 3.88289007e-001 9.45685104e-001 8.56653886e-001\n",
      " 6.28431830e-002 8.60563558e-001 8.48235288e-001 7.87484200e-001\n",
      " 7.81986943e-001 8.69544037e-001 7.54388821e-001 3.96045957e-002\n",
      " 3.88289007e-001 9.04916704e-001 2.51492023e-244 3.98194457e-001\n",
      " 8.39619626e-001 2.84411568e-004 8.80773661e-001 8.89817098e-001]\n",
      "\n",
      " yhat\n",
      "[1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.78\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 9 10]\n",
      " [ 3 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6388888888888888\n",
      "recall:  0.8235294117647058\n",
      "specificity:  0.47368421052631576\n",
      "precision:  0.5833333333333334\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.47      0.58        19\n",
      "           1       0.58      0.82      0.68        17\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.67      0.65      0.63        36\n",
      "weighted avg       0.67      0.64      0.63        36\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  2\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.00200519 0.42462387 0.07919542 0.95147324 0.03566016 0.11992262\n",
      " 0.89371732 0.93924992 0.80559399 0.87979964 0.13666913 0.00272112\n",
      " 0.09809609 0.98570537 0.12462687 0.05128548 0.40572146 0.05128548\n",
      " 0.78029937 0.76004531 0.6563635  0.07919542 0.27160506 0.87252701\n",
      " 0.36755961 0.99534482 0.48040363 0.10879899 0.05128548 0.83112731\n",
      " 0.10516513 0.70126951 0.09809609 0.02323296 0.96034125 0.75405146]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[19  0]\n",
      " [ 2 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9444444444444444\n",
      "recall:  0.8823529411764706\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        19\n",
      "           1       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.94      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  2\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   14.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[3.64626780e-01 8.08635321e-01 4.57484457e-01 6.69393391e-01\n",
      " 8.57696256e-02 2.92865909e-01 5.65517147e-01 5.19943196e-01\n",
      " 9.67555205e-01 7.52778873e-01 6.23838548e-01 2.33325422e-06\n",
      " 4.48403511e-01 6.00957375e-01 7.86068732e-01 2.92993408e-01\n",
      " 5.06803318e-01 2.92993408e-01 9.99999999e-01 4.57747705e-01\n",
      " 5.88520859e-01 4.57484457e-01 5.45490231e-01 7.66833034e-01\n",
      " 4.72573422e-01 5.66814423e-01 3.11529588e-01 5.91340217e-01\n",
      " 2.92993408e-01 8.03267484e-01 2.93079212e-01 5.85513661e-01\n",
      " 4.48403511e-01 1.65099510e-01 5.76991104e-01 6.25296631e-01]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.87\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[11  8]\n",
      " [ 1 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.75\n",
      "recall:  0.9411764705882353\n",
      "specificity:  0.5789473684210527\n",
      "precision:  0.6666666666666666\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.58      0.71        19\n",
      "           1       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.79      0.76      0.75        36\n",
      "weighted avg       0.80      0.75      0.74        36\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  2\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:07:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:07:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.3988377  0.37427342 0.5        0.60416305 0.31834126 0.42078942\n",
      " 0.6664852  0.6930593  0.4777747  0.61337286 0.4726418  0.3385204\n",
      " 0.456308   0.6685668  0.5205437  0.33800054 0.5741042  0.33800054\n",
      " 0.52180207 0.6664852  0.4624002  0.5        0.58706903 0.5738748\n",
      " 0.58706903 0.7079983  0.5673486  0.49494538 0.33800054 0.62482345\n",
      " 0.40153947 0.49494538 0.456308   0.33142447 0.6685668  0.6228075 ]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1]\n",
      "\n",
      " auc\n",
      "0.87\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[15  4]\n",
      " [ 4 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7777777777777778\n",
      "recall:  0.7647058823529411\n",
      "specificity:  0.7894736842105263\n",
      "precision:  0.7647058823529411\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        19\n",
      "           1       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.78      0.78      0.78        36\n",
      "weighted avg       0.78      0.78      0.78        36\n",
      "\n",
      "\n",
      "KFold:  3\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (318, 10)\n",
      "\n",
      "X_test:\n",
      " [[-2.18898973e-01 -6.77329376e-01 -3.17946528e-02 -1.02083202e+00\n",
      "  -1.26311816e-01 -1.14745253e+00 -2.67582805e-01 -1.01592884e+00\n",
      "  -8.88691063e-02 -6.90927524e-01]\n",
      " [-2.17427432e-01 -6.81621845e-01  8.47488543e-02 -2.26404756e-01\n",
      "  -1.04955207e-01 -7.72219808e-01 -7.31024429e-01 -1.19310006e+00\n",
      "  -2.97999509e-01 -7.77612191e-01]\n",
      " [-9.40895950e-01  9.51217327e-02 -7.70331571e-01 -1.00574444e+01\n",
      "  -5.11123018e-01  1.56022872e+00  2.66258777e+01 -3.00563562e-01\n",
      "   1.11690328e+01  5.94936961e+00]\n",
      " [-4.52520769e-01 -1.15084724e+00 -8.18409649e-01 -5.14685255e-01\n",
      "  -4.08759769e-01  7.42957994e-01 -5.28073983e-01 -1.46176927e+00\n",
      "  -6.80696611e-01 -1.09940355e+00]\n",
      " [-2.18962430e-01 -4.26126093e-01  1.01282424e+00 -7.25906291e-01\n",
      "  -2.16551224e-01 -1.18135809e+00 -8.60264506e-01 -1.63479485e+00\n",
      "  -3.58939488e-01  2.35733657e-01]\n",
      " [-2.71406578e-01 -8.82895261e-01 -1.65302661e-01 -5.72677016e-01\n",
      "  -2.59765543e-01 -7.51351701e-01 -4.57938828e-01 -5.54345179e-01\n",
      "  -3.53200255e-01 -8.58531107e-01]\n",
      " [-1.63155616e-01 -6.92357962e-01 -1.26736543e-01 -7.96332659e-01\n",
      "  -6.41370938e-02 -9.87111197e-01 -6.64787802e-01 -1.03927314e+00\n",
      "  -4.46130157e-01 -8.09366797e-01]\n",
      " [-5.46833418e-01 -1.22786469e+00 -2.98463645e-01 -1.55673638e+00\n",
      "   6.84218650e-01  2.68500920e+00  1.28554452e-01 -2.39700686e-01\n",
      "  -1.55218582e+00 -7.65246162e-01]\n",
      " [-3.41853752e-01 -9.53907648e-01 -2.61142689e-01 -4.86390211e-01\n",
      "   1.38351203e-01  1.20605815e+00 -4.98790897e-01 -6.33624583e-01\n",
      "  -2.91281648e-01 -5.82395550e-01]\n",
      " [ 1.85731067e-01 -9.64720661e-01  4.40051451e-01 -3.14892297e+00\n",
      "  -2.27057898e-01 -1.60216762e+00  3.01834675e+00 -1.27494871e+00\n",
      "   1.72358265e+00  6.14109842e-01]\n",
      " [-2.04437914e-01 -7.67363071e-01 -5.09311622e-02  7.31602231e-01\n",
      "   4.27819870e-03 -7.14360522e-01 -4.40248676e-01 -1.11082248e+00\n",
      "  -4.02085421e-01 -7.67020753e-01]\n",
      " [ 1.65713058e-01 -1.29377149e+00 -6.78647776e-01  2.33484336e+00\n",
      "  -4.34143597e-01 -9.15431794e-01 -5.12853993e-01 -1.67779518e+00\n",
      "  -1.34066723e+00 -9.13625174e-01]\n",
      " [-2.69154763e-01 -4.25396654e-01 -2.90167792e-01 -1.62217389e+00\n",
      "   1.04574547e-01 -4.88449102e-02  3.73325323e-01 -9.59317443e-01\n",
      "  -2.06325532e-02 -6.55440745e-01]\n",
      " [-1.51426693e+00  3.94948541e+01 -9.41247525e+00  7.81505331e-01\n",
      "   2.05601033e-01  3.33182923e-01 -5.96224843e-01  1.76165877e+00\n",
      "  -8.27582703e-01 -1.08238314e+00]\n",
      " [ 3.83401734e+00  1.16271547e+00  9.32309414e-01 -1.13861642e+00\n",
      "  -8.17010227e-01  3.09711442e+00 -1.41232688e+01  2.02566591e+00\n",
      "  -5.33186528e+00  6.77415752e+01]\n",
      " [ 1.19171879e-01 -4.02088994e-01 -1.43516664e-01 -1.89699004e+00\n",
      "   6.50494131e-01  8.09796757e-02  3.33175380e-01 -1.30691446e+00\n",
      "  -1.04573729e-01 -5.87825297e-01]\n",
      " [ 6.85772110e-01 -8.68380331e-01 -3.72235321e-02 -6.44123874e-01\n",
      "   1.07981359e-01  9.84708081e-01 -1.42244338e+00 -1.38859275e+00\n",
      "  -2.13460394e-01 -1.12242291e+00]\n",
      " [-3.99972416e-01  1.33698497e+00  1.07850394e+01  7.76604863e-01\n",
      "  -2.75413966e+00 -1.11917572e+00 -8.92900153e-01 -2.59628366e+00\n",
      "   2.30404342e-01  1.27097508e+00]\n",
      " [-2.05333445e-01 -7.76598185e-01 -1.54695647e-01 -6.62597872e-01\n",
      "  -8.82253911e-02 -1.29680015e+00 -1.25647855e+00 -8.85707468e-01\n",
      "  -8.92432291e-02 -9.82562604e-01]\n",
      " [-1.81812859e-01  1.27619025e-01 -1.33728048e-01 -1.08306724e+00\n",
      "  -1.30013697e-01 -1.33033581e+00 -9.00582722e-01 -1.27845145e+00\n",
      "   1.01085354e-01 -8.88390397e-01]\n",
      " [-2.15012187e-01 -7.49587353e-01  2.78661448e-01 -8.53033249e-01\n",
      "  -2.43905413e-01 -1.25301489e+00 -1.14539151e+00 -9.02017170e-01\n",
      "   3.07558233e-01 -9.58698865e-01]\n",
      " [-2.35422670e-01 -2.53617291e-01 -1.50184103e-01 -9.96510489e-01\n",
      "  -5.08284374e-02 -1.09735083e+00 -7.84501508e-01 -1.38321517e+00\n",
      "  -1.38914788e-01 -7.39987274e-01]\n",
      " [-2.05755031e-01 -7.06695917e-01 -9.45614625e-02 -9.30001395e-01\n",
      "  -7.78400849e-02 -1.02810544e+00 -9.35446273e-01 -1.42476233e+00\n",
      "  -4.66273527e-01 -8.88579423e-01]\n",
      " [ 1.65713058e-01 -1.29377149e+00 -6.78647776e-01  2.33484336e+00\n",
      "  -4.34143597e-01 -9.15431794e-01 -5.12853993e-01 -1.67779518e+00\n",
      "  -1.34066723e+00 -9.13625174e-01]\n",
      " [-2.14577064e-01 -7.10694949e-01  2.81025466e-03  3.13177572e-01\n",
      "  -2.37011564e-01 -7.85509081e-01 -7.84270106e-01 -1.17763833e+00\n",
      "  -5.35533401e-01 -2.42347000e-01]\n",
      " [-7.79765882e-01  1.78028535e+00 -1.31983824e+00  4.49743244e-01\n",
      "   3.94858554e-01  4.89610526e+00  5.80124842e-01  1.90859821e+00\n",
      "   1.67102594e+00 -1.62410599e-01]\n",
      " [-1.93823564e-01 -3.52339291e-01  1.97383753e-01 -7.33734573e-01\n",
      "  -2.64004608e-01 -1.36370491e+00 -1.40790493e+00 -4.65383597e-01\n",
      "   3.75146811e-01 -9.37212520e-01]\n",
      " [-2.05333445e-01 -7.76598185e-01 -1.54695647e-01 -6.62597872e-01\n",
      "  -8.82253911e-02 -1.29680015e+00 -1.25647855e+00 -8.85707468e-01\n",
      "  -8.92432291e-02 -9.82562604e-01]\n",
      " [-1.75924944e-01 -7.37067169e-01 -1.18311752e-01 -8.67382599e-01\n",
      "  -7.13582681e-02 -1.04105915e+00 -8.07934899e-01 -1.20549508e+00\n",
      "  -3.66031377e-01 -8.58481346e-01]\n",
      " [-3.12178652e-01 -2.11243263e-02 -4.64816794e-01 -1.58530393e+00\n",
      "  -1.08048050e-01  6.67599640e-01  8.92191130e-01 -6.99467643e-01\n",
      "   1.21006943e-02 -7.42680167e-01]\n",
      " [-2.30207471e-01 -9.76039473e-01  7.30422074e-02 -8.90932216e-01\n",
      "   5.69814688e-02 -1.25854795e+00 -8.58216118e-01 -1.70417161e+00\n",
      "  -1.71995088e-01 -7.91970763e-01]\n",
      " [-2.06808380e-01 -6.91755954e-01 -1.02685249e-01 -6.96242653e-01\n",
      "  -1.22616646e-01 -1.00737776e+00 -8.79837346e-01 -1.07961448e+00\n",
      "  -8.57297244e-04 -7.83538159e-01]\n",
      " [-3.53842994e-01 -3.90582166e-01  2.23732056e-01 -1.29919066e+00\n",
      "  -1.65885343e-01 -7.94001836e-01 -3.82904334e-01 -1.30515897e+00\n",
      "  -6.10965717e-01 -4.16241149e-01]\n",
      " [-1.33630444e-01 -1.93324220e+00 -1.35454551e+00  2.62182353e+00\n",
      "   2.14056558e+00  3.88472833e+01 -3.70960350e+00 -5.83634687e-01\n",
      "   3.47614234e+00 -1.64130508e+00]\n",
      " [-7.92196402e-01 -2.10967526e+00  1.96304059e+00 -3.77768764e+00\n",
      "  -3.07625874e+00  1.89803259e+00  3.46936401e+00  2.28845369e+01\n",
      "  -1.85655935e+01  1.54670811e-01]\n",
      " [-2.40990340e-01 -7.02232240e-01  1.39885842e-01 -6.63171811e-01\n",
      "  -1.77283539e-01 -9.38284296e-01 -1.33824798e+00 -5.35176467e-01\n",
      "  -6.58237574e-01  2.31470915e+00]] \n",
      "Shape:  (36, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0\n",
      " 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (318,)\n",
      "\n",
      "y_test:\n",
      " [0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1] \n",
      "Shape:  (36,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  3\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.6968043123389498\n",
      "\n",
      " Coefficients \n",
      "[ 2.16046166 -0.15453074  1.63735223  0.15644836  0.9681803  -0.09767219\n",
      " -0.12068426 -0.05609865  0.05411591 -0.12219081]\n",
      "\n",
      " pop_polarity\n",
      "[5.68434244e-01 6.55564332e-01 2.88165135e-04 1.48218789e-01\n",
      " 8.68459215e-01 4.70201198e-01 5.90687665e-01 3.49902529e-01\n",
      " 4.42570959e-01 7.57159372e-01 6.60628562e-01 5.92190693e-01\n",
      " 4.12388852e-01 4.89590946e-11 8.88956663e-01 7.69554676e-01\n",
      " 9.26517772e-01 9.99999682e-01 5.92435304e-01 5.48439760e-01\n",
      " 7.06777717e-01 5.34622705e-01 5.89615343e-01 5.92190693e-01\n",
      " 5.99945406e-01 2.88501983e-02 6.79032658e-01 5.92435304e-01\n",
      " 5.94843055e-01 2.44102978e-01 6.88951318e-01 5.79802410e-01\n",
      " 5.52293075e-01 1.24162562e-01 1.87918624e-02 5.50584680e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.72\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[ 9  8]\n",
      " [ 2 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7222222222222222\n",
      "recall:  0.8947368421052632\n",
      "specificity:  0.5294117647058824\n",
      "precision:  0.68\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.53      0.64        17\n",
      "           1       0.68      0.89      0.77        19\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.75      0.71      0.71        36\n",
      "weighted avg       0.75      0.72      0.71        36\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  3\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[9.51138104e-001 9.61358945e-001 6.33063033e-161 8.87332931e-001\n",
      " 9.60590724e-001 9.46609125e-001 9.63737871e-001 3.99947726e-001\n",
      " 8.99531594e-001 2.31373437e-002 9.48532892e-001 9.34274584e-001\n",
      " 9.03825228e-001 1.24846486e-092 0.00000000e+000 9.85336890e-001\n",
      " 9.99917027e-001 9.99999998e-001 9.56702950e-001 9.56303297e-001\n",
      " 9.57799225e-001 9.55953208e-001 9.57050623e-001 9.34274584e-001\n",
      " 9.51264257e-001 3.83082054e-004 9.51784012e-001 9.56702950e-001\n",
      " 9.62521776e-001 7.37557548e-001 9.54495186e-001 9.61747420e-001\n",
      " 9.37022275e-001 2.96647734e-157 8.39245341e-108 7.87863788e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.74\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 6 11]\n",
      " [ 2 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6388888888888888\n",
      "recall:  0.8947368421052632\n",
      "specificity:  0.35294117647058826\n",
      "precision:  0.6071428571428571\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.35      0.48        17\n",
      "           1       0.61      0.89      0.72        19\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.68      0.62      0.60        36\n",
      "weighted avg       0.67      0.64      0.61        36\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  3\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.36933601 0.90790885 0.02389948 0.00937592 0.9505448  0.09562428\n",
      " 0.85803197 0.26280065 0.26728609 0.193369   0.89955155 0.18291693\n",
      " 0.44238609 0.03635801 0.6799109  0.21029111 0.81281759 0.82623653\n",
      " 0.29420268 0.86809133 0.65196902 0.88063322 0.98620275 0.18291693\n",
      " 0.87222817 0.10115904 0.79451672 0.29420268 0.9707492  0.12223363\n",
      " 0.97837753 0.90216332 0.50812769 0.09353789 0.05385735 0.82753489]\n",
      "\n",
      " yhat\n",
      "[0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.98\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[16  1]\n",
      " [ 2 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9166666666666666\n",
      "recall:  0.8947368421052632\n",
      "specificity:  0.9411764705882353\n",
      "precision:  0.9444444444444444\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        17\n",
      "           1       0.94      0.89      0.92        19\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.92      0.92      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  3\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   11.8s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[5.44383295e-01 5.82270551e-01 6.51457648e-04 2.02381284e-01\n",
      " 7.90338950e-01 4.60868583e-01 5.71314119e-01 3.30876029e-01\n",
      " 4.14508699e-01 7.38010464e-01 5.23338273e-01 4.82635128e-01\n",
      " 4.48571130e-01 7.35183984e-05 9.99999308e-01 7.46328818e-01\n",
      " 9.25212816e-01 9.99999998e-01 5.65781754e-01 5.92246045e-01\n",
      " 6.58459599e-01 5.44011873e-01 5.72136503e-01 4.82635128e-01\n",
      " 5.28085833e-01 6.97630404e-02 6.64695037e-01 5.65781754e-01\n",
      " 5.74485359e-01 3.45484249e-01 6.04486797e-01 5.55084768e-01\n",
      " 5.44387876e-01 3.22396375e-01 3.21797279e-01 5.55601220e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.77\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 9  8]\n",
      " [ 2 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7222222222222222\n",
      "recall:  0.8947368421052632\n",
      "specificity:  0.5294117647058824\n",
      "precision:  0.68\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.53      0.64        17\n",
      "           1       0.68      0.89      0.77        19\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.75      0.71      0.71        36\n",
      "weighted avg       0.75      0.72      0.71        36\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  3\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:08:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:08:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.5818047  0.67697775 0.34677464 0.36893934 0.66779995 0.46182653\n",
      " 0.7020306  0.41028482 0.36360526 0.44405857 0.6043436  0.4596489\n",
      " 0.50451624 0.37599003 0.5330879  0.50451624 0.54935104 0.48881882\n",
      " 0.56707394 0.62569535 0.56877625 0.66926503 0.7020306  0.4596489\n",
      " 0.6307224  0.4587986  0.57692164 0.56707394 0.7020306  0.43575528\n",
      " 0.6554152  0.68061405 0.42554408 0.47164577 0.34418088 0.559824  ]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[12  5]\n",
      " [ 3 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7777777777777778\n",
      "recall:  0.8421052631578947\n",
      "specificity:  0.7058823529411765\n",
      "precision:  0.7619047619047619\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75        17\n",
      "           1       0.76      0.84      0.80        19\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.78      0.77      0.78        36\n",
      "weighted avg       0.78      0.78      0.78        36\n",
      "\n",
      "\n",
      "KFold:  4\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (319, 10)\n",
      "\n",
      "X_test:\n",
      " [[-1.99311406e-01 -6.77803414e-01 -1.29368981e-01 -1.78683494e-01\n",
      "  -1.57833549e-01 -9.97552278e-01 -8.32018593e-01 -1.07659755e+00\n",
      "  -5.25217855e-01 -1.89931538e-01]\n",
      " [-2.89630691e-01 -5.79678359e-02 -7.03604103e-02 -1.03998795e+00\n",
      "   3.79831421e-01 -5.38161258e-01 -1.52150654e-01 -3.55567838e-01\n",
      "  -6.59379579e-01 -3.15757523e-01]\n",
      " [-6.16525317e-01  1.34561686e+00  2.73893820e-01  7.11308496e-01\n",
      "   1.66147585e-01 -1.64218284e+00 -4.77629926e+00 -9.01458079e+00\n",
      "  -4.37165640e+00  1.61050026e+01]\n",
      " [-7.79765882e-01  1.78028535e+00 -1.31983824e+00  4.49743244e-01\n",
      "   3.94858554e-01  4.89610526e+00  5.80124842e-01  1.90859821e+00\n",
      "   1.67102594e+00 -1.62410599e-01]\n",
      " [-7.92196402e-01 -2.10967526e+00  1.96304059e+00 -3.77768764e+00\n",
      "  -3.07625874e+00  1.89803259e+00  3.46936401e+00  2.28845369e+01\n",
      "  -1.85655935e+01  1.54670811e-01]\n",
      " [-3.46662699e-01 -6.91845445e-01 -3.48746379e-02 -1.52335668e+00\n",
      "  -2.65581459e-02 -5.89542989e-01 -6.68968527e-01 -8.80526537e-01\n",
      "   6.89055868e-01 -5.43363184e-01]\n",
      " [ 7.00903566e-01 -7.06671146e-01 -6.83927773e-02 -1.10172071e+00\n",
      "  -2.30082049e-01 -1.03584564e+00 -4.20368559e-01 -4.30014166e-01\n",
      "  -6.74343794e-01 -9.42653715e-01]\n",
      " [-4.27903348e-01 -2.92420036e-01 -2.58225954e-01 -4.16117454e-01\n",
      "  -2.18541380e-01 -2.48684131e+00 -1.18577993e+00 -2.84355037e+00\n",
      "  -1.24503395e+00  1.76749674e-01]\n",
      " [-3.58204802e-01 -4.25102377e-01  2.43442207e-01 -1.23608439e+00\n",
      "  -6.04407962e-02 -7.85869608e-01 -6.76102054e-01 -1.41357509e+00\n",
      "  -8.22012275e-01 -1.44590310e+00]\n",
      " [-1.33630444e-01 -1.93324220e+00 -1.35454551e+00  2.62182353e+00\n",
      "   2.14056558e+00  3.88472833e+01 -3.70960350e+00 -5.83634687e-01\n",
      "   3.47614234e+00 -1.64130508e+00]\n",
      " [-1.53813278e-01  2.85126219e-02  4.93996762e-02 -1.07519887e+00\n",
      "   9.19640903e-02 -1.12631055e+00 -9.34694962e-01 -1.00408683e+00\n",
      "  -1.90288889e-01 -5.36292266e-01]\n",
      " [-2.32463536e-01 -8.12037555e-01 -1.63971321e-01 -1.08915551e+00\n",
      "  -1.50501138e-01 -1.06411515e+00 -9.71784079e-01 -1.06467088e+00\n",
      "   6.70091061e-02 -8.86297152e-01]\n",
      " [-3.35639558e-01 -3.22318296e-01  5.35302046e-01 -1.15396180e+00\n",
      "   2.36155994e-01 -1.57566672e+00 -2.06845923e+00 -2.25956677e+00\n",
      "  -3.82468231e-01 -1.24832699e+00]\n",
      " [-9.29643062e-02 -6.59656843e-01  1.74032224e-01 -9.88031641e-01\n",
      "   2.71763321e-01 -1.08675164e+00 -5.31681760e-01 -1.22339705e+00\n",
      "  -2.04619770e-01 -6.85427185e-01]\n",
      " [-3.42461633e-01 -1.36441580e+00  1.82474539e-01  1.81428718e+00\n",
      "   7.03643523e-02 -2.43805249e+00 -1.71348633e+00 -3.50556139e-03\n",
      "   7.09357093e-02 -8.02498982e-01]\n",
      " [-2.37545144e-01 -7.53831077e-01 -2.00806935e-01 -7.43908205e-01\n",
      "   1.50911123e-03 -8.03781418e-01 -8.65035932e-01 -1.14055345e+00\n",
      "  -4.02433084e-01 -9.10184628e-01]\n",
      " [-2.32762329e-01 -6.71347685e-01  1.70877326e-01 -1.06581678e+00\n",
      "  -1.89036970e-01 -1.67006811e-01 -1.94225837e-01 -7.79826493e-01\n",
      "  -3.87536824e-01 -8.15050059e-01]\n",
      " [-3.35639558e-01 -3.22318296e-01  5.35302046e-01 -1.15396180e+00\n",
      "   2.36155994e-01 -1.57566672e+00 -2.06845923e+00 -2.25956677e+00\n",
      "  -3.82468231e-01 -1.24832699e+00]\n",
      " [-2.48334984e-01 -8.34362989e-01 -9.80406808e-03 -8.91729420e-01\n",
      "   5.59982632e-01 -1.55055490e-02 -9.59553274e-01 -1.32388828e+00\n",
      "  -1.93926903e-01 -4.93828493e-01]\n",
      " [ 5.43878522e-01  1.72981168e-01 -3.41291830e-01 -8.49136539e-01\n",
      "  -8.56018035e-02 -1.04215040e+00 -6.70133239e-01 -1.11671848e+00\n",
      "  -2.62049292e-01 -8.97434597e-01]\n",
      " [-2.99638948e-01 -7.09157095e-01 -3.09094195e-02 -1.33382588e+00\n",
      "   1.65699161e-01 -1.00307148e+00 -2.19676584e-01 -3.13914508e-01\n",
      "  -6.31659290e-01 -4.39302392e-01]\n",
      " [-2.83383167e-01 -2.05954839e-01  8.79930236e-03 -8.45076635e-01\n",
      "   5.84958606e-02 -1.14081251e+00 -1.15449395e+00 -9.62792792e-01\n",
      "   3.43706386e-01 -8.24021029e-01]\n",
      " [-1.05240040e-01 -6.81061463e-01  1.07823441e-01 -1.36686003e+00\n",
      "   9.45894094e-02 -1.33303970e+00 -3.20833515e-01 -1.74224132e+00\n",
      "   3.30023903e-02  1.38005217e+00]\n",
      " [-1.98840309e-01 -5.88934939e-01 -1.57474059e-01 -6.51193366e-01\n",
      "  -6.30589529e-02 -8.81813955e-01 -7.85099679e-01 -1.05760200e+00\n",
      "  -4.55237566e-01 -6.92159277e-01]\n",
      " [-8.50559656e-02 -6.83151300e-01  7.94238131e-02 -1.76160284e-01\n",
      "  -6.91715738e-01 -1.86869143e+00 -2.75158654e+00  1.72312891e+00\n",
      "   2.67785460e+00  1.04953638e+00]\n",
      " [-6.14699560e-01 -9.71813957e-01 -2.13965498e-01 -1.77170260e+00\n",
      "  -3.81254121e-01  3.02921426e-01  3.49360179e+00  2.46875953e+00\n",
      "  -2.46709088e+00  1.38141684e+00]\n",
      " [-3.18662163e-01 -1.00241292e+00 -6.56201055e-02 -1.63235140e+00\n",
      "  -1.25525990e-01  4.74015571e-01  3.16902859e-01 -2.48305527e-01\n",
      "  -2.40721168e-01  1.44874754e-01]\n",
      " [ 1.19171879e-01 -4.02088994e-01 -1.43516664e-01 -1.89699004e+00\n",
      "   6.50494131e-01  8.09796757e-02  3.33175380e-01 -1.30691446e+00\n",
      "  -1.04573729e-01 -5.87825297e-01]\n",
      " [-2.49162215e-01 -4.77152262e-01 -1.03184449e-01 -1.15897825e+00\n",
      "   1.40440132e-02 -1.16897538e+00 -6.01166407e-01 -1.22327618e+00\n",
      "   3.30997871e-02 -9.21976683e-01]\n",
      " [-2.49477663e-01 -7.46623465e-01  1.26363016e-01 -9.98776222e-01\n",
      "   2.89780041e-01 -7.39710089e-01 -4.31314693e-01 -1.00478900e+00\n",
      "  -4.74168730e-01 -5.13354932e-01]\n",
      " [-3.16290697e-01 -9.72140152e-01  9.94937528e-02 -1.18245630e+00\n",
      "  -1.86932269e-01 -1.41059332e+00 -1.45142150e+00 -1.97006603e+00\n",
      "  -3.04194290e-01 -1.24108659e+00]\n",
      " [-2.89630691e-01 -5.79678359e-02 -7.03604103e-02 -1.03998795e+00\n",
      "   3.79831421e-01 -5.38161258e-01 -1.52150654e-01 -3.55567838e-01\n",
      "  -6.59379579e-01 -3.15757523e-01]\n",
      " [-5.18859142e-01 -3.13352361e-01 -4.53628644e-01 -1.63816637e+00\n",
      "  -2.69412279e-01  5.34593318e-01 -4.45230541e-01  2.34756181e+00\n",
      "   1.57958757e+00  5.26183173e+00]\n",
      " [-7.92196402e-01 -2.10967526e+00  1.96304059e+00 -3.77768764e+00\n",
      "  -3.07625874e+00  1.89803259e+00  3.46936401e+00  2.28845369e+01\n",
      "  -1.85655935e+01  1.54670811e-01]\n",
      " [-3.60569676e-01 -1.01912246e+00  2.65392332e-01 -1.09930557e+00\n",
      "   5.69553824e-02 -1.08275373e+00 -2.09667795e+00 -6.52386040e-02\n",
      "   2.39400890e+00 -5.91907998e-01]] \n",
      "Shape:  (35, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (319,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1] \n",
      "Shape:  (35,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  4\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.7891781947439809\n",
      "\n",
      " Coefficients \n",
      "[ 1.80826061  0.03753399  2.00313889  0.19658425  1.28316584 -0.10280389\n",
      " -0.21561277 -0.00948658  0.01166422 -0.11951587]\n",
      "\n",
      " pop_polarity\n",
      "[0.55360975 0.62874232 0.48372987 0.03877683 0.05337584 0.50478117\n",
      " 0.84386312 0.40796301 0.66725369 0.12699157 0.71226883 0.50959656\n",
      " 0.89019726 0.80485352 0.83862604 0.54211101 0.59691393 0.89019726\n",
      " 0.7521705  0.7658713  0.5763551  0.66226506 0.66822371 0.55737729\n",
      " 0.62748728 0.06744327 0.36056607 0.76226553 0.56861085 0.7257262\n",
      " 0.62928865 0.62874232 0.08875644 0.05337584 0.75954464]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.67\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[ 9  8]\n",
      " [ 0 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7714285714285715\n",
      "recall:  1.0\n",
      "specificity:  0.5294117647058824\n",
      "precision:  0.6923076923076923\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69        17\n",
      "           1       0.69      1.00      0.82        18\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.85      0.76      0.76        35\n",
      "weighted avg       0.84      0.77      0.76        35\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  4\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[7.94411939e-001 7.77651943e-001 1.76145794e-002 1.90598273e-004\n",
      " 2.12313260e-100 7.23330479e-001 9.99155795e-001 3.14254984e-001\n",
      " 7.66565091e-001 2.93212396e-145 8.32387703e-001 7.88492647e-001\n",
      " 7.03367707e-001 8.74523140e-001 3.49239675e-001 8.07545547e-001\n",
      " 7.70083704e-001 7.03367707e-001 8.60824292e-001 9.96608582e-001\n",
      " 7.29319007e-001 7.94944114e-001 8.21391050e-001 8.11474310e-001\n",
      " 5.47658181e-002 4.27834719e-004 5.62428738e-001 9.23492731e-001\n",
      " 7.86450518e-001 8.22468668e-001 7.07505384e-001 7.77651943e-001\n",
      " 2.99534546e-001 2.12313260e-100 3.24030736e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0]\n",
      "\n",
      " auc\n",
      "0.89\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[10  7]\n",
      " [ 1 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7714285714285715\n",
      "recall:  0.9444444444444444\n",
      "specificity:  0.5882352941176471\n",
      "precision:  0.7083333333333334\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.71        17\n",
      "           1       0.71      0.94      0.81        18\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.81      0.77      0.76        35\n",
      "weighted avg       0.81      0.77      0.76        35\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  4\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.86860942 0.13014321 0.12433646 0.04346794 0.02546416 0.6558029\n",
      " 0.55954547 0.11536309 0.23850054 0.05214127 0.93650909 0.88864513\n",
      " 0.05734691 0.8011279  0.0844087  0.91266035 0.60163779 0.05734691\n",
      " 0.9474188  0.91444654 0.38119995 0.94762144 0.71452685 0.87152594\n",
      " 0.16190746 0.02111543 0.05653209 0.13534126 0.73523669 0.74959968\n",
      " 0.67416115 0.13014321 0.19324516 0.02546416 0.69811247]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[17  0]\n",
      " [ 1 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9714285714285714\n",
      "recall:  0.9444444444444444\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        17\n",
      "           1       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.97      0.97      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  4\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    1.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.1s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.50642426 0.615472   0.29967832 0.10062343 0.29966675 0.52421661\n",
      " 0.8016085  0.41135105 0.65444637 0.29957619 0.69531935 0.52499559\n",
      " 0.8494344  0.73457121 0.65770273 0.53648908 0.5708061  0.8494344\n",
      " 0.69332062 0.75190182 0.56678252 0.64748896 0.59370071 0.54385025\n",
      " 0.59259534 0.09674889 0.39236091 0.73310027 0.568441   0.66256521\n",
      " 0.61841921 0.615472   0.14146327 0.29966675 0.71030422]\n",
      "\n",
      " yhat\n",
      "[1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.68\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 9  8]\n",
      " [ 0 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7714285714285715\n",
      "recall:  1.0\n",
      "specificity:  0.5294117647058824\n",
      "precision:  0.6923076923076923\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69        17\n",
      "           1       0.69      1.00      0.82        18\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.85      0.76      0.76        35\n",
      "weighted avg       0.84      0.77      0.76        35\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  4\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.62029094 0.4636386  0.4916812  0.47016877 0.36859745 0.47471407\n",
      " 0.43292412 0.44366693 0.41133308 0.45730937 0.61595273 0.63145506\n",
      " 0.41133308 0.6062077  0.40895385 0.69746536 0.52978647 0.41133308\n",
      " 0.6409036  0.66467845 0.4565076  0.6784162  0.492869   0.65307784\n",
      " 0.516045   0.36859745 0.3601665  0.4757243  0.5493708  0.544778\n",
      " 0.43195605 0.4636386  0.39181966 0.36859745 0.451184  ]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0]\n",
      "\n",
      " auc\n",
      "0.89\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[16  1]\n",
      " [ 6 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8\n",
      "recall:  0.6666666666666666\n",
      "specificity:  0.9411764705882353\n",
      "precision:  0.9230769230769231\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.94      0.82        17\n",
      "           1       0.92      0.67      0.77        18\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.83      0.80      0.80        35\n",
      "weighted avg       0.83      0.80      0.80        35\n",
      "\n",
      "\n",
      "KFold:  5\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (319, 10)\n",
      "\n",
      "X_test:\n",
      " [[-1.76311466e-01 -7.56781163e-01 -1.05714099e-01 -9.33509928e-01\n",
      "  -7.60736004e-02 -1.13242581e+00 -6.51302110e-01 -1.17511038e+00\n",
      "  -3.45941703e-01 -8.43081042e-01]\n",
      " [-2.71406578e-01 -8.82895261e-01 -1.65302661e-01 -5.72677016e-01\n",
      "  -2.59765543e-01 -7.51351701e-01 -4.57938828e-01 -5.54345179e-01\n",
      "  -3.53200255e-01 -8.58531107e-01]\n",
      " [-1.57445588e-01 -6.76840022e-01 -1.32457106e-01 -7.39433729e-01\n",
      "  -4.43769324e-02 -6.47252651e-01 -7.43986695e-01 -1.06993216e+00\n",
      "  -3.71365558e-01 -7.70599765e-01]\n",
      " [-5.12479702e-01 -4.29541619e-01 -6.59578081e-01 -1.93389612e+00\n",
      "  -5.24606588e-01  2.53029381e+00 -1.79492356e-01  3.61208787e-01\n",
      "  -1.07852723e+00 -1.57117874e+00]\n",
      " [-2.34732054e-01 -8.48645534e-02 -1.67502644e-01 -6.67255662e-01\n",
      "   2.66946969e-01 -9.26288871e-01 -1.00422552e+00 -1.24028799e+00\n",
      "  -5.33975559e-01 -9.45312871e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-7.92196402e-01 -2.10967526e+00  1.96304059e+00 -3.77768764e+00\n",
      "  -3.07625874e+00  1.89803259e+00  3.46936401e+00  2.28845369e+01\n",
      "  -1.85655935e+01  1.54670811e-01]\n",
      " [-8.40473654e-01 -1.90963959e+00 -7.58620401e-01  1.85092008e+00\n",
      "  -3.16903313e+00 -5.24486593e+00 -1.49258442e+01  2.63995468e+01\n",
      "   3.09257258e+01  6.59261254e-01]\n",
      " [-5.12479702e-01 -4.29541619e-01 -6.59578081e-01 -1.93389612e+00\n",
      "  -5.24606588e-01  2.53029381e+00 -1.79492356e-01  3.61208787e-01\n",
      "  -1.07852723e+00 -1.57117874e+00]\n",
      " [-3.05773356e-01 -3.72602860e-01  1.09264223e-01 -9.66677326e-01\n",
      "  -9.62730284e-02 -3.74940850e-01  6.06896304e-02 -9.90202267e-01\n",
      "  -1.42128440e-01 -4.72414322e-01]\n",
      " [-4.00613390e-01  7.78766213e-02  1.05251952e-02 -1.28969302e+00\n",
      "  -7.63889648e-01 -5.29738530e-01  1.58544622e+00 -1.85169021e-01\n",
      "  -1.23749157e+00 -2.27983952e-01]\n",
      " [ 5.29478784e-02 -6.84923413e-01  1.47698020e-01 -9.54523708e-01\n",
      "   1.01738982e-01 -1.20389331e+00 -9.25554795e-01 -1.36522343e+00\n",
      "  -4.22879791e-01 -8.69368101e-01]\n",
      " [-3.68001431e-01 -1.09846418e+00 -5.53019511e-01  3.47456322e-01\n",
      "   3.63845828e-02 -9.01266845e-01 -1.04879650e+00 -1.50055638e+00\n",
      "  -8.30116072e-01 -1.44074638e+00]\n",
      " [-1.92917363e-01 -7.89966473e-01 -1.59998009e-01 -8.30684029e-01\n",
      "  -8.36405421e-02 -1.04983473e+00 -8.80227587e-01 -1.25894301e+00\n",
      "  -3.06858919e-01 -9.90702778e-01]\n",
      " [-3.23119396e-01 -1.05702707e+00 -7.24823561e-02 -9.29454812e-01\n",
      "  -3.26315306e-01 -7.85124718e-01 -1.86217383e+00  1.47404044e+00\n",
      "   2.32513337e+00  2.72099881e-01]\n",
      " [-2.18291929e-01 -8.97827256e-01 -3.34743088e-01  1.23205614e-01\n",
      "  -8.35362087e-02 -6.76987049e-01 -3.63140298e-01 -1.23154660e+00\n",
      "  -2.45389735e-01 -7.39948961e-01]\n",
      " [-1.33630444e-01 -1.93324220e+00 -1.35454551e+00  2.62182353e+00\n",
      "   2.14056558e+00  3.88472833e+01 -3.70960350e+00 -5.83634687e-01\n",
      "   3.47614234e+00 -1.64130508e+00]\n",
      " [-2.71406578e-01 -8.82895261e-01 -1.65302661e-01 -5.72677016e-01\n",
      "  -2.59765543e-01 -7.51351701e-01 -4.57938828e-01 -5.54345179e-01\n",
      "  -3.53200255e-01 -8.58531107e-01]\n",
      " [-1.69373995e-01 -7.56037389e-01 -1.16421996e-01 -9.54751536e-01\n",
      "  -7.70146801e-02 -9.89027414e-01 -6.39442882e-01 -1.20852138e+00\n",
      "  -3.06410009e-01 -8.34682907e-01]\n",
      " [-2.43308040e-01 -6.55530203e-01 -7.41637405e-02 -5.54468482e-01\n",
      "   3.21988624e-02 -6.86704604e-01 -1.18759962e+00 -1.15870581e+00\n",
      "  -3.25530625e-01 -9.63558700e-01]\n",
      " [-3.30941065e-01 -1.71912619e-02  6.72057381e-02 -4.64620586e+00\n",
      "   2.10838671e-01 -1.98438713e+00  3.76789970e-01  3.95182820e+00\n",
      "   8.73498090e+00  7.35485314e+00]\n",
      " [-2.49144715e-01 -6.80524516e-01 -5.91590187e-02 -5.22496327e-01\n",
      "  -9.81423009e-02 -7.85189780e-01 -8.14855967e-01 -1.13846036e+00\n",
      "  -3.12730217e-01 -9.34610307e-01]\n",
      " [-2.05333445e-01 -7.76598185e-01 -1.54695647e-01 -6.62597872e-01\n",
      "  -8.82253911e-02 -1.29680015e+00 -1.25647855e+00 -8.85707468e-01\n",
      "  -8.92432291e-02 -9.82562604e-01]\n",
      " [-8.50559656e-02 -6.83151300e-01  7.94238131e-02 -1.76160284e-01\n",
      "  -6.91715738e-01 -1.86869143e+00 -2.75158654e+00  1.72312891e+00\n",
      "   2.67785460e+00  1.04953638e+00]\n",
      " [-1.92829880e-01 -6.82448977e-01 -9.36650792e-02 -7.65850496e-01\n",
      "   6.29852463e-03 -7.78630406e-01 -9.21683401e-01 -9.30502639e-01\n",
      "  -4.74444721e-01 -7.78293194e-01]\n",
      " [-3.41853752e-01 -9.53907648e-01 -2.61142689e-01 -4.86390211e-01\n",
      "   1.38351203e-01  1.20605815e+00 -4.98790897e-01 -6.33624583e-01\n",
      "  -2.91281648e-01 -5.82395550e-01]\n",
      " [-2.92907302e-01 -8.02580834e-01  3.68893082e-01 -2.68265102e-01\n",
      "  -5.11963638e-01 -8.09801647e-01 -1.11439427e+00  5.54132508e-01\n",
      "  -9.15628297e-01 -8.99213497e-01]\n",
      " [-4.38872202e-01  1.54287083e+00  1.99212394e+00 -5.00243036e-01\n",
      "  -3.26051532e-01 -4.29453348e-01 -2.37857911e+00 -3.00146832e+00\n",
      "  -7.67033882e-01  3.81227936e-02]\n",
      " [-3.18662163e-01 -1.00241292e+00 -6.56201055e-02 -1.63235140e+00\n",
      "  -1.25525990e-01  4.74015571e-01  3.16902859e-01 -2.48305527e-01\n",
      "  -2.40721168e-01  1.44874754e-01]\n",
      " [-3.12178652e-01 -2.11243263e-02 -4.64816794e-01 -1.58530393e+00\n",
      "  -1.08048050e-01  6.67599640e-01  8.92191130e-01 -6.99467643e-01\n",
      "   1.21006943e-02 -7.42680167e-01]\n",
      " [-2.19885976e-01 -7.92793631e-01 -5.09197821e-02 -7.37982952e-01\n",
      "  -9.47277736e-02 -4.47673722e-01 -1.56911650e+00 -6.92566401e-01\n",
      "   3.74462483e-01 -7.85499297e-01]\n",
      " [-3.22924199e-01  4.83836755e-01  1.82559475e-01 -2.16060547e-01\n",
      "  -7.48944865e-03  2.82051208e-01 -1.47766373e+00 -1.65251866e+00\n",
      "  -5.70673831e-01  9.13300280e-01]\n",
      " [-5.45382844e-01  1.41231484e-01  1.70356344e-01 -1.80595784e+00\n",
      "  -3.43820541e-01 -8.27321305e-01  7.85477720e-01  9.52292353e-02\n",
      "   3.13379434e+00  1.59728457e-01]\n",
      " [-9.40895950e-01  9.51217327e-02 -7.70331571e-01 -1.00574444e+01\n",
      "  -5.11123018e-01  1.56022872e+00  2.66258777e+01 -3.00563562e-01\n",
      "   1.11690328e+01  5.94936961e+00]\n",
      " [-2.34704545e-01 -5.83613346e-01 -1.21745219e-01 -7.15164937e-01\n",
      "  -7.46100100e-02 -1.05013384e+00 -9.98938169e-01 -1.18620276e+00\n",
      "  -3.35898690e-01 -7.76798558e-01]] \n",
      "Shape:  (35, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (319,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1] \n",
      "Shape:  (35,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  5\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.5954337815418473\n",
      "\n",
      " Coefficients \n",
      "[ 2.1119798  -0.09689787  1.65928614  0.15386564  0.94840634 -0.09034826\n",
      " -0.22455371 -0.04055325 -0.00449693 -0.14214108]\n",
      "\n",
      " pop_polarity\n",
      "[5.80010367e-01 4.54087884e-01 5.82486084e-01 9.03317034e-02\n",
      " 6.16977111e-01 1.19257546e-04 5.05998678e-02 7.92964970e-02\n",
      " 9.03317034e-02 5.13796247e-01 1.93671238e-01 8.12413027e-01\n",
      " 4.20998955e-01 5.68978253e-01 4.55830242e-01 4.76176160e-01\n",
      " 1.48179185e-01 4.54087884e-01 5.74401433e-01 6.18076898e-01\n",
      " 1.60360408e-01 5.73927207e-01 5.91460957e-01 6.19224182e-01\n",
      " 6.02247454e-01 4.25989984e-01 6.39392186e-01 9.58154174e-01\n",
      " 3.58250332e-01 2.13109948e-01 6.10836318e-01 5.92716943e-01\n",
      " 2.62373509e-01 8.17047542e-06 5.62842488e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.83\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[15  4]\n",
      " [ 3 13]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8\n",
      "recall:  0.8125\n",
      "specificity:  0.7894736842105263\n",
      "precision:  0.7647058823529411\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        19\n",
      "           1       0.76      0.81      0.79        16\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.80      0.80      0.80        35\n",
      "weighted avg       0.80      0.80      0.80        35\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  5\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[8.46613096e-001 8.09170900e-001 8.65540685e-001 1.25486369e-001\n",
      " 8.61334154e-001 3.23906259e-050 8.90903833e-125 2.08269878e-262\n",
      " 1.25486369e-001 7.92276297e-001 3.27783071e-001 9.32610452e-001\n",
      " 7.68612456e-001 8.49144046e-001 6.99559643e-002 8.20451306e-001\n",
      " 6.05939541e-148 8.09170900e-001 8.51760345e-001 8.54924496e-001\n",
      " 6.05784673e-016 8.44670491e-001 8.42998002e-001 2.31190883e-002\n",
      " 8.56845419e-001 6.93179272e-001 6.79720307e-001 5.20664171e-001\n",
      " 6.17717915e-001 5.37406233e-001 8.30029190e-001 7.59747605e-001\n",
      " 2.48629936e-002 2.25692543e-096 8.40767378e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.76\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[10  9]\n",
      " [ 2 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6857142857142857\n",
      "recall:  0.875\n",
      "specificity:  0.5263157894736842\n",
      "precision:  0.6086956521739131\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.53      0.65        19\n",
      "           1       0.61      0.88      0.72        16\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.72      0.70      0.68        35\n",
      "weighted avg       0.73      0.69      0.68        35\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  5\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.93078221 0.12973236 0.31179682 0.0024649  0.89418877 0.00919709\n",
      " 0.01162159 0.0784533  0.0024649  0.62238273 0.01760189 0.95763744\n",
      " 0.009903   0.83440202 0.71765355 0.76679777 0.04921438 0.12973236\n",
      " 0.95300822 0.24931324 0.40407345 0.87843229 0.21787615 0.18512758\n",
      " 0.84076649 0.29454143 0.81796274 0.63898196 0.03434957 0.06903659\n",
      " 0.8689382  0.77649052 0.16575388 0.00692305 0.92992452]\n",
      "\n",
      " yhat\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[19  0]\n",
      " [ 1 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9714285714285714\n",
      "recall:  0.9375\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        19\n",
      "           1       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.97      0.97      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  5\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   18.8s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[5.47847182e-01 4.66096070e-01 5.49733379e-01 3.08060057e-01\n",
      " 5.98723726e-01 5.37942460e-05 3.74430691e-01 3.74652170e-01\n",
      " 3.08060057e-01 5.23873000e-01 3.50000612e-01 6.92621613e-01\n",
      " 4.12520706e-01 5.42945972e-01 5.00000000e-01 4.36912739e-01\n",
      " 3.74951326e-01 4.66096070e-01 5.45653463e-01 5.76527842e-01\n",
      " 3.60421850e-01 5.41990825e-01 5.57836787e-01 5.79776509e-01\n",
      " 5.66763798e-01 4.51335583e-01 5.91605636e-01 9.10782004e-01\n",
      " 4.32776999e-01 3.74695618e-01 5.82659748e-01 6.05930344e-01\n",
      " 4.15060971e-01 5.64645868e-04 5.48208584e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1]\n",
      "\n",
      " auc\n",
      "0.83\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[15  4]\n",
      " [ 2 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8285714285714286\n",
      "recall:  0.875\n",
      "specificity:  0.7894736842105263\n",
      "precision:  0.7777777777777778\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83        19\n",
      "           1       0.78      0.88      0.82        16\n",
      "\n",
      "    accuracy                           0.83        35\n",
      "   macro avg       0.83      0.83      0.83        35\n",
      "weighted avg       0.83      0.83      0.83        35\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  5\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.7057661  0.4216959  0.6482897  0.326394   0.6857711  0.34396502\n",
      " 0.3810605  0.40458125 0.326394   0.5231077  0.326394   0.6870204\n",
      " 0.40065622 0.6334172  0.417212   0.58029866 0.46149823 0.4216959\n",
      " 0.7057661  0.5746376  0.41067845 0.7057661  0.5911511  0.49666756\n",
      " 0.7057661  0.39718318 0.49839407 0.4936001  0.34338978 0.38891315\n",
      " 0.6216975  0.46097395 0.3468205  0.3468205  0.7057661 ]\n",
      "\n",
      " yhat\n",
      "[1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1]\n",
      "\n",
      " auc\n",
      "0.89\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[16  3]\n",
      " [ 5 11]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7714285714285715\n",
      "recall:  0.6875\n",
      "specificity:  0.8421052631578947\n",
      "precision:  0.7857142857142857\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80        19\n",
      "           1       0.79      0.69      0.73        16\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.77      0.76      0.77        35\n",
      "weighted avg       0.77      0.77      0.77        35\n",
      "\n",
      "\n",
      "KFold:  6\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (319, 10)\n",
      "\n",
      "X_test:\n",
      " [[-3.15987301e-02 -8.43109872e-01  1.02658705e-02 -1.37746466e+00\n",
      "   1.82051170e-01 -1.38579723e+00 -9.22385718e-01 -1.51700688e+00\n",
      "  -3.28598933e-01 -6.67689717e-01]\n",
      " [-1.94407435e-01 -6.51248840e-01 -1.50927962e-01 -7.78422323e-01\n",
      "  -7.11447899e-02 -9.23539184e-01 -7.40455549e-01 -1.13806244e+00\n",
      "  -4.15736233e-01 -7.40462489e-01]\n",
      " [-2.56846106e-01 -6.39915997e-01  7.88268656e-01 -4.38908171e-01\n",
      "  -1.95970084e-01 -2.69651512e-01 -9.25990713e-01 -1.58397147e+00\n",
      "  -2.85092239e-01 -6.49836255e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-2.55756839e-01  2.15118672e-01 -1.99191444e-01 -6.29718276e-01\n",
      "  -1.58990729e-01 -9.43531864e-01 -1.09060220e+00 -7.07090533e-01\n",
      "  -1.87160283e-02 -7.07218983e-01]\n",
      " [-1.87746683e-01 -7.58010039e-01  8.41881571e-03 -1.07089689e+00\n",
      "  -1.08194777e-01 -1.05565599e+00 -4.64619273e-01 -1.29948858e+00\n",
      "  -1.74023926e-01 -8.21795033e-01]\n",
      " [-1.48791484e-01 -7.28950492e-01  3.05619322e-01  5.24455775e-02\n",
      "  -1.71042034e-01 -8.16066671e-01 -9.54981010e-01 -1.17491894e+00\n",
      "  -1.42351586e-01 -8.33698122e-01]\n",
      " [-4.33680920e-02 -7.48030114e-01 -1.30757030e-01 -7.35804108e-01\n",
      "  -1.24447672e-01 -1.18069939e+00 -1.22190931e+00 -7.48618590e-01\n",
      "   1.45020498e-01 -9.37746687e-01]\n",
      " [-3.03758803e-01 -9.39215546e-01 -5.47031808e-02 -1.17910290e+00\n",
      "  -1.30770960e-01 -1.43713734e+00 -9.42840249e-01 -1.85174493e+00\n",
      "  -1.73125949e-01 -3.29894554e-01]\n",
      " [-2.26062330e-01 -6.61782886e-01 -5.15420029e-02 -7.36534027e-01\n",
      "  -9.74918041e-02 -1.08241244e+00 -1.01023580e+00 -1.31883196e+00\n",
      "  -5.14436747e-01 -8.28179606e-01]\n",
      " [-2.05333445e-01 -7.76598185e-01 -1.54695647e-01 -6.62597872e-01\n",
      "  -8.82253911e-02 -1.29680015e+00 -1.25647855e+00 -8.85707468e-01\n",
      "  -8.92432291e-02 -9.82562604e-01]\n",
      " [-3.68001431e-01 -1.09846418e+00 -5.53019511e-01  3.47456322e-01\n",
      "   3.63845828e-02 -9.01266845e-01 -1.04879650e+00 -1.50055638e+00\n",
      "  -8.30116072e-01 -1.44074638e+00]\n",
      " [-1.57445588e-01 -6.76840022e-01 -1.32457106e-01 -7.39433729e-01\n",
      "  -4.43769324e-02 -6.47252651e-01 -7.43986695e-01 -1.06993216e+00\n",
      "  -3.71365558e-01 -7.70599765e-01]\n",
      " [ 1.68096102e-01 -9.88589794e-01  1.33422703e-01  4.82262910e-01\n",
      "  -3.88309216e-01 -1.63818328e+00 -1.35621276e+00 -2.27810583e-01\n",
      "  -1.59098470e-01 -9.56176481e-01]\n",
      " [-3.35639558e-01 -3.22318296e-01  5.35302046e-01 -1.15396180e+00\n",
      "   2.36155994e-01 -1.57566672e+00 -2.06845923e+00 -2.25956677e+00\n",
      "  -3.82468231e-01 -1.24832699e+00]\n",
      " [-3.18662163e-01 -1.00241292e+00 -6.56201055e-02 -1.63235140e+00\n",
      "  -1.25525990e-01  4.74015571e-01  3.16902859e-01 -2.48305527e-01\n",
      "  -2.40721168e-01  1.44874754e-01]\n",
      " [-7.92196402e-01 -2.10967526e+00  1.96304059e+00 -3.77768764e+00\n",
      "  -3.07625874e+00  1.89803259e+00  3.46936401e+00  2.28845369e+01\n",
      "  -1.85655935e+01  1.54670811e-01]\n",
      " [-4.52520769e-01 -1.15084724e+00 -8.18409649e-01 -5.14685255e-01\n",
      "  -4.08759769e-01  7.42957994e-01 -5.28073983e-01 -1.46176927e+00\n",
      "  -6.80696611e-01 -1.09940355e+00]\n",
      " [-9.40895950e-01  9.51217327e-02 -7.70331571e-01 -1.00574444e+01\n",
      "  -5.11123018e-01  1.56022872e+00  2.66258777e+01 -3.00563562e-01\n",
      "   1.11690328e+01  5.94936961e+00]\n",
      " [-2.27902566e-01 -4.06080533e-01  6.47985841e-01 -7.12495189e-01\n",
      "  -2.03756994e-01 -1.20625863e+00 -9.92701660e-01 -1.34970274e+00\n",
      "  -4.50451553e-01 -8.67419132e-01]\n",
      " [-3.68001431e-01 -1.09846418e+00 -5.53019511e-01  3.47456322e-01\n",
      "   3.63845828e-02 -9.01266845e-01 -1.04879650e+00 -1.50055638e+00\n",
      "  -8.30116072e-01 -1.44074638e+00]\n",
      " [-2.43308040e-01 -6.55530203e-01 -7.41637405e-02 -5.54468482e-01\n",
      "   3.21988624e-02 -6.86704604e-01 -1.18759962e+00 -1.15870581e+00\n",
      "  -3.25530625e-01 -9.63558700e-01]\n",
      " [-8.25986790e-01  3.46363356e+00 -3.17014181e-01  3.07491755e+00\n",
      "   6.12483111e+00 -9.28913526e-02 -1.72123831e+00  1.64430537e+00\n",
      "   6.19664057e+00  2.51748875e-01]\n",
      " [-3.42461633e-01 -1.36441580e+00  1.82474539e-01  1.81428718e+00\n",
      "   7.03643523e-02 -2.43805249e+00 -1.71348633e+00 -3.50556139e-03\n",
      "   7.09357093e-02 -8.02498982e-01]\n",
      " [-8.40473654e-01 -1.90963959e+00 -7.58620401e-01  1.85092008e+00\n",
      "  -3.16903313e+00 -5.24486593e+00 -1.49258442e+01  2.63995468e+01\n",
      "   3.09257258e+01  6.59261254e-01]\n",
      " [-2.90633417e-01 -9.14169151e-01 -8.62987076e-02  2.07228926e-01\n",
      "  -3.82111563e-01 -1.05628740e+00 -1.22257895e+00  1.02258295e+00\n",
      "   4.54342998e-01 -7.82562927e-01]\n",
      " [-2.37980767e-01  8.34271149e-01 -4.54264272e-01  2.66498015e-01\n",
      "  -3.36099693e-01 -2.73387409e-01 -1.06499614e+00 -8.80137144e-01\n",
      "  -4.44017023e-01 -3.99065002e-01]\n",
      " [-2.95451997e-01 -4.70815344e-01  9.57415886e-02 -8.28848036e-01\n",
      "   4.73707805e-02 -1.10650867e+00 -7.84172635e-01 -8.44045271e-01\n",
      "  -4.49114259e-01 -4.67299856e-01]\n",
      " [ 4.45770049e-01 -1.11703518e+00  1.98181369e-01 -1.28913457e+00\n",
      "  -3.14161558e-01 -1.91856531e+00 -2.22588728e+00  6.36178867e-01\n",
      "   2.70188079e+00 -9.83949883e-01]\n",
      " [-1.57445588e-01 -6.76840022e-01 -1.32457106e-01 -7.39433729e-01\n",
      "  -4.43769324e-02 -6.47252651e-01 -7.43986695e-01 -1.06993216e+00\n",
      "  -3.71365558e-01 -7.70599765e-01]\n",
      " [-8.53166914e-01  5.57322003e-01  4.39487252e-01 -4.27456407e+00\n",
      "  -1.93569591e+00  4.37470421e-01  6.82172775e+00  7.52433891e+00\n",
      "  -1.15913405e+00 -4.26600927e-01]\n",
      " [ 4.35134966e-01 -1.01330035e+00  3.94041257e-01 -3.85652395e-01\n",
      "  -2.50958260e-01 -1.45100873e+00 -1.97055484e+00 -1.00708181e+00\n",
      "  -8.50959751e-01  1.40874818e+00]\n",
      " [-5.18859142e-01 -3.13352361e-01 -4.53628644e-01 -1.63816637e+00\n",
      "  -2.69412279e-01  5.34593318e-01 -4.45230541e-01  2.34756181e+00\n",
      "   1.57958757e+00  5.26183173e+00]\n",
      " [ 3.50590558e-01 -8.36442818e-01 -2.78991607e-02 -1.11876521e+00\n",
      "  -1.20705383e-01 -1.53554868e+00 -1.11000961e+00 -1.66361316e+00\n",
      "   1.04217779e-01 -7.04480764e-01]\n",
      " [-3.56911576e-01 -9.90819771e-01 -3.54487712e-01 -2.07778774e-01\n",
      "   1.94076384e-01 -1.74187897e-01 -1.23290236e+00 -1.90320632e+00\n",
      "  -4.45227944e-01 -1.36801357e+00]] \n",
      "Shape:  (35, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (319,)\n",
      "\n",
      "y_test:\n",
      " [1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0] \n",
      "Shape:  (35,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  6\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.43277803021117167\n",
      "\n",
      " Coefficients \n",
      "[ 1.66904721 -0.30834461  1.67248949  0.11481787  1.30758268 -0.12436522\n",
      " -0.21869508 -0.0224232   0.01248648 -0.10654149]\n",
      "\n",
      " pop_polarity\n",
      "[7.70684722e-01 5.62247885e-01 8.24967333e-01 4.64681995e-05\n",
      " 4.43506423e-01 6.10690298e-01 7.55183633e-01 6.58747244e-01\n",
      " 5.68800298e-01 6.05446073e-01 6.07985457e-01 4.59602424e-01\n",
      " 5.88771973e-01 8.01271930e-01 8.66546146e-01 4.03131870e-01\n",
      " 4.03802436e-02 1.46101896e-01 2.07473115e-05 8.01754399e-01\n",
      " 4.59602424e-01 6.34812054e-01 9.98013536e-01 8.39136061e-01\n",
      " 1.25561782e-01 5.18554005e-01 2.56034934e-01 6.41973627e-01\n",
      " 8.95066023e-01 5.88771973e-01 5.85892508e-03 9.03030337e-01\n",
      " 9.99036661e-02 8.16120154e-01 5.63108233e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.8\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[10  7]\n",
      " [ 2 16]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7428571428571429\n",
      "recall:  0.8888888888888888\n",
      "specificity:  0.5882352941176471\n",
      "precision:  0.6956521739130435\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        17\n",
      "           1       0.70      0.89      0.78        18\n",
      "\n",
      "    accuracy                           0.74        35\n",
      "   macro avg       0.76      0.74      0.74        35\n",
      "weighted avg       0.76      0.74      0.74        35\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  6\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[8.75760137e-001 8.29787817e-001 8.39118171e-001 2.02181717e-049\n",
      " 8.00925239e-001 8.20060429e-001 8.54561006e-001 8.79060888e-001\n",
      " 7.34107191e-001 8.15285194e-001 8.21302130e-001 7.46297899e-001\n",
      " 8.49181462e-001 9.22174781e-001 7.19166026e-001 6.03167258e-001\n",
      " 2.73782688e-109 6.66697247e-001 4.77817739e-091 8.35974319e-001\n",
      " 7.46297899e-001 8.36276939e-001 9.99742927e-001 3.43023341e-001\n",
      " 4.07911775e-228 5.30067279e-001 7.37357650e-001 8.10042245e-001\n",
      " 7.66751606e-001 8.49181462e-001 5.15984455e-014 9.89619661e-001\n",
      " 1.83339062e-001 9.80667273e-001 7.85742769e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.83\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 7 10]\n",
      " [ 0 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7142857142857143\n",
      "recall:  1.0\n",
      "specificity:  0.4117647058823529\n",
      "precision:  0.6428571428571429\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.41      0.58        17\n",
      "           1       0.64      1.00      0.78        18\n",
      "\n",
      "    accuracy                           0.71        35\n",
      "   macro avg       0.82      0.71      0.68        35\n",
      "weighted avg       0.82      0.71      0.69        35\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  6\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.91494165 0.88877036 0.93031958 0.00383922 0.88513914 0.85899632\n",
      " 0.968084   0.79665407 0.88625134 0.97175577 0.1754813  0.02535367\n",
      " 0.42881352 0.54883973 0.05961705 0.10444219 0.014118   0.00619846\n",
      " 0.00890277 0.97810932 0.02535367 0.22883797 0.70242382 0.10137702\n",
      " 0.05617057 0.72873835 0.55618846 0.91977599 0.56404632 0.42881352\n",
      " 0.03540621 0.61599355 0.12126629 0.7067369  0.59365078]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[16  1]\n",
      " [ 0 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9714285714285714\n",
      "recall:  1.0\n",
      "specificity:  0.9411764705882353\n",
      "precision:  0.9473684210526315\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        17\n",
      "           1       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.97      0.97      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  6\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   14.2s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[6.86306331e-01 5.39312732e-01 7.06809339e-01 1.88880645e-05\n",
      " 5.14621064e-01 5.63612543e-01 6.35040748e-01 6.01859691e-01\n",
      " 5.31216715e-01 5.68210631e-01 5.68592678e-01 4.30579117e-01\n",
      " 5.55357789e-01 6.49273815e-01 7.95610580e-01 4.42392404e-01\n",
      " 3.43126805e-01 2.35547430e-01 3.48938548e-04 7.07624570e-01\n",
      " 4.30579117e-01 5.91358764e-01 9.89468047e-01 6.40184311e-01\n",
      " 3.43445458e-01 4.84279072e-01 3.87245242e-01 6.04223074e-01\n",
      " 7.90142039e-01 5.55357789e-01 6.37401856e-02 7.68268062e-01\n",
      " 2.23380254e-01 7.03059399e-01 5.22554385e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1]\n",
      "\n",
      " auc\n",
      "0.81\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[10  7]\n",
      " [ 1 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.7714285714285715\n",
      "recall:  0.9444444444444444\n",
      "specificity:  0.5882352941176471\n",
      "precision:  0.7083333333333334\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.71        17\n",
      "           1       0.71      0.94      0.81        18\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.81      0.77      0.76        35\n",
      "weighted avg       0.81      0.77      0.76        35\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  6\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:10:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:10:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.6140972  0.6965136  0.6732271  0.32797962 0.63138825 0.5714475\n",
      " 0.69358146 0.65267146 0.55918896 0.71979505 0.5814232  0.3975039\n",
      " 0.6732271  0.4999089  0.44155446 0.40217972 0.37482607 0.34181124\n",
      " 0.3277111  0.70240235 0.3975039  0.5990836  0.45207527 0.43378448\n",
      " 0.39026994 0.5140881  0.5271005  0.6749085  0.4776855  0.6732271\n",
      " 0.33653802 0.51761526 0.3277111  0.61023843 0.46527648]\n",
      "\n",
      " yhat\n",
      "[1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[13  4]\n",
      " [ 3 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8\n",
      "recall:  0.8333333333333334\n",
      "specificity:  0.7647058823529411\n",
      "precision:  0.7894736842105263\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.79        17\n",
      "           1       0.79      0.83      0.81        18\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.80      0.80      0.80        35\n",
      "weighted avg       0.80      0.80      0.80        35\n",
      "\n",
      "\n",
      "KFold:  7\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (319, 10)\n",
      "\n",
      "X_test:\n",
      " [[-2.30286170e-01 -7.39076715e-01 -2.78327337e-02 -1.10038326e-01\n",
      "  -2.27722030e-01 -5.47132067e-01 -4.78794899e-01 -1.00885420e+00\n",
      "  -6.10238478e-01 -3.34108773e-01]\n",
      " [-2.02971977e-01 -4.98037046e-01  6.55017594e-01 -7.03792466e-01\n",
      "  -2.24177694e-01 -9.97929401e-01 -6.16633680e-01 -1.20380662e+00\n",
      "  -2.91195761e-01 -7.37812271e-01]\n",
      " [-6.14699560e-01 -9.71813957e-01 -2.13965498e-01 -1.77170260e+00\n",
      "  -3.81254121e-01  3.02921426e-01  3.49360179e+00  2.46875953e+00\n",
      "  -2.46709088e+00  1.38141684e+00]\n",
      " [-1.19347595e-01 -7.99299468e-01  3.30069354e-01 -9.90513353e-01\n",
      "   7.08993040e-02 -9.56133523e-01 -8.35627691e-01 -8.63717816e-01\n",
      "  -3.46883316e-01 -4.53282374e-01]\n",
      " [-1.28925912e-01 -7.67097117e-01 -1.65221834e-01 -9.57164039e-01\n",
      "  -1.25965216e-01 -1.12394479e+00 -1.11604313e+00 -1.09152992e+00\n",
      "  -1.47962503e-01 -9.56335522e-01]\n",
      " [-2.34204169e-01 -7.84873993e-01  7.09332008e-02 -5.55781534e-01\n",
      "   1.97434262e-02  8.74042666e-01 -1.49965961e+00 -8.80366440e-01\n",
      "   3.16183450e-01 -9.45674497e-01]\n",
      " [-1.51426693e+00  3.94948541e+01 -9.41247525e+00  7.81505331e-01\n",
      "   2.05601033e-01  3.33182923e-01 -5.96224843e-01  1.76165877e+00\n",
      "  -8.27582703e-01 -1.08238314e+00]\n",
      " [-3.42461633e-01 -1.36441580e+00  1.82474539e-01  1.81428718e+00\n",
      "   7.03643523e-02 -2.43805249e+00 -1.71348633e+00 -3.50556139e-03\n",
      "   7.09357093e-02 -8.02498982e-01]\n",
      " [-7.79765882e-01  1.78028535e+00 -1.31983824e+00  4.49743244e-01\n",
      "   3.94858554e-01  4.89610526e+00  5.80124842e-01  1.90859821e+00\n",
      "   1.67102594e+00 -1.62410599e-01]\n",
      " [-2.15226795e-01 -7.54430791e-01 -1.16180585e-01 -1.33981157e+00\n",
      "   3.31161682e-02 -8.11472349e-01  3.55631149e-01 -1.24873569e+00\n",
      "   1.09229186e-01 -6.07235863e-01]\n",
      " [-1.91836403e-01 -7.37678004e-01 -1.11286176e-01 -8.26814516e-01\n",
      "  -3.66719959e-02 -1.09410772e+00 -8.57375058e-01 -1.18632070e+00\n",
      "  -3.21392041e-01 -8.15751187e-01]\n",
      " [-8.53166914e-01  5.57322003e-01  4.39487252e-01 -4.27456407e+00\n",
      "  -1.93569591e+00  4.37470421e-01  6.82172775e+00  7.52433891e+00\n",
      "  -1.15913405e+00 -4.26600927e-01]\n",
      " [-2.17848942e-01 -7.12439671e-01 -1.26253764e-01 -9.71026269e-01\n",
      "  -1.60277544e-01 -9.60405452e-01 -9.21351024e-02 -4.35723221e-01\n",
      "  -3.15628553e-01 -6.89988696e-01]\n",
      " [-7.06628733e-01 -1.86207877e+00 -1.09655790e-01 -6.72446978e-01\n",
      "  -7.55391659e-01  5.71844130e+00 -4.29154897e+00  4.27585144e-01\n",
      "   9.40563081e-01 -3.94303690e-01]\n",
      " [-3.01186229e-01 -9.30437414e-01 -3.06394317e-01 -1.26502201e+00\n",
      "  -8.09691338e-02  3.09071598e-01 -9.18332356e-01 -1.20868479e+00\n",
      "  -2.12035651e-01 -1.25849236e+00]\n",
      " [-3.40769228e-01 -8.13568021e-01  1.07041425e-01 -8.15779034e-01\n",
      "  -7.46154889e-02 -4.24088543e-01 -5.90658924e-01 -1.10558139e+00\n",
      "  -1.01344781e+00  1.59063170e-01]\n",
      " [-3.58484278e-01  4.28980862e-01  1.35841178e+00  1.84638517e-02\n",
      "  -1.27562667e-01 -3.71855551e-01 -8.78345469e-01 -1.42320131e+00\n",
      "   1.23760910e-01 -7.49322758e-01]\n",
      " [-2.20866563e-01 -6.41423391e-01 -1.73513930e-01 -4.31133937e-01\n",
      "  -4.87149949e-02 -1.04954496e+00 -8.48593926e-01 -1.24579175e+00\n",
      "  -4.91677542e-01 -4.79416981e-01]\n",
      " [ 6.54983230e-01 -5.81268540e-01  3.07290994e-01 -2.95888589e-01\n",
      "  -1.99206722e-01  3.12314321e-02 -1.20276589e+00 -9.10932508e-01\n",
      "   3.00127633e-01 -8.07966690e-01]\n",
      " [-4.00613390e-01  7.78766213e-02  1.05251952e-02 -1.28969302e+00\n",
      "  -7.63889648e-01 -5.29738530e-01  1.58544622e+00 -1.85169021e-01\n",
      "  -1.23749157e+00 -2.27983952e-01]\n",
      " [-3.12178652e-01 -2.11243263e-02 -4.64816794e-01 -1.58530393e+00\n",
      "  -1.08048050e-01  6.67599640e-01  8.92191130e-01 -6.99467643e-01\n",
      "   1.21006943e-02 -7.42680167e-01]\n",
      " [-1.98172155e-01 -2.32214824e-01  3.06650223e-02 -3.35656308e-01\n",
      "  -7.44916823e-02 -8.67735368e-01 -4.93062447e-01 -1.35479560e+00\n",
      "  -8.26137191e-02 -5.46264770e-01]\n",
      " [-1.57445588e-01 -6.76840022e-01 -1.32457106e-01 -7.39433729e-01\n",
      "  -4.43769324e-02 -6.47252651e-01 -7.43986695e-01 -1.06993216e+00\n",
      "  -3.71365558e-01 -7.70599765e-01]\n",
      " [ 1.85731067e-01 -9.64720661e-01  4.40051451e-01 -3.14892297e+00\n",
      "  -2.27057898e-01 -1.60216762e+00  3.01834675e+00 -1.27494871e+00\n",
      "   1.72358265e+00  6.14109842e-01]\n",
      " [-3.85251944e-01 -1.32346218e+00 -2.49638089e-01 -2.37985219e-01\n",
      "  -3.98311688e-01 -6.99379400e-01 -6.41087880e-01  3.36370475e-01\n",
      "  -3.27362100e-01 -8.34912314e-01]\n",
      " [ 1.06810320e+00 -5.05451334e-01 -1.20040054e-01 -7.78374989e-01\n",
      "  -5.46098567e-02 -1.17421741e+00 -9.96120487e-01 -1.25883624e+00\n",
      "  -6.13359588e-01 -1.00654551e+00]\n",
      " [-1.92675556e-01 -6.12896654e-01 -1.52285890e-01 -7.46817540e-01\n",
      "  -7.03703183e-02 -8.84661434e-01 -7.43965812e-01 -1.12592259e+00\n",
      "  -4.49395464e-01 -6.97305891e-01]\n",
      " [-4.27903348e-01 -2.92420036e-01 -2.58225954e-01 -4.16117454e-01\n",
      "  -2.18541380e-01 -2.48684131e+00 -1.18577993e+00 -2.84355037e+00\n",
      "  -1.24503395e+00  1.76749674e-01]\n",
      " [-6.95875658e-02 -7.09735466e-01  2.53384425e-01 -9.20217786e-01\n",
      "   2.65086454e-01 -1.19403696e+00 -1.16536462e+00 -1.43948484e+00\n",
      "  -3.81842663e-01 -7.42684204e-01]\n",
      " [-2.26804184e-01 -7.05608496e-01 -7.36077173e-02 -1.06007351e+00\n",
      "  -7.84175720e-02 -9.61354888e-01 -1.71382805e-01 -1.29407699e+00\n",
      "  -1.96645754e-01 -8.64645669e-01]\n",
      " [-2.43308040e-01 -6.55530203e-01 -7.41637405e-02 -5.54468482e-01\n",
      "   3.21988624e-02 -6.86704604e-01 -1.18759962e+00 -1.15870581e+00\n",
      "  -3.25530625e-01 -9.63558700e-01]\n",
      " [-1.87214246e-01 -1.29031929e-02 -3.31880587e-01 -8.56027818e-01\n",
      "   4.80363509e-04 -6.56642633e-01 -6.61482790e-01 -1.02148498e+00\n",
      "  -7.29143966e-01 -9.22787631e-01]\n",
      " [ 6.74342452e-02 -1.24582782e+00 -2.40599789e-01  7.37967158e-01\n",
      "  -2.24699497e-01  9.37770660e-01 -8.21709420e-01 -2.76336482e-01\n",
      "  -1.55216098e+00 -9.16181401e-01]\n",
      " [-1.77929450e-01 -5.41812171e-01  2.37439919e-01 -2.15456138e+00\n",
      "   1.81862482e+00 -7.34514923e-01 -2.78495519e+00 -3.55698160e+00\n",
      "   1.13743223e+00  1.26875088e+01]\n",
      " [-1.51426693e+00  3.94948541e+01 -9.41247525e+00  7.81505331e-01\n",
      "   2.05601033e-01  3.33182923e-01 -5.96224843e-01  1.76165877e+00\n",
      "  -8.27582703e-01 -1.08238314e+00]] \n",
      "Shape:  (35, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (319,)\n",
      "\n",
      "y_test:\n",
      " [1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0] \n",
      "Shape:  (35,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  7\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.9068914619183752\n",
      "\n",
      " Coefficients \n",
      "[ 2.16491656 -0.0083857   1.82592743  0.21371109  1.21589032 -0.12697959\n",
      " -0.07222685 -0.01143809  0.06165226 -0.1077474 ]\n",
      "\n",
      " pop_polarity\n",
      "[5.44206623e-01 8.16265698e-01 9.37576096e-02 7.94377803e-01\n",
      " 5.75552598e-01 6.38757625e-01 3.65983917e-09 8.18709608e-01\n",
      " 3.93622746e-02 5.38142088e-01 5.88019281e-01 1.68024569e-02\n",
      " 4.99196856e-01 1.00627633e-01 3.77031430e-01 5.33922615e-01\n",
      " 9.35336851e-01 5.48861802e-01 9.41820307e-01 2.23892863e-01\n",
      " 2.40834708e-01 6.43033773e-01 5.80826510e-01 7.70591167e-01\n",
      " 3.30484872e-01 9.55960834e-01 5.49351065e-01 3.76356985e-01\n",
      " 8.40136416e-01 5.48791660e-01 6.08464464e-01 4.77680710e-01\n",
      " 6.11819441e-01 8.51795890e-01 3.65983917e-09]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0]\n",
      "\n",
      " auc\n",
      "0.8\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[10  4]\n",
      " [ 3 18]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8\n",
      "recall:  0.8571428571428571\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.8181818181818182\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        14\n",
      "           1       0.82      0.86      0.84        21\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.79      0.79      0.79        35\n",
      "weighted avg       0.80      0.80      0.80        35\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  7\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[7.66762587e-01 8.29902239e-01 3.79346495e-04 8.56513026e-01\n",
      " 8.31488678e-01 7.02645333e-01 1.80789944e-87 3.24616673e-01\n",
      " 7.86488205e-05 7.19178045e-01 8.08030887e-01 5.82075173e-14\n",
      " 7.48105916e-01 9.99389340e-06 7.23486330e-01 7.19790180e-01\n",
      " 8.32231879e-01 7.88352809e-01 9.99551298e-01 2.93840874e-01\n",
      " 4.50464716e-01 8.03688714e-01 8.27853616e-01 8.70143232e-02\n",
      " 6.38959679e-01 9.99998870e-01 8.06145226e-01 2.80674825e-01\n",
      " 8.81559931e-01 7.67407887e-01 8.09674488e-01 7.96661491e-01\n",
      " 6.97282225e-01 9.99892153e-01 1.80789944e-87]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.86\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[10  4]\n",
      " [ 1 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8571428571428571\n",
      "recall:  0.9523809523809523\n",
      "specificity:  0.7142857142857143\n",
      "precision:  0.8333333333333334\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.83      0.95      0.89        21\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.87      0.83      0.84        35\n",
      "weighted avg       0.86      0.86      0.85        35\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  7\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.77732133 0.86374378 0.00795193 0.92195948 0.84749614 0.86684439\n",
      " 0.10923841 0.1402253  0.06948746 0.46345035 0.97687393 0.03908897\n",
      " 0.32619088 0.53726324 0.7182251  0.66114619 0.81118233 0.97739048\n",
      " 0.86916474 0.02037007 0.0725449  0.75178214 0.26243342 0.15466517\n",
      " 0.08478308 0.87953499 0.8338758  0.17068618 0.96603179 0.6789921\n",
      " 0.20534686 0.68254459 0.61880923 0.6815694  0.10923841]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0]\n",
      "\n",
      " auc\n",
      "1.0\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[14  0]\n",
      " [ 1 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9714285714285714\n",
      "recall:  0.9523809523809523\n",
      "specificity:  1.0\n",
      "precision:  1.0\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.95      0.98        21\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.97      0.98      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  7\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   14.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[4.84526745e-01 7.10371812e-01 1.92916441e-01 6.95562682e-01\n",
      " 5.49782112e-01 6.07140057e-01 2.70019643e-04 5.93018832e-01\n",
      " 1.43974238e-01 5.10662621e-01 5.47875266e-01 1.27926349e-01\n",
      " 4.89175524e-01 3.41646704e-01 4.60304353e-01 5.22756438e-01\n",
      " 8.39976899e-01 5.05452085e-01 8.14320326e-01 3.30137351e-01\n",
      " 3.60394244e-01 5.60748826e-01 5.41015676e-01 6.47641521e-01\n",
      " 3.68560209e-01 8.29950734e-01 5.22604351e-01 4.04241244e-01\n",
      " 7.31553597e-01 5.21505874e-01 5.65795973e-01 5.00000000e-01\n",
      " 4.90556582e-01 7.44229389e-01 2.70019643e-04]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.81\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 9  5]\n",
      " [ 1 20]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8285714285714286\n",
      "recall:  0.9523809523809523\n",
      "specificity:  0.6428571428571429\n",
      "precision:  0.8\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75        14\n",
      "           1       0.80      0.95      0.87        21\n",
      "\n",
      "    accuracy                           0.83        35\n",
      "   macro avg       0.85      0.80      0.81        35\n",
      "weighted avg       0.84      0.83      0.82        35\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  7\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.55560565 0.6814991  0.33510563 0.68835473 0.60694104 0.6190482\n",
      " 0.39007592 0.39119387 0.4651379  0.56001794 0.7079611  0.31548563\n",
      " 0.5344521  0.42349392 0.52938354 0.4516297  0.4703393  0.6861892\n",
      " 0.5994419  0.31548563 0.46487826 0.61407685 0.6263344  0.4304145\n",
      " 0.3638147  0.6287129  0.6861892  0.44877884 0.6696451  0.61158144\n",
      " 0.56975484 0.6459407  0.4591487  0.54131675 0.39007592]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0]\n",
      "\n",
      " auc\n",
      "0.88\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[11  3]\n",
      " [ 4 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8\n",
      "recall:  0.8095238095238095\n",
      "specificity:  0.7857142857142857\n",
      "precision:  0.85\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76        14\n",
      "           1       0.85      0.81      0.83        21\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.79      0.80      0.79        35\n",
      "weighted avg       0.80      0.80      0.80        35\n",
      "\n",
      "\n",
      "KFold:  8\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [-0.27507029 -0.51975374  1.41061532 ... -1.61906976 -0.28749498\n",
      "  -1.14512376]\n",
      " [-0.12828967 -0.77284035 -0.12173434 ... -1.22427973 -0.41111378\n",
      "  -0.94936041]\n",
      " [-0.31217865 -0.02112433 -0.46481679 ... -0.69946764  0.01210069\n",
      "  -0.74268017]] \n",
      "Shape:  (319, 10)\n",
      "\n",
      "X_test:\n",
      " [[-2.62506274e-01  2.19596201e-01  5.59157758e-01 -8.35929660e-01\n",
      "  -2.91854271e-01 -3.31228628e-01 -8.69135452e-02 -6.74598929e-01\n",
      "  -1.55631337e-01 -3.49805062e-01]\n",
      " [-3.68001431e-01 -1.09846418e+00 -5.53019511e-01  3.47456322e-01\n",
      "   3.63845828e-02 -9.01266845e-01 -1.04879650e+00 -1.50055638e+00\n",
      "  -8.30116072e-01 -1.44074638e+00]\n",
      " [-5.45382844e-01  1.41231484e-01  1.70356344e-01 -1.80595784e+00\n",
      "  -3.43820541e-01 -8.27321305e-01  7.85477720e-01  9.52292353e-02\n",
      "   3.13379434e+00  1.59728457e-01]\n",
      " [ 9.32005062e-02 -1.12046437e-01  2.39976100e-01 -1.00924800e+00\n",
      "   1.54167110e-01 -1.23730986e-01 -1.24652310e+00 -8.31111274e-01\n",
      "   6.49310426e-01 -9.70346885e-01]\n",
      " [-2.66018601e-01 -7.75355558e-01 -6.49965773e-03 -1.27748049e-01\n",
      "  -2.00399621e-01 -5.58553051e-01 -7.22466114e-01 -6.68885966e-01\n",
      "  -7.79880951e-01 -8.32603122e-01]\n",
      " [-3.90326516e-01 -9.42464261e-01 -4.71785179e-01  1.59010826e-01\n",
      "  -4.63861845e-01 -9.02084396e-01 -1.04080293e+00 -1.14125016e+00\n",
      "   1.08870289e+00 -1.57565535e+00]\n",
      " [-2.74467436e-01 -9.69562156e-01 -4.56654300e-02 -1.15054373e+00\n",
      "  -2.40389132e-02 -1.19577500e+00 -1.78802193e+00 -1.63058807e+00\n",
      "  -4.18176571e-01 -1.37662676e+00]\n",
      " [-3.85251944e-01 -1.32346218e+00 -2.49638089e-01 -2.37985219e-01\n",
      "  -3.98311688e-01 -6.99379400e-01 -6.41087880e-01  3.36370475e-01\n",
      "  -3.27362100e-01 -8.34912314e-01]\n",
      " [-2.47794515e-01 -8.95609475e-01 -1.20200664e-01 -7.58439437e-01\n",
      "   1.03405621e-01  3.67802154e-01 -6.95406456e-01 -7.21994039e-02\n",
      "  -4.39481096e-01 -7.23661561e-01]\n",
      " [-1.82754342e-01 -6.73162612e-01 -1.13564665e-01 -7.20025103e-01\n",
      "  -5.82390193e-02 -1.09340169e+00 -9.42144644e-01 -1.12340444e+00\n",
      "  -3.57760499e-01 -7.94213281e-01]\n",
      " [-2.18898973e-01 -6.77329376e-01 -3.17946528e-02 -1.02083202e+00\n",
      "  -1.26311816e-01 -1.14745253e+00 -2.67582805e-01 -1.01592884e+00\n",
      "  -8.88691063e-02 -6.90927524e-01]\n",
      " [-2.76802052e-01 -7.63420288e-01 -1.47956292e-02 -8.43708422e-01\n",
      "   3.56895937e-02 -1.32161909e+00 -1.06024445e+00 -1.62904938e+00\n",
      "  -3.32543077e-01 -8.61006476e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-4.15650411e-01 -4.50184913e-01 -3.38925282e-01  8.07758836e-01\n",
      "   3.51132419e-01 -1.29607773e+00 -6.80279975e-01 -1.76458161e+00\n",
      "  -1.02462095e+00 -3.64516380e-01]\n",
      " [-1.23857933e-01 -2.86779682e-01 -5.70135300e-01  1.96939136e-01\n",
      "   2.27578571e-02 -4.96470317e-01 -8.00391021e-01 -1.23638629e+00\n",
      "  -9.15155904e-01 -6.70782751e-01]\n",
      " [-4.21592880e-01 -2.44064264e-01  1.25091032e-01 -9.89593358e-02\n",
      "   2.28356929e-01  5.65802938e-01  1.69747864e-01 -1.52130339e+00\n",
      "  -7.22571637e-01  7.60118973e-01]\n",
      " [-3.19050123e-01 -1.10509215e+00 -1.04509303e-02  2.34138042e-02\n",
      "   1.50709368e+00  1.38643134e+00 -6.64199509e-01 -9.09890283e-01\n",
      "  -3.68003388e-01 -6.84310580e-01]\n",
      " [-1.51426693e+00  3.94948541e+01 -9.41247525e+00  7.81505331e-01\n",
      "   2.05601033e-01  3.33182923e-01 -5.96224843e-01  1.76165877e+00\n",
      "  -8.27582703e-01 -1.08238314e+00]\n",
      " [-9.40895950e-01  9.51217327e-02 -7.70331571e-01 -1.00574444e+01\n",
      "  -5.11123018e-01  1.56022872e+00  2.66258777e+01 -3.00563562e-01\n",
      "   1.11690328e+01  5.94936961e+00]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-1.33630444e-01 -1.93324220e+00 -1.35454551e+00  2.62182353e+00\n",
      "   2.14056558e+00  3.88472833e+01 -3.70960350e+00 -5.83634687e-01\n",
      "   3.47614234e+00 -1.64130508e+00]\n",
      " [-2.71406578e-01 -8.82895261e-01 -1.65302661e-01 -5.72677016e-01\n",
      "  -2.59765543e-01 -7.51351701e-01 -4.57938828e-01 -5.54345179e-01\n",
      "  -3.53200255e-01 -8.58531107e-01]\n",
      " [-6.14699560e-01 -9.71813957e-01 -2.13965498e-01 -1.77170260e+00\n",
      "  -3.81254121e-01  3.02921426e-01  3.49360179e+00  2.46875953e+00\n",
      "  -2.46709088e+00  1.38141684e+00]\n",
      " [-9.40895950e-01  9.51217327e-02 -7.70331571e-01 -1.00574444e+01\n",
      "  -5.11123018e-01  1.56022872e+00  2.66258777e+01 -3.00563562e-01\n",
      "   1.11690328e+01  5.94936961e+00]\n",
      " [-4.52520769e-01 -1.15084724e+00 -8.18409649e-01 -5.14685255e-01\n",
      "  -4.08759769e-01  7.42957994e-01 -5.28073983e-01 -1.46176927e+00\n",
      "  -6.80696611e-01 -1.09940355e+00]\n",
      " [-3.90326516e-01 -9.42464261e-01 -4.71785179e-01  1.59010826e-01\n",
      "  -4.63861845e-01 -9.02084396e-01 -1.04080293e+00 -1.14125016e+00\n",
      "   1.08870289e+00 -1.57565535e+00]\n",
      " [-2.49789706e-01 -6.83404951e-01  4.34946333e-01 -9.98083331e-01\n",
      "  -1.49756532e-01 -8.80562049e-01 -6.08125338e-01 -1.40799622e+00\n",
      "   8.87391698e-02 -6.98227542e-01]\n",
      " [-2.89630691e-01 -5.79678359e-02 -7.03604103e-02 -1.03998795e+00\n",
      "   3.79831421e-01 -5.38161258e-01 -1.52150654e-01 -3.55567838e-01\n",
      "  -6.59379579e-01 -3.15757523e-01]\n",
      " [-2.35883756e-01 -7.80471166e-01  4.01585568e-01 -9.71509448e-01\n",
      "  -2.66133739e-01 -6.54762966e-01 -5.86410625e-01  4.93556548e-01\n",
      "  -1.80354310e+00 -8.23437569e-01]\n",
      " [-6.90976211e-02 -7.87510315e-01  2.89590494e-02 -9.59495584e-01\n",
      "   9.91931321e-02 -1.25667219e+00 -1.06637497e+00 -1.44966175e+00\n",
      "  -4.12106113e-01 -8.38361895e-01]\n",
      " [-2.89630691e-01 -5.79678359e-02 -7.03604103e-02 -1.03998795e+00\n",
      "   3.79831421e-01 -5.38161258e-01 -1.52150654e-01 -3.55567838e-01\n",
      "  -6.59379579e-01 -3.15757523e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [ 9.16033749e-03  1.06415521e+00 -3.98155967e-01  1.46983145e-01\n",
      "   2.58624239e-01 -8.32569364e-01 -1.06078725e+00 -1.14434680e+00\n",
      "  -2.89116467e-01 -8.45972841e-01]\n",
      " [-2.00075160e-01 -7.27675614e-01  1.26510679e-02 -9.51570383e-01\n",
      "  -1.52333440e-02 -1.03174468e+00 -7.19255065e-01 -1.21894414e+00\n",
      "  -2.03544967e-01 -7.77466577e-01]\n",
      " [-1.07719556e-01 -2.54781577e-01  1.75728844e-02 -8.30753074e-01\n",
      "  -1.41898591e-01 -9.85108585e-01 -1.13633665e+00 -1.22859434e+00\n",
      "  -4.42062974e-01 -6.99880303e-01]] \n",
      "Shape:  (35, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (319,)\n",
      "\n",
      "y_test:\n",
      " [1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1] \n",
      "Shape:  (35,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  8\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.5101025609950813\n",
      "\n",
      " Coefficients \n",
      "[ 1.83397498 -0.14422029  1.56942211  0.08436629  0.96052835 -0.09303864\n",
      " -0.16254419 -0.05250244  0.0393248  -0.10693962]\n",
      "\n",
      " pop_polarity\n",
      "[6.53701261e-01 4.12049073e-01 3.37315145e-01 8.21099315e-01\n",
      " 5.45739934e-01 3.27821471e-01 6.39456997e-01 3.60775696e-01\n",
      " 5.43445440e-01 5.89480120e-01 5.55511669e-01 6.25336299e-01\n",
      " 6.97797999e-05 5.02183305e-01 4.36580759e-01 5.17333836e-01\n",
      " 8.32434295e-01 1.84184123e-10 2.17761022e-04 6.97797999e-05\n",
      " 1.22044684e-01 4.58543051e-01 9.12078591e-02 2.17761022e-04\n",
      " 1.55769033e-01 3.27821471e-01 7.18690310e-01 5.63472510e-01\n",
      " 6.52530310e-01 7.30378339e-01 5.63472510e-01 6.97797999e-05\n",
      " 5.98311995e-01 6.28338531e-01 6.38488438e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.92\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[16  4]\n",
      " [ 0 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8857142857142857\n",
      "recall:  1.0\n",
      "specificity:  0.8\n",
      "precision:  0.7894736842105263\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        20\n",
      "           1       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.89      0.90      0.89        35\n",
      "weighted avg       0.91      0.89      0.89        35\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  8\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[7.52371763e-001 7.07072457e-001 6.24997079e-002 9.26605573e-001\n",
      " 7.47705927e-001 6.83985270e-001 7.33486276e-001 6.28571747e-001\n",
      " 7.14551882e-001 8.05777449e-001 7.65537632e-001 7.58168995e-001\n",
      " 4.69690230e-048 6.41490721e-001 7.87910370e-001 6.38170336e-001\n",
      " 9.01621206e-001 2.92947865e-095 1.91158204e-089 4.69690230e-048\n",
      " 8.34662291e-151 7.51344745e-001 3.33679370e-004 1.91158204e-089\n",
      " 6.07303861e-001 6.83985270e-001 7.90145870e-001 7.56442937e-001\n",
      " 4.91911423e-001 8.50490341e-001 7.56442937e-001 4.69690230e-048\n",
      " 8.66718136e-001 8.01950257e-001 8.32305793e-001]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.82\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 9 11]\n",
      " [ 1 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6571428571428571\n",
      "recall:  0.9333333333333333\n",
      "specificity:  0.45\n",
      "precision:  0.56\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.45      0.60        20\n",
      "           1       0.56      0.93      0.70        15\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.73      0.69      0.65        35\n",
      "weighted avg       0.75      0.66      0.64        35\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  8\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[5.13432009e-01 8.84020892e-04 1.48605121e-01 7.60166214e-01\n",
      " 8.01708124e-01 4.11760178e-02 6.50608248e-01 8.55236590e-02\n",
      " 6.59719608e-01 9.07600150e-01 2.80763431e-01 8.93015986e-01\n",
      " 2.75461564e-03 4.86710339e-01 4.71553266e-02 5.47036333e-01\n",
      " 6.97310378e-01 7.83748260e-03 1.43919902e-02 2.75461564e-03\n",
      " 4.43892659e-02 9.44758868e-02 2.47857795e-02 1.43919902e-02\n",
      " 2.44167963e-03 4.11760178e-02 6.50122781e-01 1.28850921e-01\n",
      " 7.63445203e-01 9.82783781e-01 1.28850921e-01 2.75461564e-03\n",
      " 9.00949170e-01 9.79073874e-01 9.54981483e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[19  1]\n",
      " [ 1 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9428571428571428\n",
      "recall:  0.9333333333333333\n",
      "specificity:  0.95\n",
      "precision:  0.9333333333333333\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        20\n",
      "           1       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.94      0.94      0.94        35\n",
      "weighted avg       0.94      0.94      0.94        35\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  8\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.6s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[6.52436253e-01 3.78617533e-01 4.26280697e-01 7.95882196e-01\n",
      " 5.10477743e-01 3.18728623e-01 6.42422287e-01 3.62267412e-01\n",
      " 5.52218325e-01 5.72719962e-01 5.44879923e-01 6.01091495e-01\n",
      " 1.30913850e-06 4.31086569e-01 4.30867294e-01 4.84756660e-01\n",
      " 7.53374682e-01 1.82576529e-04 7.97654566e-04 1.30913850e-06\n",
      " 3.00546712e-01 4.55078473e-01 1.55270652e-01 7.97654566e-04\n",
      " 2.07996412e-01 3.18728623e-01 6.72335256e-01 6.02496602e-01\n",
      " 6.51770238e-01 6.86264035e-01 6.02496602e-01 1.30913850e-06\n",
      " 6.21489278e-01 6.06104492e-01 6.38616406e-01]\n",
      "\n",
      " yhat\n",
      "[1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.91\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[15  5]\n",
      " [ 1 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8285714285714286\n",
      "recall:  0.9333333333333333\n",
      "specificity:  0.75\n",
      "precision:  0.7368421052631579\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83        20\n",
      "           1       0.74      0.93      0.82        15\n",
      "\n",
      "    accuracy                           0.83        35\n",
      "   macro avg       0.84      0.84      0.83        35\n",
      "weighted avg       0.85      0.83      0.83        35\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  8\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.45547515 0.40260646 0.37276804 0.5742092  0.526677   0.4144144\n",
      " 0.530583   0.36430824 0.57942224 0.71595776 0.5776663  0.6309655\n",
      " 0.33664733 0.4278126  0.50723696 0.45819935 0.5131325  0.4064884\n",
      " 0.35868078 0.33664733 0.4759037  0.4187326  0.3294078  0.35868078\n",
      " 0.3666072  0.4144144  0.6586751  0.476551   0.50643957 0.6528726\n",
      " 0.476551   0.33664733 0.6487767  0.6826244  0.69438326]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1]\n",
      "\n",
      " auc\n",
      "0.89\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[17  3]\n",
      " [ 3 12]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8285714285714286\n",
      "recall:  0.8\n",
      "specificity:  0.85\n",
      "precision:  0.8\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        20\n",
      "           1       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.83        35\n",
      "   macro avg       0.82      0.82      0.83        35\n",
      "weighted avg       0.83      0.83      0.83        35\n",
      "\n",
      "\n",
      "KFold:  9\n",
      "\n",
      "X_train:\n",
      " [[-0.24978971 -0.68340495  0.43494633 ... -1.40799622  0.08873917\n",
      "  -0.69822754]\n",
      " [ 0.16571306 -1.29377149 -0.67864778 ... -1.67779518 -1.34066723\n",
      "  -0.91362517]\n",
      " [-0.45252077 -1.15084724 -0.81840965 ... -1.46176927 -0.68069661\n",
      "  -1.09940355]\n",
      " ...\n",
      " [ 0.00916034  1.06415521 -0.39815597 ... -1.1443468  -0.28911647\n",
      "  -0.84597284]\n",
      " [-0.20007516 -0.72767561  0.01265107 ... -1.21894414 -0.20354497\n",
      "  -0.77746658]\n",
      " [-0.10771956 -0.25478158  0.01757288 ... -1.22859434 -0.44206297\n",
      "  -0.6998803 ]] \n",
      "Shape:  (319, 10)\n",
      "\n",
      "X_test:\n",
      " [[-3.35639558e-01 -3.22318296e-01  5.35302046e-01 -1.15396180e+00\n",
      "   2.36155994e-01 -1.57566672e+00 -2.06845923e+00 -2.25956677e+00\n",
      "  -3.82468231e-01 -1.24832699e+00]\n",
      " [ 1.19171879e-01 -4.02088994e-01 -1.43516664e-01 -1.89699004e+00\n",
      "   6.50494131e-01  8.09796757e-02  3.33175380e-01 -1.30691446e+00\n",
      "  -1.04573729e-01 -5.87825297e-01]\n",
      " [-2.63207998e-01 -3.66939477e-01 -1.06865104e-01 -1.22574428e+00\n",
      "  -1.71830501e-01 -8.28041449e-01  4.26908071e-01 -1.10406518e+00\n",
      "  -6.99577247e-02 -4.51076822e-01]\n",
      " [-2.83817985e-01 -2.49196261e-01  2.99278700e-01 -7.85238112e-01\n",
      "   1.84401102e+00 -3.24082329e-01 -7.85401351e-01 -1.07499987e+00\n",
      "  -4.31016838e-01 -4.36317671e-01]\n",
      " [-6.59192470e-01 -2.36242143e+00 -5.10736393e+00  2.35416497e+01\n",
      "  -2.05457825e+00 -1.24997755e+00  6.78791690e+00  1.16109552e+00\n",
      "  -1.24122158e-01  1.45984070e+00]\n",
      " [-3.85251944e-01 -1.32346218e+00 -2.49638089e-01 -2.37985219e-01\n",
      "  -3.98311688e-01 -6.99379400e-01 -6.41087880e-01  3.36370475e-01\n",
      "  -3.27362100e-01 -8.34912314e-01]\n",
      " [-3.96557440e-01 -9.35000401e-01 -2.95718534e-01  4.74334530e-02\n",
      "  -5.22142346e-01 -1.39214529e+00  7.57594616e-01  5.30552874e-01\n",
      "   3.14212772e+00 -1.04116615e-01]\n",
      " [-8.50559656e-02 -6.83151300e-01  7.94238131e-02 -1.76160284e-01\n",
      "  -6.91715738e-01 -1.86869143e+00 -2.75158654e+00  1.72312891e+00\n",
      "   2.67785460e+00  1.04953638e+00]\n",
      " [-5.12479702e-01 -4.29541619e-01 -6.59578081e-01 -1.93389612e+00\n",
      "  -5.24606588e-01  2.53029381e+00 -1.79492356e-01  3.61208787e-01\n",
      "  -1.07852723e+00 -1.57117874e+00]\n",
      " [-7.79765882e-01  1.78028535e+00 -1.31983824e+00  4.49743244e-01\n",
      "   3.94858554e-01  4.89610526e+00  5.80124842e-01  1.90859821e+00\n",
      "   1.67102594e+00 -1.62410599e-01]\n",
      " [-2.18898973e-01 -6.77329376e-01 -3.17946528e-02 -1.02083202e+00\n",
      "  -1.26311816e-01 -1.14745253e+00 -2.67582805e-01 -1.01592884e+00\n",
      "  -8.88691063e-02 -6.90927524e-01]\n",
      " [-2.37848159e-01  1.14125535e-01 -1.73509062e-01  3.42650457e-01\n",
      "   6.97409418e-02 -5.84136016e-01 -8.97977508e-01 -9.63816168e-01\n",
      "  -5.42768582e-01  3.61656558e-01]\n",
      " [-5.54222072e-02 -7.70396674e-01 -8.18876249e-02 -8.76819166e-01\n",
      "   2.29966618e-02 -1.09793166e+00 -9.21236046e-01 -9.52368884e-01\n",
      "  -7.24597123e-01 -9.41996511e-01]\n",
      " [-3.46411864e-01 -9.29144789e-01 -5.93748288e-02 -1.08620553e+00\n",
      "   3.00756077e-01  9.56671585e-03 -1.04368517e+00 -1.32372826e+00\n",
      "  -6.36597137e-01 -3.12093773e-01]\n",
      " [-2.71406578e-01 -8.82895261e-01 -1.65302661e-01 -5.72677016e-01\n",
      "  -2.59765543e-01 -7.51351701e-01 -4.57938828e-01 -5.54345179e-01\n",
      "  -3.53200255e-01 -8.58531107e-01]\n",
      " [-2.15012187e-01 -7.49587353e-01  2.78661448e-01 -8.53033249e-01\n",
      "  -2.43905413e-01 -1.25301489e+00 -1.14539151e+00 -9.02017170e-01\n",
      "   3.07558233e-01 -9.58698865e-01]\n",
      " [-2.66686145e-01 -9.00708894e-01 -4.50156550e-01  4.02516496e-01\n",
      "   3.89111533e-01  1.52921724e+00 -4.43842031e-01 -7.02148571e-01\n",
      "  -2.61542858e-01 -7.10844302e-02]\n",
      " [-5.12479702e-01 -4.29541619e-01 -6.59578081e-01 -1.93389612e+00\n",
      "  -5.24606588e-01  2.53029381e+00 -1.79492356e-01  3.61208787e-01\n",
      "  -1.07852723e+00 -1.57117874e+00]\n",
      " [-2.36513483e-01 -7.96601969e-01 -2.70436203e-01 -4.94635254e-01\n",
      "  -6.31044943e-02  1.62500937e-01 -8.01823654e-01 -9.30005948e-01\n",
      "  -3.36534630e-01 -8.48162959e-01]\n",
      " [-3.35639558e-01 -3.22318296e-01  5.35302046e-01 -1.15396180e+00\n",
      "   2.36155994e-01 -1.57566672e+00 -2.06845923e+00 -2.25956677e+00\n",
      "  -3.82468231e-01 -1.24832699e+00]\n",
      " [-2.46314740e-01  1.23969337e-01 -2.48930747e-01 -8.44601418e-01\n",
      "   5.47087094e-02 -9.91317741e-01 -1.03469662e+00 -1.24048617e+00\n",
      "  -3.62584388e-01 -8.87294571e-01]\n",
      " [-3.58204802e-01 -4.25102377e-01  2.43442207e-01 -1.23608439e+00\n",
      "  -6.04407962e-02 -7.85869608e-01 -6.76102054e-01 -1.41357509e+00\n",
      "  -8.22012275e-01 -1.44590310e+00]\n",
      " [-6.16525317e-01  1.34561686e+00  2.73893820e-01  7.11308496e-01\n",
      "   1.66147585e-01 -1.64218284e+00 -4.77629926e+00 -9.01458079e+00\n",
      "  -4.37165640e+00  1.61050026e+01]\n",
      " [-1.32354759e-01 -9.83779462e-01 -4.14194387e-01  4.02564390e-01\n",
      "  -1.52008968e-01 -7.87220148e-01 -7.53778081e-01 -1.38924572e+00\n",
      "  -5.14753683e-01 -7.89986714e-01]\n",
      " [ 4.49302823e-01 -7.18756253e-01  1.99836304e+00 -1.27722458e-01\n",
      "  -1.41308786e-01 -1.22968220e+00 -1.48163970e+00 -2.02684012e+00\n",
      "   2.31189365e-01 -7.77598868e-01]\n",
      " [-5.47268633e-02 -6.70644430e-01 -6.27036578e-02 -7.77218673e-01\n",
      "  -7.86464743e-02 -1.07630427e+00 -8.11564439e-01 -1.13239906e+00\n",
      "  -3.56333721e-01 -8.48467208e-01]\n",
      " [-2.49485411e-01 -8.18633144e-01 -6.85226244e-02  2.40552141e-01\n",
      "  -2.77801719e-01 -1.84996790e-01 -1.35094977e+00 -9.61031642e-02\n",
      "   7.97747945e-01 -6.45207904e-01]\n",
      " [-3.58204802e-01 -4.25102377e-01  2.43442207e-01 -1.23608439e+00\n",
      "  -6.04407962e-02 -7.85869608e-01 -6.76102054e-01 -1.41357509e+00\n",
      "  -8.22012275e-01 -1.44590310e+00]\n",
      " [-2.49789694e-01 -5.76402123e-01  6.27035865e-01 -8.64538976e-01\n",
      "  -1.65816343e-01 -1.07426141e+00 -1.06751678e+00 -1.62689305e+00\n",
      "  -4.00067810e-01 -8.95420051e-01]\n",
      " [-2.09443339e-01 -6.62345301e-01 -6.63908606e-02 -8.45308377e-01\n",
      "  -3.51501778e-02 -9.68122928e-01 -7.62429469e-01 -1.18067800e+00\n",
      "  -3.48298913e-01 -7.39877864e-01]\n",
      " [-2.22623236e-01 -9.73361294e-01  4.44715330e-02 -7.12408488e-01\n",
      "  -1.93489361e-01 -1.40873971e+00 -1.20513403e+00 -1.74946437e+00\n",
      "  -1.12806182e-01 -5.85825445e-01]\n",
      " [-2.50140320e-01 -1.41379208e-01 -2.63668153e-02 -3.38114012e-01\n",
      "   6.00537805e-01 -1.14730371e+00 -1.13990819e+00 -9.91107132e-01\n",
      "  -2.02598270e-01 -8.57203978e-01]\n",
      " [-2.75070291e-01 -5.19753741e-01  1.41061532e+00 -4.51938679e-01\n",
      "  -2.00708480e-01 -8.02841462e-01 -7.94703498e-01 -1.61906976e+00\n",
      "  -2.87494980e-01 -1.14512376e+00]\n",
      " [-1.28289670e-01 -7.72840353e-01 -1.21734339e-01 -8.47865447e-01\n",
      "  -8.92008444e-02 -1.20007632e+00 -9.53714873e-01 -1.22427973e+00\n",
      "  -4.11113784e-01 -9.49360406e-01]\n",
      " [-3.12178652e-01 -2.11243263e-02 -4.64816794e-01 -1.58530393e+00\n",
      "  -1.08048050e-01  6.67599640e-01  8.92191130e-01 -6.99467643e-01\n",
      "   1.21006943e-02 -7.42680167e-01]] \n",
      "Shape:  (35, 10)\n",
      "\n",
      "y_train:\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1] \n",
      "Shape:  (319,)\n",
      "\n",
      "y_test:\n",
      " [0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0] \n",
      "Shape:  (35,)\n",
      "\n",
      " train_model() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " logistic_baseline() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  9\n",
      "\n",
      " logistic_regression() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intercept \n",
      "0.49565020389772496\n",
      "\n",
      " Coefficients \n",
      "[ 1.84494385  0.00610346  1.93634133 -0.02908202  1.00614148 -0.08920296\n",
      " -0.30237411 -0.06871222  0.00748609 -0.1449877 ]\n",
      "\n",
      " pop_polarity\n",
      "[9.07335896e-01 7.70493530e-01 4.37616289e-01 9.44195189e-01\n",
      " 1.66256295e-07 3.21106072e-01 1.90964632e-01 6.33134146e-01\n",
      " 1.01766364e-01 2.16510971e-02 5.69859652e-01 5.28748402e-01\n",
      " 7.00957597e-01 6.26273162e-01 4.47730968e-01 7.45502772e-01\n",
      " 3.91898382e-01 1.01766364e-01 4.73520302e-01 9.07335896e-01\n",
      " 5.62674978e-01 7.01376858e-01 4.71435348e-01 4.45980512e-01\n",
      " 9.97164493e-01 6.79660473e-01 5.35514481e-01 7.01376858e-01\n",
      " 8.53332559e-01 6.15040369e-01 6.64965648e-01 7.74550468e-01\n",
      " 9.57493573e-01 6.38198971e-01 2.28539243e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.65\n",
      "\n",
      " model_logr_baseline[\"con_matrix\"]\n",
      "[[ 9  8]\n",
      " [ 4 14]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6571428571428571\n",
      "recall:  0.7777777777777778\n",
      "specificity:  0.5294117647058824\n",
      "precision:  0.6363636363636364\n",
      "\n",
      " model_logr_baseline[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60        17\n",
      "           1       0.64      0.78      0.70        18\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.66      0.65      0.65        35\n",
      "weighted avg       0.66      0.66      0.65        35\n",
      "\n",
      "\n",
      " gaussian_nb() - Gaussian Naive Bayes is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  9\n",
      "\n",
      " gaussian_nb() is activated...\n",
      "\n",
      "\n",
      " pop_polarity\n",
      "[7.65912312e-01 9.42382140e-01 7.64325246e-01 9.87795471e-01\n",
      " 4.64301005e-48 7.22251592e-01 6.17318855e-02 7.13685663e-02\n",
      " 1.54179262e-01 1.88505738e-04 8.34415141e-01 8.31571383e-01\n",
      " 8.99575273e-01 8.30600159e-01 8.24430396e-01 8.55440416e-01\n",
      " 6.63164899e-01 1.54179262e-01 8.37341907e-01 7.65912312e-01\n",
      " 8.49845177e-01 8.25120846e-01 6.69220714e-03 8.44691271e-01\n",
      " 9.96855395e-01 9.04235516e-01 7.63232312e-01 8.25120846e-01\n",
      " 8.56504098e-01 8.59320038e-01 8.17261424e-01 9.04191680e-01\n",
      " 8.97412923e-01 8.75676203e-01 5.68981750e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " auc\n",
      "0.81\n",
      "\n",
      " model_gnb[\"con_matrix\"]\n",
      "[[ 6 11]\n",
      " [ 1 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6571428571428571\n",
      "recall:  0.9444444444444444\n",
      "specificity:  0.35294117647058826\n",
      "precision:  0.6071428571428571\n",
      "\n",
      " model_gnb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.35      0.50        17\n",
      "           1       0.61      0.94      0.74        18\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.73      0.65      0.62        35\n",
      "weighted avg       0.73      0.66      0.62        35\n",
      "\n",
      "\n",
      " random_forest() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  9\n",
      "\n",
      " random_forest() is activated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[0.11352909 0.10191652 0.38367195 0.83427407 0.00126037 0.09840162\n",
      " 0.41063952 0.14518188 0.01613923 0.04283693 0.27619442 0.81263492\n",
      " 0.92659965 0.819257   0.06759714 0.5258679  0.52804274 0.01613923\n",
      " 0.69924251 0.11352909 0.94273559 0.43377025 0.1468391  0.74928355\n",
      " 0.86079099 0.97173799 0.89860403 0.43377025 0.88879124 0.94738045\n",
      " 0.87734537 0.89262538 0.73506736 0.9715373  0.0941181 ]\n",
      "\n",
      " yhat\n",
      "[0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.99\n",
      "\n",
      " model_rf[\"con_matrix\"]\n",
      "[[16  1]\n",
      " [ 1 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.9428571428571428\n",
      "recall:  0.9444444444444444\n",
      "specificity:  0.9411764705882353\n",
      "precision:  0.9444444444444444\n",
      "\n",
      " model_rf[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        17\n",
      "           1       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.94      0.94      0.94        35\n",
      "weighted avg       0.94      0.94      0.94        35\n",
      "\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  9\n",
      "\n",
      " svm() is activated...\n",
      "\n",
      "\n",
      " RandomizedSearchCV fitting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomizedSearchCV finish fitting.\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pop_polarity\n",
      "[7.23076288e-01 6.38449420e-01 4.87879364e-01 7.03405873e-01\n",
      " 1.86784368e-04 4.17430702e-01 3.37424606e-01 5.87583042e-01\n",
      " 3.58653093e-01 1.87566992e-01 5.35905870e-01 5.00000000e-01\n",
      " 5.97748444e-01 5.43757893e-01 4.82701708e-01 6.24439367e-01\n",
      " 4.22299537e-01 3.58653093e-01 5.00000000e-01 7.23076288e-01\n",
      " 5.45624889e-01 6.04175581e-01 4.04439312e-01 4.60415757e-01\n",
      " 9.23553803e-01 5.90099227e-01 5.15039527e-01 6.04175581e-01\n",
      " 6.83707869e-01 5.53531590e-01 5.70231992e-01 6.03291147e-01\n",
      " 7.84997114e-01 5.68417924e-01 4.11104546e-01]\n",
      "\n",
      " yhat\n",
      "[1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.62\n",
      "\n",
      " model_svm[\"con_matrix\"]\n",
      "[[ 9  8]\n",
      " [ 3 15]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.6857142857142857\n",
      "recall:  0.8333333333333334\n",
      "specificity:  0.5294117647058824\n",
      "precision:  0.6521739130434783\n",
      "\n",
      " model_svm[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.53      0.62        17\n",
      "           1       0.65      0.83      0.73        18\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.70      0.68      0.68        35\n",
      "weighted avg       0.70      0.69      0.68        35\n",
      "\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "nKFold round:  9\n",
      "\n",
      " xgboost() is activated...\n",
      "\n",
      "[05:11:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[05:11:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      " pop_polarity\n",
      "[0.4559974  0.5113604  0.5605751  0.62940365 0.33179677 0.36057758\n",
      " 0.36654738 0.49174565 0.33309007 0.4449962  0.5959336  0.58618635\n",
      " 0.6668657  0.521526   0.41312975 0.5902151  0.5206407  0.33309007\n",
      " 0.6176878  0.4559974  0.66187733 0.4559974  0.43452343 0.58772093\n",
      " 0.635807   0.6840375  0.5391767  0.4559974  0.7046782  0.7046782\n",
      " 0.6157482  0.65619355 0.60511243 0.6840375  0.4679156 ]\n",
      "\n",
      " yhat\n",
      "[0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0]\n",
      "\n",
      " auc\n",
      "0.92\n",
      "\n",
      " model_xgb[\"con_matrix\"]\n",
      "[[13  4]\n",
      " [ 1 17]]\n",
      "\n",
      " Model performance calculate from confusion matrix:\n",
      "\n",
      "accuracy:  0.8571428571428571\n",
      "recall:  0.9444444444444444\n",
      "specificity:  0.7647058823529411\n",
      "precision:  0.8095238095238095\n",
      "\n",
      " model_xgb[\"class_report\"]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84        17\n",
      "           1       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.87      0.85      0.86        35\n",
      "weighted avg       0.87      0.86      0.86        35\n",
      "\n",
      "\n",
      " compare_final_result() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      "=====  Logistic baseline  =====\n",
      "accuracy =  0.6571428571428571\n",
      "recall =  0.7777777777777778\n",
      "specificity =  0.5294117647058824\n",
      "precision =  0.6363636363636364\n",
      "auc =  0.65\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      "=====  GaussianNB  =====\n",
      "accuracy =  0.6571428571428571\n",
      "recall =  0.9444444444444444\n",
      "specificity =  0.35294117647058826\n",
      "precision =  0.6071428571428571\n",
      "auc =  0.81\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      "=====  Random forest  =====\n",
      "accuracy =  0.9428571428571428\n",
      "recall =  0.9444444444444444\n",
      "specificity =  0.9411764705882353\n",
      "precision =  0.9444444444444444\n",
      "auc =  0.99\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      "=====  SVM  =====\n",
      "accuracy =  0.6857142857142857\n",
      "recall =  0.8333333333333334\n",
      "specificity =  0.5294117647058824\n",
      "precision =  0.6521739130434783\n",
      "auc =  0.62\n",
      "\n",
      " get_max_index() is activated...\n",
      "\n",
      "\n",
      "Hostpital: bdms\n",
      "\n",
      "=====  XGBoost  =====\n",
      "accuracy =  0.8571428571428571\n",
      "recall =  0.9444444444444444\n",
      "specificity =  0.7647058823529411\n",
      "precision =  0.8095238095238095\n",
      "auc =  0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.0s finished\n",
      "C:\\ProgramFiles_Anaconda\\Anaconda3\\envs\\math_stat_class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hosp_name_list)):\n",
    "    \n",
    "    print (\"\\n\\n====================================================\")\n",
    "    print (\"\\nHospital name: \" + hosp_name_list[i] )\n",
    "    print (\"\\n====================================================\")\n",
    "           \n",
    "    print (\"\\n\\n----------------------------------------------------\")\n",
    "    print (\"\\n\" + hosp_name_list[i])\n",
    "    print (\"\\n>>>>> Step: Read data for NLP process <<<<<\")\n",
    "    sta_hosp[hosp_name_abb[i] + \"_data\"] = data.data_loader( hosp_name = hosp_name_list[i] )\n",
    "        \n",
    "    #Plot to check balancing of dataset\n",
    "    sta_hosp[hosp_name_abb[i] + \"_data\"].plot_data( sta_hosp[hosp_name_abb[i] + \"_data\"].df_nlp )\n",
    "    \n",
    "    #Up sample and plot graph for checking\n",
    "    sta_hosp[hosp_name_abb[i] + \"_data\"].up_sample()\n",
    "    \n",
    "    #Generate sparse vector of features\n",
    "    sta_hosp[hosp_name_abb[i] + \"_vector\"] = nlp.nlp_process(mode = mode_model,\n",
    "                                                hosp_name = hosp_name_list[i], \n",
    "                                                dataset = sta_hosp[hosp_name_abb[i] + \"_data\"].df_nlp_up,\n",
    "                                                dataset_type = \"up-sample\",\n",
    "                                                description = \"Up-sample dataset\")\n",
    "    \n",
    "    #Reduce features and train the model with 10-folds cross validation\n",
    "    sta_hosp[hosp_name_abb[i] + \"_dict_param\"] = {}\n",
    "    #\n",
    "    sta_hosp[hosp_name_abb[i] + \"_dict_param\"][\"hosp_name\"] = hosp_name_abb[i]\n",
    "    sta_hosp[hosp_name_abb[i] + \"_dict_param\"][\"vec_tfidf_vectorizer\"] = sta_hosp[hosp_name_abb[i] + \"_vector\"].vec_tfidf_vectorizer\n",
    "    sta_hosp[hosp_name_abb[i] + \"_dict_param\"][\"data_tfidf_vectorizer\"] = sta_hosp[hosp_name_abb[i] + \"_vector\"].data_tfidf_vectorizer\n",
    "    sta_hosp[hosp_name_abb[i] + \"_dict_param\"][\"vec_tfidf_vectorizer_bigram\"] = sta_hosp[hosp_name_abb[i] + \"_vector\"].vec_tfidf_vectorizer_bigram\n",
    "    sta_hosp[hosp_name_abb[i] + \"_dict_param\"][\"data_tfidf_vectorizer_bigram\"] = sta_hosp[hosp_name_abb[i] + \"_vector\"].data_tfidf_vectorizer_bigram\n",
    "    sta_hosp[hosp_name_abb[i] + \"_dict_param\"][\"polarity\"] = sta_hosp[hosp_name_abb[i] + \"_vector\"].df_nlp[\"polarity\"]\n",
    "    #\n",
    "    sta_hosp[hosp_name_abb[i] + \"_model\"] = sta.model_sentiment( sta_hosp[hosp_name_abb[i] + \"_dict_param\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 344,
   "position": {
    "height": "275px",
    "left": "963px",
    "right": "20px",
    "top": "75px",
    "width": "406px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
