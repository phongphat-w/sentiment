{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### @author: Phongphat Wiwatthanasetthakarn   @create: 2020-04-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-translate\n",
      "  Using cached google_cloud_translate-2.0.1-py2.py3-none-any.whl (90 kB)\n",
      "Collecting google-api-core[grpc]<2.0.0dev,>=1.15.0\n",
      "  Using cached google_api_core-1.17.0-py2.py3-none-any.whl (70 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.1.0\n",
      "  Using cached google_cloud_core-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting protobuf>=3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.  Downloading protobuf-3.12.0-cp37-cp37m-win_amd64.whl (1.0 MB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Using cached googleapis-common-protos-1.51.0.tar.gz (35 kB)\n",
      "\n",
      "Collecting google-auth<2.0dev,>=1.14.0\n",
      "  Downloading google_auth-1.14.3-py2.py3-none-any.whl (89 kB)\n",
      "Requirement already satisfied: pytz in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (2020.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (2.23.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (46.1.3.post20200330)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (1.14.0)\n",
      "Collecting grpcio<2.0dev,>=1.8.2; extra == \"grpc\"\n",
      "  Downloading grpcio-1.29.0-cp37-cp37m-win_amd64.whl (2.3 MB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate) (1.25.8)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: googleapis-common-protos\n",
      "  Building wheel for googleapis-common-protos (setup.py): started\n",
      "  Building wheel for googleapis-common-protos (setup.py): finished with status 'done'\n",
      "  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.51.0-py3-none-any.whl size=77602 sha256=c4cd5279905b311708d622a7716e2aed6861c208358c7e9a5bd9b2bc679e8555\n",
      "  Stored in directory: c:\\users\\os\\appdata\\local\\pip\\cache\\wheels\\4c\\a1\\71\\5e427276ceeff277fd76878d1b19fbf4587a2845015d86864b\n",
      "Successfully built googleapis-common-protos\n",
      "Installing collected packages: protobuf, googleapis-common-protos, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, grpcio, google-api-core, google-cloud-core, google-cloud-translate\n",
      "Successfully installed cachetools-4.1.0 google-api-core-1.17.0 google-auth-1.14.3 google-cloud-core-1.3.0 google-cloud-translate-2.0.1 googleapis-common-protos-1.51.0 grpcio-1.29.0 protobuf-3.12.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.0\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tqdm in c:\\programfiles_anaconda\\anaconda3\\lib\\site-packages (4.46.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEcFTaez8Tl0"
   },
   "outputs": [],
   "source": [
    "#web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import time, sleep\n",
    "from random import randint\n",
    "\n",
    "#Translation\n",
    "from google.cloud import translate\n",
    "\n",
    "#Utilities\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraping_path = \"./scraping/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9S5u5uCguJwy"
   },
   "outputs": [],
   "source": [
    "def honestdoc_comment(hosp_name):\n",
    "\t\"\"\"\n",
    "\tThis function is to scrap data from a webboard (https://www.honestdocs.com).\n",
    "\t\"\"\"\n",
    "\t#create connection\n",
    "\turl = r\"https://www.honestdocs.co/hospitals/\"\n",
    "\turl += hosp_name\n",
    "\tdata = requests.get(url)\n",
    "\tprint(\"requests code : {}\".format(data.status_code)) \n",
    "\tprint(\"note\\n2xx: success\\n4xx, 5xx: error\")\n",
    "\n",
    "\t#scrape comment and score\n",
    "\tstart_time = time() #start scraping data from page1\n",
    "\tr = requests.get(url, params=dict(query=\"web scraping\",page=1)) \n",
    "\tsoup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\tn = len(soup.find_all(\"div\",{\"class\":\"comments__content\"})) #find n of items in the page\n",
    "\n",
    "\t#extract each item\n",
    "\tcomment = [soup.find_all(\"div\",\n",
    "\t\t\t\t\t\t\t {\"class\":\"comments__content\"})[i].get_text().strip() for i in range(0,n)]\n",
    "\tscore = [soup.find_all(\"span\",\n",
    "\t\t\t\t\t\t   {\"class\":\"stars star-rating\"})[i].attrs[\"data-score\"] for i in range(0,n)]\n",
    "\telapsed_time = time() - start_time #finish scraping data from page1\n",
    "\tprint(\"Time used for scraping data from page - 1 : {} s\".format(elapsed_time))\n",
    "\tsleep(randint(1,3)) #mimic human behavior\n",
    "\t\t   \n",
    "\tp = 2 #start scraping data from page2\n",
    "\twhile n > 0: #until the number of items in a page = 0\n",
    "\t\tstart_time = time() \n",
    "\t\tr = requests.get(url, params=dict(query=\"web scraping\",page=p))\n",
    "\t\tsoup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\t\tn = len(soup.find_all(\"div\",{\"class\":\"comments__content\"}))\n",
    "\t\t[comment.append(soup.find_all(\"div\",\n",
    "\t\t\t\t\t\t\t\t\t  {\"class\":\"comments__content\"})[i].get_text().strip()) for i in range(0,n)]\n",
    "\t\t[score.append(soup.find_all(\"span\",\n",
    "\t\t\t\t\t\t\t\t\t{\"class\":\"stars star-rating\"})[i].attrs[\"data-score\"]) for i in range(0,n)]\n",
    "\t\telapsed_time = time() - start_time\n",
    "\t\tprint(\"Time used for scraping data from page - {} : {} s\".format(p, elapsed_time))\n",
    "\t\tp +=1\n",
    "\t\tsleep(randint(1,3))\n",
    "\n",
    "\n",
    "\t#backup data \n",
    "\tpd.DataFrame({\"comment\": comment,\n",
    "\t\t\t\t  \"score\": score\n",
    "\t\t\t\t}).to_csv(scraping_path + \"comment_\" + hosp_name + \".csv\", index=False)\t  \n",
    "\n",
    "\treturn comment, score\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credential json file format that generated from google cloud platform service\n",
    "import os\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"c:\\Users\\os\\Desktop\\RADS611\\Lab\\sentimenthospital.json\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"./credential/sentimenthospital.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project id from google cloud platform service\n",
    "project_id=\"sentimenthospital\"\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    client = translate.TranslationServiceClient()\n",
    "    parent = client.location_path(project_id, \"global\")\n",
    "\n",
    "    response = client.translate_text(\n",
    "        parent=parent,\n",
    "        contents=[text],\n",
    "        mime_type=\"text/plain\",  # mime types: text/plain, text/html\n",
    "        source_language_code=\"th\",\n",
    "        target_language_code=\"en\",\n",
    "    )    \n",
    "    \n",
    "    for translation in response.translations:        \n",
    "        text_return = translation.translated_text\n",
    "    \n",
    "    return text_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles_Anaconda\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "hosp_name_list = [\"ramathibodi-hospital\", \"siriraj-hospital\", \"king-chulalongkorn-memorial-hospital\", \"bangkok-hospital\"]\n",
    "#\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hvKaL3hPKT6E",
    "outputId": "3f195419-f7fd-4cef-c369-7bf73c5b3ac7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " =================\n",
      "\n",
      " hospital name = ramathibodi-hospital\n",
      "\n",
      " =================\n",
      "requests code : 200\n",
      "note\n",
      "2xx: success\n",
      "4xx, 5xx: error\n",
      "Time used for scraping data from page - 1 : 0.36368846893310547 s\n",
      "Time used for scraping data from page - 2 : 0.37401247024536133 s\n",
      "Time used for scraping data from page - 3 : 0.3660440444946289 s\n",
      "Time used for scraping data from page - 4 : 0.36528992652893066 s\n",
      "Time used for scraping data from page - 5 : 0.3946206569671631 s\n",
      "Time used for scraping data from page - 6 : 0.3676881790161133 s\n",
      "Time used for scraping data from page - 7 : 0.3675520420074463 s\n",
      "Time used for scraping data from page - 8 : 0.39696192741394043 s\n",
      "Time used for scraping data from page - 9 : 0.36362171173095703 s\n",
      "Time used for scraping data from page - 10 : 0.3807680606842041 s\n",
      "Time used for scraping data from page - 11 : 0.40509676933288574 s\n",
      "Time used for scraping data from page - 12 : 0.35715794563293457 s\n",
      "Time used for scraping data from page - 13 : 0.5846250057220459 s\n",
      "Time used for scraping data from page - 14 : 0.38087964057922363 s\n",
      "Time used for scraping data from page - 15 : 0.3824625015258789 s\n",
      "Time used for scraping data from page - 16 : 0.37456750869750977 s\n",
      "Time used for scraping data from page - 17 : 0.37903928756713867 s\n",
      "Time used for scraping data from page - 18 : 0.37508368492126465 s\n",
      "Time used for scraping data from page - 19 : 0.3332233428955078 s\n",
      "Time used for scraping data from page - 20 : 0.4337270259857178 s\n",
      "Time used for scraping data from page - 21 : 0.39026927947998047 s\n",
      "Time used for scraping data from page - 22 : 0.36011242866516113 s\n",
      "Time used for scraping data from page - 23 : 0.3902561664581299 s\n",
      "Time used for scraping data from page - 24 : 0.35796356201171875 s\n",
      "Time used for scraping data from page - 25 : 0.3469104766845703 s\n",
      "Time used for scraping data from page - 26 : 0.3802776336669922 s\n",
      "Time used for scraping data from page - 27 : 0.3435084819793701 s\n",
      "Time used for scraping data from page - 28 : 0.3624880313873291 s\n",
      "Time used for scraping data from page - 29 : 0.35206079483032227 s\n",
      "Time used for scraping data from page - 30 : 0.36446356773376465 s\n",
      "Time used for scraping data from page - 31 : 0.34360289573669434 s\n",
      "Time used for scraping data from page - 32 : 0.3567953109741211 s\n",
      "Time used for scraping data from page - 33 : 0.33241891860961914 s\n",
      "Time used for scraping data from page - 34 : 0.38100290298461914 s\n",
      "Time used for scraping data from page - 35 : 0.38213443756103516 s\n",
      "Time used for scraping data from page - 36 : 0.3816192150115967 s\n",
      "Time used for scraping data from page - 37 : 0.4053020477294922 s\n",
      "Time used for scraping data from page - 38 : 0.4394664764404297 s\n",
      "Time used for scraping data from page - 39 : 0.3387324810028076 s\n",
      "Time used for scraping data from page - 40 : 0.35477590560913086 s\n",
      "Time used for scraping data from page - 41 : 0.3609633445739746 s\n",
      "Time used for scraping data from page - 42 : 0.6496756076812744 s\n",
      "Time used for scraping data from page - 43 : 0.3461573123931885 s\n",
      "Time used for scraping data from page - 44 : 0.36704397201538086 s\n",
      "Time used for scraping data from page - 45 : 0.3608853816986084 s\n",
      "Time used for scraping data from page - 46 : 0.3709146976470947 s\n",
      "Time used for scraping data from page - 47 : 0.36989402770996094 s\n",
      "Time used for scraping data from page - 48 : 0.37674903869628906 s\n",
      "Time used for scraping data from page - 49 : 0.36542177200317383 s\n",
      "Time used for scraping data from page - 50 : 0.339993953704834 s\n",
      "Time used for scraping data from page - 51 : 0.47768068313598633 s\n",
      "Time used for scraping data from page - 52 : 0.38971400260925293 s\n",
      "Time used for scraping data from page - 53 : 0.3389475345611572 s\n",
      "Time used for scraping data from page - 54 : 0.34160780906677246 s\n",
      "Time used for scraping data from page - 55 : 0.4183628559112549 s\n",
      "Time used for scraping data from page - 56 : 0.3464934825897217 s\n",
      "Time used for scraping data from page - 57 : 0.3335268497467041 s\n",
      "Time used for scraping data from page - 58 : 0.3678300380706787 s\n",
      "Time used for scraping data from page - 59 : 0.3920719623565674 s\n",
      "Time used for scraping data from page - 60 : 0.3486664295196533 s\n",
      "Time used for scraping data from page - 61 : 0.3872385025024414 s\n",
      "Time used for scraping data from page - 62 : 0.3400692939758301 s\n",
      "Time used for scraping data from page - 63 : 0.39893484115600586 s\n",
      "Time used for scraping data from page - 64 : 0.4356253147125244 s\n",
      "Time used for scraping data from page - 65 : 0.38410496711730957 s\n",
      "Time used for scraping data from page - 66 : 0.35074806213378906 s\n",
      "Time used for scraping data from page - 67 : 0.3502202033996582 s\n",
      "Time used for scraping data from page - 68 : 0.39589786529541016 s\n",
      "Time used for scraping data from page - 69 : 0.38233184814453125 s\n",
      "Time used for scraping data from page - 70 : 0.3707304000854492 s\n",
      "Time used for scraping data from page - 71 : 0.3714325428009033 s\n",
      "Time used for scraping data from page - 72 : 0.3439173698425293 s\n",
      "Time used for scraping data from page - 73 : 0.36377429962158203 s\n",
      "Time used for scraping data from page - 74 : 0.36195945739746094 s\n",
      "Time used for scraping data from page - 75 : 0.350191593170166 s\n",
      "Time used for scraping data from page - 76 : 0.2984583377838135 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [02:13<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview data\n",
      "\n",
      "                                               comment  score  \\\n",
      "0    เคยได้ไปลองใช้บริการคลีนิคนอกเวลาของรามาเมื่อต...      5   \n",
      "1    ผมเคยไปทำเลสิกที่นี้ ดีมากครับตอนนี้ผ่ามาจะ2ปี...      4   \n",
      "2    รักษามาหลายปีแล้วตั้งแต่อายุ14 ตอนนี้จะจบปริญญ...      5   \n",
      "3    ที่ตึกพระเทพชั้น 2 สถานที่เครื่องมือดูทันสมัย ...      3   \n",
      "4    Its a public hospital so service is bad (nurse...      4   \n",
      "..                                                 ...    ...   \n",
      "219  การบริการดี รพ สะอาดหมอสอบถามตลอดคอยดุแลตลอดคอ...      5   \n",
      "220                                        บริการดีมาก      5   \n",
      "221  คนไข้ค่อนข้างเยอะทำให้การได้รับการบริการค่อนข่...      4   \n",
      "222       คอยตั้งแต่9โมงเช้าถึงเที่ยงไม่ได้ระบการรักษา      1   \n",
      "223  คุณหมอเก่ง ให้คำแนะนำที่ละเอียดชัดเจนดี การผ่า...      5   \n",
      "\n",
      "                                                    en  \n",
      "0    Had tried the part-time clinic service at the ...  \n",
      "1    I've been to Lasik here. Very good. Now, after...  \n",
      "2    Healed many years since age 14 This is a bache...  \n",
      "3    At Phra Thep Building, 2nd floor, the place lo...  \n",
      "4    Its a public hospital so service is bad (nurse...  \n",
      "..                                                 ...  \n",
      "219  The service is very clean, the doctor asks all...  \n",
      "220                                  Very good service  \n",
      "221  Quite a lot of patients, causing the service t...  \n",
      "222  Waiting from 9 o'clock in the morning to noon ...  \n",
      "223  Dr. Keng gave detailed and clear advice. Moder...  \n",
      "\n",
      "[224 rows x 3 columns]\n",
      "\n",
      " =================\n",
      "\n",
      " hospital name = siriraj-hospital\n",
      "\n",
      " =================\n",
      "requests code : 200\n",
      "note\n",
      "2xx: success\n",
      "4xx, 5xx: error\n",
      "Time used for scraping data from page - 1 : 0.3692951202392578 s\n",
      "Time used for scraping data from page - 2 : 0.3662276268005371 s\n",
      "Time used for scraping data from page - 3 : 0.35646581649780273 s\n",
      "Time used for scraping data from page - 4 : 0.3786623477935791 s\n",
      "Time used for scraping data from page - 5 : 0.4280521869659424 s\n",
      "Time used for scraping data from page - 6 : 0.40308690071105957 s\n",
      "Time used for scraping data from page - 7 : 0.367570161819458 s\n",
      "Time used for scraping data from page - 8 : 0.3508925437927246 s\n",
      "Time used for scraping data from page - 9 : 0.3904871940612793 s\n",
      "Time used for scraping data from page - 10 : 0.45383644104003906 s\n",
      "Time used for scraping data from page - 11 : 0.39246392250061035 s\n",
      "Time used for scraping data from page - 12 : 0.35139966011047363 s\n",
      "Time used for scraping data from page - 13 : 0.37665486335754395 s\n",
      "Time used for scraping data from page - 14 : 0.3694891929626465 s\n",
      "Time used for scraping data from page - 15 : 0.38263678550720215 s\n",
      "Time used for scraping data from page - 16 : 0.40555596351623535 s\n",
      "Time used for scraping data from page - 17 : 0.36320066452026367 s\n",
      "Time used for scraping data from page - 18 : 0.35157060623168945 s\n",
      "Time used for scraping data from page - 19 : 0.4018118381500244 s\n",
      "Time used for scraping data from page - 20 : 0.3544747829437256 s\n",
      "Time used for scraping data from page - 21 : 0.36229419708251953 s\n",
      "Time used for scraping data from page - 22 : 0.3531155586242676 s\n",
      "Time used for scraping data from page - 23 : 0.34136343002319336 s\n",
      "Time used for scraping data from page - 24 : 0.3578500747680664 s\n",
      "Time used for scraping data from page - 25 : 0.3674747943878174 s\n",
      "Time used for scraping data from page - 26 : 0.3925445079803467 s\n",
      "Time used for scraping data from page - 27 : 0.3966207504272461 s\n",
      "Time used for scraping data from page - 28 : 0.36177682876586914 s\n",
      "Time used for scraping data from page - 29 : 0.36969780921936035 s\n",
      "Time used for scraping data from page - 30 : 0.3830571174621582 s\n",
      "Time used for scraping data from page - 31 : 0.39148950576782227 s\n",
      "Time used for scraping data from page - 32 : 0.35962605476379395 s\n",
      "Time used for scraping data from page - 33 : 0.3631727695465088 s\n",
      "Time used for scraping data from page - 34 : 0.3393886089324951 s\n",
      "Time used for scraping data from page - 35 : 0.45047640800476074 s\n",
      "Time used for scraping data from page - 36 : 0.3954141139984131 s\n",
      "Time used for scraping data from page - 37 : 0.360443115234375 s\n",
      "Time used for scraping data from page - 38 : 0.3674335479736328 s\n",
      "Time used for scraping data from page - 39 : 0.40244317054748535 s\n",
      "Time used for scraping data from page - 40 : 0.41730809211730957 s\n",
      "Time used for scraping data from page - 41 : 0.4305565357208252 s\n",
      "Time used for scraping data from page - 42 : 0.36623644828796387 s\n",
      "Time used for scraping data from page - 43 : 0.350818395614624 s\n",
      "Time used for scraping data from page - 44 : 0.36110591888427734 s\n",
      "Time used for scraping data from page - 45 : 0.40636682510375977 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [01:17<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview data\n",
      "\n",
      "                                               comment  score  \\\n",
      "0    พยาบาลบริการดีคุณหมอสุภาพโรงพยาบาลรักษาความสะอ...      5   \n",
      "1    ใช้บริการปรึกษาเรื่องแผลคีลอยด์ที่บริเวรต้นแขน...      5   \n",
      "2    เป็นโรงพยาบาลที่ดีมากๆคะเคยรักษาเนื้องอกที่มดล...      5   \n",
      "3    รพ.ศิริราช คุณหมอและพยาบาลน่ารักมากค่ะ ให้คำแน...      5   \n",
      "4    พาคุณย่าไปรักษาโรคมะเร็ง บริการดี รวดเร็วเป็นก...      5   \n",
      "..                                                 ...    ...   \n",
      "127  เริ่มแรกเข้า ER เนื่องจากคุณแม่ล้ม และไข้ขึ้นส...      5   \n",
      "128  ผมได้รับการรักษามะเร็งจนหายดีใช้ชีวิตเหมือนคนป...      5   \n",
      "129  เนื่องจากการรักษาต้องทำการผ่าตัด และฉันเลือกดม...      3   \n",
      "130                                     บริการก็ใช้ได้      4   \n",
      "131  สถานที่คับแคบเมื่อเทียบกับจำนวนคนที่ใช้บริการ ...      4   \n",
      "\n",
      "                                                    en  \n",
      "0    The nurse is very good, the doctor is polite, ...  \n",
      "1    Use a consultative service for keloids on the ...  \n",
      "2    It is a very good hospital. Used to treat uter...  \n",
      "3    Siriraj Hospital. The doctors and nurses are v...  \n",
      "4    Take Grandma to treat cancer. Good service, fa...  \n",
      "..                                                 ...  \n",
      "127  Initially entered into ER because the mother f...  \n",
      "128  I've been treated for cancer until I am health...  \n",
      "129  Because the treatment requires surgery And I c...  \n",
      "130                                      Service is ok  \n",
      "131  The place is cramped compared to the number of...  \n",
      "\n",
      "[132 rows x 3 columns]\n",
      "\n",
      " =================\n",
      "\n",
      " hospital name = king-chulalongkorn-memorial-hospital\n",
      "\n",
      " =================\n",
      "requests code : 200\n",
      "note\n",
      "2xx: success\n",
      "4xx, 5xx: error\n",
      "Time used for scraping data from page - 1 : 0.36142897605895996 s\n",
      "Time used for scraping data from page - 2 : 0.38404178619384766 s\n",
      "Time used for scraping data from page - 3 : 0.3614675998687744 s\n",
      "Time used for scraping data from page - 4 : 0.3590664863586426 s\n",
      "Time used for scraping data from page - 5 : 0.36789679527282715 s\n",
      "Time used for scraping data from page - 6 : 0.3494546413421631 s\n",
      "Time used for scraping data from page - 7 : 0.34926676750183105 s\n",
      "Time used for scraping data from page - 8 : 0.3970816135406494 s\n",
      "Time used for scraping data from page - 9 : 0.37546539306640625 s\n",
      "Time used for scraping data from page - 10 : 0.4057962894439697 s\n",
      "Time used for scraping data from page - 11 : 0.34600162506103516 s\n",
      "Time used for scraping data from page - 12 : 0.3666706085205078 s\n",
      "Time used for scraping data from page - 13 : 0.38031482696533203 s\n",
      "Time used for scraping data from page - 14 : 0.3634812831878662 s\n",
      "Time used for scraping data from page - 15 : 0.3713958263397217 s\n",
      "Time used for scraping data from page - 16 : 0.3969597816467285 s\n",
      "Time used for scraping data from page - 17 : 0.36862945556640625 s\n",
      "Time used for scraping data from page - 18 : 0.36910438537597656 s\n",
      "Time used for scraping data from page - 19 : 0.3473505973815918 s\n",
      "Time used for scraping data from page - 20 : 0.3434884548187256 s\n",
      "Time used for scraping data from page - 21 : 0.33321475982666016 s\n",
      "Time used for scraping data from page - 22 : 0.6669995784759521 s\n",
      "Time used for scraping data from page - 23 : 0.3530917167663574 s\n",
      "Time used for scraping data from page - 24 : 0.3610374927520752 s\n",
      "Time used for scraping data from page - 25 : 0.3452937602996826 s\n",
      "Time used for scraping data from page - 26 : 0.361588716506958 s\n",
      "Time used for scraping data from page - 27 : 0.38527536392211914 s\n",
      "Time used for scraping data from page - 28 : 0.3509547710418701 s\n",
      "Time used for scraping data from page - 29 : 0.36626720428466797 s\n",
      "Time used for scraping data from page - 30 : 0.3738875389099121 s\n",
      "Time used for scraping data from page - 31 : 0.3651542663574219 s\n",
      "Time used for scraping data from page - 32 : 0.401353120803833 s\n",
      "Time used for scraping data from page - 33 : 0.34555506706237793 s\n",
      "Time used for scraping data from page - 34 : 0.36660122871398926 s\n",
      "Time used for scraping data from page - 35 : 0.36898040771484375 s\n",
      "Time used for scraping data from page - 36 : 0.34146928787231445 s\n",
      "Time used for scraping data from page - 37 : 0.36091184616088867 s\n",
      "Time used for scraping data from page - 38 : 0.40122222900390625 s\n",
      "Time used for scraping data from page - 39 : 0.3462684154510498 s\n",
      "Time used for scraping data from page - 40 : 0.37598156929016113 s\n",
      "Time used for scraping data from page - 41 : 0.37185120582580566 s\n",
      "Time used for scraping data from page - 42 : 0.3860759735107422 s\n",
      "Time used for scraping data from page - 43 : 0.37385034561157227 s\n",
      "Time used for scraping data from page - 44 : 0.36998558044433594 s\n",
      "Time used for scraping data from page - 45 : 0.3709743022918701 s\n",
      "Time used for scraping data from page - 46 : 0.396986722946167 s\n",
      "Time used for scraping data from page - 47 : 0.3790454864501953 s\n",
      "Time used for scraping data from page - 48 : 0.37261199951171875 s\n",
      "Time used for scraping data from page - 49 : 0.3559274673461914 s\n",
      "Time used for scraping data from page - 50 : 0.37915539741516113 s\n",
      "Time used for scraping data from page - 51 : 0.35280799865722656 s\n",
      "Time used for scraping data from page - 52 : 0.3659944534301758 s\n",
      "Time used for scraping data from page - 53 : 0.34625697135925293 s\n",
      "Time used for scraping data from page - 54 : 0.4262561798095703 s\n",
      "Time used for scraping data from page - 55 : 0.3798959255218506 s\n",
      "Time used for scraping data from page - 56 : 0.34851813316345215 s\n",
      "Time used for scraping data from page - 57 : 0.34111857414245605 s\n",
      "Time used for scraping data from page - 58 : 0.36070823669433594 s\n",
      "Time used for scraping data from page - 59 : 0.380216121673584 s\n",
      "Time used for scraping data from page - 60 : 0.3506355285644531 s\n",
      "Time used for scraping data from page - 61 : 0.3258364200592041 s\n",
      "Time used for scraping data from page - 62 : 0.3354051113128662 s\n",
      "Time used for scraping data from page - 63 : 0.3698158264160156 s\n",
      "Time used for scraping data from page - 64 : 0.34806370735168457 s\n",
      "Time used for scraping data from page - 65 : 0.3686506748199463 s\n",
      "Time used for scraping data from page - 66 : 0.347156286239624 s\n",
      "Time used for scraping data from page - 67 : 0.3546919822692871 s\n",
      "Time used for scraping data from page - 68 : 0.37598466873168945 s\n",
      "Time used for scraping data from page - 69 : 0.3763749599456787 s\n",
      "Time used for scraping data from page - 70 : 0.3930981159210205 s\n",
      "Time used for scraping data from page - 71 : 0.3463096618652344 s\n",
      "Time used for scraping data from page - 72 : 0.36691856384277344 s\n",
      "Time used for scraping data from page - 73 : 0.3437771797180176 s\n",
      "Time used for scraping data from page - 74 : 0.3590726852416992 s\n",
      "Time used for scraping data from page - 75 : 0.3780360221862793 s\n",
      "Time used for scraping data from page - 76 : 0.4060683250427246 s\n",
      "Time used for scraping data from page - 77 : 0.348797082901001 s\n",
      "Time used for scraping data from page - 78 : 0.35514116287231445 s\n",
      "Time used for scraping data from page - 79 : 0.3789408206939697 s\n",
      "Time used for scraping data from page - 80 : 0.3735840320587158 s\n",
      "Time used for scraping data from page - 81 : 0.36008620262145996 s\n",
      "Time used for scraping data from page - 82 : 0.5575413703918457 s\n",
      "Time used for scraping data from page - 83 : 0.38307714462280273 s\n",
      "Time used for scraping data from page - 84 : 0.34299349784851074 s\n",
      "Time used for scraping data from page - 85 : 0.34261322021484375 s\n",
      "Time used for scraping data from page - 86 : 0.35722970962524414 s\n",
      "Time used for scraping data from page - 87 : 0.34894490242004395 s\n",
      "Time used for scraping data from page - 88 : 0.3679647445678711 s\n",
      "Time used for scraping data from page - 89 : 0.35390257835388184 s\n",
      "Time used for scraping data from page - 90 : 0.37195897102355957 s\n",
      "Time used for scraping data from page - 91 : 0.3600656986236572 s\n",
      "Time used for scraping data from page - 92 : 0.37816333770751953 s\n",
      "Time used for scraping data from page - 93 : 0.45102643966674805 s\n",
      "Time used for scraping data from page - 94 : 0.3623991012573242 s\n",
      "Time used for scraping data from page - 95 : 0.367706298828125 s\n",
      "Time used for scraping data from page - 96 : 0.34249377250671387 s\n",
      "Time used for scraping data from page - 97 : 0.35756945610046387 s\n",
      "Time used for scraping data from page - 98 : 0.4057893753051758 s\n",
      "Time used for scraping data from page - 99 : 0.37378406524658203 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used for scraping data from page - 100 : 0.3927161693572998 s\n",
      "Time used for scraping data from page - 101 : 0.3721473217010498 s\n",
      "Time used for scraping data from page - 102 : 0.3464512825012207 s\n",
      "Time used for scraping data from page - 103 : 0.36713624000549316 s\n",
      "Time used for scraping data from page - 104 : 0.3723886013031006 s\n",
      "Time used for scraping data from page - 105 : 0.40877485275268555 s\n",
      "Time used for scraping data from page - 106 : 0.37152624130249023 s\n",
      "Time used for scraping data from page - 107 : 0.3447589874267578 s\n",
      "Time used for scraping data from page - 108 : 0.33499741554260254 s\n",
      "Time used for scraping data from page - 109 : 0.34685349464416504 s\n",
      "Time used for scraping data from page - 110 : 0.4071919918060303 s\n",
      "Time used for scraping data from page - 111 : 0.36176466941833496 s\n",
      "Time used for scraping data from page - 112 : 0.37180161476135254 s\n",
      "Time used for scraping data from page - 113 : 0.36124706268310547 s\n",
      "Time used for scraping data from page - 114 : 0.3611903190612793 s\n",
      "Time used for scraping data from page - 115 : 0.3353614807128906 s\n",
      "Time used for scraping data from page - 116 : 0.34490180015563965 s\n",
      "Time used for scraping data from page - 117 : 0.37311744689941406 s\n",
      "Time used for scraping data from page - 118 : 0.3502969741821289 s\n",
      "Time used for scraping data from page - 119 : 0.33585476875305176 s\n",
      "Time used for scraping data from page - 120 : 0.30446863174438477 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 355/355 [03:26<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview data\n",
      "\n",
      "                                               comment  score  \\\n",
      "0    เรื่อง ของเรื่องมีอยู่ว่า ไม่มีไข้ แต่โดนกักตั...      5   \n",
      "1    บริการค่อนข้างดีค่ะ คุณหมอพยาบาลใจดีเป็นกันเอง...      4   \n",
      "2    ไปรับการตรวจเรื่องเม็ดเลือดในปัสสาวะค่ะ ต้องจอ...      4   \n",
      "3    บริการค่อยข้างดีค่ะ แต่รอคิวนานนิดหน่อย แต่วิน...      5   \n",
      "4    ได้มีอาการอาหารเป็นพิษและเข้าทำการรักษาที่โรงพ...      5   \n",
      "..                                                 ...    ...   \n",
      "350  ค่ำวันที่ 26 ตุลาคม 2559 เหตุการณ์ในวันนั้นฉัน...      5   \n",
      "351  ทำเพื่ออะไรรีวิวนี้แต่เราไปรักษารพจุฬาก็ได้รับ...      5   \n",
      "352  ทาง รพ. บริการคนไข้ดีมาก ใส่ใจผู้ป่วย เป็นกันเ...      5   \n",
      "353                                            หมอเก่ง      3   \n",
      "354  เมื่อวันที่ 7 เมษายน 2559 ตัวผมเองรุ้สึกว่าไม่...      4   \n",
      "\n",
      "                                                    en  \n",
      "0    The matter is that there is no fever but being...  \n",
      "1    The service is quite good. The doctor was very...  \n",
      "2    Went to get a blood test in urine Have to rese...  \n",
      "3    Good service But waiting in a long queue But a...  \n",
      "4    Have food poisoning and go to treatment at thi...  \n",
      "..                                                 ...  \n",
      "350  The evening of 26 October 2016, the event that...  \n",
      "351  What to do for this review, but we went to Chu...  \n",
      "352  The hospital service is very patient, the pati...  \n",
      "353                                        Good doctor  \n",
      "354  On April 7, 2016, I felt that I didn't have th...  \n",
      "\n",
      "[355 rows x 3 columns]\n",
      "\n",
      " =================\n",
      "\n",
      " hospital name = bangkok-hospital\n",
      "\n",
      " =================\n",
      "requests code : 200\n",
      "note\n",
      "2xx: success\n",
      "4xx, 5xx: error\n",
      "Time used for scraping data from page - 1 : 0.3543570041656494 s\n",
      "Time used for scraping data from page - 2 : 0.3654189109802246 s\n",
      "Time used for scraping data from page - 3 : 0.4009363651275635 s\n",
      "Time used for scraping data from page - 4 : 0.3362851142883301 s\n",
      "Time used for scraping data from page - 5 : 0.37296319007873535 s\n",
      "Time used for scraping data from page - 6 : 0.36828136444091797 s\n",
      "Time used for scraping data from page - 7 : 0.35118746757507324 s\n",
      "Time used for scraping data from page - 8 : 0.3455519676208496 s\n",
      "Time used for scraping data from page - 9 : 0.39575624465942383 s\n",
      "Time used for scraping data from page - 10 : 0.3814690113067627 s\n",
      "Time used for scraping data from page - 11 : 0.38101673126220703 s\n",
      "Time used for scraping data from page - 12 : 0.35612988471984863 s\n",
      "Time used for scraping data from page - 13 : 0.3508734703063965 s\n",
      "Time used for scraping data from page - 14 : 0.37036681175231934 s\n",
      "Time used for scraping data from page - 15 : 0.34962987899780273 s\n",
      "Time used for scraping data from page - 16 : 0.3414318561553955 s\n",
      "Time used for scraping data from page - 17 : 0.3550987243652344 s\n",
      "Time used for scraping data from page - 18 : 0.33635520935058594 s\n",
      "Time used for scraping data from page - 19 : 0.34366822242736816 s\n",
      "Time used for scraping data from page - 20 : 0.33908867835998535 s\n",
      "Time used for scraping data from page - 21 : 0.3566291332244873 s\n",
      "Time used for scraping data from page - 22 : 0.3711082935333252 s\n",
      "Time used for scraping data from page - 23 : 0.3436107635498047 s\n",
      "Time used for scraping data from page - 24 : 0.37483763694763184 s\n",
      "Time used for scraping data from page - 25 : 0.4987456798553467 s\n",
      "Time used for scraping data from page - 26 : 0.35246777534484863 s\n",
      "Time used for scraping data from page - 27 : 0.37916135787963867 s\n",
      "Time used for scraping data from page - 28 : 0.36157798767089844 s\n",
      "Time used for scraping data from page - 29 : 0.33129310607910156 s\n",
      "Time used for scraping data from page - 30 : 0.34794163703918457 s\n",
      "Time used for scraping data from page - 31 : 0.36072850227355957 s\n",
      "Time used for scraping data from page - 32 : 0.3704512119293213 s\n",
      "Time used for scraping data from page - 33 : 0.3387463092803955 s\n",
      "Time used for scraping data from page - 34 : 0.37082719802856445 s\n",
      "Time used for scraping data from page - 35 : 0.390474796295166 s\n",
      "Time used for scraping data from page - 36 : 0.33612775802612305 s\n",
      "Time used for scraping data from page - 37 : 0.3522167205810547 s\n",
      "Time used for scraping data from page - 38 : 0.34407997131347656 s\n",
      "Time used for scraping data from page - 39 : 0.3284270763397217 s\n",
      "Time used for scraping data from page - 40 : 0.35317325592041016 s\n",
      "Time used for scraping data from page - 41 : 0.3562326431274414 s\n",
      "Time used for scraping data from page - 42 : 0.3302958011627197 s\n",
      "Time used for scraping data from page - 43 : 0.3588225841522217 s\n",
      "Time used for scraping data from page - 44 : 0.3672502040863037 s\n",
      "Time used for scraping data from page - 45 : 0.3832271099090576 s\n",
      "Time used for scraping data from page - 46 : 0.3550529479980469 s\n",
      "Time used for scraping data from page - 47 : 0.4674363136291504 s\n",
      "Time used for scraping data from page - 48 : 0.38216209411621094 s\n",
      "Time used for scraping data from page - 49 : 0.3653445243835449 s\n",
      "Time used for scraping data from page - 50 : 0.37311744689941406 s\n",
      "Time used for scraping data from page - 51 : 0.37458300590515137 s\n",
      "Time used for scraping data from page - 52 : 0.35953593254089355 s\n",
      "Time used for scraping data from page - 53 : 0.364177942276001 s\n",
      "Time used for scraping data from page - 54 : 0.36763763427734375 s\n",
      "Time used for scraping data from page - 55 : 0.34453630447387695 s\n",
      "Time used for scraping data from page - 56 : 0.3651444911956787 s\n",
      "Time used for scraping data from page - 57 : 0.35709285736083984 s\n",
      "Time used for scraping data from page - 58 : 0.37638115882873535 s\n",
      "Time used for scraping data from page - 59 : 0.3846468925476074 s\n",
      "Time used for scraping data from page - 60 : 0.42578577995300293 s\n",
      "Time used for scraping data from page - 61 : 0.36468982696533203 s\n",
      "Time used for scraping data from page - 62 : 0.3295626640319824 s\n",
      "Time used for scraping data from page - 63 : 0.3480048179626465 s\n",
      "Time used for scraping data from page - 64 : 0.3392446041107178 s\n",
      "Time used for scraping data from page - 65 : 0.34998226165771484 s\n",
      "Time used for scraping data from page - 66 : 0.3544032573699951 s\n",
      "Time used for scraping data from page - 67 : 0.34738779067993164 s\n",
      "Time used for scraping data from page - 68 : 0.3594057559967041 s\n",
      "Time used for scraping data from page - 69 : 0.4218897819519043 s\n",
      "Time used for scraping data from page - 70 : 0.39252543449401855 s\n",
      "Time used for scraping data from page - 71 : 0.35909390449523926 s\n",
      "Time used for scraping data from page - 72 : 0.3550574779510498 s\n",
      "Time used for scraping data from page - 73 : 0.375046968460083 s\n",
      "Time used for scraping data from page - 74 : 0.334043025970459 s\n",
      "Time used for scraping data from page - 75 : 0.33147716522216797 s\n",
      "Time used for scraping data from page - 76 : 0.44731903076171875 s\n",
      "Time used for scraping data from page - 77 : 0.328094482421875 s\n",
      "Time used for scraping data from page - 78 : 0.3441460132598877 s\n",
      "Time used for scraping data from page - 79 : 0.3852105140686035 s\n",
      "Time used for scraping data from page - 80 : 0.34262824058532715 s\n",
      "Time used for scraping data from page - 81 : 0.32947325706481934 s\n",
      "Time used for scraping data from page - 82 : 0.2908463478088379 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [02:15<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview data\n",
      "\n",
      "                                               comment  score  \\\n",
      "0    คุณหมอที่แผนกอายุรกรรมเป็นกันเอง วินิจฉัยถูกโร...      4   \n",
      "1    เคยไปรักษาตัวอยู่ที่แผนกจิตรักษ์ แผนกดูแลเรื่อ...      5   \n",
      "2    บริการดีมาก รวดเร็ว พาแขกคนจีนไปก็มีล่ามจีนแปล...      3   \n",
      "3    มีการบริการดี คุณหมอมีความรู้ความสามารถมาก และ...      4   \n",
      "4    บริการดีมากชัดเจนดีพยาบาลก็พูดดีบุคลากรพูดดีหม...      5   \n",
      "..                                                 ...    ...   \n",
      "236  โรงพยาบาลสะอาด /การดูแลของแพทย์และเอาใจใส่เป็น...      5   \n",
      "237  เกิดที่รพ..นี้ จนตอนนี้ 30 กว่าปีคุณหมอหรือพยา...      5   \n",
      "238              สะดวกใส่ใจทุกรายบะเอียดบริการเป็นเลิศ      5   \n",
      "239  วันนี้ไปหาหมอที่รพ.นี้ เป็นรพ.ที่ดีมาก เพราะที...      5   \n",
      "240  เคยเข้าไปใช้บริการอยู่ครั้งสองครั้งค่ะ ดิฉันจำ...      3   \n",
      "\n",
      "                                                    en  \n",
      "0    The doctor at the Internal Medicine Department...  \n",
      "1    Used to heal himself at the Conservation Depar...  \n",
      "2    Service is very good, fast, take Chinese guest...  \n",
      "3    With good service The doctor is very knowledge...  \n",
      "4    The service is very good, clear, good, the nur...  \n",
      "..                                                 ...  \n",
      "236  Clean hospital / Medical care and attentivenes...  \n",
      "237  Born in this hospital until now, over 30 years...  \n",
      "238  Convenient, attentive to every detail, excelle...  \n",
      "239  Today, go to the doctor at this hospital. Is a...  \n",
      "240  Used to use the service twice. I remember that...  \n",
      "\n",
      "[241 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hosp_name_list)):\n",
    "    #\n",
    "    file_name = scraping_path + \"comment_\" + hosp_name_list[i] + \".csv\"\n",
    "    file_name_en = scraping_path + \"comment_\" + hosp_name_list[i] + \"_en\" + \".csv\"\n",
    "    #\n",
    "    print(\"\\n =================\")\n",
    "    print(\"\\n hospital name = \" + hosp_name_list[i])\n",
    "    print(\"\\n =================\")\n",
    "    #\n",
    "    comments, scores = honestdoc_comment(hosp_name_list[i])\n",
    "    #\n",
    "    com_df = pd.read_csv(file_name)\n",
    "    #    \n",
    "    com_df[\"en\"] = com_df.progress_apply( lambda x: translate_text(x[\"comment\"]), axis=1  )\n",
    "    #\n",
    "    print(\"\\nPreview data\\n\")\n",
    "    print(com_df)\n",
    "    #\n",
    "    com_df.to_csv(file_name_en, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
